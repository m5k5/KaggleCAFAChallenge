{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c1d77e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 08:37:07.865734: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-08 08:37:08.293871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "/mnt/e/ML/cafa-5-protein-function-prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 08:37:08.834055: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-08 08:37:08.850406: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-08 08:37:08.850726: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "DATA_PATH = os.getenv('DATA_PATH')\n",
    "print(DATA_PATH)\n",
    "\n",
    "# Choose subontology (CCO, MFO or BPO)\n",
    "SO = 'BPO'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3544f8a",
   "metadata": {},
   "source": [
    "## Reading fasta, obo and tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b515f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "sequences = [rec.seq for rec in SeqIO.parse(os.path.join(DATA_PATH, \"Train/train_sequences.fasta\"),\"fasta\")]\n",
    "ids = [rec.id for rec in SeqIO.parse(os.path.join(DATA_PATH, \"Train/train_sequences.fasta\"),\"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2898414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "import obonet\n",
    "\n",
    "# Read the taxrank ontology\n",
    "url = os.path.join(DATA_PATH, \"Train/go-basic.obo\")\n",
    "graph = obonet.read_obo(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f4bf949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3497732, 3)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, \"Train/train_terms.tsv\"), sep='\\t')\n",
    "\n",
    "dfSO = df.loc[df[\"aspect\"]==SO]\n",
    "uniqueTerms = dfSO[\"term\"].unique()\n",
    "termsArr = list(dfSO[\"term\"].to_numpy())\n",
    "\n",
    "uniqueTermsDict={}\n",
    "for i,el in enumerate(uniqueTerms):\n",
    "    uniqueTermsDict[el] = i\n",
    "    \n",
    "print(dfSO.shape)\n",
    "df=dfSO\n",
    "\n",
    "df.set_index(\"EntryID\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4dec705",
   "metadata": {},
   "outputs": [],
   "source": [
    "testID = df.index.to_list()[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5338b7f8",
   "metadata": {},
   "source": [
    "## GO analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1058ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_counts = df[\"term\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb35584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_name = {id_: data.get('name') for id_, data in graph.nodes(data=True)}\n",
    "name_to_id = {data['name']: id_ for id_, data in graph.nodes(data=True) if 'name' in data}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c099fc2",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cae9a3b0",
   "metadata": {},
   "source": [
    "The task is a multilabel classification: The output has several possible targets (Gene Ontologies) but each can only be 1 (existing) or 0 (non existing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8e63ed9",
   "metadata": {},
   "source": [
    "Extract label weights from IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7e3c316",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfIa = pd.read_csv(os.path.join(DATA_PATH, \"IA.txt\"), sep='\\t', header=None)\n",
    "\n",
    "dfIa.set_index(0, inplace=True)\n",
    "\n",
    "labelWeights=[]\n",
    "allIndices = dfIa.index.tolist()\n",
    "\n",
    "\n",
    "for go in item_counts.index.to_list():\n",
    "    if go in allIndices:\n",
    "        labelWeights.append(dfIa.loc[go].to_numpy()[0])\n",
    "    else:\n",
    "        labelWeights.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99f6a6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GO:0008152' 'GO:0034655' 'GO:0072523' 'GO:0044270' 'GO:0006753'\n",
      " 'GO:1901292' 'GO:0044237' 'GO:1901360' 'GO:0008150' 'GO:1901564'\n",
      " 'GO:1901565' 'GO:0009117' 'GO:0006139' 'GO:0044281' 'GO:0046496'\n",
      " 'GO:0019362' 'GO:0046483' 'GO:0055086' 'GO:0044248' 'GO:0019439'\n",
      " 'GO:0019637' 'GO:0006807' 'GO:0019677' 'GO:1901361' 'GO:0006163'\n",
      " 'GO:0046700' 'GO:0009987' 'GO:0006725' 'GO:0006796' 'GO:0034641'\n",
      " 'GO:0072521' 'GO:0071704' 'GO:0019364' 'GO:1901575' 'GO:0072526'\n",
      " 'GO:0046434' 'GO:0009166' 'GO:0072524' 'GO:0006195' 'GO:0009056'\n",
      " 'GO:0044238' 'GO:0006793' 'GO:0019674']\n",
      "[[0 0 0 ... 0 0 0]]\n",
      "21285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pickle\n",
    "\n",
    "topGOs= item_counts\n",
    "topGOs=topGOs.index.to_list()\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([topGOs])\n",
    "\n",
    "dftest=df.loc[testID]\n",
    "indices = dftest[\"term\"].to_numpy()\n",
    "print(indices)\n",
    "print(mlb.transform([indices]))\n",
    "print(len(mlb.classes_))\n",
    "\n",
    "with open(os.path.join(DATA_PATH,'MLB_'+SO+'.pkl'), 'wb') as f:\n",
    "    pickle.dump(mlb, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92019f8c",
   "metadata": {},
   "source": [
    "## Amino acids encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b747477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aminos_list = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e42462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_dict = {'A': 1, 'B':24, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'O': 21, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'U': 22, 'V': 18, 'W': 19, 'Y': 20, 'X':30, 'Z':23}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfd823ba",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "431f9df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max. length of the sequences is 35375\n"
     ]
    }
   ],
   "source": [
    "seqLengths = [len(seq) for seq in sequences]\n",
    "maxLen = max(seqLengths)\n",
    "print(\"The max. length of the sequences is {}\".format(maxLen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e581e06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A0A009IHW8' 'A0A021WW32' 'A0A023FFD0' ... 'X5L1L5' 'X5L565' 'X5M5N0']\n",
      "92210\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dfAll=pd.read_csv(os.path.join(DATA_PATH, \"Train/train_terms.tsv\"), sep='\\t')\n",
    "\n",
    "soEntries = dfAll.loc[dfAll[\"aspect\"]==SO]\n",
    "soEntryIds = soEntries[\"EntryID\"].unique()\n",
    "\n",
    "# print(len(seqEntries))\n",
    "print(soEntryIds)\n",
    "\n",
    "SoSequences = []\n",
    "for entry in soEntryIds:\n",
    "    SoSequences.append(sequences[ids.index(entry)])\n",
    "\n",
    "print(len(SoSequences))\n",
    "dfAll.set_index(\"EntryID\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44f722e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99572\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "TRAIN_VAL_SPLIT = 0.7\n",
    "k = 3\n",
    "\n",
    "allAA = list(aa_dict.keys())\n",
    "allAA.sort()\n",
    "allCombinations= list(product(*(allAA for i in range(k))))\n",
    "allCombinations=np.array([''.join(el) for el in allCombinations])\n",
    "\n",
    "positionDict = dict(zip(allCombinations, np.arange(0,allCombinations.size).T))\n",
    "\n",
    "#Use numpy vectorize to speed up the mapping (hopefully)\n",
    "mapping = lambda x: aa_dict[x]\n",
    "vectMapping = np.vectorize(mapping)\n",
    "\n",
    "# Shuffle the data\n",
    "import random\n",
    "random.seed(516213)\n",
    "c = list(zip(sequences, ids))\n",
    "random.shuffle(c)\n",
    "sequencesShuffle, idsShuffle = zip(*c)\n",
    "\n",
    "\n",
    "#Train Validation Split\n",
    "split = int(np.floor(len(sequencesShuffle)*TRAIN_VAL_SPLIT))\n",
    "print(split)\n",
    "trainSeq = sequencesShuffle[0:split]\n",
    "valSeq = sequencesShuffle[split+1:]\n",
    "trainIds = idsShuffle[0:split]\n",
    "valIds = idsShuffle[split+1:]\n",
    "\n",
    "\n",
    "def generator():\n",
    "  for i,seq in enumerate(trainSeq):\n",
    "      entryId = trainIds[i]\n",
    "      \n",
    "      if entryId in soEntryIds:\n",
    "        labelData = df.loc[entryId]\n",
    "        # indices = labelData[\"termToken\"].to_numpy()\n",
    "        indices = labelData[\"term\"].to_numpy()\n",
    "      else:\n",
    "        indices=[]\n",
    "\n",
    "      with warnings.catch_warnings():\n",
    "          #supress the warnings for unknown classes\n",
    "          warnings.simplefilter(\"ignore\")\n",
    "          y = mlb.transform([indices])\n",
    "      \n",
    "      \n",
    "      kmers = [seq[i:i+k] if i < len(seq)-(k-1) else 0 for i,el in enumerate(seq)]\n",
    "      kmers = kmers[0:-(k-1)]\n",
    "      kmers = [str(el) for el in kmers]\n",
    "      values, counts = np.unique(kmers, return_counts=True)\n",
    "      freqVector=np.zeros(allCombinations.shape)\n",
    "      for j,v in enumerate(values):\n",
    "          freqVector[positionDict[v]] = counts[j]\n",
    "      yield (freqVector,y[0])\n",
    "\n",
    "\n",
    "def generatorVal():\n",
    "  for i,seq in enumerate(valSeq):\n",
    "      entryId = valIds[i]\n",
    "      if entryId in soEntryIds:\n",
    "        labelData = df.loc[entryId]\n",
    "        # indices = labelData[\"termToken\"].to_numpy()\n",
    "        indices = labelData[\"term\"].to_numpy()\n",
    "      else:\n",
    "        indices=[]\n",
    "\n",
    "      with warnings.catch_warnings():\n",
    "          #supress the warnings for unknown classes\n",
    "          warnings.simplefilter(\"ignore\")\n",
    "          y = mlb.transform([indices])\n",
    "      \n",
    "      kmers = [seq[i:i+k] if i < len(seq)-(k-1) else 0 for i,el in enumerate(seq)]\n",
    "      kmers = kmers[0:-(k-1)]\n",
    "      kmers = [str(el) for el in kmers]\n",
    "      values, counts = np.unique(kmers, return_counts=True)\n",
    "      freqVector=np.zeros(allCombinations.shape)\n",
    "      for j,v in enumerate(values):\n",
    "          freqVector[positionDict[v]] = counts[j]\n",
    "      yield (freqVector,y[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2727338a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first sample: (15625,)\n",
      "The first sample has 0 classes\n"
     ]
    }
   ],
   "source": [
    "g = generator()\n",
    "test = next(g)\n",
    "print(\"The first sample: {}\".format(test[0].shape))\n",
    "print(\"The first sample has {} classes\".format(np.count_nonzero(test[1])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10c4a51a",
   "metadata": {},
   "source": [
    "## Tensorflow Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63f0d2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(<tf.Tensor: shape=(15625,), dtype=int32, numpy=array([0, 0, 0, ..., 0, 0, 0], dtype=int32)>, <tf.Tensor: shape=(21285,), dtype=int32, numpy=array([0, 0, 0, ..., 0, 0, 0], dtype=int32)>)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 08:38:12.962279: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-08 08:38:12.962663: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-08 08:38:12.963006: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-08 08:38:13.390287: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-08 08:38:13.390623: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-08 08:38:13.390635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-06-08 08:38:13.390929: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-08 08:38:13.390961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6569 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:2b:00.0, compute capability: 6.1\n",
      "2023-06-08 08:38:13.423858: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "xSize = allCombinations.shape[0]\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(generator, output_signature=(\n",
    "         tf.TensorSpec(shape=(xSize,), dtype=tf.int32),\n",
    "         tf.TensorSpec(shape=(len(mlb.classes_),), dtype=tf.int32)))\n",
    "print(list(dataset.take(1)))\n",
    "\n",
    "datasetVal = tf.data.Dataset.from_generator(generatorVal, output_signature=(\n",
    "         tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "         tf.TensorSpec(shape=(len(mlb.classes_),), dtype=tf.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0a554f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98752d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embedConvModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 15625)]           0         \n",
      "                                                                 \n",
      " tf.expand_dims (TFOpLambda)  (None, 15625, 1)         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 15619, 8)          64        \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 15613, 8)          456       \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 15607, 8)          456       \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 15601, 16)         912       \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 15595, 16)         1808      \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 7795, 16)          1808      \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 3895, 16)          1808      \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 1945, 16)          1808      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 31120)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1991744   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 21285)             1383525   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,388,549\n",
      "Trainable params: 3,388,549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "VOCAB_SIZE=len(aa_dict)\n",
    "EMBED_DIM=100\n",
    "\n",
    "def createModel():\n",
    "    inputs = tf.keras.Input(shape=(xSize,))\n",
    "    # x=layers.Embedding(VOCAB_SIZE, EMBED_DIM, name=\"embedding\")(inputs)\n",
    "\n",
    "    x=layers.Conv1D(8, 7, activation=tf.keras.activations.relu)(tf.expand_dims(inputs,2))\n",
    "    x=layers.Conv1D(8, 7, activation=tf.keras.activations.relu)(x)\n",
    "    x=layers.Conv1D(8, 7, activation=tf.keras.activations.relu)(x)\n",
    "    x=layers.Conv1D(16, 7, activation=tf.keras.activations.relu)(x)\n",
    "    x=layers.Conv1D(16, 7, activation=tf.keras.activations.relu)(x)\n",
    "    x=layers.Conv1D(16, 7,strides=2, activation=tf.keras.activations.relu)(x)\n",
    "    x=layers.Conv1D(16, 7,strides=2, activation=tf.keras.activations.relu)(x)\n",
    "    x=layers.Conv1D(16, 7,strides=2, activation=tf.keras.activations.relu)(x)\n",
    "\n",
    "    # x=layers.Conv1D(32, 5, activation=tf.keras.activations.relu)(x)\n",
    "    # x=layers.Conv1D(32, 5, activation=tf.keras.activations.relu)(x)\n",
    "    # x=layers.Conv1D(32, 5, activation=tf.keras.activations.relu)(x)\n",
    "    x=layers.Flatten()(x)\n",
    "    x=layers.Dense(64)(x)\n",
    "    x=layers.LeakyReLU()(x)\n",
    "    x=layers.Dense(64)(x)\n",
    "    x=layers.LeakyReLU()(x)\n",
    "    outputs=layers.Dense(len(mlb.classes_), activation=tf.keras.activations.sigmoid)(x)\n",
    "    # outputs=layers.Softmax()(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name=\"embedConvModel\")\n",
    "\n",
    "model = createModel()\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73140569",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "VOCAB_SIZE=len(aa_dict)\n",
    "EMBED_DIM=500\n",
    "OUT_SEQ_LENGTH=10\n",
    "\n",
    "def createRnnModel():\n",
    "    inputs = tf.keras.Input(shape=(TRUNCATE,))\n",
    "    # x = tf.keras.layers.Masking(0)(inputs)\n",
    "    x=layers.Embedding(VOCAB_SIZE, EMBED_DIM, mask_zero=True, name=\"embedding\")(inputs)\n",
    "\n",
    "    # x = layers.RepeatVector(OUT_SEQ_LENGTH)(x)\n",
    "\n",
    "    x = layers.Bidirectional(layers.LSTM(200, return_sequences=True))(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(200))(x)\n",
    "    # x = layers.LSTM(64)(x)\n",
    "    x = layers.Dense(500)(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Dense(500)(x)\n",
    "    outputs=layers.Dense(len(mlb.classes_), activation=tf.keras.activations.sigmoid)(x)\n",
    "    # outputs=layers.Softmax()(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name=\"embedRnnModel\")\n",
    "\n",
    "# model = createRnnModel()\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a3ddc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Learning rate schedule\n",
    "initial_learning_rate = 0.01\n",
    "decaySteps=5000\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(initial_learning_rate, first_decay_steps=decaySteps/4,\n",
    "                                                                t_mul=2.0, m_mul=0.7, alpha=0.001)\n",
    "# lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "#     initial_learning_rate, decay_steps=decaySteps, alpha=0.01)\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate,decay_steps=decaySteps,decay_rate=0.9,staircase=False)\n",
    "step = np.linspace(0,decaySteps)\n",
    "lr = lr_schedule(step)\n",
    "plt.figure(figsize = (8,6))\n",
    "# plt.yscale(\"log\")\n",
    "plt.plot(step, lr)\n",
    "plt.ylim([0,max(plt.ylim())])\n",
    "plt.xlabel('step')\n",
    "_ = plt.ylabel('Learning Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4760b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.6762641, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6762641, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.losses import Loss\n",
    "\n",
    "class WeightedBinaryCE(Loss):\n",
    "    # initialize instance attributes\n",
    "    def __init__(self, classWeights, labelSmoothing=0.0):\n",
    "        super(WeightedBinaryCE, self).__init__()\n",
    "        self.labelSmoothing = tf.constant(labelSmoothing, dtype=tf.dtypes.float32)\n",
    "        self.classWeights= tf.constant(classWeights, dtype=tf.dtypes.float32)\n",
    "        \n",
    "    # Compute loss\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        if(self.labelSmoothing>0):\n",
    "            y_true = y_true*(1-self.labelSmoothing)+self.labelSmoothing/2\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        y_pred = tf.clip_by_value(y_pred,tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
    "        term_0 = tf.math.multiply(self.classWeights * tf.math.subtract(1.0 , y_true), tf.math.log(tf.math.subtract(1.0, y_pred) + tf.keras.backend.epsilon()))\n",
    "        term_1 = tf.math.multiply(self.classWeights * y_true, tf.math.log(y_pred + tf.keras.backend.epsilon()))\n",
    "        losses = term_0 + term_1\n",
    "        return -tf.reduce_mean(losses, axis=0)\n",
    "    \n",
    "\n",
    "testLoss = WeightedBinaryCE([1,1,1])\n",
    "labelsTrue = tf.constant([[1,0,1], [1,1,0]])\n",
    "labelsPred = tf.constant([[0.42,0.111,0.957], [0.877,0.121,0.544]])\n",
    "\n",
    "print(testLoss(labelsTrue, labelsPred))\n",
    "kerasCE = tf.keras.losses.BinaryCrossentropy()\n",
    "print(kerasCE(labelsTrue, labelsPred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b3c7a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.058596253, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class DiceLoss(Loss):\n",
    "    # initialize instance attributes\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        \n",
    "    # Compute loss\n",
    "    def call(self, y_true, y_pred, smooth=1e-6):\n",
    "      inputs = tf.squeeze(tf.cast(y_pred, tf.dtypes.float32))\n",
    "      targets = tf.squeeze(tf.cast(y_true, tf.dtypes.float32))\n",
    "    \n",
    "      intersection = tf.math.reduce_sum(tf.math.multiply(targets, inputs))\n",
    "      dice = (2*intersection + smooth) / (tf.math.reduce_sum(targets) + tf.math.reduce_sum(inputs) + smooth)\n",
    "      return 1 - dice\n",
    "    \n",
    "\n",
    "testLoss = DiceLoss()\n",
    "labelsTrue = tf.constant([[1,0,1], [1,1,0]])\n",
    "labelsPred = tf.constant([[0.9,0.01,0.957], [0.877,0.921,0.1]])\n",
    "\n",
    "print(testLoss(labelsTrue, labelsPred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c21d9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-0.4285214, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# α controls the amount of Dice term contribution in the loss f\n",
    "# β ∈ [0, 1] controls the level of model penalization for false positives/negatives: when β is set to\n",
    "# a value smaller than 0.5, FP are penalized more than FN\n",
    "\n",
    "\n",
    "class WeightedComboLoss(Loss):\n",
    "    # initialize instance attributes\n",
    "    def __init__(self, labelWeights, alpha=0.5, beta=0.5):\n",
    "        super(WeightedComboLoss, self).__init__()\n",
    "        self.classWeights = tf.constant(labelWeights, dtype=tf.dtypes.float32)\n",
    "        self.alpha=tf.constant(alpha, dtype=tf.dtypes.float32)\n",
    "        self.beta=tf.constant(beta, dtype=tf.dtypes.float32)\n",
    "        \n",
    "    # Compute loss\n",
    "    def call(self, y_true, y_pred, smooth=1e-6):\n",
    "      inputs = tf.squeeze(tf.cast(y_pred, tf.dtypes.float32))\n",
    "      targets = tf.squeeze(tf.cast(y_true, tf.dtypes.float32))\n",
    "    \n",
    "      intersection = tf.math.reduce_sum(tf.math.multiply(targets, inputs))\n",
    "      dice = (2*intersection + smooth) / (tf.math.reduce_sum(targets) + tf.math.reduce_sum(inputs) + smooth)\n",
    "     \n",
    "      y_true = tf.cast(y_true, tf.float32)\n",
    "      y_pred = tf.cast(y_pred, tf.float32)\n",
    "      y_pred = tf.clip_by_value(y_pred,tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
    "      term_0 = tf.math.multiply((1-self.beta) * self.classWeights * tf.math.subtract(1.0 , y_true), tf.math.log(tf.math.subtract(1.0, y_pred) + tf.keras.backend.epsilon()))\n",
    "      term_1 = tf.math.multiply(self.beta * self.classWeights * y_true, tf.math.log(y_pred + tf.keras.backend.epsilon()))\n",
    "      losses = term_0 + term_1\n",
    "      weightedCE = -tf.reduce_mean(losses, axis=0)\n",
    "\n",
    "      combo = (self.alpha * weightedCE) - ((1 - self.alpha) * dice)\n",
    "\n",
    "      return combo\n",
    "    \n",
    "\n",
    "testLoss = WeightedComboLoss([1,1,1])\n",
    "labelsTrue = tf.constant([[1,0,1], [1,1,0]])\n",
    "labelsPred = tf.constant([[0.9,0.1,0.9], [0.8,0.9,0.05]])\n",
    "\n",
    "print(testLoss(labelsTrue, labelsPred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7880ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.85714275>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class WeightedF1(tf.keras.metrics.Metric):\n",
    "    def __init__(self, classWeights, threshold=0.5):\n",
    "        super(WeightedF1, self).__init__()\n",
    "        self.classWeights= tf.constant(classWeights, dtype=tf.dtypes.float32)\n",
    "        self.threshold= tf.constant(threshold, dtype=tf.dtypes.float32)\n",
    "        self.f1 = self.add_weight(name='f1', initializer='zeros')\n",
    "        self.total = self.add_weight('total', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        m = tf.math.count_nonzero(tf.reduce_min(y_pred, axis=1))\n",
    "        n = tf.shape(y_pred)[0]\n",
    "        y_true = tf.cast(y_true, tf.bool)\n",
    "        y_pred = tf.math.greater_equal(y_pred,self.threshold)\n",
    "   \n",
    "\n",
    "        tp = tf.math.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))\n",
    "        tp = tf.cast(tp, self.dtype)\n",
    "        tp = tf.math.multiply(tp, self.classWeights)\n",
    "        tp = tf.cast(tp, self.dtype)\n",
    "\n",
    "        tn = tf.math.logical_and(tf.equal(y_true, False), tf.equal(y_pred, False))\n",
    "        tn = tf.cast(tn, self.dtype)\n",
    "        tn = tf.math.multiply(tn, self.classWeights)\n",
    "        tn = tf.cast(tn, self.dtype)\n",
    "\n",
    "        fp = tf.math.logical_and(tf.equal(y_true, True), tf.equal(y_pred, False))\n",
    "        fp = tf.cast(fp, self.dtype)\n",
    "        fp = tf.math.multiply(fp, self.classWeights)\n",
    "        fp = tf.cast(fp, self.dtype)\n",
    "\n",
    "        fn = tf.math.logical_and(tf.equal(y_true, False), tf.equal(y_pred, True))\n",
    "        fn = tf.cast(fn, self.dtype)\n",
    "        fn = tf.math.multiply(fn, self.classWeights)\n",
    "        fn = tf.cast(fn, self.dtype)\n",
    "\n",
    "        pr = tf.math.divide(tf.math.reduce_sum(tp, axis=1),tf.math.reduce_sum(tp+fp+tf.keras.backend.epsilon(), axis=1))\n",
    "        m = tf.cast(m, pr.dtype)\n",
    "        if(m>0):\n",
    "            wPr = tf.math.reduce_sum(pr)/m\n",
    "        else:\n",
    "            wPr = tf.constant(0, tf.dtypes.float32)\n",
    "\n",
    "        re = tf.math.divide(tf.math.reduce_sum(tp, axis=1),tf.math.reduce_sum(tp+fn+tf.keras.backend.epsilon(), axis=1))\n",
    "        n = tf.cast(n, re.dtype)\n",
    "        wRe = tf.math.reduce_sum(re)/n\n",
    "\n",
    "        res = tf.math.divide(2*wPr*wRe, wPr + wRe + tf.keras.backend.epsilon())\n",
    "\n",
    "        self.f1.assign_add(res)\n",
    "        self.total.assign_add(1)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.math.divide(self.f1, self.total)\n",
    "\n",
    "testM = WeightedF1(classWeights=[1,1,2])\n",
    "labelsTrue = tf.constant([[1,0,1], [1,1,0]])\n",
    "labelsPred = tf.constant([[0.8,0.1,0.9], [0.9,0.9,0.6]])\n",
    "\n",
    "testM.update_state(labelsTrue, labelsPred)\n",
    "testM.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2f43e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE=32\n",
    "\n",
    "# batchedDataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "# batchedDatasetVal = datasetVal.batch(BATCH_SIZE, drop_remainder=False)\n",
    "\n",
    "# batchedDataset = batchedDataset.cache(os.path.join(DATA_PATH, \"datasetCache\"+SO))\n",
    "# batchedDatasetVal = batchedDatasetVal.cache(os.path.join(DATA_PATH, \"datasetCacheVal\"+SO))\n",
    "\n",
    "# optimizer = tf.keras.optimizers.AdamW(learning_rate=lr_schedule)\n",
    "\n",
    "# loss_fn = WeightedBinaryCE(labelWeights)\n",
    "\n",
    "# train_acc_metric = tf.keras.metrics.BinaryAccuracy()\n",
    "# train_f1_metric = WeightedF1(classWeights=labelWeights, threshold=0.5)\n",
    "# train_prec = tf.keras.metrics.Precision()\n",
    "# train_rec = tf.keras.metrics.Recall()\n",
    "\n",
    "# model.compile(optimizer, loss_fn, metrics=[train_acc_metric,train_prec,train_f1_metric,train_rec ])\n",
    "\n",
    "# model.fit(batchedDataset, epochs=1, validation_data=batchedDatasetVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9113c4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 08:38:14.374920: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-08 08:38:15.805589: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-06-08 08:38:16.557270: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fc20d063e70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-08 08:38:16.557314: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce GTX 1070, Compute Capability 6.1\n",
      "2023-06-08 08:38:16.560211: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-06-08 08:38:16.651298: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/Step 0, Loss: 0.29654, Accuracy: 0.49872, F1: 0.0023, Prec: 0.0011, Rec: 0.5145 lr: 0.00070\n",
      "Epoch 1/Step 10, Loss: 0.28491, Accuracy: 0.68435, F1: 0.0084, Prec: 0.0016, Rec: 0.4164 lr: 0.00070\n",
      "Epoch 1/Step 20, Loss: 0.00244, Accuracy: 0.72995, F1: 0.0133, Prec: 0.0018, Rec: 0.4032 lr: 0.00070\n",
      "Epoch 1/Step 30, Loss: -0.01654, Accuracy: 0.80076, F1: 0.0639, Prec: 0.0024, Rec: 0.4137 lr: 0.00070\n",
      "Epoch 1/Step 40, Loss: -0.02679, Accuracy: 0.84522, F1: 0.0624, Prec: 0.0032, Rec: 0.4245 lr: 0.00070\n",
      "Epoch 1/Step 50, Loss: -0.02546, Accuracy: 0.87257, F1: 0.0502, Prec: 0.0039, Rec: 0.4263 lr: 0.00070\n",
      "Epoch 1/Step 60, Loss: -0.02661, Accuracy: 0.89103, F1: 0.0419, Prec: 0.0045, Rec: 0.4258 lr: 0.00070\n",
      "Epoch 1/Step 70, Loss: -0.02470, Accuracy: 0.90430, F1: 0.0360, Prec: 0.0051, Rec: 0.4278 lr: 0.00070\n",
      "Epoch 1/Step 80, Loss: -0.02429, Accuracy: 0.91430, F1: 0.0316, Prec: 0.0056, Rec: 0.4283 lr: 0.00070\n",
      "Epoch 1/Step 90, Loss: -0.02824, Accuracy: 0.92211, F1: 0.0281, Prec: 0.0062, Rec: 0.4279 lr: 0.00070\n",
      "Epoch 1/Step 100, Loss: -0.02556, Accuracy: 0.92839, F1: 0.0253, Prec: 0.0067, Rec: 0.4289 lr: 0.00070\n",
      "Epoch 1/Step 110, Loss: -0.03120, Accuracy: 0.93356, F1: 0.0230, Prec: 0.0073, Rec: 0.4284 lr: 0.00070\n",
      "Epoch 1/Step 120, Loss: -0.02311, Accuracy: 0.93788, F1: 0.0336, Prec: 0.0079, Rec: 0.4282 lr: 0.00070\n",
      "Epoch 1/Step 130, Loss: -0.02491, Accuracy: 0.94156, F1: 0.0527, Prec: 0.0084, Rec: 0.4288 lr: 0.00070\n",
      "Epoch 1/Step 140, Loss: -0.03641, Accuracy: 0.94473, F1: 0.0663, Prec: 0.0089, Rec: 0.4279 lr: 0.00070\n",
      "Epoch 1/Step 150, Loss: -0.02574, Accuracy: 0.94749, F1: 0.0763, Prec: 0.0094, Rec: 0.4283 lr: 0.00070\n",
      "Epoch 1/Step 160, Loss: -0.02627, Accuracy: 0.94995, F1: 0.0836, Prec: 0.0099, Rec: 0.4291 lr: 0.00070\n",
      "Epoch 1/Step 170, Loss: -0.02237, Accuracy: 0.95214, F1: 0.0890, Prec: 0.0103, Rec: 0.4296 lr: 0.00070\n",
      "Epoch 1/Step 180, Loss: -0.03652, Accuracy: 0.95412, F1: 0.0948, Prec: 0.0108, Rec: 0.4298 lr: 0.00070\n",
      "Epoch 1/Step 190, Loss: -0.02622, Accuracy: 0.95590, F1: 0.0990, Prec: 0.0112, Rec: 0.4297 lr: 0.00070\n",
      "Epoch 1/Step 200, Loss: -0.02766, Accuracy: 0.95752, F1: 0.1038, Prec: 0.0118, Rec: 0.4291 lr: 0.00070\n",
      "Epoch 1/Step 210, Loss: -0.03426, Accuracy: 0.95903, F1: 0.1076, Prec: 0.0122, Rec: 0.4299 lr: 0.00070\n",
      "Epoch 1/Step 220, Loss: -0.04373, Accuracy: 0.96043, F1: 0.1109, Prec: 0.0127, Rec: 0.4301 lr: 0.00070\n",
      "Epoch 1/Step 230, Loss: -0.03571, Accuracy: 0.96174, F1: 0.1147, Prec: 0.0131, Rec: 0.4298 lr: 0.00070\n",
      "Epoch 1/Step 240, Loss: -0.05151, Accuracy: 0.96296, F1: 0.1180, Prec: 0.0136, Rec: 0.4293 lr: 0.00070\n",
      "Epoch 1/Step 250, Loss: -0.04567, Accuracy: 0.96411, F1: 0.1207, Prec: 0.0140, Rec: 0.4287 lr: 0.00070\n",
      "Epoch 1/Step 260, Loss: -0.05921, Accuracy: 0.96519, F1: 0.1238, Prec: 0.0144, Rec: 0.4285 lr: 0.00070\n",
      "Epoch 1/Step 270, Loss: -0.04917, Accuracy: 0.96622, F1: 0.1269, Prec: 0.0149, Rec: 0.4277 lr: 0.00070\n",
      "Epoch 1/Step 280, Loss: -0.05585, Accuracy: 0.96718, F1: 0.1290, Prec: 0.0153, Rec: 0.4261 lr: 0.00070\n",
      "Epoch 1/Step 290, Loss: -0.05959, Accuracy: 0.96810, F1: 0.1307, Prec: 0.0156, Rec: 0.4240 lr: 0.00070\n",
      "Epoch 1/Step 300, Loss: -0.07421, Accuracy: 0.96898, F1: 0.1328, Prec: 0.0160, Rec: 0.4225 lr: 0.00070\n",
      "Epoch 1/Step 310, Loss: -0.06308, Accuracy: 0.96982, F1: 0.1345, Prec: 0.0164, Rec: 0.4206 lr: 0.00070\n",
      "Epoch 1/Step 320, Loss: -0.07336, Accuracy: 0.97062, F1: 0.1362, Prec: 0.0167, Rec: 0.4185 lr: 0.00070\n",
      "Epoch 1/Step 330, Loss: -0.08835, Accuracy: 0.97139, F1: 0.1381, Prec: 0.0171, Rec: 0.4155 lr: 0.00070\n",
      "Epoch 1/Step 340, Loss: -0.08241, Accuracy: 0.97212, F1: 0.1400, Prec: 0.0174, Rec: 0.4125 lr: 0.00070\n",
      "Epoch 1/Step 350, Loss: -0.10083, Accuracy: 0.97282, F1: 0.1416, Prec: 0.0177, Rec: 0.4092 lr: 0.00070\n",
      "Epoch 1/Step 360, Loss: -0.09610, Accuracy: 0.97348, F1: 0.1434, Prec: 0.0181, Rec: 0.4064 lr: 0.00070\n",
      "Epoch 1/Step 370, Loss: -0.08670, Accuracy: 0.97412, F1: 0.1446, Prec: 0.0183, Rec: 0.4031 lr: 0.00070\n",
      "Epoch 1/Step 380, Loss: -0.09967, Accuracy: 0.97473, F1: 0.1457, Prec: 0.0186, Rec: 0.4001 lr: 0.00070\n",
      "Epoch 1/Step 390, Loss: -0.08749, Accuracy: 0.97532, F1: 0.1468, Prec: 0.0189, Rec: 0.3964 lr: 0.00070\n",
      "Epoch 1/Step 400, Loss: -0.07964, Accuracy: 0.97587, F1: 0.1478, Prec: 0.0191, Rec: 0.3926 lr: 0.00070\n",
      "Epoch 1/Step 410, Loss: -0.11054, Accuracy: 0.97640, F1: 0.1488, Prec: 0.0194, Rec: 0.3893 lr: 0.00070\n",
      "Epoch 1/Step 420, Loss: -0.10555, Accuracy: 0.97691, F1: 0.1500, Prec: 0.0196, Rec: 0.3860 lr: 0.00070\n",
      "Epoch 1/Step 430, Loss: -0.08428, Accuracy: 0.97739, F1: 0.1509, Prec: 0.0199, Rec: 0.3828 lr: 0.00070\n",
      "Epoch 1/Step 440, Loss: -0.08382, Accuracy: 0.97785, F1: 0.1522, Prec: 0.0201, Rec: 0.3792 lr: 0.00070\n",
      "Epoch 1/Step 450, Loss: -0.09320, Accuracy: 0.97829, F1: 0.1536, Prec: 0.0204, Rec: 0.3761 lr: 0.00070\n",
      "Epoch 1/Step 460, Loss: -0.08472, Accuracy: 0.97871, F1: 0.1541, Prec: 0.0206, Rec: 0.3735 lr: 0.00070\n",
      "Epoch 1/Step 470, Loss: -0.09716, Accuracy: 0.97912, F1: 0.1552, Prec: 0.0209, Rec: 0.3709 lr: 0.00070\n",
      "Epoch 1/Step 480, Loss: -0.10001, Accuracy: 0.97951, F1: 0.1563, Prec: 0.0211, Rec: 0.3680 lr: 0.00070\n",
      "Epoch 1/Step 490, Loss: -0.08425, Accuracy: 0.97988, F1: 0.1570, Prec: 0.0214, Rec: 0.3648 lr: 0.00070\n",
      "Epoch 1/Step 500, Loss: -0.10121, Accuracy: 0.98024, F1: 0.1574, Prec: 0.0216, Rec: 0.3623 lr: 0.00070\n",
      "Epoch 1/Step 510, Loss: -0.09399, Accuracy: 0.98059, F1: 0.1582, Prec: 0.0218, Rec: 0.3597 lr: 0.00070\n",
      "Epoch 1/Step 520, Loss: -0.09098, Accuracy: 0.98092, F1: 0.1590, Prec: 0.0221, Rec: 0.3573 lr: 0.00070\n",
      "Epoch 1/Step 530, Loss: -0.09760, Accuracy: 0.98124, F1: 0.1596, Prec: 0.0223, Rec: 0.3549 lr: 0.00070\n",
      "Epoch 1/Step 540, Loss: -0.07928, Accuracy: 0.98154, F1: 0.1604, Prec: 0.0226, Rec: 0.3524 lr: 0.00070\n",
      "Epoch 1/Step 550, Loss: -0.10302, Accuracy: 0.98184, F1: 0.1614, Prec: 0.0228, Rec: 0.3499 lr: 0.00070\n",
      "Epoch 1/Step 560, Loss: -0.11100, Accuracy: 0.98213, F1: 0.1619, Prec: 0.0230, Rec: 0.3480 lr: 0.00070\n",
      "Epoch 1/Step 570, Loss: -0.08695, Accuracy: 0.98240, F1: 0.1625, Prec: 0.0233, Rec: 0.3460 lr: 0.00070\n",
      "Epoch 1/Step 580, Loss: -0.10439, Accuracy: 0.98267, F1: 0.1634, Prec: 0.0235, Rec: 0.3439 lr: 0.00070\n",
      "Epoch 1/Step 590, Loss: -0.07778, Accuracy: 0.98292, F1: 0.1638, Prec: 0.0238, Rec: 0.3420 lr: 0.00070\n",
      "Epoch 1/Step 600, Loss: -0.08265, Accuracy: 0.98317, F1: 0.1644, Prec: 0.0240, Rec: 0.3398 lr: 0.00070\n",
      "Epoch 1/Step 610, Loss: -0.09754, Accuracy: 0.98341, F1: 0.1649, Prec: 0.0242, Rec: 0.3379 lr: 0.00070\n",
      "Epoch 1/Step 620, Loss: -0.09728, Accuracy: 0.98364, F1: 0.1655, Prec: 0.0245, Rec: 0.3361 lr: 0.00070\n",
      "Epoch 1/Step 630, Loss: -0.09112, Accuracy: 0.98387, F1: 0.1661, Prec: 0.0247, Rec: 0.3346 lr: 0.00070\n",
      "Epoch 1/Step 640, Loss: -0.09510, Accuracy: 0.98409, F1: 0.1666, Prec: 0.0250, Rec: 0.3329 lr: 0.00070\n",
      "Epoch 1/Step 650, Loss: -0.08671, Accuracy: 0.98430, F1: 0.1671, Prec: 0.0252, Rec: 0.3313 lr: 0.00070\n",
      "Epoch 1/Step 660, Loss: -0.09431, Accuracy: 0.98451, F1: 0.1677, Prec: 0.0254, Rec: 0.3298 lr: 0.00070\n",
      "Epoch 1/Step 670, Loss: -0.07450, Accuracy: 0.98471, F1: 0.1683, Prec: 0.0256, Rec: 0.3282 lr: 0.00070\n",
      "Epoch 1/Step 680, Loss: -0.09272, Accuracy: 0.98490, F1: 0.1686, Prec: 0.0258, Rec: 0.3266 lr: 0.00070\n",
      "Epoch 1/Step 690, Loss: -0.10488, Accuracy: 0.98509, F1: 0.1691, Prec: 0.0260, Rec: 0.3251 lr: 0.00070\n",
      "Epoch 1/Step 700, Loss: -0.09650, Accuracy: 0.98528, F1: 0.1694, Prec: 0.0263, Rec: 0.3240 lr: 0.00070\n",
      "Epoch 1/Step 710, Loss: -0.10037, Accuracy: 0.98545, F1: 0.1696, Prec: 0.0265, Rec: 0.3226 lr: 0.00070\n",
      "Epoch 1/Step 720, Loss: -0.09100, Accuracy: 0.98563, F1: 0.1702, Prec: 0.0267, Rec: 0.3213 lr: 0.00070\n",
      "Epoch 1/Step 730, Loss: -0.10709, Accuracy: 0.98580, F1: 0.1706, Prec: 0.0269, Rec: 0.3201 lr: 0.00070\n",
      "Epoch 1/Step 740, Loss: -0.09675, Accuracy: 0.98596, F1: 0.1710, Prec: 0.0271, Rec: 0.3189 lr: 0.00070\n",
      "Epoch 1/Step 750, Loss: -0.09601, Accuracy: 0.98612, F1: 0.1715, Prec: 0.0273, Rec: 0.3176 lr: 0.00070\n",
      "Epoch 1/Step 760, Loss: -0.09753, Accuracy: 0.98628, F1: 0.1719, Prec: 0.0276, Rec: 0.3165 lr: 0.00070\n",
      "Epoch 1/Step 770, Loss: -0.08678, Accuracy: 0.98643, F1: 0.1723, Prec: 0.0278, Rec: 0.3154 lr: 0.00070\n",
      "Epoch 1/Step 780, Loss: -0.09783, Accuracy: 0.98658, F1: 0.1727, Prec: 0.0280, Rec: 0.3141 lr: 0.00070\n",
      "Epoch 1/Step 790, Loss: -0.10777, Accuracy: 0.98672, F1: 0.1732, Prec: 0.0282, Rec: 0.3128 lr: 0.00070\n",
      "Epoch 1/Step 800, Loss: -0.09164, Accuracy: 0.98686, F1: 0.1736, Prec: 0.0284, Rec: 0.3114 lr: 0.00070\n",
      "Epoch 1/Step 810, Loss: -0.09453, Accuracy: 0.98700, F1: 0.1739, Prec: 0.0286, Rec: 0.3104 lr: 0.00070\n",
      "Epoch 1/Step 820, Loss: -0.10490, Accuracy: 0.98713, F1: 0.1742, Prec: 0.0288, Rec: 0.3095 lr: 0.00070\n",
      "Epoch 1/Step 830, Loss: -0.09005, Accuracy: 0.98727, F1: 0.1744, Prec: 0.0290, Rec: 0.3084 lr: 0.00070\n",
      "Epoch 1/Step 840, Loss: -0.10082, Accuracy: 0.98739, F1: 0.1747, Prec: 0.0293, Rec: 0.3071 lr: 0.00070\n",
      "Epoch 1/Step 850, Loss: -0.09658, Accuracy: 0.98752, F1: 0.1751, Prec: 0.0295, Rec: 0.3061 lr: 0.00070\n",
      "Epoch 1/Step 860, Loss: -0.09773, Accuracy: 0.98764, F1: 0.1754, Prec: 0.0297, Rec: 0.3050 lr: 0.00070\n",
      "Epoch 1/Step 870, Loss: -0.09556, Accuracy: 0.98776, F1: 0.1756, Prec: 0.0299, Rec: 0.3037 lr: 0.00070\n",
      "Epoch 1/Step 880, Loss: -0.08852, Accuracy: 0.98787, F1: 0.1761, Prec: 0.0301, Rec: 0.3027 lr: 0.00070\n",
      "Epoch 1/Step 890, Loss: -0.10106, Accuracy: 0.98799, F1: 0.1764, Prec: 0.0303, Rec: 0.3019 lr: 0.00070\n",
      "Epoch 1/Step 900, Loss: -0.10234, Accuracy: 0.98810, F1: 0.1766, Prec: 0.0305, Rec: 0.3007 lr: 0.00070\n",
      "Epoch 1/Step 910, Loss: -0.08299, Accuracy: 0.98821, F1: 0.1768, Prec: 0.0307, Rec: 0.2998 lr: 0.00070\n",
      "Epoch 1/Step 920, Loss: -0.09259, Accuracy: 0.98831, F1: 0.1773, Prec: 0.0309, Rec: 0.2989 lr: 0.00070\n",
      "Epoch 1/Step 930, Loss: -0.08358, Accuracy: 0.98842, F1: 0.1775, Prec: 0.0311, Rec: 0.2982 lr: 0.00070\n",
      "Epoch 1/Step 940, Loss: -0.07735, Accuracy: 0.98852, F1: 0.1776, Prec: 0.0313, Rec: 0.2976 lr: 0.00070\n",
      "Epoch 1/Step 950, Loss: -0.09407, Accuracy: 0.98862, F1: 0.1779, Prec: 0.0315, Rec: 0.2968 lr: 0.00070\n",
      "Epoch 1/Step 960, Loss: -0.10070, Accuracy: 0.98872, F1: 0.1782, Prec: 0.0317, Rec: 0.2961 lr: 0.00070\n",
      "Epoch 1/Step 970, Loss: -0.10172, Accuracy: 0.98882, F1: 0.1785, Prec: 0.0319, Rec: 0.2952 lr: 0.00070\n",
      "Epoch 1/Step 980, Loss: -0.10122, Accuracy: 0.98891, F1: 0.1787, Prec: 0.0322, Rec: 0.2943 lr: 0.00070\n",
      "Epoch 1/Step 990, Loss: -0.09733, Accuracy: 0.98900, F1: 0.1789, Prec: 0.0324, Rec: 0.2935 lr: 0.00070\n",
      "Epoch 1/Step 1000, Loss: -0.10178, Accuracy: 0.98909, F1: 0.1791, Prec: 0.0325, Rec: 0.2929 lr: 0.00070\n",
      "Epoch 1/Step 1010, Loss: -0.10156, Accuracy: 0.98918, F1: 0.1795, Prec: 0.0328, Rec: 0.2920 lr: 0.00070\n",
      "Epoch 1/Step 1020, Loss: -0.08823, Accuracy: 0.98927, F1: 0.1797, Prec: 0.0330, Rec: 0.2915 lr: 0.00070\n",
      "Epoch 1/Step 1030, Loss: -0.08475, Accuracy: 0.98935, F1: 0.1798, Prec: 0.0331, Rec: 0.2909 lr: 0.00070\n",
      "Epoch 1/Step 1040, Loss: -0.09739, Accuracy: 0.98943, F1: 0.1799, Prec: 0.0334, Rec: 0.2902 lr: 0.00070\n",
      "Epoch 1/Step 1050, Loss: -0.09653, Accuracy: 0.98952, F1: 0.1801, Prec: 0.0336, Rec: 0.2896 lr: 0.00070\n",
      "Epoch 1/Step 1060, Loss: -0.09387, Accuracy: 0.98960, F1: 0.1801, Prec: 0.0337, Rec: 0.2891 lr: 0.00070\n",
      "Epoch 1/Step 1070, Loss: -0.10721, Accuracy: 0.98967, F1: 0.1805, Prec: 0.0340, Rec: 0.2885 lr: 0.00070\n",
      "Epoch 1/Step 1080, Loss: -0.10568, Accuracy: 0.98975, F1: 0.1808, Prec: 0.0342, Rec: 0.2879 lr: 0.00070\n",
      "Epoch 1/Step 1090, Loss: -0.09837, Accuracy: 0.98983, F1: 0.1809, Prec: 0.0344, Rec: 0.2872 lr: 0.00070\n",
      "Epoch 1/Step 1100, Loss: -0.09169, Accuracy: 0.98990, F1: 0.1810, Prec: 0.0346, Rec: 0.2866 lr: 0.00070\n",
      "Epoch 1/Step 1110, Loss: -0.09956, Accuracy: 0.98997, F1: 0.1813, Prec: 0.0348, Rec: 0.2859 lr: 0.00070\n",
      "Epoch 1/Step 1120, Loss: -0.09298, Accuracy: 0.99004, F1: 0.1814, Prec: 0.0350, Rec: 0.2853 lr: 0.00070\n",
      "Epoch 1/Step 1130, Loss: -0.09899, Accuracy: 0.99012, F1: 0.1815, Prec: 0.0351, Rec: 0.2849 lr: 0.00070\n",
      "Epoch 1/Step 1140, Loss: -0.09288, Accuracy: 0.99018, F1: 0.1816, Prec: 0.0353, Rec: 0.2844 lr: 0.00070\n",
      "Epoch 1/Step 1150, Loss: -0.09381, Accuracy: 0.99025, F1: 0.1819, Prec: 0.0355, Rec: 0.2840 lr: 0.00070\n",
      "Epoch 1/Step 1160, Loss: -0.11299, Accuracy: 0.99032, F1: 0.1821, Prec: 0.0357, Rec: 0.2836 lr: 0.00070\n",
      "Epoch 1/Step 1170, Loss: -0.08875, Accuracy: 0.99039, F1: 0.1823, Prec: 0.0359, Rec: 0.2831 lr: 0.00070\n",
      "Epoch 1/Step 1180, Loss: -0.09610, Accuracy: 0.99045, F1: 0.1825, Prec: 0.0362, Rec: 0.2825 lr: 0.00070\n",
      "Epoch 1/Step 1190, Loss: -0.10088, Accuracy: 0.99051, F1: 0.1826, Prec: 0.0363, Rec: 0.2818 lr: 0.00070\n",
      "Epoch 1/Step 1200, Loss: -0.09382, Accuracy: 0.99057, F1: 0.1827, Prec: 0.0365, Rec: 0.2814 lr: 0.00070\n",
      "Epoch 1/Step 1210, Loss: -0.09503, Accuracy: 0.99064, F1: 0.1828, Prec: 0.0367, Rec: 0.2810 lr: 0.00070\n",
      "Epoch 1/Step 1220, Loss: -0.08676, Accuracy: 0.99070, F1: 0.1828, Prec: 0.0369, Rec: 0.2807 lr: 0.00070\n",
      "Epoch 1/Step 1230, Loss: -0.10121, Accuracy: 0.99076, F1: 0.1829, Prec: 0.0371, Rec: 0.2803 lr: 0.00070\n",
      "Epoch 1/Step 1240, Loss: -0.11594, Accuracy: 0.99081, F1: 0.1832, Prec: 0.0373, Rec: 0.2797 lr: 0.00070\n",
      "Epoch 1/Step 1250, Loss: -0.09588, Accuracy: 0.99087, F1: 0.1834, Prec: 0.0375, Rec: 0.2793 lr: 0.00070\n",
      "Epoch 1/Step 1260, Loss: -0.08312, Accuracy: 0.99093, F1: 0.1835, Prec: 0.0377, Rec: 0.2789 lr: 0.00070\n",
      "Epoch 1/Step 1270, Loss: -0.08491, Accuracy: 0.99098, F1: 0.1836, Prec: 0.0379, Rec: 0.2786 lr: 0.00070\n",
      "Epoch 1/Step 1280, Loss: -0.10443, Accuracy: 0.99104, F1: 0.1839, Prec: 0.0381, Rec: 0.2782 lr: 0.00070\n",
      "Epoch 1/Step 1290, Loss: -0.11089, Accuracy: 0.99109, F1: 0.1841, Prec: 0.0383, Rec: 0.2779 lr: 0.00070\n",
      "Epoch 1/Step 1300, Loss: -0.10993, Accuracy: 0.99114, F1: 0.1843, Prec: 0.0385, Rec: 0.2776 lr: 0.00070\n",
      "Epoch 1/Step 1310, Loss: -0.10897, Accuracy: 0.99120, F1: 0.1846, Prec: 0.0387, Rec: 0.2773 lr: 0.00070\n",
      "Epoch 1/Step 1320, Loss: -0.10182, Accuracy: 0.99125, F1: 0.1847, Prec: 0.0389, Rec: 0.2769 lr: 0.00070\n",
      "Epoch 1/Step 1330, Loss: -0.10201, Accuracy: 0.99130, F1: 0.1849, Prec: 0.0391, Rec: 0.2765 lr: 0.00070\n",
      "Epoch 1/Step 1340, Loss: -0.10071, Accuracy: 0.99135, F1: 0.1852, Prec: 0.0393, Rec: 0.2763 lr: 0.00070\n",
      "Epoch 1/Step 1350, Loss: -0.10039, Accuracy: 0.99140, F1: 0.1853, Prec: 0.0395, Rec: 0.2758 lr: 0.00070\n",
      "Epoch 1/Step 1360, Loss: -0.09489, Accuracy: 0.99145, F1: 0.1855, Prec: 0.0397, Rec: 0.2754 lr: 0.00070\n",
      "Epoch 1/Step 1370, Loss: -0.09485, Accuracy: 0.99150, F1: 0.1857, Prec: 0.0399, Rec: 0.2752 lr: 0.00070\n",
      "Epoch 1/Step 1380, Loss: -0.10766, Accuracy: 0.99154, F1: 0.1858, Prec: 0.0401, Rec: 0.2749 lr: 0.00070\n",
      "Epoch 1/Step 1390, Loss: -0.11157, Accuracy: 0.99159, F1: 0.1858, Prec: 0.0403, Rec: 0.2746 lr: 0.00070\n",
      "Epoch 1/Step 1400, Loss: -0.09607, Accuracy: 0.99164, F1: 0.1860, Prec: 0.0405, Rec: 0.2743 lr: 0.00070\n",
      "Epoch 1/Step 1410, Loss: -0.11430, Accuracy: 0.99168, F1: 0.1862, Prec: 0.0407, Rec: 0.2739 lr: 0.00070\n",
      "Epoch 1/Step 1420, Loss: -0.10494, Accuracy: 0.99173, F1: 0.1862, Prec: 0.0408, Rec: 0.2735 lr: 0.00070\n",
      "Epoch 1/Step 1430, Loss: -0.10685, Accuracy: 0.99177, F1: 0.1865, Prec: 0.0410, Rec: 0.2731 lr: 0.00070\n",
      "Epoch 1/Step 1440, Loss: -0.09002, Accuracy: 0.99182, F1: 0.1866, Prec: 0.0412, Rec: 0.2728 lr: 0.00070\n",
      "Epoch 1/Step 1450, Loss: -0.09381, Accuracy: 0.99186, F1: 0.1867, Prec: 0.0414, Rec: 0.2723 lr: 0.00070\n",
      "Epoch 1/Step 1460, Loss: -0.08543, Accuracy: 0.99190, F1: 0.1869, Prec: 0.0416, Rec: 0.2720 lr: 0.00070\n",
      "Epoch 1/Step 1470, Loss: -0.10975, Accuracy: 0.99195, F1: 0.1871, Prec: 0.0418, Rec: 0.2716 lr: 0.00070\n",
      "Epoch 1/Step 1480, Loss: -0.11547, Accuracy: 0.99199, F1: 0.1872, Prec: 0.0420, Rec: 0.2712 lr: 0.00070\n",
      "Epoch 1/Step 1490, Loss: -0.09568, Accuracy: 0.99203, F1: 0.1874, Prec: 0.0422, Rec: 0.2709 lr: 0.00070\n",
      "Epoch 1/Step 1500, Loss: -0.10249, Accuracy: 0.99207, F1: 0.1874, Prec: 0.0423, Rec: 0.2706 lr: 0.00070\n",
      "Epoch 1/Step 1510, Loss: -0.09259, Accuracy: 0.99211, F1: 0.1876, Prec: 0.0425, Rec: 0.2703 lr: 0.00070\n",
      "Epoch 1/Step 1520, Loss: -0.11500, Accuracy: 0.99215, F1: 0.1877, Prec: 0.0427, Rec: 0.2701 lr: 0.00070\n",
      "Epoch 1/Step 1530, Loss: -0.10248, Accuracy: 0.99219, F1: 0.1878, Prec: 0.0429, Rec: 0.2699 lr: 0.00070\n",
      "Epoch 1/Step 1540, Loss: -0.09112, Accuracy: 0.99223, F1: 0.1879, Prec: 0.0431, Rec: 0.2695 lr: 0.00070\n",
      "Epoch 1/Step 1550, Loss: -0.11082, Accuracy: 0.99227, F1: 0.1881, Prec: 0.0433, Rec: 0.2692 lr: 0.00070\n",
      "Epoch finished. Start validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 08:41:57.554763: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.9981\n",
      "Validation f1: 0.2083\n",
      "Validation precision: 0.2057\n",
      "Validation recall: 0.2314\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_0_valF1Score0.208/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_0_valF1Score0.208/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 2\n",
      "Epoch 2/Step 0, Loss: -0.11167, Accuracy: 0.99816, F1: 0.2465, Prec: 0.2139, Rec: 0.2593 lr: 0.00070\n",
      "Epoch 2/Step 10, Loss: -0.10340, Accuracy: 0.99802, F1: 0.2215, Prec: 0.2186, Rec: 0.2324 lr: 0.00070\n",
      "Epoch 2/Step 20, Loss: -0.10081, Accuracy: 0.99809, F1: 0.2198, Prec: 0.2136, Rec: 0.2322 lr: 0.00070\n",
      "Epoch 2/Step 30, Loss: -0.10478, Accuracy: 0.99813, F1: 0.2148, Prec: 0.2121, Rec: 0.2338 lr: 0.00070\n",
      "Epoch 2/Step 40, Loss: -0.10890, Accuracy: 0.99813, F1: 0.2170, Prec: 0.2161, Rec: 0.2349 lr: 0.00070\n",
      "Epoch 2/Step 50, Loss: -0.11043, Accuracy: 0.99812, F1: 0.2164, Prec: 0.2143, Rec: 0.2367 lr: 0.00070\n",
      "Epoch 2/Step 60, Loss: -0.10996, Accuracy: 0.99815, F1: 0.2143, Prec: 0.2154, Rec: 0.2331 lr: 0.00070\n",
      "Epoch 2/Step 70, Loss: -0.10798, Accuracy: 0.99817, F1: 0.2130, Prec: 0.2150, Rec: 0.2338 lr: 0.00070\n",
      "Epoch 2/Step 80, Loss: -0.10422, Accuracy: 0.99818, F1: 0.2123, Prec: 0.2149, Rec: 0.2326 lr: 0.00070\n",
      "Epoch 2/Step 90, Loss: -0.10394, Accuracy: 0.99818, F1: 0.2121, Prec: 0.2160, Rec: 0.2315 lr: 0.00070\n",
      "Epoch 2/Step 100, Loss: -0.11032, Accuracy: 0.99819, F1: 0.2111, Prec: 0.2149, Rec: 0.2319 lr: 0.00070\n",
      "Epoch 2/Step 110, Loss: -0.11422, Accuracy: 0.99818, F1: 0.2123, Prec: 0.2160, Rec: 0.2300 lr: 0.00070\n",
      "Epoch 2/Step 120, Loss: -0.09590, Accuracy: 0.99818, F1: 0.2124, Prec: 0.2168, Rec: 0.2288 lr: 0.00070\n",
      "Epoch 2/Step 130, Loss: -0.10739, Accuracy: 0.99818, F1: 0.2114, Prec: 0.2167, Rec: 0.2289 lr: 0.00070\n",
      "Epoch 2/Step 140, Loss: -0.10978, Accuracy: 0.99818, F1: 0.2114, Prec: 0.2173, Rec: 0.2273 lr: 0.00070\n",
      "Epoch 2/Step 150, Loss: -0.09822, Accuracy: 0.99816, F1: 0.2125, Prec: 0.2178, Rec: 0.2275 lr: 0.00070\n",
      "Epoch 2/Step 160, Loss: -0.10584, Accuracy: 0.99817, F1: 0.2119, Prec: 0.2182, Rec: 0.2274 lr: 0.00070\n",
      "Epoch 2/Step 170, Loss: -0.08397, Accuracy: 0.99817, F1: 0.2112, Prec: 0.2176, Rec: 0.2274 lr: 0.00070\n",
      "Epoch 2/Step 180, Loss: -0.09369, Accuracy: 0.99818, F1: 0.2112, Prec: 0.2180, Rec: 0.2270 lr: 0.00070\n",
      "Epoch 2/Step 190, Loss: -0.09612, Accuracy: 0.99818, F1: 0.2108, Prec: 0.2179, Rec: 0.2266 lr: 0.00070\n",
      "Epoch 2/Step 200, Loss: -0.09742, Accuracy: 0.99817, F1: 0.2110, Prec: 0.2191, Rec: 0.2254 lr: 0.00070\n",
      "Epoch 2/Step 210, Loss: -0.09603, Accuracy: 0.99817, F1: 0.2110, Prec: 0.2188, Rec: 0.2256 lr: 0.00070\n",
      "Epoch 2/Step 220, Loss: -0.10869, Accuracy: 0.99817, F1: 0.2110, Prec: 0.2191, Rec: 0.2253 lr: 0.00070\n",
      "Epoch 2/Step 230, Loss: -0.10037, Accuracy: 0.99817, F1: 0.2112, Prec: 0.2193, Rec: 0.2254 lr: 0.00070\n",
      "Epoch 2/Step 240, Loss: -0.12285, Accuracy: 0.99816, F1: 0.2113, Prec: 0.2197, Rec: 0.2260 lr: 0.00070\n",
      "Epoch 2/Step 250, Loss: -0.10455, Accuracy: 0.99816, F1: 0.2114, Prec: 0.2197, Rec: 0.2256 lr: 0.00070\n",
      "Epoch 2/Step 260, Loss: -0.10941, Accuracy: 0.99816, F1: 0.2122, Prec: 0.2204, Rec: 0.2258 lr: 0.00070\n",
      "Epoch 2/Step 270, Loss: -0.10682, Accuracy: 0.99816, F1: 0.2129, Prec: 0.2205, Rec: 0.2259 lr: 0.00070\n",
      "Epoch 2/Step 280, Loss: -0.10341, Accuracy: 0.99816, F1: 0.2130, Prec: 0.2206, Rec: 0.2263 lr: 0.00070\n",
      "Epoch 2/Step 290, Loss: -0.10927, Accuracy: 0.99816, F1: 0.2125, Prec: 0.2204, Rec: 0.2258 lr: 0.00070\n",
      "Epoch 2/Step 300, Loss: -0.11966, Accuracy: 0.99816, F1: 0.2127, Prec: 0.2204, Rec: 0.2261 lr: 0.00070\n",
      "Epoch 2/Step 310, Loss: -0.11392, Accuracy: 0.99816, F1: 0.2121, Prec: 0.2198, Rec: 0.2264 lr: 0.00070\n",
      "Epoch 2/Step 320, Loss: -0.11837, Accuracy: 0.99816, F1: 0.2119, Prec: 0.2204, Rec: 0.2266 lr: 0.00070\n",
      "Epoch 2/Step 330, Loss: -0.12985, Accuracy: 0.99817, F1: 0.2124, Prec: 0.2210, Rec: 0.2268 lr: 0.00070\n",
      "Epoch 2/Step 340, Loss: -0.11300, Accuracy: 0.99817, F1: 0.2126, Prec: 0.2215, Rec: 0.2266 lr: 0.00070\n",
      "Epoch 2/Step 350, Loss: -0.11753, Accuracy: 0.99816, F1: 0.2126, Prec: 0.2216, Rec: 0.2266 lr: 0.00070\n",
      "Epoch 2/Step 360, Loss: -0.13353, Accuracy: 0.99817, F1: 0.2129, Prec: 0.2219, Rec: 0.2271 lr: 0.00070\n",
      "Epoch 2/Step 370, Loss: -0.11269, Accuracy: 0.99817, F1: 0.2126, Prec: 0.2217, Rec: 0.2268 lr: 0.00070\n",
      "Epoch 2/Step 380, Loss: -0.12673, Accuracy: 0.99817, F1: 0.2125, Prec: 0.2216, Rec: 0.2272 lr: 0.00070\n",
      "Epoch 2/Step 390, Loss: -0.10378, Accuracy: 0.99818, F1: 0.2123, Prec: 0.2217, Rec: 0.2267 lr: 0.00070\n",
      "Epoch 2/Step 400, Loss: -0.09441, Accuracy: 0.99817, F1: 0.2122, Prec: 0.2214, Rec: 0.2266 lr: 0.00070\n",
      "Epoch 2/Step 410, Loss: -0.11210, Accuracy: 0.99818, F1: 0.2119, Prec: 0.2213, Rec: 0.2265 lr: 0.00070\n",
      "Epoch 2/Step 420, Loss: -0.11789, Accuracy: 0.99818, F1: 0.2120, Prec: 0.2214, Rec: 0.2266 lr: 0.00070\n",
      "Epoch 2/Step 430, Loss: -0.10111, Accuracy: 0.99818, F1: 0.2118, Prec: 0.2215, Rec: 0.2267 lr: 0.00070\n",
      "Epoch 2/Step 440, Loss: -0.09607, Accuracy: 0.99818, F1: 0.2120, Prec: 0.2218, Rec: 0.2269 lr: 0.00070\n",
      "Epoch 2/Step 450, Loss: -0.10963, Accuracy: 0.99818, F1: 0.2123, Prec: 0.2221, Rec: 0.2267 lr: 0.00070\n",
      "Epoch 2/Step 460, Loss: -0.10327, Accuracy: 0.99818, F1: 0.2120, Prec: 0.2219, Rec: 0.2270 lr: 0.00070\n",
      "Epoch 2/Step 470, Loss: -0.10659, Accuracy: 0.99819, F1: 0.2120, Prec: 0.2222, Rec: 0.2267 lr: 0.00070\n",
      "Epoch 2/Step 480, Loss: -0.11138, Accuracy: 0.99818, F1: 0.2122, Prec: 0.2220, Rec: 0.2270 lr: 0.00070\n",
      "Epoch 2/Step 490, Loss: -0.08601, Accuracy: 0.99818, F1: 0.2120, Prec: 0.2221, Rec: 0.2266 lr: 0.00070\n",
      "Epoch 2/Step 500, Loss: -0.11125, Accuracy: 0.99818, F1: 0.2116, Prec: 0.2220, Rec: 0.2268 lr: 0.00070\n",
      "Epoch 2/Step 510, Loss: -0.11138, Accuracy: 0.99818, F1: 0.2117, Prec: 0.2221, Rec: 0.2268 lr: 0.00070\n",
      "Epoch 2/Step 520, Loss: -0.10311, Accuracy: 0.99818, F1: 0.2119, Prec: 0.2225, Rec: 0.2271 lr: 0.00070\n",
      "Epoch 2/Step 530, Loss: -0.10209, Accuracy: 0.99818, F1: 0.2118, Prec: 0.2222, Rec: 0.2270 lr: 0.00070\n",
      "Epoch 2/Step 540, Loss: -0.10102, Accuracy: 0.99818, F1: 0.2121, Prec: 0.2225, Rec: 0.2271 lr: 0.00070\n",
      "Epoch 2/Step 550, Loss: -0.11641, Accuracy: 0.99818, F1: 0.2124, Prec: 0.2229, Rec: 0.2269 lr: 0.00070\n",
      "Epoch 2/Step 560, Loss: -0.11711, Accuracy: 0.99818, F1: 0.2123, Prec: 0.2228, Rec: 0.2273 lr: 0.00070\n",
      "Epoch 2/Step 570, Loss: -0.10768, Accuracy: 0.99818, F1: 0.2123, Prec: 0.2229, Rec: 0.2271 lr: 0.00070\n",
      "Epoch 2/Step 580, Loss: -0.12808, Accuracy: 0.99818, F1: 0.2124, Prec: 0.2232, Rec: 0.2271 lr: 0.00070\n",
      "Epoch 2/Step 590, Loss: -0.08264, Accuracy: 0.99818, F1: 0.2122, Prec: 0.2226, Rec: 0.2273 lr: 0.00070\n",
      "Epoch 2/Step 600, Loss: -0.08217, Accuracy: 0.99818, F1: 0.2123, Prec: 0.2229, Rec: 0.2271 lr: 0.00070\n",
      "Epoch 2/Step 610, Loss: -0.12319, Accuracy: 0.99818, F1: 0.2124, Prec: 0.2232, Rec: 0.2270 lr: 0.00070\n",
      "Epoch 2/Step 620, Loss: -0.13088, Accuracy: 0.99818, F1: 0.2126, Prec: 0.2236, Rec: 0.2273 lr: 0.00070\n",
      "Epoch 2/Step 630, Loss: -0.10205, Accuracy: 0.99818, F1: 0.2128, Prec: 0.2237, Rec: 0.2273 lr: 0.00070\n",
      "Epoch 2/Step 640, Loss: -0.11592, Accuracy: 0.99818, F1: 0.2129, Prec: 0.2238, Rec: 0.2276 lr: 0.00070\n",
      "Epoch 2/Step 650, Loss: -0.09838, Accuracy: 0.99818, F1: 0.2131, Prec: 0.2237, Rec: 0.2278 lr: 0.00070\n",
      "Epoch 2/Step 660, Loss: -0.12597, Accuracy: 0.99818, F1: 0.2133, Prec: 0.2241, Rec: 0.2280 lr: 0.00070\n",
      "Epoch 2/Step 670, Loss: -0.08883, Accuracy: 0.99818, F1: 0.2134, Prec: 0.2242, Rec: 0.2283 lr: 0.00070\n",
      "Epoch 2/Step 680, Loss: -0.10389, Accuracy: 0.99818, F1: 0.2133, Prec: 0.2240, Rec: 0.2284 lr: 0.00070\n",
      "Epoch 2/Step 690, Loss: -0.12852, Accuracy: 0.99818, F1: 0.2132, Prec: 0.2239, Rec: 0.2285 lr: 0.00070\n",
      "Epoch 2/Step 700, Loss: -0.10421, Accuracy: 0.99819, F1: 0.2132, Prec: 0.2240, Rec: 0.2286 lr: 0.00070\n",
      "Epoch 2/Step 710, Loss: -0.10934, Accuracy: 0.99819, F1: 0.2131, Prec: 0.2239, Rec: 0.2290 lr: 0.00070\n",
      "Epoch 2/Step 720, Loss: -0.13046, Accuracy: 0.99819, F1: 0.2132, Prec: 0.2242, Rec: 0.2291 lr: 0.00070\n",
      "Epoch 2/Step 730, Loss: -0.11148, Accuracy: 0.99819, F1: 0.2134, Prec: 0.2243, Rec: 0.2291 lr: 0.00070\n",
      "Epoch 2/Step 740, Loss: -0.10324, Accuracy: 0.99819, F1: 0.2134, Prec: 0.2240, Rec: 0.2292 lr: 0.00070\n",
      "Epoch 2/Step 750, Loss: -0.10560, Accuracy: 0.99819, F1: 0.2137, Prec: 0.2242, Rec: 0.2292 lr: 0.00070\n",
      "Epoch 2/Step 760, Loss: -0.11467, Accuracy: 0.99819, F1: 0.2138, Prec: 0.2243, Rec: 0.2292 lr: 0.00070\n",
      "Epoch 2/Step 770, Loss: -0.09753, Accuracy: 0.99819, F1: 0.2138, Prec: 0.2242, Rec: 0.2294 lr: 0.00070\n",
      "Epoch 2/Step 780, Loss: -0.11522, Accuracy: 0.99819, F1: 0.2141, Prec: 0.2245, Rec: 0.2295 lr: 0.00070\n",
      "Epoch 2/Step 790, Loss: -0.11630, Accuracy: 0.99819, F1: 0.2143, Prec: 0.2245, Rec: 0.2296 lr: 0.00070\n",
      "Epoch 2/Step 800, Loss: -0.10484, Accuracy: 0.99819, F1: 0.2144, Prec: 0.2244, Rec: 0.2296 lr: 0.00070\n",
      "Epoch 2/Step 810, Loss: -0.09576, Accuracy: 0.99819, F1: 0.2145, Prec: 0.2244, Rec: 0.2297 lr: 0.00070\n",
      "Epoch 2/Step 820, Loss: -0.11774, Accuracy: 0.99819, F1: 0.2144, Prec: 0.2243, Rec: 0.2298 lr: 0.00070\n",
      "Epoch 2/Step 830, Loss: -0.09651, Accuracy: 0.99819, F1: 0.2143, Prec: 0.2243, Rec: 0.2299 lr: 0.00070\n",
      "Epoch 2/Step 840, Loss: -0.11843, Accuracy: 0.99819, F1: 0.2144, Prec: 0.2244, Rec: 0.2300 lr: 0.00070\n",
      "Epoch 2/Step 850, Loss: -0.10916, Accuracy: 0.99819, F1: 0.2145, Prec: 0.2245, Rec: 0.2299 lr: 0.00070\n",
      "Epoch 2/Step 860, Loss: -0.12304, Accuracy: 0.99819, F1: 0.2146, Prec: 0.2247, Rec: 0.2298 lr: 0.00070\n",
      "Epoch 2/Step 870, Loss: -0.10457, Accuracy: 0.99819, F1: 0.2146, Prec: 0.2249, Rec: 0.2296 lr: 0.00070\n",
      "Epoch 2/Step 880, Loss: -0.10852, Accuracy: 0.99819, F1: 0.2149, Prec: 0.2250, Rec: 0.2299 lr: 0.00070\n",
      "Epoch 2/Step 890, Loss: -0.11079, Accuracy: 0.99819, F1: 0.2150, Prec: 0.2251, Rec: 0.2300 lr: 0.00070\n",
      "Epoch 2/Step 900, Loss: -0.14050, Accuracy: 0.99819, F1: 0.2152, Prec: 0.2256, Rec: 0.2301 lr: 0.00070\n",
      "Epoch 2/Step 910, Loss: -0.09177, Accuracy: 0.99819, F1: 0.2153, Prec: 0.2255, Rec: 0.2302 lr: 0.00070\n",
      "Epoch 2/Step 920, Loss: -0.10676, Accuracy: 0.99819, F1: 0.2155, Prec: 0.2256, Rec: 0.2302 lr: 0.00070\n",
      "Epoch 2/Step 930, Loss: -0.09629, Accuracy: 0.99819, F1: 0.2156, Prec: 0.2257, Rec: 0.2304 lr: 0.00070\n",
      "Epoch 2/Step 940, Loss: -0.10082, Accuracy: 0.99820, F1: 0.2155, Prec: 0.2256, Rec: 0.2305 lr: 0.00070\n",
      "Epoch 2/Step 950, Loss: -0.12676, Accuracy: 0.99820, F1: 0.2157, Prec: 0.2260, Rec: 0.2305 lr: 0.00070\n",
      "Epoch 2/Step 960, Loss: -0.12329, Accuracy: 0.99820, F1: 0.2157, Prec: 0.2261, Rec: 0.2305 lr: 0.00070\n",
      "Epoch 2/Step 970, Loss: -0.10795, Accuracy: 0.99820, F1: 0.2157, Prec: 0.2262, Rec: 0.2303 lr: 0.00070\n",
      "Epoch 2/Step 980, Loss: -0.12990, Accuracy: 0.99820, F1: 0.2157, Prec: 0.2260, Rec: 0.2304 lr: 0.00070\n",
      "Epoch 2/Step 990, Loss: -0.10887, Accuracy: 0.99820, F1: 0.2157, Prec: 0.2259, Rec: 0.2306 lr: 0.00070\n",
      "Epoch 2/Step 1000, Loss: -0.12152, Accuracy: 0.99820, F1: 0.2157, Prec: 0.2260, Rec: 0.2307 lr: 0.00070\n",
      "Epoch 2/Step 1010, Loss: -0.13217, Accuracy: 0.99820, F1: 0.2159, Prec: 0.2265, Rec: 0.2307 lr: 0.00070\n",
      "Epoch 2/Step 1020, Loss: -0.10256, Accuracy: 0.99820, F1: 0.2159, Prec: 0.2264, Rec: 0.2307 lr: 0.00070\n",
      "Epoch 2/Step 1030, Loss: -0.10809, Accuracy: 0.99821, F1: 0.2160, Prec: 0.2267, Rec: 0.2308 lr: 0.00070\n",
      "Epoch 2/Step 1040, Loss: -0.10874, Accuracy: 0.99821, F1: 0.2160, Prec: 0.2269, Rec: 0.2306 lr: 0.00070\n",
      "Epoch 2/Step 1050, Loss: -0.12217, Accuracy: 0.99821, F1: 0.2160, Prec: 0.2269, Rec: 0.2307 lr: 0.00070\n",
      "Epoch 2/Step 1060, Loss: -0.12248, Accuracy: 0.99821, F1: 0.2159, Prec: 0.2271, Rec: 0.2308 lr: 0.00070\n",
      "Epoch 2/Step 1070, Loss: -0.11733, Accuracy: 0.99821, F1: 0.2162, Prec: 0.2273, Rec: 0.2307 lr: 0.00070\n",
      "Epoch 2/Step 1080, Loss: -0.10154, Accuracy: 0.99821, F1: 0.2163, Prec: 0.2276, Rec: 0.2308 lr: 0.00070\n",
      "Epoch 2/Step 1090, Loss: -0.10647, Accuracy: 0.99821, F1: 0.2163, Prec: 0.2277, Rec: 0.2308 lr: 0.00070\n",
      "Epoch 2/Step 1100, Loss: -0.12439, Accuracy: 0.99821, F1: 0.2164, Prec: 0.2278, Rec: 0.2309 lr: 0.00070\n",
      "Epoch 2/Step 1110, Loss: -0.10252, Accuracy: 0.99821, F1: 0.2165, Prec: 0.2280, Rec: 0.2307 lr: 0.00070\n",
      "Epoch 2/Step 1120, Loss: -0.10400, Accuracy: 0.99821, F1: 0.2164, Prec: 0.2281, Rec: 0.2307 lr: 0.00070\n",
      "Epoch 2/Step 1130, Loss: -0.11598, Accuracy: 0.99822, F1: 0.2164, Prec: 0.2283, Rec: 0.2308 lr: 0.00070\n",
      "Epoch 2/Step 1140, Loss: -0.10353, Accuracy: 0.99822, F1: 0.2164, Prec: 0.2284, Rec: 0.2307 lr: 0.00070\n",
      "Epoch 2/Step 1150, Loss: -0.11208, Accuracy: 0.99822, F1: 0.2165, Prec: 0.2284, Rec: 0.2309 lr: 0.00070\n",
      "Epoch 2/Step 1160, Loss: -0.12102, Accuracy: 0.99822, F1: 0.2166, Prec: 0.2287, Rec: 0.2310 lr: 0.00070\n",
      "Epoch 2/Step 1170, Loss: -0.10698, Accuracy: 0.99822, F1: 0.2166, Prec: 0.2289, Rec: 0.2310 lr: 0.00070\n",
      "Epoch 2/Step 1180, Loss: -0.09182, Accuracy: 0.99822, F1: 0.2168, Prec: 0.2292, Rec: 0.2309 lr: 0.00070\n",
      "Epoch 2/Step 1190, Loss: -0.11573, Accuracy: 0.99822, F1: 0.2166, Prec: 0.2292, Rec: 0.2308 lr: 0.00070\n",
      "Epoch 2/Step 1200, Loss: -0.11076, Accuracy: 0.99822, F1: 0.2166, Prec: 0.2294, Rec: 0.2310 lr: 0.00070\n",
      "Epoch 2/Step 1210, Loss: -0.11355, Accuracy: 0.99822, F1: 0.2167, Prec: 0.2296, Rec: 0.2311 lr: 0.00070\n",
      "Epoch 2/Step 1220, Loss: -0.10568, Accuracy: 0.99823, F1: 0.2166, Prec: 0.2296, Rec: 0.2312 lr: 0.00070\n",
      "Epoch 2/Step 1230, Loss: -0.12760, Accuracy: 0.99823, F1: 0.2165, Prec: 0.2297, Rec: 0.2312 lr: 0.00070\n",
      "Epoch 2/Step 1240, Loss: -0.15794, Accuracy: 0.99823, F1: 0.2168, Prec: 0.2300, Rec: 0.2312 lr: 0.00070\n",
      "Epoch 2/Step 1250, Loss: -0.10577, Accuracy: 0.99823, F1: 0.2169, Prec: 0.2301, Rec: 0.2313 lr: 0.00070\n",
      "Epoch 2/Step 1260, Loss: -0.11381, Accuracy: 0.99823, F1: 0.2169, Prec: 0.2303, Rec: 0.2313 lr: 0.00070\n",
      "Epoch 2/Step 1270, Loss: -0.09967, Accuracy: 0.99823, F1: 0.2169, Prec: 0.2304, Rec: 0.2314 lr: 0.00070\n",
      "Epoch 2/Step 1280, Loss: -0.15826, Accuracy: 0.99823, F1: 0.2171, Prec: 0.2307, Rec: 0.2314 lr: 0.00070\n",
      "Epoch 2/Step 1290, Loss: -0.13360, Accuracy: 0.99823, F1: 0.2172, Prec: 0.2308, Rec: 0.2315 lr: 0.00070\n",
      "Epoch 2/Step 1300, Loss: -0.12674, Accuracy: 0.99823, F1: 0.2172, Prec: 0.2310, Rec: 0.2315 lr: 0.00070\n",
      "Epoch 2/Step 1310, Loss: -0.12323, Accuracy: 0.99823, F1: 0.2174, Prec: 0.2312, Rec: 0.2316 lr: 0.00070\n",
      "Epoch 2/Step 1320, Loss: -0.11240, Accuracy: 0.99823, F1: 0.2174, Prec: 0.2314, Rec: 0.2317 lr: 0.00070\n",
      "Epoch 2/Step 1330, Loss: -0.13230, Accuracy: 0.99824, F1: 0.2175, Prec: 0.2317, Rec: 0.2316 lr: 0.00070\n",
      "Epoch 2/Step 1340, Loss: -0.11305, Accuracy: 0.99824, F1: 0.2177, Prec: 0.2319, Rec: 0.2318 lr: 0.00070\n",
      "Epoch 2/Step 1350, Loss: -0.10659, Accuracy: 0.99824, F1: 0.2177, Prec: 0.2319, Rec: 0.2318 lr: 0.00070\n",
      "Epoch 2/Step 1360, Loss: -0.09701, Accuracy: 0.99824, F1: 0.2178, Prec: 0.2321, Rec: 0.2316 lr: 0.00070\n",
      "Epoch 2/Step 1370, Loss: -0.11623, Accuracy: 0.99824, F1: 0.2178, Prec: 0.2323, Rec: 0.2318 lr: 0.00070\n",
      "Epoch 2/Step 1380, Loss: -0.12285, Accuracy: 0.99824, F1: 0.2178, Prec: 0.2324, Rec: 0.2319 lr: 0.00070\n",
      "Epoch 2/Step 1390, Loss: -0.13465, Accuracy: 0.99824, F1: 0.2177, Prec: 0.2324, Rec: 0.2319 lr: 0.00070\n",
      "Epoch 2/Step 1400, Loss: -0.11486, Accuracy: 0.99824, F1: 0.2178, Prec: 0.2325, Rec: 0.2319 lr: 0.00070\n",
      "Epoch 2/Step 1410, Loss: -0.13236, Accuracy: 0.99824, F1: 0.2179, Prec: 0.2325, Rec: 0.2321 lr: 0.00070\n",
      "Epoch 2/Step 1420, Loss: -0.11953, Accuracy: 0.99824, F1: 0.2178, Prec: 0.2326, Rec: 0.2320 lr: 0.00070\n",
      "Epoch 2/Step 1430, Loss: -0.11236, Accuracy: 0.99824, F1: 0.2179, Prec: 0.2328, Rec: 0.2319 lr: 0.00070\n",
      "Epoch 2/Step 1440, Loss: -0.09871, Accuracy: 0.99824, F1: 0.2179, Prec: 0.2329, Rec: 0.2320 lr: 0.00070\n",
      "Epoch 2/Step 1450, Loss: -0.10550, Accuracy: 0.99824, F1: 0.2179, Prec: 0.2330, Rec: 0.2320 lr: 0.00070\n",
      "Epoch 2/Step 1460, Loss: -0.09175, Accuracy: 0.99824, F1: 0.2180, Prec: 0.2331, Rec: 0.2320 lr: 0.00070\n",
      "Epoch 2/Step 1470, Loss: -0.13376, Accuracy: 0.99825, F1: 0.2181, Prec: 0.2332, Rec: 0.2320 lr: 0.00070\n",
      "Epoch 2/Step 1480, Loss: -0.12888, Accuracy: 0.99825, F1: 0.2181, Prec: 0.2335, Rec: 0.2321 lr: 0.00070\n",
      "Epoch 2/Step 1490, Loss: -0.11257, Accuracy: 0.99825, F1: 0.2182, Prec: 0.2336, Rec: 0.2322 lr: 0.00070\n",
      "Epoch 2/Step 1500, Loss: -0.12456, Accuracy: 0.99825, F1: 0.2182, Prec: 0.2337, Rec: 0.2323 lr: 0.00070\n",
      "Epoch 2/Step 1510, Loss: -0.10370, Accuracy: 0.99825, F1: 0.2182, Prec: 0.2338, Rec: 0.2323 lr: 0.00070\n",
      "Epoch 2/Step 1520, Loss: -0.14267, Accuracy: 0.99825, F1: 0.2182, Prec: 0.2340, Rec: 0.2323 lr: 0.00070\n",
      "Epoch 2/Step 1530, Loss: -0.11147, Accuracy: 0.99825, F1: 0.2183, Prec: 0.2342, Rec: 0.2325 lr: 0.00070\n",
      "Epoch 2/Step 1540, Loss: -0.09569, Accuracy: 0.99825, F1: 0.2182, Prec: 0.2342, Rec: 0.2324 lr: 0.00070\n",
      "Epoch 2/Step 1550, Loss: -0.12736, Accuracy: 0.99825, F1: 0.2184, Prec: 0.2345, Rec: 0.2324 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9984\n",
      "Validation f1: 0.2218\n",
      "Validation precision: 0.2605\n",
      "Validation recall: 0.2296\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_1_valF1Score0.222/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_1_valF1Score0.222/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 3\n",
      "Epoch 3/Step 0, Loss: -0.12634, Accuracy: 0.99852, F1: 0.2601, Prec: 0.2887, Rec: 0.2458 lr: 0.00070\n",
      "Epoch 3/Step 10, Loss: -0.12568, Accuracy: 0.99828, F1: 0.2387, Prec: 0.2796, Rec: 0.2452 lr: 0.00070\n",
      "Epoch 3/Step 20, Loss: -0.11210, Accuracy: 0.99829, F1: 0.2349, Prec: 0.2615, Rec: 0.2487 lr: 0.00070\n",
      "Epoch 3/Step 30, Loss: -0.12043, Accuracy: 0.99833, F1: 0.2322, Prec: 0.2609, Rec: 0.2518 lr: 0.00070\n",
      "Epoch 3/Step 40, Loss: -0.11036, Accuracy: 0.99832, F1: 0.2338, Prec: 0.2638, Rec: 0.2503 lr: 0.00070\n",
      "Epoch 3/Step 50, Loss: -0.12425, Accuracy: 0.99830, F1: 0.2335, Prec: 0.2590, Rec: 0.2536 lr: 0.00070\n",
      "Epoch 3/Step 60, Loss: -0.13265, Accuracy: 0.99832, F1: 0.2313, Prec: 0.2598, Rec: 0.2513 lr: 0.00070\n",
      "Epoch 3/Step 70, Loss: -0.11447, Accuracy: 0.99834, F1: 0.2292, Prec: 0.2588, Rec: 0.2523 lr: 0.00070\n",
      "Epoch 3/Step 80, Loss: -0.11386, Accuracy: 0.99836, F1: 0.2284, Prec: 0.2596, Rec: 0.2511 lr: 0.00070\n",
      "Epoch 3/Step 90, Loss: -0.11580, Accuracy: 0.99834, F1: 0.2287, Prec: 0.2589, Rec: 0.2508 lr: 0.00070\n",
      "Epoch 3/Step 100, Loss: -0.13472, Accuracy: 0.99835, F1: 0.2285, Prec: 0.2592, Rec: 0.2513 lr: 0.00070\n",
      "Epoch 3/Step 110, Loss: -0.12322, Accuracy: 0.99834, F1: 0.2298, Prec: 0.2596, Rec: 0.2486 lr: 0.00070\n",
      "Epoch 3/Step 120, Loss: -0.10689, Accuracy: 0.99833, F1: 0.2296, Prec: 0.2591, Rec: 0.2489 lr: 0.00070\n",
      "Epoch 3/Step 130, Loss: -0.10783, Accuracy: 0.99834, F1: 0.2286, Prec: 0.2594, Rec: 0.2479 lr: 0.00070\n",
      "Epoch 3/Step 140, Loss: -0.12700, Accuracy: 0.99833, F1: 0.2287, Prec: 0.2603, Rec: 0.2459 lr: 0.00070\n",
      "Epoch 3/Step 150, Loss: -0.10864, Accuracy: 0.99831, F1: 0.2296, Prec: 0.2589, Rec: 0.2474 lr: 0.00070\n",
      "Epoch 3/Step 160, Loss: -0.12358, Accuracy: 0.99831, F1: 0.2295, Prec: 0.2586, Rec: 0.2477 lr: 0.00070\n",
      "Epoch 3/Step 170, Loss: -0.09126, Accuracy: 0.99832, F1: 0.2288, Prec: 0.2581, Rec: 0.2467 lr: 0.00070\n",
      "Epoch 3/Step 180, Loss: -0.10922, Accuracy: 0.99832, F1: 0.2289, Prec: 0.2579, Rec: 0.2472 lr: 0.00070\n",
      "Epoch 3/Step 190, Loss: -0.11455, Accuracy: 0.99831, F1: 0.2282, Prec: 0.2572, Rec: 0.2466 lr: 0.00070\n",
      "Epoch 3/Step 200, Loss: -0.11089, Accuracy: 0.99831, F1: 0.2281, Prec: 0.2581, Rec: 0.2456 lr: 0.00070\n",
      "Epoch 3/Step 210, Loss: -0.11233, Accuracy: 0.99830, F1: 0.2282, Prec: 0.2573, Rec: 0.2463 lr: 0.00070\n",
      "Epoch 3/Step 220, Loss: -0.13306, Accuracy: 0.99830, F1: 0.2283, Prec: 0.2575, Rec: 0.2464 lr: 0.00070\n",
      "Epoch 3/Step 230, Loss: -0.10099, Accuracy: 0.99830, F1: 0.2282, Prec: 0.2577, Rec: 0.2459 lr: 0.00070\n",
      "Epoch 3/Step 240, Loss: -0.14373, Accuracy: 0.99830, F1: 0.2287, Prec: 0.2591, Rec: 0.2455 lr: 0.00070\n",
      "Epoch 3/Step 250, Loss: -0.11819, Accuracy: 0.99830, F1: 0.2287, Prec: 0.2590, Rec: 0.2453 lr: 0.00070\n",
      "Epoch 3/Step 260, Loss: -0.12743, Accuracy: 0.99830, F1: 0.2290, Prec: 0.2593, Rec: 0.2449 lr: 0.00070\n",
      "Epoch 3/Step 270, Loss: -0.14228, Accuracy: 0.99830, F1: 0.2299, Prec: 0.2595, Rec: 0.2448 lr: 0.00070\n",
      "Epoch 3/Step 280, Loss: -0.12104, Accuracy: 0.99830, F1: 0.2297, Prec: 0.2598, Rec: 0.2445 lr: 0.00070\n",
      "Epoch 3/Step 290, Loss: -0.11984, Accuracy: 0.99830, F1: 0.2293, Prec: 0.2590, Rec: 0.2443 lr: 0.00070\n",
      "Epoch 3/Step 300, Loss: -0.13105, Accuracy: 0.99830, F1: 0.2295, Prec: 0.2593, Rec: 0.2443 lr: 0.00070\n",
      "Epoch 3/Step 310, Loss: -0.12799, Accuracy: 0.99830, F1: 0.2292, Prec: 0.2589, Rec: 0.2443 lr: 0.00070\n",
      "Epoch 3/Step 320, Loss: -0.13406, Accuracy: 0.99830, F1: 0.2290, Prec: 0.2592, Rec: 0.2449 lr: 0.00070\n",
      "Epoch 3/Step 330, Loss: -0.13438, Accuracy: 0.99831, F1: 0.2292, Prec: 0.2605, Rec: 0.2447 lr: 0.00070\n",
      "Epoch 3/Step 340, Loss: -0.11863, Accuracy: 0.99830, F1: 0.2293, Prec: 0.2602, Rec: 0.2450 lr: 0.00070\n",
      "Epoch 3/Step 350, Loss: -0.10891, Accuracy: 0.99830, F1: 0.2292, Prec: 0.2603, Rec: 0.2448 lr: 0.00070\n",
      "Epoch 3/Step 360, Loss: -0.15316, Accuracy: 0.99831, F1: 0.2296, Prec: 0.2613, Rec: 0.2454 lr: 0.00070\n",
      "Epoch 3/Step 370, Loss: -0.12238, Accuracy: 0.99831, F1: 0.2293, Prec: 0.2610, Rec: 0.2449 lr: 0.00070\n",
      "Epoch 3/Step 380, Loss: -0.14494, Accuracy: 0.99832, F1: 0.2290, Prec: 0.2615, Rec: 0.2447 lr: 0.00070\n",
      "Epoch 3/Step 390, Loss: -0.11872, Accuracy: 0.99832, F1: 0.2286, Prec: 0.2615, Rec: 0.2446 lr: 0.00070\n",
      "Epoch 3/Step 400, Loss: -0.10258, Accuracy: 0.99832, F1: 0.2284, Prec: 0.2609, Rec: 0.2447 lr: 0.00070\n",
      "Epoch 3/Step 410, Loss: -0.11991, Accuracy: 0.99832, F1: 0.2280, Prec: 0.2611, Rec: 0.2442 lr: 0.00070\n",
      "Epoch 3/Step 420, Loss: -0.13501, Accuracy: 0.99832, F1: 0.2280, Prec: 0.2614, Rec: 0.2445 lr: 0.00070\n",
      "Epoch 3/Step 430, Loss: -0.11571, Accuracy: 0.99832, F1: 0.2279, Prec: 0.2614, Rec: 0.2447 lr: 0.00070\n",
      "Epoch 3/Step 440, Loss: -0.11023, Accuracy: 0.99832, F1: 0.2282, Prec: 0.2617, Rec: 0.2447 lr: 0.00070\n",
      "Epoch 3/Step 450, Loss: -0.12269, Accuracy: 0.99832, F1: 0.2285, Prec: 0.2615, Rec: 0.2448 lr: 0.00070\n",
      "Epoch 3/Step 460, Loss: -0.11741, Accuracy: 0.99832, F1: 0.2281, Prec: 0.2611, Rec: 0.2451 lr: 0.00070\n",
      "Epoch 3/Step 470, Loss: -0.11220, Accuracy: 0.99833, F1: 0.2279, Prec: 0.2616, Rec: 0.2448 lr: 0.00070\n",
      "Epoch 3/Step 480, Loss: -0.13143, Accuracy: 0.99832, F1: 0.2281, Prec: 0.2613, Rec: 0.2448 lr: 0.00070\n",
      "Epoch 3/Step 490, Loss: -0.10155, Accuracy: 0.99832, F1: 0.2277, Prec: 0.2608, Rec: 0.2447 lr: 0.00070\n",
      "Epoch 3/Step 500, Loss: -0.12251, Accuracy: 0.99832, F1: 0.2274, Prec: 0.2604, Rec: 0.2449 lr: 0.00070\n",
      "Epoch 3/Step 510, Loss: -0.13048, Accuracy: 0.99832, F1: 0.2275, Prec: 0.2606, Rec: 0.2449 lr: 0.00070\n",
      "Epoch 3/Step 520, Loss: -0.10726, Accuracy: 0.99832, F1: 0.2277, Prec: 0.2609, Rec: 0.2452 lr: 0.00070\n",
      "Epoch 3/Step 530, Loss: -0.11520, Accuracy: 0.99832, F1: 0.2274, Prec: 0.2605, Rec: 0.2449 lr: 0.00070\n",
      "Epoch 3/Step 540, Loss: -0.11009, Accuracy: 0.99832, F1: 0.2276, Prec: 0.2607, Rec: 0.2448 lr: 0.00070\n",
      "Epoch 3/Step 550, Loss: -0.14254, Accuracy: 0.99832, F1: 0.2279, Prec: 0.2611, Rec: 0.2450 lr: 0.00070\n",
      "Epoch 3/Step 560, Loss: -0.13020, Accuracy: 0.99832, F1: 0.2278, Prec: 0.2611, Rec: 0.2449 lr: 0.00070\n",
      "Epoch 3/Step 570, Loss: -0.12968, Accuracy: 0.99832, F1: 0.2278, Prec: 0.2612, Rec: 0.2450 lr: 0.00070\n",
      "Epoch 3/Step 580, Loss: -0.13465, Accuracy: 0.99832, F1: 0.2278, Prec: 0.2611, Rec: 0.2452 lr: 0.00070\n",
      "Epoch 3/Step 590, Loss: -0.09425, Accuracy: 0.99832, F1: 0.2276, Prec: 0.2609, Rec: 0.2451 lr: 0.00070\n",
      "Epoch 3/Step 600, Loss: -0.09332, Accuracy: 0.99832, F1: 0.2277, Prec: 0.2613, Rec: 0.2449 lr: 0.00070\n",
      "Epoch 3/Step 610, Loss: -0.13334, Accuracy: 0.99832, F1: 0.2278, Prec: 0.2613, Rec: 0.2451 lr: 0.00070\n",
      "Epoch 3/Step 620, Loss: -0.14733, Accuracy: 0.99831, F1: 0.2281, Prec: 0.2615, Rec: 0.2456 lr: 0.00070\n",
      "Epoch 3/Step 630, Loss: -0.11951, Accuracy: 0.99832, F1: 0.2284, Prec: 0.2616, Rec: 0.2455 lr: 0.00070\n",
      "Epoch 3/Step 640, Loss: -0.12932, Accuracy: 0.99832, F1: 0.2284, Prec: 0.2619, Rec: 0.2456 lr: 0.00070\n",
      "Epoch 3/Step 650, Loss: -0.11690, Accuracy: 0.99832, F1: 0.2285, Prec: 0.2617, Rec: 0.2457 lr: 0.00070\n",
      "Epoch 3/Step 660, Loss: -0.13913, Accuracy: 0.99832, F1: 0.2286, Prec: 0.2620, Rec: 0.2459 lr: 0.00070\n",
      "Epoch 3/Step 670, Loss: -0.10037, Accuracy: 0.99832, F1: 0.2286, Prec: 0.2621, Rec: 0.2461 lr: 0.00070\n",
      "Epoch 3/Step 680, Loss: -0.10885, Accuracy: 0.99832, F1: 0.2286, Prec: 0.2620, Rec: 0.2462 lr: 0.00070\n",
      "Epoch 3/Step 690, Loss: -0.13839, Accuracy: 0.99832, F1: 0.2285, Prec: 0.2620, Rec: 0.2461 lr: 0.00070\n",
      "Epoch 3/Step 700, Loss: -0.12263, Accuracy: 0.99832, F1: 0.2284, Prec: 0.2620, Rec: 0.2460 lr: 0.00070\n",
      "Epoch 3/Step 710, Loss: -0.12631, Accuracy: 0.99832, F1: 0.2284, Prec: 0.2620, Rec: 0.2464 lr: 0.00070\n",
      "Epoch 3/Step 720, Loss: -0.13784, Accuracy: 0.99832, F1: 0.2286, Prec: 0.2622, Rec: 0.2465 lr: 0.00070\n",
      "Epoch 3/Step 730, Loss: -0.11979, Accuracy: 0.99833, F1: 0.2286, Prec: 0.2626, Rec: 0.2461 lr: 0.00070\n",
      "Epoch 3/Step 740, Loss: -0.11598, Accuracy: 0.99833, F1: 0.2286, Prec: 0.2623, Rec: 0.2459 lr: 0.00070\n",
      "Epoch 3/Step 750, Loss: -0.11142, Accuracy: 0.99833, F1: 0.2288, Prec: 0.2624, Rec: 0.2461 lr: 0.00070\n",
      "Epoch 3/Step 760, Loss: -0.13415, Accuracy: 0.99833, F1: 0.2289, Prec: 0.2626, Rec: 0.2459 lr: 0.00070\n",
      "Epoch 3/Step 770, Loss: -0.11610, Accuracy: 0.99833, F1: 0.2289, Prec: 0.2625, Rec: 0.2460 lr: 0.00070\n",
      "Epoch 3/Step 780, Loss: -0.12958, Accuracy: 0.99833, F1: 0.2292, Prec: 0.2630, Rec: 0.2461 lr: 0.00070\n",
      "Epoch 3/Step 790, Loss: -0.13227, Accuracy: 0.99833, F1: 0.2293, Prec: 0.2629, Rec: 0.2461 lr: 0.00070\n",
      "Epoch 3/Step 800, Loss: -0.11615, Accuracy: 0.99833, F1: 0.2294, Prec: 0.2629, Rec: 0.2458 lr: 0.00070\n",
      "Epoch 3/Step 810, Loss: -0.10260, Accuracy: 0.99833, F1: 0.2295, Prec: 0.2629, Rec: 0.2459 lr: 0.00070\n",
      "Epoch 3/Step 820, Loss: -0.13472, Accuracy: 0.99833, F1: 0.2293, Prec: 0.2626, Rec: 0.2459 lr: 0.00070\n",
      "Epoch 3/Step 830, Loss: -0.11925, Accuracy: 0.99833, F1: 0.2292, Prec: 0.2629, Rec: 0.2459 lr: 0.00070\n",
      "Epoch 3/Step 840, Loss: -0.13214, Accuracy: 0.99833, F1: 0.2293, Prec: 0.2630, Rec: 0.2459 lr: 0.00070\n",
      "Epoch 3/Step 850, Loss: -0.11394, Accuracy: 0.99833, F1: 0.2294, Prec: 0.2630, Rec: 0.2458 lr: 0.00070\n",
      "Epoch 3/Step 860, Loss: -0.12969, Accuracy: 0.99833, F1: 0.2295, Prec: 0.2632, Rec: 0.2457 lr: 0.00070\n",
      "Epoch 3/Step 870, Loss: -0.13205, Accuracy: 0.99833, F1: 0.2295, Prec: 0.2634, Rec: 0.2454 lr: 0.00070\n",
      "Epoch 3/Step 880, Loss: -0.11657, Accuracy: 0.99833, F1: 0.2299, Prec: 0.2634, Rec: 0.2455 lr: 0.00070\n",
      "Epoch 3/Step 890, Loss: -0.12716, Accuracy: 0.99833, F1: 0.2298, Prec: 0.2635, Rec: 0.2456 lr: 0.00070\n",
      "Epoch 3/Step 900, Loss: -0.16869, Accuracy: 0.99834, F1: 0.2300, Prec: 0.2642, Rec: 0.2456 lr: 0.00070\n",
      "Epoch 3/Step 910, Loss: -0.09892, Accuracy: 0.99834, F1: 0.2301, Prec: 0.2642, Rec: 0.2455 lr: 0.00070\n",
      "Epoch 3/Step 920, Loss: -0.12240, Accuracy: 0.99834, F1: 0.2303, Prec: 0.2642, Rec: 0.2456 lr: 0.00070\n",
      "Epoch 3/Step 930, Loss: -0.11565, Accuracy: 0.99834, F1: 0.2303, Prec: 0.2643, Rec: 0.2459 lr: 0.00070\n",
      "Epoch 3/Step 940, Loss: -0.11051, Accuracy: 0.99834, F1: 0.2302, Prec: 0.2642, Rec: 0.2459 lr: 0.00070\n",
      "Epoch 3/Step 950, Loss: -0.13765, Accuracy: 0.99834, F1: 0.2305, Prec: 0.2647, Rec: 0.2458 lr: 0.00070\n",
      "Epoch 3/Step 960, Loss: -0.13654, Accuracy: 0.99834, F1: 0.2305, Prec: 0.2645, Rec: 0.2460 lr: 0.00070\n",
      "Epoch 3/Step 970, Loss: -0.12070, Accuracy: 0.99834, F1: 0.2305, Prec: 0.2644, Rec: 0.2458 lr: 0.00070\n",
      "Epoch 3/Step 980, Loss: -0.13760, Accuracy: 0.99834, F1: 0.2305, Prec: 0.2643, Rec: 0.2458 lr: 0.00070\n",
      "Epoch 3/Step 990, Loss: -0.11435, Accuracy: 0.99834, F1: 0.2305, Prec: 0.2641, Rec: 0.2458 lr: 0.00070\n",
      "Epoch 3/Step 1000, Loss: -0.14037, Accuracy: 0.99834, F1: 0.2305, Prec: 0.2641, Rec: 0.2461 lr: 0.00070\n",
      "Epoch 3/Step 1010, Loss: -0.14822, Accuracy: 0.99834, F1: 0.2307, Prec: 0.2644, Rec: 0.2463 lr: 0.00070\n",
      "Epoch 3/Step 1020, Loss: -0.11388, Accuracy: 0.99834, F1: 0.2307, Prec: 0.2643, Rec: 0.2462 lr: 0.00070\n",
      "Epoch 3/Step 1030, Loss: -0.11156, Accuracy: 0.99834, F1: 0.2307, Prec: 0.2644, Rec: 0.2463 lr: 0.00070\n",
      "Epoch 3/Step 1040, Loss: -0.12749, Accuracy: 0.99834, F1: 0.2307, Prec: 0.2646, Rec: 0.2463 lr: 0.00070\n",
      "Epoch 3/Step 1050, Loss: -0.13718, Accuracy: 0.99834, F1: 0.2306, Prec: 0.2646, Rec: 0.2463 lr: 0.00070\n",
      "Epoch 3/Step 1060, Loss: -0.13128, Accuracy: 0.99834, F1: 0.2305, Prec: 0.2645, Rec: 0.2465 lr: 0.00070\n",
      "Epoch 3/Step 1070, Loss: -0.12755, Accuracy: 0.99834, F1: 0.2307, Prec: 0.2647, Rec: 0.2466 lr: 0.00070\n",
      "Epoch 3/Step 1080, Loss: -0.11017, Accuracy: 0.99834, F1: 0.2308, Prec: 0.2648, Rec: 0.2467 lr: 0.00070\n",
      "Epoch 3/Step 1090, Loss: -0.11505, Accuracy: 0.99834, F1: 0.2308, Prec: 0.2649, Rec: 0.2468 lr: 0.00070\n",
      "Epoch 3/Step 1100, Loss: -0.13234, Accuracy: 0.99835, F1: 0.2310, Prec: 0.2649, Rec: 0.2468 lr: 0.00070\n",
      "Epoch 3/Step 1110, Loss: -0.10914, Accuracy: 0.99834, F1: 0.2310, Prec: 0.2651, Rec: 0.2468 lr: 0.00070\n",
      "Epoch 3/Step 1120, Loss: -0.11361, Accuracy: 0.99834, F1: 0.2310, Prec: 0.2649, Rec: 0.2469 lr: 0.00070\n",
      "Epoch 3/Step 1130, Loss: -0.11998, Accuracy: 0.99835, F1: 0.2309, Prec: 0.2650, Rec: 0.2470 lr: 0.00070\n",
      "Epoch 3/Step 1140, Loss: -0.11194, Accuracy: 0.99835, F1: 0.2309, Prec: 0.2650, Rec: 0.2470 lr: 0.00070\n",
      "Epoch 3/Step 1150, Loss: -0.11979, Accuracy: 0.99835, F1: 0.2310, Prec: 0.2648, Rec: 0.2472 lr: 0.00070\n",
      "Epoch 3/Step 1160, Loss: -0.12935, Accuracy: 0.99835, F1: 0.2311, Prec: 0.2650, Rec: 0.2475 lr: 0.00070\n",
      "Epoch 3/Step 1170, Loss: -0.12121, Accuracy: 0.99835, F1: 0.2311, Prec: 0.2653, Rec: 0.2474 lr: 0.00070\n",
      "Epoch 3/Step 1180, Loss: -0.09987, Accuracy: 0.99835, F1: 0.2313, Prec: 0.2655, Rec: 0.2474 lr: 0.00070\n",
      "Epoch 3/Step 1190, Loss: -0.13759, Accuracy: 0.99835, F1: 0.2311, Prec: 0.2655, Rec: 0.2472 lr: 0.00070\n",
      "Epoch 3/Step 1200, Loss: -0.12227, Accuracy: 0.99835, F1: 0.2311, Prec: 0.2656, Rec: 0.2475 lr: 0.00070\n",
      "Epoch 3/Step 1210, Loss: -0.12509, Accuracy: 0.99835, F1: 0.2312, Prec: 0.2659, Rec: 0.2477 lr: 0.00070\n",
      "Epoch 3/Step 1220, Loss: -0.12647, Accuracy: 0.99835, F1: 0.2311, Prec: 0.2657, Rec: 0.2478 lr: 0.00070\n",
      "Epoch 3/Step 1230, Loss: -0.14204, Accuracy: 0.99835, F1: 0.2312, Prec: 0.2658, Rec: 0.2477 lr: 0.00070\n",
      "Epoch 3/Step 1240, Loss: -0.16839, Accuracy: 0.99835, F1: 0.2314, Prec: 0.2662, Rec: 0.2477 lr: 0.00070\n",
      "Epoch 3/Step 1250, Loss: -0.10933, Accuracy: 0.99835, F1: 0.2315, Prec: 0.2662, Rec: 0.2478 lr: 0.00070\n",
      "Epoch 3/Step 1260, Loss: -0.12478, Accuracy: 0.99835, F1: 0.2316, Prec: 0.2664, Rec: 0.2479 lr: 0.00070\n",
      "Epoch 3/Step 1270, Loss: -0.11503, Accuracy: 0.99836, F1: 0.2315, Prec: 0.2666, Rec: 0.2479 lr: 0.00070\n",
      "Epoch 3/Step 1280, Loss: -0.17313, Accuracy: 0.99836, F1: 0.2317, Prec: 0.2667, Rec: 0.2479 lr: 0.00070\n",
      "Epoch 3/Step 1290, Loss: -0.14853, Accuracy: 0.99836, F1: 0.2318, Prec: 0.2667, Rec: 0.2482 lr: 0.00070\n",
      "Epoch 3/Step 1300, Loss: -0.12848, Accuracy: 0.99836, F1: 0.2319, Prec: 0.2667, Rec: 0.2482 lr: 0.00070\n",
      "Epoch 3/Step 1310, Loss: -0.14084, Accuracy: 0.99836, F1: 0.2320, Prec: 0.2669, Rec: 0.2483 lr: 0.00070\n",
      "Epoch 3/Step 1320, Loss: -0.12116, Accuracy: 0.99836, F1: 0.2321, Prec: 0.2671, Rec: 0.2484 lr: 0.00070\n",
      "Epoch 3/Step 1330, Loss: -0.14306, Accuracy: 0.99836, F1: 0.2322, Prec: 0.2673, Rec: 0.2484 lr: 0.00070\n",
      "Epoch 3/Step 1340, Loss: -0.12701, Accuracy: 0.99836, F1: 0.2323, Prec: 0.2675, Rec: 0.2486 lr: 0.00070\n",
      "Epoch 3/Step 1350, Loss: -0.11143, Accuracy: 0.99836, F1: 0.2323, Prec: 0.2675, Rec: 0.2486 lr: 0.00070\n",
      "Epoch 3/Step 1360, Loss: -0.10463, Accuracy: 0.99836, F1: 0.2324, Prec: 0.2676, Rec: 0.2485 lr: 0.00070\n",
      "Epoch 3/Step 1370, Loss: -0.12705, Accuracy: 0.99836, F1: 0.2324, Prec: 0.2677, Rec: 0.2487 lr: 0.00070\n",
      "Epoch 3/Step 1380, Loss: -0.13014, Accuracy: 0.99836, F1: 0.2324, Prec: 0.2677, Rec: 0.2488 lr: 0.00070\n",
      "Epoch 3/Step 1390, Loss: -0.14384, Accuracy: 0.99836, F1: 0.2323, Prec: 0.2676, Rec: 0.2487 lr: 0.00070\n",
      "Epoch 3/Step 1400, Loss: -0.12571, Accuracy: 0.99836, F1: 0.2323, Prec: 0.2676, Rec: 0.2488 lr: 0.00070\n",
      "Epoch 3/Step 1410, Loss: -0.14067, Accuracy: 0.99836, F1: 0.2324, Prec: 0.2678, Rec: 0.2488 lr: 0.00070\n",
      "Epoch 3/Step 1420, Loss: -0.12124, Accuracy: 0.99836, F1: 0.2323, Prec: 0.2677, Rec: 0.2488 lr: 0.00070\n",
      "Epoch 3/Step 1430, Loss: -0.12049, Accuracy: 0.99836, F1: 0.2325, Prec: 0.2678, Rec: 0.2488 lr: 0.00070\n",
      "Epoch 3/Step 1440, Loss: -0.11344, Accuracy: 0.99836, F1: 0.2325, Prec: 0.2678, Rec: 0.2489 lr: 0.00070\n",
      "Epoch 3/Step 1450, Loss: -0.11579, Accuracy: 0.99836, F1: 0.2325, Prec: 0.2680, Rec: 0.2489 lr: 0.00070\n",
      "Epoch 3/Step 1460, Loss: -0.10522, Accuracy: 0.99836, F1: 0.2326, Prec: 0.2679, Rec: 0.2489 lr: 0.00070\n",
      "Epoch 3/Step 1470, Loss: -0.14755, Accuracy: 0.99836, F1: 0.2327, Prec: 0.2680, Rec: 0.2489 lr: 0.00070\n",
      "Epoch 3/Step 1480, Loss: -0.13866, Accuracy: 0.99836, F1: 0.2326, Prec: 0.2682, Rec: 0.2489 lr: 0.00070\n",
      "Epoch 3/Step 1490, Loss: -0.11845, Accuracy: 0.99836, F1: 0.2327, Prec: 0.2683, Rec: 0.2491 lr: 0.00070\n",
      "Epoch 3/Step 1500, Loss: -0.13660, Accuracy: 0.99836, F1: 0.2327, Prec: 0.2684, Rec: 0.2491 lr: 0.00070\n",
      "Epoch 3/Step 1510, Loss: -0.12561, Accuracy: 0.99836, F1: 0.2327, Prec: 0.2686, Rec: 0.2491 lr: 0.00070\n",
      "Epoch 3/Step 1520, Loss: -0.15688, Accuracy: 0.99836, F1: 0.2328, Prec: 0.2687, Rec: 0.2493 lr: 0.00070\n",
      "Epoch 3/Step 1530, Loss: -0.11970, Accuracy: 0.99837, F1: 0.2328, Prec: 0.2690, Rec: 0.2494 lr: 0.00070\n",
      "Epoch 3/Step 1540, Loss: -0.10298, Accuracy: 0.99837, F1: 0.2328, Prec: 0.2690, Rec: 0.2494 lr: 0.00070\n",
      "Epoch 3/Step 1550, Loss: -0.13868, Accuracy: 0.99837, F1: 0.2330, Prec: 0.2692, Rec: 0.2495 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9984\n",
      "Validation f1: 0.2360\n",
      "Validation precision: 0.2763\n",
      "Validation recall: 0.2412\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_2_valF1Score0.236/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_2_valF1Score0.236/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 4\n",
      "Epoch 4/Step 0, Loss: -0.13741, Accuracy: 0.99858, F1: 0.2867, Prec: 0.3166, Rec: 0.2633 lr: 0.00070\n",
      "Epoch 4/Step 10, Loss: -0.13978, Accuracy: 0.99838, F1: 0.2571, Prec: 0.3145, Rec: 0.2621 lr: 0.00070\n",
      "Epoch 4/Step 20, Loss: -0.12380, Accuracy: 0.99839, F1: 0.2522, Prec: 0.2965, Rec: 0.2664 lr: 0.00070\n",
      "Epoch 4/Step 30, Loss: -0.12664, Accuracy: 0.99844, F1: 0.2478, Prec: 0.2976, Rec: 0.2675 lr: 0.00070\n",
      "Epoch 4/Step 40, Loss: -0.11770, Accuracy: 0.99842, F1: 0.2513, Prec: 0.2969, Rec: 0.2687 lr: 0.00070\n",
      "Epoch 4/Step 50, Loss: -0.14348, Accuracy: 0.99840, F1: 0.2507, Prec: 0.2931, Rec: 0.2721 lr: 0.00070\n",
      "Epoch 4/Step 60, Loss: -0.15116, Accuracy: 0.99842, F1: 0.2489, Prec: 0.2948, Rec: 0.2695 lr: 0.00070\n",
      "Epoch 4/Step 70, Loss: -0.13453, Accuracy: 0.99845, F1: 0.2472, Prec: 0.2947, Rec: 0.2708 lr: 0.00070\n",
      "Epoch 4/Step 80, Loss: -0.12674, Accuracy: 0.99846, F1: 0.2468, Prec: 0.2943, Rec: 0.2683 lr: 0.00070\n",
      "Epoch 4/Step 90, Loss: -0.12562, Accuracy: 0.99845, F1: 0.2474, Prec: 0.2949, Rec: 0.2684 lr: 0.00070\n",
      "Epoch 4/Step 100, Loss: -0.15424, Accuracy: 0.99846, F1: 0.2480, Prec: 0.2958, Rec: 0.2705 lr: 0.00070\n",
      "Epoch 4/Step 110, Loss: -0.13780, Accuracy: 0.99845, F1: 0.2492, Prec: 0.2981, Rec: 0.2672 lr: 0.00070\n",
      "Epoch 4/Step 120, Loss: -0.11199, Accuracy: 0.99845, F1: 0.2489, Prec: 0.2976, Rec: 0.2671 lr: 0.00070\n",
      "Epoch 4/Step 130, Loss: -0.12290, Accuracy: 0.99845, F1: 0.2481, Prec: 0.2982, Rec: 0.2671 lr: 0.00070\n",
      "Epoch 4/Step 140, Loss: -0.13345, Accuracy: 0.99845, F1: 0.2481, Prec: 0.3002, Rec: 0.2634 lr: 0.00070\n",
      "Epoch 4/Step 150, Loss: -0.11861, Accuracy: 0.99843, F1: 0.2491, Prec: 0.2983, Rec: 0.2638 lr: 0.00070\n",
      "Epoch 4/Step 160, Loss: -0.13102, Accuracy: 0.99843, F1: 0.2481, Prec: 0.2958, Rec: 0.2650 lr: 0.00070\n",
      "Epoch 4/Step 170, Loss: -0.10871, Accuracy: 0.99843, F1: 0.2475, Prec: 0.2947, Rec: 0.2640 lr: 0.00070\n",
      "Epoch 4/Step 180, Loss: -0.12921, Accuracy: 0.99843, F1: 0.2476, Prec: 0.2952, Rec: 0.2641 lr: 0.00070\n",
      "Epoch 4/Step 190, Loss: -0.12782, Accuracy: 0.99843, F1: 0.2470, Prec: 0.2945, Rec: 0.2639 lr: 0.00070\n",
      "Epoch 4/Step 200, Loss: -0.12680, Accuracy: 0.99842, F1: 0.2466, Prec: 0.2952, Rec: 0.2628 lr: 0.00070\n",
      "Epoch 4/Step 210, Loss: -0.12193, Accuracy: 0.99841, F1: 0.2465, Prec: 0.2937, Rec: 0.2635 lr: 0.00070\n",
      "Epoch 4/Step 220, Loss: -0.15476, Accuracy: 0.99841, F1: 0.2466, Prec: 0.2942, Rec: 0.2634 lr: 0.00070\n",
      "Epoch 4/Step 230, Loss: -0.10679, Accuracy: 0.99841, F1: 0.2466, Prec: 0.2944, Rec: 0.2629 lr: 0.00070\n",
      "Epoch 4/Step 240, Loss: -0.16342, Accuracy: 0.99841, F1: 0.2471, Prec: 0.2955, Rec: 0.2631 lr: 0.00070\n",
      "Epoch 4/Step 250, Loss: -0.13134, Accuracy: 0.99841, F1: 0.2469, Prec: 0.2947, Rec: 0.2630 lr: 0.00070\n",
      "Epoch 4/Step 260, Loss: -0.13819, Accuracy: 0.99840, F1: 0.2473, Prec: 0.2943, Rec: 0.2636 lr: 0.00070\n",
      "Epoch 4/Step 270, Loss: -0.16373, Accuracy: 0.99840, F1: 0.2489, Prec: 0.2946, Rec: 0.2638 lr: 0.00070\n",
      "Epoch 4/Step 280, Loss: -0.14740, Accuracy: 0.99840, F1: 0.2510, Prec: 0.2952, Rec: 0.2633 lr: 0.00070\n",
      "Epoch 4/Step 290, Loss: -0.12816, Accuracy: 0.99840, F1: 0.2512, Prec: 0.2942, Rec: 0.2631 lr: 0.00070\n",
      "Epoch 4/Step 300, Loss: -0.15008, Accuracy: 0.99840, F1: 0.2515, Prec: 0.2944, Rec: 0.2634 lr: 0.00070\n",
      "Epoch 4/Step 310, Loss: -0.14075, Accuracy: 0.99840, F1: 0.2510, Prec: 0.2939, Rec: 0.2636 lr: 0.00070\n",
      "Epoch 4/Step 320, Loss: -0.14434, Accuracy: 0.99840, F1: 0.2511, Prec: 0.2944, Rec: 0.2641 lr: 0.00070\n",
      "Epoch 4/Step 330, Loss: -0.15696, Accuracy: 0.99841, F1: 0.2513, Prec: 0.2955, Rec: 0.2643 lr: 0.00070\n",
      "Epoch 4/Step 340, Loss: -0.13243, Accuracy: 0.99841, F1: 0.2514, Prec: 0.2961, Rec: 0.2641 lr: 0.00070\n",
      "Epoch 4/Step 350, Loss: -0.11866, Accuracy: 0.99841, F1: 0.2513, Prec: 0.2963, Rec: 0.2641 lr: 0.00070\n",
      "Epoch 4/Step 360, Loss: -0.15909, Accuracy: 0.99841, F1: 0.2515, Prec: 0.2971, Rec: 0.2647 lr: 0.00070\n",
      "Epoch 4/Step 370, Loss: -0.14000, Accuracy: 0.99841, F1: 0.2512, Prec: 0.2964, Rec: 0.2647 lr: 0.00070\n",
      "Epoch 4/Step 380, Loss: -0.16486, Accuracy: 0.99842, F1: 0.2508, Prec: 0.2971, Rec: 0.2645 lr: 0.00070\n",
      "Epoch 4/Step 390, Loss: -0.13087, Accuracy: 0.99842, F1: 0.2502, Prec: 0.2974, Rec: 0.2638 lr: 0.00070\n",
      "Epoch 4/Step 400, Loss: -0.10375, Accuracy: 0.99842, F1: 0.2499, Prec: 0.2965, Rec: 0.2641 lr: 0.00070\n",
      "Epoch 4/Step 410, Loss: -0.13013, Accuracy: 0.99842, F1: 0.2495, Prec: 0.2961, Rec: 0.2640 lr: 0.00070\n",
      "Epoch 4/Step 420, Loss: -0.15028, Accuracy: 0.99842, F1: 0.2496, Prec: 0.2968, Rec: 0.2642 lr: 0.00070\n",
      "Epoch 4/Step 430, Loss: -0.12589, Accuracy: 0.99842, F1: 0.2494, Prec: 0.2966, Rec: 0.2644 lr: 0.00070\n",
      "Epoch 4/Step 440, Loss: -0.12528, Accuracy: 0.99842, F1: 0.2496, Prec: 0.2969, Rec: 0.2646 lr: 0.00070\n",
      "Epoch 4/Step 450, Loss: -0.13311, Accuracy: 0.99842, F1: 0.2499, Prec: 0.2969, Rec: 0.2645 lr: 0.00070\n",
      "Epoch 4/Step 460, Loss: -0.12723, Accuracy: 0.99842, F1: 0.2494, Prec: 0.2964, Rec: 0.2647 lr: 0.00070\n",
      "Epoch 4/Step 470, Loss: -0.12013, Accuracy: 0.99842, F1: 0.2492, Prec: 0.2969, Rec: 0.2643 lr: 0.00070\n",
      "Epoch 4/Step 480, Loss: -0.13334, Accuracy: 0.99842, F1: 0.2491, Prec: 0.2968, Rec: 0.2639 lr: 0.00070\n",
      "Epoch 4/Step 490, Loss: -0.12788, Accuracy: 0.99842, F1: 0.2489, Prec: 0.2962, Rec: 0.2639 lr: 0.00070\n",
      "Epoch 4/Step 500, Loss: -0.13309, Accuracy: 0.99842, F1: 0.2485, Prec: 0.2959, Rec: 0.2639 lr: 0.00070\n",
      "Epoch 4/Step 510, Loss: -0.15909, Accuracy: 0.99842, F1: 0.2486, Prec: 0.2961, Rec: 0.2641 lr: 0.00070\n",
      "Epoch 4/Step 520, Loss: -0.11504, Accuracy: 0.99842, F1: 0.2486, Prec: 0.2969, Rec: 0.2643 lr: 0.00070\n",
      "Epoch 4/Step 530, Loss: -0.12783, Accuracy: 0.99842, F1: 0.2485, Prec: 0.2966, Rec: 0.2641 lr: 0.00070\n",
      "Epoch 4/Step 540, Loss: -0.11252, Accuracy: 0.99842, F1: 0.2485, Prec: 0.2966, Rec: 0.2639 lr: 0.00070\n",
      "Epoch 4/Step 550, Loss: -0.16143, Accuracy: 0.99842, F1: 0.2488, Prec: 0.2970, Rec: 0.2641 lr: 0.00070\n",
      "Epoch 4/Step 560, Loss: -0.13819, Accuracy: 0.99842, F1: 0.2488, Prec: 0.2971, Rec: 0.2641 lr: 0.00070\n",
      "Epoch 4/Step 570, Loss: -0.13165, Accuracy: 0.99842, F1: 0.2487, Prec: 0.2973, Rec: 0.2641 lr: 0.00070\n",
      "Epoch 4/Step 580, Loss: -0.14512, Accuracy: 0.99842, F1: 0.2488, Prec: 0.2976, Rec: 0.2642 lr: 0.00070\n",
      "Epoch 4/Step 590, Loss: -0.10326, Accuracy: 0.99842, F1: 0.2486, Prec: 0.2973, Rec: 0.2641 lr: 0.00070\n",
      "Epoch 4/Step 600, Loss: -0.11532, Accuracy: 0.99842, F1: 0.2486, Prec: 0.2980, Rec: 0.2639 lr: 0.00070\n",
      "Epoch 4/Step 610, Loss: -0.14951, Accuracy: 0.99842, F1: 0.2487, Prec: 0.2979, Rec: 0.2638 lr: 0.00070\n",
      "Epoch 4/Step 620, Loss: -0.15973, Accuracy: 0.99842, F1: 0.2489, Prec: 0.2980, Rec: 0.2645 lr: 0.00070\n",
      "Epoch 4/Step 630, Loss: -0.14629, Accuracy: 0.99842, F1: 0.2492, Prec: 0.2982, Rec: 0.2645 lr: 0.00070\n",
      "Epoch 4/Step 640, Loss: -0.14398, Accuracy: 0.99842, F1: 0.2492, Prec: 0.2986, Rec: 0.2645 lr: 0.00070\n",
      "Epoch 4/Step 650, Loss: -0.13528, Accuracy: 0.99842, F1: 0.2492, Prec: 0.2984, Rec: 0.2646 lr: 0.00070\n",
      "Epoch 4/Step 660, Loss: -0.15174, Accuracy: 0.99842, F1: 0.2493, Prec: 0.2986, Rec: 0.2648 lr: 0.00070\n",
      "Epoch 4/Step 670, Loss: -0.11036, Accuracy: 0.99842, F1: 0.2492, Prec: 0.2989, Rec: 0.2648 lr: 0.00070\n",
      "Epoch 4/Step 680, Loss: -0.11351, Accuracy: 0.99842, F1: 0.2490, Prec: 0.2989, Rec: 0.2648 lr: 0.00070\n",
      "Epoch 4/Step 690, Loss: -0.15678, Accuracy: 0.99842, F1: 0.2489, Prec: 0.2989, Rec: 0.2648 lr: 0.00070\n",
      "Epoch 4/Step 700, Loss: -0.13740, Accuracy: 0.99843, F1: 0.2487, Prec: 0.2989, Rec: 0.2646 lr: 0.00070\n",
      "Epoch 4/Step 710, Loss: -0.15082, Accuracy: 0.99843, F1: 0.2487, Prec: 0.2992, Rec: 0.2651 lr: 0.00070\n",
      "Epoch 4/Step 720, Loss: -0.14792, Accuracy: 0.99843, F1: 0.2489, Prec: 0.2993, Rec: 0.2650 lr: 0.00070\n",
      "Epoch 4/Step 730, Loss: -0.12826, Accuracy: 0.99843, F1: 0.2491, Prec: 0.2996, Rec: 0.2648 lr: 0.00070\n",
      "Epoch 4/Step 740, Loss: -0.13939, Accuracy: 0.99843, F1: 0.2492, Prec: 0.2995, Rec: 0.2647 lr: 0.00070\n",
      "Epoch 4/Step 750, Loss: -0.12137, Accuracy: 0.99843, F1: 0.2495, Prec: 0.2996, Rec: 0.2648 lr: 0.00070\n",
      "Epoch 4/Step 760, Loss: -0.15267, Accuracy: 0.99843, F1: 0.2497, Prec: 0.2998, Rec: 0.2647 lr: 0.00070\n",
      "Epoch 4/Step 770, Loss: -0.14580, Accuracy: 0.99843, F1: 0.2496, Prec: 0.2998, Rec: 0.2649 lr: 0.00070\n",
      "Epoch 4/Step 780, Loss: -0.13168, Accuracy: 0.99844, F1: 0.2500, Prec: 0.3005, Rec: 0.2650 lr: 0.00070\n",
      "Epoch 4/Step 790, Loss: -0.14262, Accuracy: 0.99843, F1: 0.2500, Prec: 0.3003, Rec: 0.2650 lr: 0.00070\n",
      "Epoch 4/Step 800, Loss: -0.12184, Accuracy: 0.99843, F1: 0.2500, Prec: 0.3001, Rec: 0.2648 lr: 0.00070\n",
      "Epoch 4/Step 810, Loss: -0.10875, Accuracy: 0.99843, F1: 0.2501, Prec: 0.3000, Rec: 0.2648 lr: 0.00070\n",
      "Epoch 4/Step 820, Loss: -0.14636, Accuracy: 0.99844, F1: 0.2499, Prec: 0.2996, Rec: 0.2648 lr: 0.00070\n",
      "Epoch 4/Step 830, Loss: -0.13730, Accuracy: 0.99844, F1: 0.2497, Prec: 0.2998, Rec: 0.2649 lr: 0.00070\n",
      "Epoch 4/Step 840, Loss: -0.14874, Accuracy: 0.99844, F1: 0.2499, Prec: 0.3001, Rec: 0.2648 lr: 0.00070\n",
      "Epoch 4/Step 850, Loss: -0.12843, Accuracy: 0.99844, F1: 0.2500, Prec: 0.3003, Rec: 0.2647 lr: 0.00070\n",
      "Epoch 4/Step 860, Loss: -0.14993, Accuracy: 0.99844, F1: 0.2500, Prec: 0.3005, Rec: 0.2646 lr: 0.00070\n",
      "Epoch 4/Step 870, Loss: -0.14789, Accuracy: 0.99844, F1: 0.2500, Prec: 0.3006, Rec: 0.2644 lr: 0.00070\n",
      "Epoch 4/Step 880, Loss: -0.12533, Accuracy: 0.99844, F1: 0.2503, Prec: 0.3007, Rec: 0.2644 lr: 0.00070\n",
      "Epoch 4/Step 890, Loss: -0.13942, Accuracy: 0.99844, F1: 0.2502, Prec: 0.3007, Rec: 0.2644 lr: 0.00070\n",
      "Epoch 4/Step 900, Loss: -0.18632, Accuracy: 0.99844, F1: 0.2504, Prec: 0.3014, Rec: 0.2645 lr: 0.00070\n",
      "Epoch 4/Step 910, Loss: -0.10933, Accuracy: 0.99844, F1: 0.2503, Prec: 0.3015, Rec: 0.2642 lr: 0.00070\n",
      "Epoch 4/Step 920, Loss: -0.13561, Accuracy: 0.99844, F1: 0.2505, Prec: 0.3015, Rec: 0.2642 lr: 0.00070\n",
      "Epoch 4/Step 930, Loss: -0.12540, Accuracy: 0.99844, F1: 0.2505, Prec: 0.3014, Rec: 0.2644 lr: 0.00070\n",
      "Epoch 4/Step 940, Loss: -0.12904, Accuracy: 0.99844, F1: 0.2502, Prec: 0.3013, Rec: 0.2643 lr: 0.00070\n",
      "Epoch 4/Step 950, Loss: -0.15374, Accuracy: 0.99845, F1: 0.2504, Prec: 0.3016, Rec: 0.2644 lr: 0.00070\n",
      "Epoch 4/Step 960, Loss: -0.15184, Accuracy: 0.99845, F1: 0.2504, Prec: 0.3015, Rec: 0.2643 lr: 0.00070\n",
      "Epoch 4/Step 970, Loss: -0.13188, Accuracy: 0.99845, F1: 0.2504, Prec: 0.3015, Rec: 0.2641 lr: 0.00070\n",
      "Epoch 4/Step 980, Loss: -0.15302, Accuracy: 0.99845, F1: 0.2503, Prec: 0.3015, Rec: 0.2640 lr: 0.00070\n",
      "Epoch 4/Step 990, Loss: -0.12444, Accuracy: 0.99845, F1: 0.2502, Prec: 0.3011, Rec: 0.2640 lr: 0.00070\n",
      "Epoch 4/Step 1000, Loss: -0.15573, Accuracy: 0.99845, F1: 0.2502, Prec: 0.3010, Rec: 0.2642 lr: 0.00070\n",
      "Epoch 4/Step 1010, Loss: -0.16596, Accuracy: 0.99845, F1: 0.2503, Prec: 0.3013, Rec: 0.2644 lr: 0.00070\n",
      "Epoch 4/Step 1020, Loss: -0.12316, Accuracy: 0.99845, F1: 0.2503, Prec: 0.3013, Rec: 0.2643 lr: 0.00070\n",
      "Epoch 4/Step 1030, Loss: -0.13232, Accuracy: 0.99845, F1: 0.2503, Prec: 0.3014, Rec: 0.2644 lr: 0.00070\n",
      "Epoch 4/Step 1040, Loss: -0.14454, Accuracy: 0.99845, F1: 0.2503, Prec: 0.3016, Rec: 0.2643 lr: 0.00070\n",
      "Epoch 4/Step 1050, Loss: -0.14993, Accuracy: 0.99845, F1: 0.2502, Prec: 0.3016, Rec: 0.2643 lr: 0.00070\n",
      "Epoch 4/Step 1060, Loss: -0.14951, Accuracy: 0.99845, F1: 0.2501, Prec: 0.3015, Rec: 0.2645 lr: 0.00070\n",
      "Epoch 4/Step 1070, Loss: -0.14174, Accuracy: 0.99845, F1: 0.2503, Prec: 0.3017, Rec: 0.2646 lr: 0.00070\n",
      "Epoch 4/Step 1080, Loss: -0.12022, Accuracy: 0.99845, F1: 0.2504, Prec: 0.3019, Rec: 0.2646 lr: 0.00070\n",
      "Epoch 4/Step 1090, Loss: -0.12132, Accuracy: 0.99845, F1: 0.2504, Prec: 0.3018, Rec: 0.2646 lr: 0.00070\n",
      "Epoch 4/Step 1100, Loss: -0.14509, Accuracy: 0.99845, F1: 0.2505, Prec: 0.3019, Rec: 0.2646 lr: 0.00070\n",
      "Epoch 4/Step 1110, Loss: -0.12255, Accuracy: 0.99845, F1: 0.2505, Prec: 0.3021, Rec: 0.2647 lr: 0.00070\n",
      "Epoch 4/Step 1120, Loss: -0.13027, Accuracy: 0.99845, F1: 0.2505, Prec: 0.3021, Rec: 0.2647 lr: 0.00070\n",
      "Epoch 4/Step 1130, Loss: -0.12160, Accuracy: 0.99845, F1: 0.2504, Prec: 0.3023, Rec: 0.2648 lr: 0.00070\n",
      "Epoch 4/Step 1140, Loss: -0.12368, Accuracy: 0.99846, F1: 0.2503, Prec: 0.3023, Rec: 0.2646 lr: 0.00070\n",
      "Epoch 4/Step 1150, Loss: -0.13594, Accuracy: 0.99846, F1: 0.2504, Prec: 0.3022, Rec: 0.2648 lr: 0.00070\n",
      "Epoch 4/Step 1160, Loss: -0.12739, Accuracy: 0.99846, F1: 0.2506, Prec: 0.3024, Rec: 0.2652 lr: 0.00070\n",
      "Epoch 4/Step 1170, Loss: -0.13017, Accuracy: 0.99846, F1: 0.2506, Prec: 0.3024, Rec: 0.2651 lr: 0.00070\n",
      "Epoch 4/Step 1180, Loss: -0.10854, Accuracy: 0.99846, F1: 0.2507, Prec: 0.3027, Rec: 0.2651 lr: 0.00070\n",
      "Epoch 4/Step 1190, Loss: -0.15211, Accuracy: 0.99846, F1: 0.2506, Prec: 0.3027, Rec: 0.2650 lr: 0.00070\n",
      "Epoch 4/Step 1200, Loss: -0.13652, Accuracy: 0.99846, F1: 0.2506, Prec: 0.3028, Rec: 0.2653 lr: 0.00070\n",
      "Epoch 4/Step 1210, Loss: -0.14292, Accuracy: 0.99846, F1: 0.2507, Prec: 0.3029, Rec: 0.2654 lr: 0.00070\n",
      "Epoch 4/Step 1220, Loss: -0.15234, Accuracy: 0.99846, F1: 0.2505, Prec: 0.3029, Rec: 0.2655 lr: 0.00070\n",
      "Epoch 4/Step 1230, Loss: -0.14952, Accuracy: 0.99846, F1: 0.2506, Prec: 0.3029, Rec: 0.2655 lr: 0.00070\n",
      "Epoch 4/Step 1240, Loss: -0.17452, Accuracy: 0.99846, F1: 0.2508, Prec: 0.3031, Rec: 0.2654 lr: 0.00070\n",
      "Epoch 4/Step 1250, Loss: -0.11300, Accuracy: 0.99846, F1: 0.2508, Prec: 0.3032, Rec: 0.2655 lr: 0.00070\n",
      "Epoch 4/Step 1260, Loss: -0.13595, Accuracy: 0.99846, F1: 0.2509, Prec: 0.3032, Rec: 0.2656 lr: 0.00070\n",
      "Epoch 4/Step 1270, Loss: -0.12943, Accuracy: 0.99846, F1: 0.2509, Prec: 0.3034, Rec: 0.2656 lr: 0.00070\n",
      "Epoch 4/Step 1280, Loss: -0.18776, Accuracy: 0.99846, F1: 0.2510, Prec: 0.3035, Rec: 0.2656 lr: 0.00070\n",
      "Epoch 4/Step 1290, Loss: -0.16297, Accuracy: 0.99846, F1: 0.2510, Prec: 0.3036, Rec: 0.2658 lr: 0.00070\n",
      "Epoch 4/Step 1300, Loss: -0.14541, Accuracy: 0.99846, F1: 0.2511, Prec: 0.3036, Rec: 0.2658 lr: 0.00070\n",
      "Epoch 4/Step 1310, Loss: -0.15360, Accuracy: 0.99846, F1: 0.2512, Prec: 0.3037, Rec: 0.2659 lr: 0.00070\n",
      "Epoch 4/Step 1320, Loss: -0.13137, Accuracy: 0.99846, F1: 0.2513, Prec: 0.3039, Rec: 0.2658 lr: 0.00070\n",
      "Epoch 4/Step 1330, Loss: -0.14799, Accuracy: 0.99846, F1: 0.2513, Prec: 0.3039, Rec: 0.2658 lr: 0.00070\n",
      "Epoch 4/Step 1340, Loss: -0.13946, Accuracy: 0.99846, F1: 0.2515, Prec: 0.3041, Rec: 0.2659 lr: 0.00070\n",
      "Epoch 4/Step 1350, Loss: -0.12212, Accuracy: 0.99846, F1: 0.2515, Prec: 0.3041, Rec: 0.2660 lr: 0.00070\n",
      "Epoch 4/Step 1360, Loss: -0.11794, Accuracy: 0.99846, F1: 0.2516, Prec: 0.3042, Rec: 0.2659 lr: 0.00070\n",
      "Epoch 4/Step 1370, Loss: -0.12926, Accuracy: 0.99846, F1: 0.2516, Prec: 0.3043, Rec: 0.2660 lr: 0.00070\n",
      "Epoch 4/Step 1380, Loss: -0.14488, Accuracy: 0.99846, F1: 0.2516, Prec: 0.3044, Rec: 0.2661 lr: 0.00070\n",
      "Epoch 4/Step 1390, Loss: -0.16468, Accuracy: 0.99846, F1: 0.2514, Prec: 0.3043, Rec: 0.2660 lr: 0.00070\n",
      "Epoch 4/Step 1400, Loss: -0.13715, Accuracy: 0.99847, F1: 0.2515, Prec: 0.3044, Rec: 0.2660 lr: 0.00070\n",
      "Epoch 4/Step 1410, Loss: -0.15304, Accuracy: 0.99847, F1: 0.2516, Prec: 0.3045, Rec: 0.2661 lr: 0.00070\n",
      "Epoch 4/Step 1420, Loss: -0.12675, Accuracy: 0.99847, F1: 0.2515, Prec: 0.3044, Rec: 0.2660 lr: 0.00070\n",
      "Epoch 4/Step 1430, Loss: -0.13173, Accuracy: 0.99847, F1: 0.2517, Prec: 0.3046, Rec: 0.2659 lr: 0.00070\n",
      "Epoch 4/Step 1440, Loss: -0.11639, Accuracy: 0.99847, F1: 0.2517, Prec: 0.3047, Rec: 0.2659 lr: 0.00070\n",
      "Epoch 4/Step 1450, Loss: -0.12705, Accuracy: 0.99847, F1: 0.2517, Prec: 0.3048, Rec: 0.2658 lr: 0.00070\n",
      "Epoch 4/Step 1460, Loss: -0.12561, Accuracy: 0.99847, F1: 0.2519, Prec: 0.3048, Rec: 0.2659 lr: 0.00070\n",
      "Epoch 4/Step 1470, Loss: -0.15330, Accuracy: 0.99847, F1: 0.2520, Prec: 0.3048, Rec: 0.2659 lr: 0.00070\n",
      "Epoch 4/Step 1480, Loss: -0.14676, Accuracy: 0.99847, F1: 0.2520, Prec: 0.3050, Rec: 0.2658 lr: 0.00070\n",
      "Epoch 4/Step 1490, Loss: -0.12254, Accuracy: 0.99847, F1: 0.2521, Prec: 0.3051, Rec: 0.2659 lr: 0.00070\n",
      "Epoch 4/Step 1500, Loss: -0.15164, Accuracy: 0.99847, F1: 0.2520, Prec: 0.3052, Rec: 0.2660 lr: 0.00070\n",
      "Epoch 4/Step 1510, Loss: -0.13993, Accuracy: 0.99847, F1: 0.2522, Prec: 0.3054, Rec: 0.2660 lr: 0.00070\n",
      "Epoch 4/Step 1520, Loss: -0.16440, Accuracy: 0.99847, F1: 0.2522, Prec: 0.3056, Rec: 0.2662 lr: 0.00070\n",
      "Epoch 4/Step 1530, Loss: -0.13439, Accuracy: 0.99847, F1: 0.2523, Prec: 0.3059, Rec: 0.2664 lr: 0.00070\n",
      "Epoch 4/Step 1540, Loss: -0.11602, Accuracy: 0.99847, F1: 0.2522, Prec: 0.3061, Rec: 0.2662 lr: 0.00070\n",
      "Epoch 4/Step 1550, Loss: -0.15317, Accuracy: 0.99847, F1: 0.2526, Prec: 0.3062, Rec: 0.2662 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9985\n",
      "Validation f1: 0.2648\n",
      "Validation precision: 0.2929\n",
      "Validation recall: 0.2439\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_3_valF1Score0.265/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_3_valF1Score0.265/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 5\n",
      "Epoch 5/Step 0, Loss: -0.14763, Accuracy: 0.99868, F1: 0.3399, Prec: 0.3564, Rec: 0.2681 lr: 0.00070\n",
      "Epoch 5/Step 10, Loss: -0.15157, Accuracy: 0.99846, F1: 0.2820, Prec: 0.3483, Rec: 0.2833 lr: 0.00070\n",
      "Epoch 5/Step 20, Loss: -0.14138, Accuracy: 0.99849, F1: 0.2762, Prec: 0.3334, Rec: 0.2845 lr: 0.00070\n",
      "Epoch 5/Step 30, Loss: -0.13992, Accuracy: 0.99854, F1: 0.2706, Prec: 0.3355, Rec: 0.2839 lr: 0.00070\n",
      "Epoch 5/Step 40, Loss: -0.12754, Accuracy: 0.99852, F1: 0.2749, Prec: 0.3365, Rec: 0.2840 lr: 0.00070\n",
      "Epoch 5/Step 50, Loss: -0.15218, Accuracy: 0.99851, F1: 0.2733, Prec: 0.3308, Rec: 0.2876 lr: 0.00070\n",
      "Epoch 5/Step 60, Loss: -0.15957, Accuracy: 0.99853, F1: 0.2716, Prec: 0.3330, Rec: 0.2853 lr: 0.00070\n",
      "Epoch 5/Step 70, Loss: -0.15124, Accuracy: 0.99855, F1: 0.2706, Prec: 0.3352, Rec: 0.2864 lr: 0.00070\n",
      "Epoch 5/Step 80, Loss: -0.14149, Accuracy: 0.99856, F1: 0.2690, Prec: 0.3339, Rec: 0.2838 lr: 0.00070\n",
      "Epoch 5/Step 90, Loss: -0.13418, Accuracy: 0.99856, F1: 0.2685, Prec: 0.3357, Rec: 0.2839 lr: 0.00070\n",
      "Epoch 5/Step 100, Loss: -0.16343, Accuracy: 0.99857, F1: 0.2690, Prec: 0.3379, Rec: 0.2859 lr: 0.00070\n",
      "Epoch 5/Step 110, Loss: -0.14579, Accuracy: 0.99856, F1: 0.2709, Prec: 0.3404, Rec: 0.2843 lr: 0.00070\n",
      "Epoch 5/Step 120, Loss: -0.11881, Accuracy: 0.99855, F1: 0.2714, Prec: 0.3389, Rec: 0.2834 lr: 0.00070\n",
      "Epoch 5/Step 130, Loss: -0.13074, Accuracy: 0.99855, F1: 0.2700, Prec: 0.3377, Rec: 0.2854 lr: 0.00070\n",
      "Epoch 5/Step 140, Loss: -0.13482, Accuracy: 0.99855, F1: 0.2696, Prec: 0.3393, Rec: 0.2814 lr: 0.00070\n",
      "Epoch 5/Step 150, Loss: -0.13379, Accuracy: 0.99853, F1: 0.2706, Prec: 0.3371, Rec: 0.2811 lr: 0.00070\n",
      "Epoch 5/Step 160, Loss: -0.14773, Accuracy: 0.99852, F1: 0.2691, Prec: 0.3340, Rec: 0.2820 lr: 0.00070\n",
      "Epoch 5/Step 170, Loss: -0.12643, Accuracy: 0.99853, F1: 0.2684, Prec: 0.3322, Rec: 0.2808 lr: 0.00070\n",
      "Epoch 5/Step 180, Loss: -0.13733, Accuracy: 0.99853, F1: 0.2689, Prec: 0.3330, Rec: 0.2806 lr: 0.00070\n",
      "Epoch 5/Step 190, Loss: -0.14415, Accuracy: 0.99852, F1: 0.2683, Prec: 0.3322, Rec: 0.2808 lr: 0.00070\n",
      "Epoch 5/Step 200, Loss: -0.14075, Accuracy: 0.99852, F1: 0.2677, Prec: 0.3329, Rec: 0.2800 lr: 0.00070\n",
      "Epoch 5/Step 210, Loss: -0.12806, Accuracy: 0.99851, F1: 0.2678, Prec: 0.3318, Rec: 0.2801 lr: 0.00070\n",
      "Epoch 5/Step 220, Loss: -0.16720, Accuracy: 0.99851, F1: 0.2680, Prec: 0.3321, Rec: 0.2803 lr: 0.00070\n",
      "Epoch 5/Step 230, Loss: -0.12000, Accuracy: 0.99851, F1: 0.2681, Prec: 0.3320, Rec: 0.2798 lr: 0.00070\n",
      "Epoch 5/Step 240, Loss: -0.17157, Accuracy: 0.99851, F1: 0.2689, Prec: 0.3331, Rec: 0.2797 lr: 0.00070\n",
      "Epoch 5/Step 250, Loss: -0.15010, Accuracy: 0.99850, F1: 0.2686, Prec: 0.3326, Rec: 0.2796 lr: 0.00070\n",
      "Epoch 5/Step 260, Loss: -0.15605, Accuracy: 0.99850, F1: 0.2689, Prec: 0.3320, Rec: 0.2798 lr: 0.00070\n",
      "Epoch 5/Step 270, Loss: -0.18267, Accuracy: 0.99850, F1: 0.2692, Prec: 0.3314, Rec: 0.2804 lr: 0.00070\n",
      "Epoch 5/Step 280, Loss: -0.17466, Accuracy: 0.99850, F1: 0.2694, Prec: 0.3323, Rec: 0.2796 lr: 0.00070\n",
      "Epoch 5/Step 290, Loss: -0.14354, Accuracy: 0.99850, F1: 0.2688, Prec: 0.3321, Rec: 0.2793 lr: 0.00070\n",
      "Epoch 5/Step 300, Loss: -0.15751, Accuracy: 0.99850, F1: 0.2688, Prec: 0.3322, Rec: 0.2796 lr: 0.00070\n",
      "Epoch 5/Step 310, Loss: -0.15557, Accuracy: 0.99850, F1: 0.2684, Prec: 0.3318, Rec: 0.2797 lr: 0.00070\n",
      "Epoch 5/Step 320, Loss: -0.15141, Accuracy: 0.99851, F1: 0.2688, Prec: 0.3325, Rec: 0.2801 lr: 0.00070\n",
      "Epoch 5/Step 330, Loss: -0.17888, Accuracy: 0.99851, F1: 0.2692, Prec: 0.3338, Rec: 0.2805 lr: 0.00070\n",
      "Epoch 5/Step 340, Loss: -0.14642, Accuracy: 0.99851, F1: 0.2692, Prec: 0.3349, Rec: 0.2799 lr: 0.00070\n",
      "Epoch 5/Step 350, Loss: -0.13091, Accuracy: 0.99851, F1: 0.2693, Prec: 0.3354, Rec: 0.2800 lr: 0.00070\n",
      "Epoch 5/Step 360, Loss: -0.17304, Accuracy: 0.99851, F1: 0.2696, Prec: 0.3360, Rec: 0.2807 lr: 0.00070\n",
      "Epoch 5/Step 370, Loss: -0.16199, Accuracy: 0.99851, F1: 0.2697, Prec: 0.3359, Rec: 0.2805 lr: 0.00070\n",
      "Epoch 5/Step 380, Loss: -0.16882, Accuracy: 0.99852, F1: 0.2694, Prec: 0.3365, Rec: 0.2803 lr: 0.00070\n",
      "Epoch 5/Step 390, Loss: -0.14243, Accuracy: 0.99852, F1: 0.2689, Prec: 0.3367, Rec: 0.2798 lr: 0.00070\n",
      "Epoch 5/Step 400, Loss: -0.11600, Accuracy: 0.99852, F1: 0.2687, Prec: 0.3366, Rec: 0.2798 lr: 0.00070\n",
      "Epoch 5/Step 410, Loss: -0.13681, Accuracy: 0.99852, F1: 0.2685, Prec: 0.3366, Rec: 0.2797 lr: 0.00070\n",
      "Epoch 5/Step 420, Loss: -0.16486, Accuracy: 0.99853, F1: 0.2687, Prec: 0.3373, Rec: 0.2798 lr: 0.00070\n",
      "Epoch 5/Step 430, Loss: -0.13785, Accuracy: 0.99853, F1: 0.2684, Prec: 0.3371, Rec: 0.2799 lr: 0.00070\n",
      "Epoch 5/Step 440, Loss: -0.14315, Accuracy: 0.99852, F1: 0.2685, Prec: 0.3373, Rec: 0.2802 lr: 0.00070\n",
      "Epoch 5/Step 450, Loss: -0.15552, Accuracy: 0.99852, F1: 0.2687, Prec: 0.3376, Rec: 0.2799 lr: 0.00070\n",
      "Epoch 5/Step 460, Loss: -0.14541, Accuracy: 0.99853, F1: 0.2682, Prec: 0.3371, Rec: 0.2802 lr: 0.00070\n",
      "Epoch 5/Step 470, Loss: -0.13801, Accuracy: 0.99853, F1: 0.2682, Prec: 0.3376, Rec: 0.2798 lr: 0.00070\n",
      "Epoch 5/Step 480, Loss: -0.14911, Accuracy: 0.99853, F1: 0.2685, Prec: 0.3379, Rec: 0.2792 lr: 0.00070\n",
      "Epoch 5/Step 490, Loss: -0.14168, Accuracy: 0.99853, F1: 0.2684, Prec: 0.3376, Rec: 0.2788 lr: 0.00070\n",
      "Epoch 5/Step 500, Loss: -0.14082, Accuracy: 0.99853, F1: 0.2680, Prec: 0.3371, Rec: 0.2789 lr: 0.00070\n",
      "Epoch 5/Step 510, Loss: -0.16922, Accuracy: 0.99853, F1: 0.2681, Prec: 0.3372, Rec: 0.2790 lr: 0.00070\n",
      "Epoch 5/Step 520, Loss: -0.11747, Accuracy: 0.99853, F1: 0.2683, Prec: 0.3381, Rec: 0.2792 lr: 0.00070\n",
      "Epoch 5/Step 530, Loss: -0.13189, Accuracy: 0.99853, F1: 0.2682, Prec: 0.3380, Rec: 0.2787 lr: 0.00070\n",
      "Epoch 5/Step 540, Loss: -0.12037, Accuracy: 0.99853, F1: 0.2683, Prec: 0.3376, Rec: 0.2787 lr: 0.00070\n",
      "Epoch 5/Step 550, Loss: -0.17753, Accuracy: 0.99853, F1: 0.2684, Prec: 0.3378, Rec: 0.2790 lr: 0.00070\n",
      "Epoch 5/Step 560, Loss: -0.14395, Accuracy: 0.99853, F1: 0.2684, Prec: 0.3381, Rec: 0.2789 lr: 0.00070\n",
      "Epoch 5/Step 570, Loss: -0.13875, Accuracy: 0.99853, F1: 0.2683, Prec: 0.3382, Rec: 0.2790 lr: 0.00070\n",
      "Epoch 5/Step 580, Loss: -0.14395, Accuracy: 0.99853, F1: 0.2684, Prec: 0.3385, Rec: 0.2788 lr: 0.00070\n",
      "Epoch 5/Step 590, Loss: -0.12037, Accuracy: 0.99853, F1: 0.2684, Prec: 0.3382, Rec: 0.2788 lr: 0.00070\n",
      "Epoch 5/Step 600, Loss: -0.12832, Accuracy: 0.99853, F1: 0.2684, Prec: 0.3387, Rec: 0.2786 lr: 0.00070\n",
      "Epoch 5/Step 610, Loss: -0.16059, Accuracy: 0.99853, F1: 0.2684, Prec: 0.3388, Rec: 0.2784 lr: 0.00070\n",
      "Epoch 5/Step 620, Loss: -0.17006, Accuracy: 0.99853, F1: 0.2685, Prec: 0.3388, Rec: 0.2792 lr: 0.00070\n",
      "Epoch 5/Step 630, Loss: -0.15415, Accuracy: 0.99853, F1: 0.2689, Prec: 0.3389, Rec: 0.2792 lr: 0.00070\n",
      "Epoch 5/Step 640, Loss: -0.14838, Accuracy: 0.99853, F1: 0.2691, Prec: 0.3393, Rec: 0.2791 lr: 0.00070\n",
      "Epoch 5/Step 650, Loss: -0.13868, Accuracy: 0.99853, F1: 0.2692, Prec: 0.3390, Rec: 0.2793 lr: 0.00070\n",
      "Epoch 5/Step 660, Loss: -0.16570, Accuracy: 0.99853, F1: 0.2693, Prec: 0.3391, Rec: 0.2795 lr: 0.00070\n",
      "Epoch 5/Step 670, Loss: -0.12158, Accuracy: 0.99853, F1: 0.2693, Prec: 0.3394, Rec: 0.2794 lr: 0.00070\n",
      "Epoch 5/Step 680, Loss: -0.12768, Accuracy: 0.99853, F1: 0.2691, Prec: 0.3395, Rec: 0.2794 lr: 0.00070\n",
      "Epoch 5/Step 690, Loss: -0.17684, Accuracy: 0.99853, F1: 0.2691, Prec: 0.3394, Rec: 0.2794 lr: 0.00070\n",
      "Epoch 5/Step 700, Loss: -0.15203, Accuracy: 0.99853, F1: 0.2689, Prec: 0.3396, Rec: 0.2792 lr: 0.00070\n",
      "Epoch 5/Step 710, Loss: -0.16600, Accuracy: 0.99853, F1: 0.2689, Prec: 0.3399, Rec: 0.2797 lr: 0.00070\n",
      "Epoch 5/Step 720, Loss: -0.17177, Accuracy: 0.99854, F1: 0.2690, Prec: 0.3399, Rec: 0.2795 lr: 0.00070\n",
      "Epoch 5/Step 730, Loss: -0.13834, Accuracy: 0.99854, F1: 0.2690, Prec: 0.3402, Rec: 0.2794 lr: 0.00070\n",
      "Epoch 5/Step 740, Loss: -0.15343, Accuracy: 0.99854, F1: 0.2692, Prec: 0.3401, Rec: 0.2792 lr: 0.00070\n",
      "Epoch 5/Step 750, Loss: -0.13396, Accuracy: 0.99854, F1: 0.2698, Prec: 0.3404, Rec: 0.2794 lr: 0.00070\n",
      "Epoch 5/Step 760, Loss: -0.16020, Accuracy: 0.99854, F1: 0.2702, Prec: 0.3405, Rec: 0.2792 lr: 0.00070\n",
      "Epoch 5/Step 770, Loss: -0.17349, Accuracy: 0.99854, F1: 0.2703, Prec: 0.3406, Rec: 0.2794 lr: 0.00070\n",
      "Epoch 5/Step 780, Loss: -0.13966, Accuracy: 0.99854, F1: 0.2708, Prec: 0.3413, Rec: 0.2794 lr: 0.00070\n",
      "Epoch 5/Step 790, Loss: -0.16317, Accuracy: 0.99854, F1: 0.2709, Prec: 0.3412, Rec: 0.2793 lr: 0.00070\n",
      "Epoch 5/Step 800, Loss: -0.13101, Accuracy: 0.99854, F1: 0.2709, Prec: 0.3409, Rec: 0.2793 lr: 0.00070\n",
      "Epoch 5/Step 810, Loss: -0.11027, Accuracy: 0.99854, F1: 0.2710, Prec: 0.3408, Rec: 0.2791 lr: 0.00070\n",
      "Epoch 5/Step 820, Loss: -0.15609, Accuracy: 0.99854, F1: 0.2710, Prec: 0.3404, Rec: 0.2791 lr: 0.00070\n",
      "Epoch 5/Step 830, Loss: -0.15416, Accuracy: 0.99854, F1: 0.2708, Prec: 0.3407, Rec: 0.2792 lr: 0.00070\n",
      "Epoch 5/Step 840, Loss: -0.16966, Accuracy: 0.99854, F1: 0.2711, Prec: 0.3409, Rec: 0.2793 lr: 0.00070\n",
      "Epoch 5/Step 850, Loss: -0.14112, Accuracy: 0.99854, F1: 0.2714, Prec: 0.3409, Rec: 0.2792 lr: 0.00070\n",
      "Epoch 5/Step 860, Loss: -0.16207, Accuracy: 0.99854, F1: 0.2716, Prec: 0.3412, Rec: 0.2791 lr: 0.00070\n",
      "Epoch 5/Step 870, Loss: -0.15158, Accuracy: 0.99854, F1: 0.2715, Prec: 0.3412, Rec: 0.2788 lr: 0.00070\n",
      "Epoch 5/Step 880, Loss: -0.13490, Accuracy: 0.99854, F1: 0.2717, Prec: 0.3411, Rec: 0.2790 lr: 0.00070\n",
      "Epoch 5/Step 890, Loss: -0.15376, Accuracy: 0.99854, F1: 0.2717, Prec: 0.3411, Rec: 0.2790 lr: 0.00070\n",
      "Epoch 5/Step 900, Loss: -0.20607, Accuracy: 0.99854, F1: 0.2720, Prec: 0.3418, Rec: 0.2792 lr: 0.00070\n",
      "Epoch 5/Step 910, Loss: -0.12143, Accuracy: 0.99855, F1: 0.2719, Prec: 0.3420, Rec: 0.2789 lr: 0.00070\n",
      "Epoch 5/Step 920, Loss: -0.14877, Accuracy: 0.99854, F1: 0.2721, Prec: 0.3419, Rec: 0.2789 lr: 0.00070\n",
      "Epoch 5/Step 930, Loss: -0.13014, Accuracy: 0.99854, F1: 0.2721, Prec: 0.3417, Rec: 0.2791 lr: 0.00070\n",
      "Epoch 5/Step 940, Loss: -0.15325, Accuracy: 0.99855, F1: 0.2718, Prec: 0.3415, Rec: 0.2792 lr: 0.00070\n",
      "Epoch 5/Step 950, Loss: -0.17495, Accuracy: 0.99855, F1: 0.2721, Prec: 0.3419, Rec: 0.2791 lr: 0.00070\n",
      "Epoch 5/Step 960, Loss: -0.17787, Accuracy: 0.99855, F1: 0.2723, Prec: 0.3419, Rec: 0.2792 lr: 0.00070\n",
      "Epoch 5/Step 970, Loss: -0.14274, Accuracy: 0.99855, F1: 0.2724, Prec: 0.3420, Rec: 0.2790 lr: 0.00070\n",
      "Epoch 5/Step 980, Loss: -0.15669, Accuracy: 0.99855, F1: 0.2723, Prec: 0.3418, Rec: 0.2788 lr: 0.00070\n",
      "Epoch 5/Step 990, Loss: -0.14228, Accuracy: 0.99855, F1: 0.2723, Prec: 0.3413, Rec: 0.2788 lr: 0.00070\n",
      "Epoch 5/Step 1000, Loss: -0.16562, Accuracy: 0.99855, F1: 0.2723, Prec: 0.3413, Rec: 0.2790 lr: 0.00070\n",
      "Epoch 5/Step 1010, Loss: -0.18045, Accuracy: 0.99855, F1: 0.2725, Prec: 0.3416, Rec: 0.2793 lr: 0.00070\n",
      "Epoch 5/Step 1020, Loss: -0.12705, Accuracy: 0.99855, F1: 0.2723, Prec: 0.3414, Rec: 0.2792 lr: 0.00070\n",
      "Epoch 5/Step 1030, Loss: -0.14476, Accuracy: 0.99855, F1: 0.2723, Prec: 0.3415, Rec: 0.2793 lr: 0.00070\n",
      "Epoch 5/Step 1040, Loss: -0.16277, Accuracy: 0.99855, F1: 0.2723, Prec: 0.3417, Rec: 0.2791 lr: 0.00070\n",
      "Epoch 5/Step 1050, Loss: -0.17133, Accuracy: 0.99855, F1: 0.2722, Prec: 0.3417, Rec: 0.2792 lr: 0.00070\n",
      "Epoch 5/Step 1060, Loss: -0.16761, Accuracy: 0.99855, F1: 0.2721, Prec: 0.3417, Rec: 0.2794 lr: 0.00070\n",
      "Epoch 5/Step 1070, Loss: -0.16200, Accuracy: 0.99855, F1: 0.2726, Prec: 0.3419, Rec: 0.2794 lr: 0.00070\n",
      "Epoch 5/Step 1080, Loss: -0.12781, Accuracy: 0.99855, F1: 0.2729, Prec: 0.3421, Rec: 0.2795 lr: 0.00070\n",
      "Epoch 5/Step 1090, Loss: -0.12941, Accuracy: 0.99855, F1: 0.2728, Prec: 0.3420, Rec: 0.2794 lr: 0.00070\n",
      "Epoch 5/Step 1100, Loss: -0.15811, Accuracy: 0.99855, F1: 0.2729, Prec: 0.3420, Rec: 0.2795 lr: 0.00070\n",
      "Epoch 5/Step 1110, Loss: -0.13084, Accuracy: 0.99855, F1: 0.2730, Prec: 0.3423, Rec: 0.2795 lr: 0.00070\n",
      "Epoch 5/Step 1120, Loss: -0.14347, Accuracy: 0.99855, F1: 0.2729, Prec: 0.3423, Rec: 0.2796 lr: 0.00070\n",
      "Epoch 5/Step 1130, Loss: -0.13946, Accuracy: 0.99856, F1: 0.2728, Prec: 0.3425, Rec: 0.2797 lr: 0.00070\n",
      "Epoch 5/Step 1140, Loss: -0.13917, Accuracy: 0.99856, F1: 0.2728, Prec: 0.3425, Rec: 0.2797 lr: 0.00070\n",
      "Epoch 5/Step 1150, Loss: -0.15639, Accuracy: 0.99856, F1: 0.2728, Prec: 0.3426, Rec: 0.2798 lr: 0.00070\n",
      "Epoch 5/Step 1160, Loss: -0.13067, Accuracy: 0.99856, F1: 0.2730, Prec: 0.3428, Rec: 0.2802 lr: 0.00070\n",
      "Epoch 5/Step 1170, Loss: -0.13994, Accuracy: 0.99856, F1: 0.2733, Prec: 0.3430, Rec: 0.2801 lr: 0.00070\n",
      "Epoch 5/Step 1180, Loss: -0.11655, Accuracy: 0.99856, F1: 0.2735, Prec: 0.3432, Rec: 0.2801 lr: 0.00070\n",
      "Epoch 5/Step 1190, Loss: -0.16277, Accuracy: 0.99856, F1: 0.2734, Prec: 0.3433, Rec: 0.2799 lr: 0.00070\n",
      "Epoch 5/Step 1200, Loss: -0.15632, Accuracy: 0.99856, F1: 0.2734, Prec: 0.3435, Rec: 0.2802 lr: 0.00070\n",
      "Epoch 5/Step 1210, Loss: -0.15171, Accuracy: 0.99856, F1: 0.2735, Prec: 0.3437, Rec: 0.2803 lr: 0.00070\n",
      "Epoch 5/Step 1220, Loss: -0.17240, Accuracy: 0.99856, F1: 0.2733, Prec: 0.3437, Rec: 0.2804 lr: 0.00070\n",
      "Epoch 5/Step 1230, Loss: -0.16481, Accuracy: 0.99856, F1: 0.2734, Prec: 0.3437, Rec: 0.2803 lr: 0.00070\n",
      "Epoch 5/Step 1240, Loss: -0.19567, Accuracy: 0.99856, F1: 0.2738, Prec: 0.3439, Rec: 0.2803 lr: 0.00070\n",
      "Epoch 5/Step 1250, Loss: -0.11754, Accuracy: 0.99856, F1: 0.2739, Prec: 0.3440, Rec: 0.2804 lr: 0.00070\n",
      "Epoch 5/Step 1260, Loss: -0.14628, Accuracy: 0.99856, F1: 0.2740, Prec: 0.3440, Rec: 0.2804 lr: 0.00070\n",
      "Epoch 5/Step 1270, Loss: -0.14107, Accuracy: 0.99856, F1: 0.2740, Prec: 0.3441, Rec: 0.2805 lr: 0.00070\n",
      "Epoch 5/Step 1280, Loss: -0.20807, Accuracy: 0.99856, F1: 0.2743, Prec: 0.3441, Rec: 0.2805 lr: 0.00070\n",
      "Epoch 5/Step 1290, Loss: -0.17030, Accuracy: 0.99856, F1: 0.2743, Prec: 0.3443, Rec: 0.2807 lr: 0.00070\n",
      "Epoch 5/Step 1300, Loss: -0.15124, Accuracy: 0.99856, F1: 0.2744, Prec: 0.3442, Rec: 0.2807 lr: 0.00070\n",
      "Epoch 5/Step 1310, Loss: -0.16346, Accuracy: 0.99856, F1: 0.2745, Prec: 0.3442, Rec: 0.2808 lr: 0.00070\n",
      "Epoch 5/Step 1320, Loss: -0.13827, Accuracy: 0.99856, F1: 0.2747, Prec: 0.3444, Rec: 0.2808 lr: 0.00070\n",
      "Epoch 5/Step 1330, Loss: -0.15983, Accuracy: 0.99856, F1: 0.2747, Prec: 0.3445, Rec: 0.2807 lr: 0.00070\n",
      "Epoch 5/Step 1340, Loss: -0.14737, Accuracy: 0.99856, F1: 0.2749, Prec: 0.3445, Rec: 0.2810 lr: 0.00070\n",
      "Epoch 5/Step 1350, Loss: -0.12457, Accuracy: 0.99856, F1: 0.2749, Prec: 0.3445, Rec: 0.2810 lr: 0.00070\n",
      "Epoch 5/Step 1360, Loss: -0.13640, Accuracy: 0.99856, F1: 0.2750, Prec: 0.3447, Rec: 0.2809 lr: 0.00070\n",
      "Epoch 5/Step 1370, Loss: -0.13475, Accuracy: 0.99856, F1: 0.2749, Prec: 0.3448, Rec: 0.2810 lr: 0.00070\n",
      "Epoch 5/Step 1380, Loss: -0.15908, Accuracy: 0.99857, F1: 0.2749, Prec: 0.3449, Rec: 0.2810 lr: 0.00070\n",
      "Epoch 5/Step 1390, Loss: -0.18092, Accuracy: 0.99857, F1: 0.2748, Prec: 0.3448, Rec: 0.2809 lr: 0.00070\n",
      "Epoch 5/Step 1400, Loss: -0.16407, Accuracy: 0.99857, F1: 0.2749, Prec: 0.3448, Rec: 0.2810 lr: 0.00070\n",
      "Epoch 5/Step 1410, Loss: -0.16780, Accuracy: 0.99857, F1: 0.2751, Prec: 0.3449, Rec: 0.2810 lr: 0.00070\n",
      "Epoch 5/Step 1420, Loss: -0.14082, Accuracy: 0.99857, F1: 0.2750, Prec: 0.3448, Rec: 0.2809 lr: 0.00070\n",
      "Epoch 5/Step 1430, Loss: -0.13806, Accuracy: 0.99857, F1: 0.2752, Prec: 0.3449, Rec: 0.2809 lr: 0.00070\n",
      "Epoch 5/Step 1440, Loss: -0.12854, Accuracy: 0.99857, F1: 0.2752, Prec: 0.3448, Rec: 0.2809 lr: 0.00070\n",
      "Epoch 5/Step 1450, Loss: -0.14282, Accuracy: 0.99857, F1: 0.2753, Prec: 0.3451, Rec: 0.2808 lr: 0.00070\n",
      "Epoch 5/Step 1460, Loss: -0.13475, Accuracy: 0.99857, F1: 0.2754, Prec: 0.3449, Rec: 0.2808 lr: 0.00070\n",
      "Epoch 5/Step 1470, Loss: -0.16047, Accuracy: 0.99857, F1: 0.2757, Prec: 0.3450, Rec: 0.2808 lr: 0.00070\n",
      "Epoch 5/Step 1480, Loss: -0.16024, Accuracy: 0.99857, F1: 0.2759, Prec: 0.3452, Rec: 0.2807 lr: 0.00070\n",
      "Epoch 5/Step 1490, Loss: -0.13732, Accuracy: 0.99857, F1: 0.2760, Prec: 0.3453, Rec: 0.2808 lr: 0.00070\n",
      "Epoch 5/Step 1500, Loss: -0.16542, Accuracy: 0.99857, F1: 0.2760, Prec: 0.3454, Rec: 0.2808 lr: 0.00070\n",
      "Epoch 5/Step 1510, Loss: -0.14644, Accuracy: 0.99857, F1: 0.2765, Prec: 0.3456, Rec: 0.2808 lr: 0.00070\n",
      "Epoch 5/Step 1520, Loss: -0.18406, Accuracy: 0.99857, F1: 0.2767, Prec: 0.3458, Rec: 0.2810 lr: 0.00070\n",
      "Epoch 5/Step 1530, Loss: -0.14118, Accuracy: 0.99857, F1: 0.2768, Prec: 0.3462, Rec: 0.2811 lr: 0.00070\n",
      "Epoch 5/Step 1540, Loss: -0.12420, Accuracy: 0.99857, F1: 0.2768, Prec: 0.3462, Rec: 0.2810 lr: 0.00070\n",
      "Epoch 5/Step 1550, Loss: -0.16857, Accuracy: 0.99857, F1: 0.2771, Prec: 0.3463, Rec: 0.2810 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9985\n",
      "Validation f1: 0.2879\n",
      "Validation precision: 0.3157\n",
      "Validation recall: 0.2389\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_4_valF1Score0.288/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_4_valF1Score0.288/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 6\n",
      "Epoch 6/Step 0, Loss: -0.15905, Accuracy: 0.99874, F1: 0.3896, Prec: 0.3892, Rec: 0.2836 lr: 0.00070\n",
      "Epoch 6/Step 10, Loss: -0.16966, Accuracy: 0.99860, F1: 0.3246, Prec: 0.4066, Rec: 0.2944 lr: 0.00070\n",
      "Epoch 6/Step 20, Loss: -0.15573, Accuracy: 0.99862, F1: 0.3133, Prec: 0.3860, Rec: 0.2985 lr: 0.00070\n",
      "Epoch 6/Step 30, Loss: -0.15302, Accuracy: 0.99865, F1: 0.3053, Prec: 0.3845, Rec: 0.2994 lr: 0.00070\n",
      "Epoch 6/Step 40, Loss: -0.14169, Accuracy: 0.99865, F1: 0.3071, Prec: 0.3912, Rec: 0.2948 lr: 0.00070\n",
      "Epoch 6/Step 50, Loss: -0.15494, Accuracy: 0.99863, F1: 0.3059, Prec: 0.3803, Rec: 0.2990 lr: 0.00070\n",
      "Epoch 6/Step 60, Loss: -0.17115, Accuracy: 0.99864, F1: 0.3060, Prec: 0.3790, Rec: 0.2986 lr: 0.00070\n",
      "Epoch 6/Step 70, Loss: -0.16012, Accuracy: 0.99866, F1: 0.3085, Prec: 0.3825, Rec: 0.2985 lr: 0.00070\n",
      "Epoch 6/Step 80, Loss: -0.15229, Accuracy: 0.99867, F1: 0.3111, Prec: 0.3802, Rec: 0.2968 lr: 0.00070\n",
      "Epoch 6/Step 90, Loss: -0.15273, Accuracy: 0.99866, F1: 0.3136, Prec: 0.3809, Rec: 0.2973 lr: 0.00070\n",
      "Epoch 6/Step 100, Loss: -0.17962, Accuracy: 0.99867, F1: 0.3148, Prec: 0.3831, Rec: 0.2996 lr: 0.00070\n",
      "Epoch 6/Step 110, Loss: -0.16151, Accuracy: 0.99866, F1: 0.3175, Prec: 0.3858, Rec: 0.2985 lr: 0.00070\n",
      "Epoch 6/Step 120, Loss: -0.13492, Accuracy: 0.99866, F1: 0.3186, Prec: 0.3862, Rec: 0.2966 lr: 0.00070\n",
      "Epoch 6/Step 130, Loss: -0.13544, Accuracy: 0.99866, F1: 0.3172, Prec: 0.3846, Rec: 0.2988 lr: 0.00070\n",
      "Epoch 6/Step 140, Loss: -0.14587, Accuracy: 0.99866, F1: 0.3170, Prec: 0.3871, Rec: 0.2942 lr: 0.00070\n",
      "Epoch 6/Step 150, Loss: -0.14782, Accuracy: 0.99864, F1: 0.3172, Prec: 0.3846, Rec: 0.2935 lr: 0.00070\n",
      "Epoch 6/Step 160, Loss: -0.16367, Accuracy: 0.99863, F1: 0.3144, Prec: 0.3786, Rec: 0.2952 lr: 0.00070\n",
      "Epoch 6/Step 170, Loss: -0.14823, Accuracy: 0.99863, F1: 0.3132, Prec: 0.3768, Rec: 0.2937 lr: 0.00070\n",
      "Epoch 6/Step 180, Loss: -0.14945, Accuracy: 0.99863, F1: 0.3130, Prec: 0.3782, Rec: 0.2935 lr: 0.00070\n",
      "Epoch 6/Step 190, Loss: -0.15815, Accuracy: 0.99863, F1: 0.3115, Prec: 0.3777, Rec: 0.2936 lr: 0.00070\n",
      "Epoch 6/Step 200, Loss: -0.15153, Accuracy: 0.99862, F1: 0.3096, Prec: 0.3786, Rec: 0.2927 lr: 0.00070\n",
      "Epoch 6/Step 210, Loss: -0.13528, Accuracy: 0.99862, F1: 0.3086, Prec: 0.3771, Rec: 0.2929 lr: 0.00070\n",
      "Epoch 6/Step 220, Loss: -0.17583, Accuracy: 0.99862, F1: 0.3082, Prec: 0.3769, Rec: 0.2929 lr: 0.00070\n",
      "Epoch 6/Step 230, Loss: -0.13312, Accuracy: 0.99862, F1: 0.3084, Prec: 0.3775, Rec: 0.2923 lr: 0.00070\n",
      "Epoch 6/Step 240, Loss: -0.19319, Accuracy: 0.99862, F1: 0.3090, Prec: 0.3787, Rec: 0.2921 lr: 0.00070\n",
      "Epoch 6/Step 250, Loss: -0.17209, Accuracy: 0.99861, F1: 0.3084, Prec: 0.3779, Rec: 0.2923 lr: 0.00070\n",
      "Epoch 6/Step 260, Loss: -0.17168, Accuracy: 0.99861, F1: 0.3086, Prec: 0.3775, Rec: 0.2925 lr: 0.00070\n",
      "Epoch 6/Step 270, Loss: -0.19403, Accuracy: 0.99861, F1: 0.3088, Prec: 0.3769, Rec: 0.2928 lr: 0.00070\n",
      "Epoch 6/Step 280, Loss: -0.18554, Accuracy: 0.99861, F1: 0.3093, Prec: 0.3776, Rec: 0.2920 lr: 0.00070\n",
      "Epoch 6/Step 290, Loss: -0.15401, Accuracy: 0.99861, F1: 0.3090, Prec: 0.3776, Rec: 0.2918 lr: 0.00070\n",
      "Epoch 6/Step 300, Loss: -0.16486, Accuracy: 0.99861, F1: 0.3083, Prec: 0.3775, Rec: 0.2922 lr: 0.00070\n",
      "Epoch 6/Step 310, Loss: -0.16445, Accuracy: 0.99861, F1: 0.3075, Prec: 0.3770, Rec: 0.2923 lr: 0.00070\n",
      "Epoch 6/Step 320, Loss: -0.15769, Accuracy: 0.99861, F1: 0.3083, Prec: 0.3779, Rec: 0.2927 lr: 0.00070\n",
      "Epoch 6/Step 330, Loss: -0.19247, Accuracy: 0.99861, F1: 0.3094, Prec: 0.3786, Rec: 0.2931 lr: 0.00070\n",
      "Epoch 6/Step 340, Loss: -0.15518, Accuracy: 0.99861, F1: 0.3094, Prec: 0.3793, Rec: 0.2928 lr: 0.00070\n",
      "Epoch 6/Step 350, Loss: -0.13356, Accuracy: 0.99861, F1: 0.3091, Prec: 0.3800, Rec: 0.2928 lr: 0.00070\n",
      "Epoch 6/Step 360, Loss: -0.17117, Accuracy: 0.99862, F1: 0.3093, Prec: 0.3807, Rec: 0.2934 lr: 0.00070\n",
      "Epoch 6/Step 370, Loss: -0.16966, Accuracy: 0.99862, F1: 0.3091, Prec: 0.3801, Rec: 0.2933 lr: 0.00070\n",
      "Epoch 6/Step 380, Loss: -0.17901, Accuracy: 0.99862, F1: 0.3092, Prec: 0.3807, Rec: 0.2931 lr: 0.00070\n",
      "Epoch 6/Step 390, Loss: -0.15799, Accuracy: 0.99863, F1: 0.3091, Prec: 0.3813, Rec: 0.2926 lr: 0.00070\n",
      "Epoch 6/Step 400, Loss: -0.12378, Accuracy: 0.99863, F1: 0.3085, Prec: 0.3812, Rec: 0.2927 lr: 0.00070\n",
      "Epoch 6/Step 410, Loss: -0.13716, Accuracy: 0.99863, F1: 0.3082, Prec: 0.3808, Rec: 0.2928 lr: 0.00070\n",
      "Epoch 6/Step 420, Loss: -0.17206, Accuracy: 0.99863, F1: 0.3092, Prec: 0.3817, Rec: 0.2926 lr: 0.00070\n",
      "Epoch 6/Step 430, Loss: -0.14941, Accuracy: 0.99863, F1: 0.3088, Prec: 0.3811, Rec: 0.2926 lr: 0.00070\n",
      "Epoch 6/Step 440, Loss: -0.15262, Accuracy: 0.99862, F1: 0.3083, Prec: 0.3806, Rec: 0.2931 lr: 0.00070\n",
      "Epoch 6/Step 450, Loss: -0.16941, Accuracy: 0.99863, F1: 0.3083, Prec: 0.3812, Rec: 0.2928 lr: 0.00070\n",
      "Epoch 6/Step 460, Loss: -0.15987, Accuracy: 0.99863, F1: 0.3080, Prec: 0.3807, Rec: 0.2930 lr: 0.00070\n",
      "Epoch 6/Step 470, Loss: -0.15005, Accuracy: 0.99863, F1: 0.3081, Prec: 0.3811, Rec: 0.2927 lr: 0.00070\n",
      "Epoch 6/Step 480, Loss: -0.16039, Accuracy: 0.99863, F1: 0.3076, Prec: 0.3811, Rec: 0.2921 lr: 0.00070\n",
      "Epoch 6/Step 490, Loss: -0.15552, Accuracy: 0.99863, F1: 0.3072, Prec: 0.3806, Rec: 0.2920 lr: 0.00070\n",
      "Epoch 6/Step 500, Loss: -0.15868, Accuracy: 0.99863, F1: 0.3070, Prec: 0.3801, Rec: 0.2919 lr: 0.00070\n",
      "Epoch 6/Step 510, Loss: -0.18538, Accuracy: 0.99863, F1: 0.3070, Prec: 0.3801, Rec: 0.2920 lr: 0.00070\n",
      "Epoch 6/Step 520, Loss: -0.13008, Accuracy: 0.99863, F1: 0.3071, Prec: 0.3809, Rec: 0.2921 lr: 0.00070\n",
      "Epoch 6/Step 530, Loss: -0.14442, Accuracy: 0.99863, F1: 0.3070, Prec: 0.3806, Rec: 0.2918 lr: 0.00070\n",
      "Epoch 6/Step 540, Loss: -0.14288, Accuracy: 0.99863, F1: 0.3074, Prec: 0.3804, Rec: 0.2917 lr: 0.00070\n",
      "Epoch 6/Step 550, Loss: -0.19668, Accuracy: 0.99863, F1: 0.3076, Prec: 0.3803, Rec: 0.2921 lr: 0.00070\n",
      "Epoch 6/Step 560, Loss: -0.15025, Accuracy: 0.99863, F1: 0.3080, Prec: 0.3805, Rec: 0.2921 lr: 0.00070\n",
      "Epoch 6/Step 570, Loss: -0.15200, Accuracy: 0.99863, F1: 0.3077, Prec: 0.3806, Rec: 0.2921 lr: 0.00070\n",
      "Epoch 6/Step 580, Loss: -0.14724, Accuracy: 0.99863, F1: 0.3073, Prec: 0.3806, Rec: 0.2918 lr: 0.00070\n",
      "Epoch 6/Step 590, Loss: -0.12482, Accuracy: 0.99863, F1: 0.3068, Prec: 0.3802, Rec: 0.2918 lr: 0.00070\n",
      "Epoch 6/Step 600, Loss: -0.14161, Accuracy: 0.99863, F1: 0.3067, Prec: 0.3805, Rec: 0.2917 lr: 0.00070\n",
      "Epoch 6/Step 610, Loss: -0.19215, Accuracy: 0.99862, F1: 0.3064, Prec: 0.3808, Rec: 0.2916 lr: 0.00070\n",
      "Epoch 6/Step 620, Loss: -0.18462, Accuracy: 0.99862, F1: 0.3064, Prec: 0.3811, Rec: 0.2923 lr: 0.00070\n",
      "Epoch 6/Step 630, Loss: -0.15858, Accuracy: 0.99862, F1: 0.3064, Prec: 0.3810, Rec: 0.2923 lr: 0.00070\n",
      "Epoch 6/Step 640, Loss: -0.15233, Accuracy: 0.99862, F1: 0.3067, Prec: 0.3812, Rec: 0.2921 lr: 0.00070\n",
      "Epoch 6/Step 650, Loss: -0.15471, Accuracy: 0.99862, F1: 0.3071, Prec: 0.3811, Rec: 0.2922 lr: 0.00070\n",
      "Epoch 6/Step 660, Loss: -0.18059, Accuracy: 0.99862, F1: 0.3071, Prec: 0.3810, Rec: 0.2924 lr: 0.00070\n",
      "Epoch 6/Step 670, Loss: -0.13562, Accuracy: 0.99863, F1: 0.3071, Prec: 0.3812, Rec: 0.2923 lr: 0.00070\n",
      "Epoch 6/Step 680, Loss: -0.13692, Accuracy: 0.99863, F1: 0.3068, Prec: 0.3813, Rec: 0.2924 lr: 0.00070\n",
      "Epoch 6/Step 690, Loss: -0.19606, Accuracy: 0.99863, F1: 0.3069, Prec: 0.3814, Rec: 0.2924 lr: 0.00070\n",
      "Epoch 6/Step 700, Loss: -0.16819, Accuracy: 0.99863, F1: 0.3068, Prec: 0.3815, Rec: 0.2923 lr: 0.00070\n",
      "Epoch 6/Step 710, Loss: -0.18059, Accuracy: 0.99863, F1: 0.3068, Prec: 0.3819, Rec: 0.2926 lr: 0.00070\n",
      "Epoch 6/Step 720, Loss: -0.19115, Accuracy: 0.99863, F1: 0.3070, Prec: 0.3819, Rec: 0.2927 lr: 0.00070\n",
      "Epoch 6/Step 730, Loss: -0.14695, Accuracy: 0.99863, F1: 0.3073, Prec: 0.3821, Rec: 0.2926 lr: 0.00070\n",
      "Epoch 6/Step 740, Loss: -0.16389, Accuracy: 0.99863, F1: 0.3075, Prec: 0.3820, Rec: 0.2924 lr: 0.00070\n",
      "Epoch 6/Step 750, Loss: -0.15002, Accuracy: 0.99863, F1: 0.3082, Prec: 0.3822, Rec: 0.2924 lr: 0.00070\n",
      "Epoch 6/Step 760, Loss: -0.16580, Accuracy: 0.99863, F1: 0.3089, Prec: 0.3822, Rec: 0.2922 lr: 0.00070\n",
      "Epoch 6/Step 770, Loss: -0.18576, Accuracy: 0.99863, F1: 0.3094, Prec: 0.3824, Rec: 0.2924 lr: 0.00070\n",
      "Epoch 6/Step 780, Loss: -0.15393, Accuracy: 0.99864, F1: 0.3098, Prec: 0.3833, Rec: 0.2925 lr: 0.00070\n",
      "Epoch 6/Step 790, Loss: -0.17452, Accuracy: 0.99863, F1: 0.3097, Prec: 0.3830, Rec: 0.2924 lr: 0.00070\n",
      "Epoch 6/Step 800, Loss: -0.13744, Accuracy: 0.99863, F1: 0.3098, Prec: 0.3827, Rec: 0.2924 lr: 0.00070\n",
      "Epoch 6/Step 810, Loss: -0.11351, Accuracy: 0.99863, F1: 0.3103, Prec: 0.3826, Rec: 0.2922 lr: 0.00070\n",
      "Epoch 6/Step 820, Loss: -0.16705, Accuracy: 0.99864, F1: 0.3105, Prec: 0.3821, Rec: 0.2921 lr: 0.00070\n",
      "Epoch 6/Step 830, Loss: -0.16523, Accuracy: 0.99864, F1: 0.3104, Prec: 0.3823, Rec: 0.2923 lr: 0.00070\n",
      "Epoch 6/Step 840, Loss: -0.18167, Accuracy: 0.99864, F1: 0.3107, Prec: 0.3825, Rec: 0.2924 lr: 0.00070\n",
      "Epoch 6/Step 850, Loss: -0.15785, Accuracy: 0.99864, F1: 0.3113, Prec: 0.3825, Rec: 0.2923 lr: 0.00070\n",
      "Epoch 6/Step 860, Loss: -0.17190, Accuracy: 0.99864, F1: 0.3118, Prec: 0.3827, Rec: 0.2923 lr: 0.00070\n",
      "Epoch 6/Step 870, Loss: -0.15918, Accuracy: 0.99864, F1: 0.3118, Prec: 0.3827, Rec: 0.2919 lr: 0.00070\n",
      "Epoch 6/Step 880, Loss: -0.14061, Accuracy: 0.99864, F1: 0.3120, Prec: 0.3826, Rec: 0.2921 lr: 0.00070\n",
      "Epoch 6/Step 890, Loss: -0.15722, Accuracy: 0.99864, F1: 0.3117, Prec: 0.3823, Rec: 0.2921 lr: 0.00070\n",
      "Epoch 6/Step 900, Loss: -0.21428, Accuracy: 0.99864, F1: 0.3121, Prec: 0.3829, Rec: 0.2922 lr: 0.00070\n",
      "Epoch 6/Step 910, Loss: -0.13333, Accuracy: 0.99864, F1: 0.3120, Prec: 0.3831, Rec: 0.2919 lr: 0.00070\n",
      "Epoch 6/Step 920, Loss: -0.15971, Accuracy: 0.99864, F1: 0.3121, Prec: 0.3831, Rec: 0.2918 lr: 0.00070\n",
      "Epoch 6/Step 930, Loss: -0.14488, Accuracy: 0.99864, F1: 0.3121, Prec: 0.3828, Rec: 0.2920 lr: 0.00070\n",
      "Epoch 6/Step 940, Loss: -0.16320, Accuracy: 0.99864, F1: 0.3118, Prec: 0.3825, Rec: 0.2921 lr: 0.00070\n",
      "Epoch 6/Step 950, Loss: -0.18578, Accuracy: 0.99864, F1: 0.3122, Prec: 0.3829, Rec: 0.2921 lr: 0.00070\n",
      "Epoch 6/Step 960, Loss: -0.19137, Accuracy: 0.99864, F1: 0.3123, Prec: 0.3827, Rec: 0.2921 lr: 0.00070\n",
      "Epoch 6/Step 970, Loss: -0.14819, Accuracy: 0.99864, F1: 0.3125, Prec: 0.3827, Rec: 0.2919 lr: 0.00070\n",
      "Epoch 6/Step 980, Loss: -0.16208, Accuracy: 0.99864, F1: 0.3126, Prec: 0.3827, Rec: 0.2916 lr: 0.00070\n",
      "Epoch 6/Step 990, Loss: -0.15479, Accuracy: 0.99864, F1: 0.3125, Prec: 0.3821, Rec: 0.2916 lr: 0.00070\n",
      "Epoch 6/Step 1000, Loss: -0.17974, Accuracy: 0.99864, F1: 0.3125, Prec: 0.3821, Rec: 0.2918 lr: 0.00070\n",
      "Epoch 6/Step 1010, Loss: -0.19530, Accuracy: 0.99864, F1: 0.3129, Prec: 0.3824, Rec: 0.2920 lr: 0.00070\n",
      "Epoch 6/Step 1020, Loss: -0.11684, Accuracy: 0.99864, F1: 0.3130, Prec: 0.3823, Rec: 0.2918 lr: 0.00070\n",
      "Epoch 6/Step 1030, Loss: -0.15271, Accuracy: 0.99864, F1: 0.3127, Prec: 0.3821, Rec: 0.2919 lr: 0.00070\n",
      "Epoch 6/Step 1040, Loss: -0.17883, Accuracy: 0.99864, F1: 0.3125, Prec: 0.3821, Rec: 0.2919 lr: 0.00070\n",
      "Epoch 6/Step 1050, Loss: -0.17904, Accuracy: 0.99864, F1: 0.3123, Prec: 0.3821, Rec: 0.2919 lr: 0.00070\n",
      "Epoch 6/Step 1060, Loss: -0.17736, Accuracy: 0.99864, F1: 0.3122, Prec: 0.3820, Rec: 0.2920 lr: 0.00070\n",
      "Epoch 6/Step 1070, Loss: -0.17133, Accuracy: 0.99864, F1: 0.3125, Prec: 0.3822, Rec: 0.2921 lr: 0.00070\n",
      "Epoch 6/Step 1080, Loss: -0.12962, Accuracy: 0.99864, F1: 0.3130, Prec: 0.3823, Rec: 0.2921 lr: 0.00070\n",
      "Epoch 6/Step 1090, Loss: -0.14321, Accuracy: 0.99864, F1: 0.3132, Prec: 0.3823, Rec: 0.2920 lr: 0.00070\n",
      "Epoch 6/Step 1100, Loss: -0.16571, Accuracy: 0.99864, F1: 0.3132, Prec: 0.3822, Rec: 0.2920 lr: 0.00070\n",
      "Epoch 6/Step 1110, Loss: -0.14150, Accuracy: 0.99864, F1: 0.3133, Prec: 0.3824, Rec: 0.2921 lr: 0.00070\n",
      "Epoch 6/Step 1120, Loss: -0.14663, Accuracy: 0.99864, F1: 0.3132, Prec: 0.3824, Rec: 0.2921 lr: 0.00070\n",
      "Epoch 6/Step 1130, Loss: -0.15963, Accuracy: 0.99865, F1: 0.3130, Prec: 0.3825, Rec: 0.2923 lr: 0.00070\n",
      "Epoch 6/Step 1140, Loss: -0.14413, Accuracy: 0.99865, F1: 0.3129, Prec: 0.3827, Rec: 0.2922 lr: 0.00070\n",
      "Epoch 6/Step 1150, Loss: -0.17502, Accuracy: 0.99865, F1: 0.3129, Prec: 0.3828, Rec: 0.2923 lr: 0.00070\n",
      "Epoch 6/Step 1160, Loss: -0.13858, Accuracy: 0.99865, F1: 0.3134, Prec: 0.3831, Rec: 0.2927 lr: 0.00070\n",
      "Epoch 6/Step 1170, Loss: -0.15282, Accuracy: 0.99865, F1: 0.3139, Prec: 0.3832, Rec: 0.2926 lr: 0.00070\n",
      "Epoch 6/Step 1180, Loss: -0.12871, Accuracy: 0.99865, F1: 0.3142, Prec: 0.3833, Rec: 0.2926 lr: 0.00070\n",
      "Epoch 6/Step 1190, Loss: -0.17084, Accuracy: 0.99865, F1: 0.3142, Prec: 0.3835, Rec: 0.2924 lr: 0.00070\n",
      "Epoch 6/Step 1200, Loss: -0.16752, Accuracy: 0.99865, F1: 0.3142, Prec: 0.3837, Rec: 0.2926 lr: 0.00070\n",
      "Epoch 6/Step 1210, Loss: -0.15835, Accuracy: 0.99865, F1: 0.3142, Prec: 0.3838, Rec: 0.2928 lr: 0.00070\n",
      "Epoch 6/Step 1220, Loss: -0.17788, Accuracy: 0.99865, F1: 0.3142, Prec: 0.3837, Rec: 0.2930 lr: 0.00070\n",
      "Epoch 6/Step 1230, Loss: -0.17312, Accuracy: 0.99865, F1: 0.3144, Prec: 0.3837, Rec: 0.2930 lr: 0.00070\n",
      "Epoch 6/Step 1240, Loss: -0.20810, Accuracy: 0.99865, F1: 0.3147, Prec: 0.3838, Rec: 0.2929 lr: 0.00070\n",
      "Epoch 6/Step 1250, Loss: -0.12544, Accuracy: 0.99865, F1: 0.3147, Prec: 0.3839, Rec: 0.2930 lr: 0.00070\n",
      "Epoch 6/Step 1260, Loss: -0.15400, Accuracy: 0.99865, F1: 0.3145, Prec: 0.3839, Rec: 0.2931 lr: 0.00070\n",
      "Epoch 6/Step 1270, Loss: -0.14526, Accuracy: 0.99865, F1: 0.3143, Prec: 0.3840, Rec: 0.2932 lr: 0.00070\n",
      "Epoch 6/Step 1280, Loss: -0.22398, Accuracy: 0.99865, F1: 0.3146, Prec: 0.3840, Rec: 0.2932 lr: 0.00070\n",
      "Epoch 6/Step 1290, Loss: -0.18509, Accuracy: 0.99865, F1: 0.3147, Prec: 0.3842, Rec: 0.2934 lr: 0.00070\n",
      "Epoch 6/Step 1300, Loss: -0.16501, Accuracy: 0.99865, F1: 0.3148, Prec: 0.3841, Rec: 0.2934 lr: 0.00070\n",
      "Epoch 6/Step 1310, Loss: -0.16914, Accuracy: 0.99865, F1: 0.3150, Prec: 0.3841, Rec: 0.2934 lr: 0.00070\n",
      "Epoch 6/Step 1320, Loss: -0.15105, Accuracy: 0.99865, F1: 0.3152, Prec: 0.3844, Rec: 0.2934 lr: 0.00070\n",
      "Epoch 6/Step 1330, Loss: -0.17611, Accuracy: 0.99865, F1: 0.3152, Prec: 0.3845, Rec: 0.2933 lr: 0.00070\n",
      "Epoch 6/Step 1340, Loss: -0.14652, Accuracy: 0.99865, F1: 0.3152, Prec: 0.3845, Rec: 0.2936 lr: 0.00070\n",
      "Epoch 6/Step 1350, Loss: -0.12982, Accuracy: 0.99865, F1: 0.3150, Prec: 0.3843, Rec: 0.2936 lr: 0.00070\n",
      "Epoch 6/Step 1360, Loss: -0.14448, Accuracy: 0.99865, F1: 0.3151, Prec: 0.3845, Rec: 0.2935 lr: 0.00070\n",
      "Epoch 6/Step 1370, Loss: -0.14635, Accuracy: 0.99865, F1: 0.3149, Prec: 0.3846, Rec: 0.2935 lr: 0.00070\n",
      "Epoch 6/Step 1380, Loss: -0.16663, Accuracy: 0.99866, F1: 0.3148, Prec: 0.3846, Rec: 0.2936 lr: 0.00070\n",
      "Epoch 6/Step 1390, Loss: -0.18542, Accuracy: 0.99866, F1: 0.3146, Prec: 0.3844, Rec: 0.2935 lr: 0.00070\n",
      "Epoch 6/Step 1400, Loss: -0.18388, Accuracy: 0.99866, F1: 0.3147, Prec: 0.3844, Rec: 0.2936 lr: 0.00070\n",
      "Epoch 6/Step 1410, Loss: -0.17301, Accuracy: 0.99866, F1: 0.3148, Prec: 0.3845, Rec: 0.2936 lr: 0.00070\n",
      "Epoch 6/Step 1420, Loss: -0.15303, Accuracy: 0.99866, F1: 0.3147, Prec: 0.3844, Rec: 0.2935 lr: 0.00070\n",
      "Epoch 6/Step 1430, Loss: -0.14828, Accuracy: 0.99866, F1: 0.3149, Prec: 0.3846, Rec: 0.2934 lr: 0.00070\n",
      "Epoch 6/Step 1440, Loss: -0.14538, Accuracy: 0.99866, F1: 0.3149, Prec: 0.3844, Rec: 0.2935 lr: 0.00070\n",
      "Epoch 6/Step 1450, Loss: -0.15065, Accuracy: 0.99866, F1: 0.3151, Prec: 0.3846, Rec: 0.2934 lr: 0.00070\n",
      "Epoch 6/Step 1460, Loss: -0.14609, Accuracy: 0.99866, F1: 0.3152, Prec: 0.3846, Rec: 0.2933 lr: 0.00070\n",
      "Epoch 6/Step 1470, Loss: -0.16489, Accuracy: 0.99866, F1: 0.3157, Prec: 0.3845, Rec: 0.2934 lr: 0.00070\n",
      "Epoch 6/Step 1480, Loss: -0.16619, Accuracy: 0.99866, F1: 0.3164, Prec: 0.3847, Rec: 0.2933 lr: 0.00070\n",
      "Epoch 6/Step 1490, Loss: -0.14319, Accuracy: 0.99866, F1: 0.3167, Prec: 0.3848, Rec: 0.2933 lr: 0.00070\n",
      "Epoch 6/Step 1500, Loss: -0.17657, Accuracy: 0.99866, F1: 0.3166, Prec: 0.3850, Rec: 0.2934 lr: 0.00070\n",
      "Epoch 6/Step 1510, Loss: -0.15915, Accuracy: 0.99866, F1: 0.3169, Prec: 0.3852, Rec: 0.2933 lr: 0.00070\n",
      "Epoch 6/Step 1520, Loss: -0.19154, Accuracy: 0.99866, F1: 0.3174, Prec: 0.3853, Rec: 0.2935 lr: 0.00070\n",
      "Epoch 6/Step 1530, Loss: -0.15177, Accuracy: 0.99866, F1: 0.3178, Prec: 0.3855, Rec: 0.2937 lr: 0.00070\n",
      "Epoch 6/Step 1540, Loss: -0.13233, Accuracy: 0.99866, F1: 0.3178, Prec: 0.3856, Rec: 0.2935 lr: 0.00070\n",
      "Epoch 6/Step 1550, Loss: -0.17622, Accuracy: 0.99866, F1: 0.3182, Prec: 0.3856, Rec: 0.2935 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9985\n",
      "Validation f1: 0.3839\n",
      "Validation precision: 0.3211\n",
      "Validation recall: 0.2405\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_5_valF1Score0.384/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_5_valF1Score0.384/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 7\n",
      "Epoch 7/Step 0, Loss: -0.17483, Accuracy: 0.99881, F1: 0.5289, Prec: 0.4322, Rec: 0.3120 lr: 0.00070\n",
      "Epoch 7/Step 10, Loss: -0.18891, Accuracy: 0.99865, F1: 0.4324, Prec: 0.4367, Rec: 0.3109 lr: 0.00070\n",
      "Epoch 7/Step 20, Loss: -0.17727, Accuracy: 0.99870, F1: 0.4019, Prec: 0.4278, Rec: 0.3083 lr: 0.00070\n",
      "Epoch 7/Step 30, Loss: -0.16459, Accuracy: 0.99873, F1: 0.3743, Prec: 0.4252, Rec: 0.3110 lr: 0.00070\n",
      "Epoch 7/Step 40, Loss: -0.14634, Accuracy: 0.99874, F1: 0.3687, Prec: 0.4346, Rec: 0.3077 lr: 0.00070\n",
      "Epoch 7/Step 50, Loss: -0.17241, Accuracy: 0.99872, F1: 0.3628, Prec: 0.4272, Rec: 0.3105 lr: 0.00070\n",
      "Epoch 7/Step 60, Loss: -0.17871, Accuracy: 0.99872, F1: 0.3614, Prec: 0.4213, Rec: 0.3117 lr: 0.00070\n",
      "Epoch 7/Step 70, Loss: -0.17655, Accuracy: 0.99874, F1: 0.3692, Prec: 0.4234, Rec: 0.3114 lr: 0.00070\n",
      "Epoch 7/Step 80, Loss: -0.15811, Accuracy: 0.99875, F1: 0.3739, Prec: 0.4216, Rec: 0.3089 lr: 0.00070\n",
      "Epoch 7/Step 90, Loss: -0.16496, Accuracy: 0.99874, F1: 0.3766, Prec: 0.4206, Rec: 0.3101 lr: 0.00070\n",
      "Epoch 7/Step 100, Loss: -0.18284, Accuracy: 0.99875, F1: 0.3791, Prec: 0.4224, Rec: 0.3124 lr: 0.00070\n",
      "Epoch 7/Step 110, Loss: -0.17157, Accuracy: 0.99874, F1: 0.3847, Prec: 0.4247, Rec: 0.3115 lr: 0.00070\n",
      "Epoch 7/Step 120, Loss: -0.15087, Accuracy: 0.99873, F1: 0.3883, Prec: 0.4235, Rec: 0.3106 lr: 0.00070\n",
      "Epoch 7/Step 130, Loss: -0.13830, Accuracy: 0.99873, F1: 0.3871, Prec: 0.4222, Rec: 0.3122 lr: 0.00070\n",
      "Epoch 7/Step 140, Loss: -0.15391, Accuracy: 0.99873, F1: 0.3882, Prec: 0.4233, Rec: 0.3084 lr: 0.00070\n",
      "Epoch 7/Step 150, Loss: -0.15400, Accuracy: 0.99872, F1: 0.3904, Prec: 0.4223, Rec: 0.3060 lr: 0.00070\n",
      "Epoch 7/Step 160, Loss: -0.16884, Accuracy: 0.99870, F1: 0.3850, Prec: 0.4148, Rec: 0.3075 lr: 0.00070\n",
      "Epoch 7/Step 170, Loss: -0.15787, Accuracy: 0.99870, F1: 0.3811, Prec: 0.4103, Rec: 0.3066 lr: 0.00070\n",
      "Epoch 7/Step 180, Loss: -0.16974, Accuracy: 0.99870, F1: 0.3802, Prec: 0.4126, Rec: 0.3059 lr: 0.00070\n",
      "Epoch 7/Step 190, Loss: -0.16857, Accuracy: 0.99870, F1: 0.3768, Prec: 0.4122, Rec: 0.3054 lr: 0.00070\n",
      "Epoch 7/Step 200, Loss: -0.15900, Accuracy: 0.99869, F1: 0.3726, Prec: 0.4129, Rec: 0.3046 lr: 0.00070\n",
      "Epoch 7/Step 210, Loss: -0.15172, Accuracy: 0.99869, F1: 0.3691, Prec: 0.4113, Rec: 0.3048 lr: 0.00070\n",
      "Epoch 7/Step 220, Loss: -0.19279, Accuracy: 0.99869, F1: 0.3673, Prec: 0.4110, Rec: 0.3050 lr: 0.00070\n",
      "Epoch 7/Step 230, Loss: -0.14263, Accuracy: 0.99869, F1: 0.3664, Prec: 0.4109, Rec: 0.3046 lr: 0.00070\n",
      "Epoch 7/Step 240, Loss: -0.20196, Accuracy: 0.99868, F1: 0.3670, Prec: 0.4129, Rec: 0.3043 lr: 0.00070\n",
      "Epoch 7/Step 250, Loss: -0.18239, Accuracy: 0.99868, F1: 0.3655, Prec: 0.4124, Rec: 0.3040 lr: 0.00070\n",
      "Epoch 7/Step 260, Loss: -0.18903, Accuracy: 0.99868, F1: 0.3650, Prec: 0.4116, Rec: 0.3046 lr: 0.00070\n",
      "Epoch 7/Step 270, Loss: -0.20777, Accuracy: 0.99868, F1: 0.3650, Prec: 0.4117, Rec: 0.3044 lr: 0.00070\n",
      "Epoch 7/Step 280, Loss: -0.19614, Accuracy: 0.99868, F1: 0.3653, Prec: 0.4123, Rec: 0.3038 lr: 0.00070\n",
      "Epoch 7/Step 290, Loss: -0.16968, Accuracy: 0.99868, F1: 0.3653, Prec: 0.4129, Rec: 0.3035 lr: 0.00070\n",
      "Epoch 7/Step 300, Loss: -0.18968, Accuracy: 0.99868, F1: 0.3648, Prec: 0.4131, Rec: 0.3039 lr: 0.00070\n",
      "Epoch 7/Step 310, Loss: -0.18317, Accuracy: 0.99868, F1: 0.3637, Prec: 0.4129, Rec: 0.3042 lr: 0.00070\n",
      "Epoch 7/Step 320, Loss: -0.16133, Accuracy: 0.99869, F1: 0.3649, Prec: 0.4144, Rec: 0.3042 lr: 0.00070\n",
      "Epoch 7/Step 330, Loss: -0.19599, Accuracy: 0.99869, F1: 0.3659, Prec: 0.4148, Rec: 0.3045 lr: 0.00070\n",
      "Epoch 7/Step 340, Loss: -0.17305, Accuracy: 0.99869, F1: 0.3666, Prec: 0.4155, Rec: 0.3045 lr: 0.00070\n",
      "Epoch 7/Step 350, Loss: -0.15602, Accuracy: 0.99869, F1: 0.3670, Prec: 0.4170, Rec: 0.3045 lr: 0.00070\n",
      "Epoch 7/Step 360, Loss: -0.17808, Accuracy: 0.99869, F1: 0.3670, Prec: 0.4175, Rec: 0.3052 lr: 0.00070\n",
      "Epoch 7/Step 370, Loss: -0.18101, Accuracy: 0.99869, F1: 0.3671, Prec: 0.4169, Rec: 0.3053 lr: 0.00070\n",
      "Epoch 7/Step 380, Loss: -0.19769, Accuracy: 0.99870, F1: 0.3687, Prec: 0.4174, Rec: 0.3051 lr: 0.00070\n",
      "Epoch 7/Step 390, Loss: -0.16017, Accuracy: 0.99870, F1: 0.3698, Prec: 0.4182, Rec: 0.3047 lr: 0.00070\n",
      "Epoch 7/Step 400, Loss: -0.13471, Accuracy: 0.99870, F1: 0.3693, Prec: 0.4182, Rec: 0.3047 lr: 0.00070\n",
      "Epoch 7/Step 410, Loss: -0.14222, Accuracy: 0.99870, F1: 0.3682, Prec: 0.4180, Rec: 0.3047 lr: 0.00070\n",
      "Epoch 7/Step 420, Loss: -0.17965, Accuracy: 0.99870, F1: 0.3696, Prec: 0.4188, Rec: 0.3047 lr: 0.00070\n",
      "Epoch 7/Step 430, Loss: -0.15996, Accuracy: 0.99870, F1: 0.3705, Prec: 0.4187, Rec: 0.3045 lr: 0.00070\n",
      "Epoch 7/Step 440, Loss: -0.17360, Accuracy: 0.99870, F1: 0.3698, Prec: 0.4173, Rec: 0.3053 lr: 0.00070\n",
      "Epoch 7/Step 450, Loss: -0.18094, Accuracy: 0.99870, F1: 0.3691, Prec: 0.4176, Rec: 0.3053 lr: 0.00070\n",
      "Epoch 7/Step 460, Loss: -0.16716, Accuracy: 0.99870, F1: 0.3681, Prec: 0.4170, Rec: 0.3054 lr: 0.00070\n",
      "Epoch 7/Step 470, Loss: -0.16863, Accuracy: 0.99870, F1: 0.3683, Prec: 0.4175, Rec: 0.3052 lr: 0.00070\n",
      "Epoch 7/Step 480, Loss: -0.17271, Accuracy: 0.99870, F1: 0.3685, Prec: 0.4172, Rec: 0.3048 lr: 0.00070\n",
      "Epoch 7/Step 490, Loss: -0.16377, Accuracy: 0.99870, F1: 0.3681, Prec: 0.4165, Rec: 0.3047 lr: 0.00070\n",
      "Epoch 7/Step 500, Loss: -0.16978, Accuracy: 0.99870, F1: 0.3676, Prec: 0.4162, Rec: 0.3046 lr: 0.00070\n",
      "Epoch 7/Step 510, Loss: -0.19887, Accuracy: 0.99870, F1: 0.3683, Prec: 0.4160, Rec: 0.3049 lr: 0.00070\n",
      "Epoch 7/Step 520, Loss: -0.14420, Accuracy: 0.99870, F1: 0.3696, Prec: 0.4168, Rec: 0.3051 lr: 0.00070\n",
      "Epoch 7/Step 530, Loss: -0.15941, Accuracy: 0.99870, F1: 0.3703, Prec: 0.4170, Rec: 0.3048 lr: 0.00070\n",
      "Epoch 7/Step 540, Loss: -0.16480, Accuracy: 0.99870, F1: 0.3716, Prec: 0.4169, Rec: 0.3047 lr: 0.00070\n",
      "Epoch 7/Step 550, Loss: -0.20047, Accuracy: 0.99870, F1: 0.3730, Prec: 0.4169, Rec: 0.3050 lr: 0.00070\n",
      "Epoch 7/Step 560, Loss: -0.16287, Accuracy: 0.99870, F1: 0.3743, Prec: 0.4169, Rec: 0.3051 lr: 0.00070\n",
      "Epoch 7/Step 570, Loss: -0.17621, Accuracy: 0.99870, F1: 0.3748, Prec: 0.4172, Rec: 0.3052 lr: 0.00070\n",
      "Epoch 7/Step 580, Loss: -0.15522, Accuracy: 0.99870, F1: 0.3748, Prec: 0.4174, Rec: 0.3050 lr: 0.00070\n",
      "Epoch 7/Step 590, Loss: -0.13246, Accuracy: 0.99870, F1: 0.3748, Prec: 0.4172, Rec: 0.3051 lr: 0.00070\n",
      "Epoch 7/Step 600, Loss: -0.15361, Accuracy: 0.99870, F1: 0.3748, Prec: 0.4179, Rec: 0.3049 lr: 0.00070\n",
      "Epoch 7/Step 610, Loss: -0.21091, Accuracy: 0.99870, F1: 0.3746, Prec: 0.4179, Rec: 0.3050 lr: 0.00070\n",
      "Epoch 7/Step 620, Loss: -0.19579, Accuracy: 0.99870, F1: 0.3743, Prec: 0.4184, Rec: 0.3054 lr: 0.00070\n",
      "Epoch 7/Step 630, Loss: -0.16445, Accuracy: 0.99870, F1: 0.3737, Prec: 0.4180, Rec: 0.3054 lr: 0.00070\n",
      "Epoch 7/Step 640, Loss: -0.16227, Accuracy: 0.99870, F1: 0.3738, Prec: 0.4182, Rec: 0.3053 lr: 0.00070\n",
      "Epoch 7/Step 650, Loss: -0.15844, Accuracy: 0.99870, F1: 0.3749, Prec: 0.4185, Rec: 0.3051 lr: 0.00070\n",
      "Epoch 7/Step 660, Loss: -0.18777, Accuracy: 0.99870, F1: 0.3752, Prec: 0.4182, Rec: 0.3053 lr: 0.00070\n",
      "Epoch 7/Step 670, Loss: -0.14528, Accuracy: 0.99870, F1: 0.3756, Prec: 0.4183, Rec: 0.3053 lr: 0.00070\n",
      "Epoch 7/Step 680, Loss: -0.14776, Accuracy: 0.99870, F1: 0.3753, Prec: 0.4184, Rec: 0.3055 lr: 0.00070\n",
      "Epoch 7/Step 690, Loss: -0.20293, Accuracy: 0.99870, F1: 0.3752, Prec: 0.4184, Rec: 0.3054 lr: 0.00070\n",
      "Epoch 7/Step 700, Loss: -0.17711, Accuracy: 0.99870, F1: 0.3756, Prec: 0.4185, Rec: 0.3052 lr: 0.00070\n",
      "Epoch 7/Step 710, Loss: -0.19085, Accuracy: 0.99870, F1: 0.3757, Prec: 0.4188, Rec: 0.3057 lr: 0.00070\n",
      "Epoch 7/Step 720, Loss: -0.19911, Accuracy: 0.99870, F1: 0.3759, Prec: 0.4192, Rec: 0.3054 lr: 0.00070\n",
      "Epoch 7/Step 730, Loss: -0.16222, Accuracy: 0.99870, F1: 0.3757, Prec: 0.4190, Rec: 0.3055 lr: 0.00070\n",
      "Epoch 7/Step 740, Loss: -0.17422, Accuracy: 0.99871, F1: 0.3754, Prec: 0.4189, Rec: 0.3053 lr: 0.00070\n",
      "Epoch 7/Step 750, Loss: -0.15960, Accuracy: 0.99871, F1: 0.3759, Prec: 0.4190, Rec: 0.3053 lr: 0.00070\n",
      "Epoch 7/Step 760, Loss: -0.16945, Accuracy: 0.99871, F1: 0.3765, Prec: 0.4191, Rec: 0.3051 lr: 0.00070\n",
      "Epoch 7/Step 770, Loss: -0.19534, Accuracy: 0.99871, F1: 0.3775, Prec: 0.4194, Rec: 0.3052 lr: 0.00070\n",
      "Epoch 7/Step 780, Loss: -0.16258, Accuracy: 0.99871, F1: 0.3789, Prec: 0.4204, Rec: 0.3053 lr: 0.00070\n",
      "Epoch 7/Step 790, Loss: -0.18710, Accuracy: 0.99871, F1: 0.3788, Prec: 0.4201, Rec: 0.3052 lr: 0.00070\n",
      "Epoch 7/Step 800, Loss: -0.15180, Accuracy: 0.99871, F1: 0.3785, Prec: 0.4199, Rec: 0.3051 lr: 0.00070\n",
      "Epoch 7/Step 810, Loss: -0.12314, Accuracy: 0.99871, F1: 0.3787, Prec: 0.4196, Rec: 0.3050 lr: 0.00070\n",
      "Epoch 7/Step 820, Loss: -0.17792, Accuracy: 0.99871, F1: 0.3795, Prec: 0.4191, Rec: 0.3048 lr: 0.00070\n",
      "Epoch 7/Step 830, Loss: -0.18511, Accuracy: 0.99871, F1: 0.3795, Prec: 0.4194, Rec: 0.3050 lr: 0.00070\n",
      "Epoch 7/Step 840, Loss: -0.19485, Accuracy: 0.99871, F1: 0.3793, Prec: 0.4194, Rec: 0.3050 lr: 0.00070\n",
      "Epoch 7/Step 850, Loss: -0.16257, Accuracy: 0.99871, F1: 0.3792, Prec: 0.4191, Rec: 0.3050 lr: 0.00070\n",
      "Epoch 7/Step 860, Loss: -0.17862, Accuracy: 0.99871, F1: 0.3794, Prec: 0.4193, Rec: 0.3049 lr: 0.00070\n",
      "Epoch 7/Step 870, Loss: -0.17412, Accuracy: 0.99871, F1: 0.3794, Prec: 0.4193, Rec: 0.3045 lr: 0.00070\n",
      "Epoch 7/Step 880, Loss: -0.14508, Accuracy: 0.99871, F1: 0.3794, Prec: 0.4191, Rec: 0.3046 lr: 0.00070\n",
      "Epoch 7/Step 890, Loss: -0.16780, Accuracy: 0.99871, F1: 0.3790, Prec: 0.4189, Rec: 0.3046 lr: 0.00070\n",
      "Epoch 7/Step 900, Loss: -0.22997, Accuracy: 0.99871, F1: 0.3792, Prec: 0.4195, Rec: 0.3047 lr: 0.00070\n",
      "Epoch 7/Step 910, Loss: -0.15243, Accuracy: 0.99871, F1: 0.3794, Prec: 0.4198, Rec: 0.3045 lr: 0.00070\n",
      "Epoch 7/Step 920, Loss: -0.17107, Accuracy: 0.99871, F1: 0.3792, Prec: 0.4196, Rec: 0.3044 lr: 0.00070\n",
      "Epoch 7/Step 930, Loss: -0.16629, Accuracy: 0.99871, F1: 0.3787, Prec: 0.4195, Rec: 0.3045 lr: 0.00070\n",
      "Epoch 7/Step 940, Loss: -0.16530, Accuracy: 0.99871, F1: 0.3781, Prec: 0.4193, Rec: 0.3046 lr: 0.00070\n",
      "Epoch 7/Step 950, Loss: -0.19970, Accuracy: 0.99871, F1: 0.3781, Prec: 0.4196, Rec: 0.3047 lr: 0.00070\n",
      "Epoch 7/Step 960, Loss: -0.20168, Accuracy: 0.99871, F1: 0.3779, Prec: 0.4193, Rec: 0.3047 lr: 0.00070\n",
      "Epoch 7/Step 970, Loss: -0.15117, Accuracy: 0.99871, F1: 0.3781, Prec: 0.4194, Rec: 0.3043 lr: 0.00070\n",
      "Epoch 7/Step 980, Loss: -0.16220, Accuracy: 0.99871, F1: 0.3786, Prec: 0.4194, Rec: 0.3040 lr: 0.00070\n",
      "Epoch 7/Step 990, Loss: -0.16432, Accuracy: 0.99871, F1: 0.3786, Prec: 0.4188, Rec: 0.3040 lr: 0.00070\n",
      "Epoch 7/Step 1000, Loss: -0.18350, Accuracy: 0.99871, F1: 0.3786, Prec: 0.4186, Rec: 0.3042 lr: 0.00070\n",
      "Epoch 7/Step 1010, Loss: -0.20146, Accuracy: 0.99871, F1: 0.3789, Prec: 0.4190, Rec: 0.3044 lr: 0.00070\n",
      "Epoch 7/Step 1020, Loss: -0.15210, Accuracy: 0.99871, F1: 0.3789, Prec: 0.4187, Rec: 0.3043 lr: 0.00070\n",
      "Epoch 7/Step 1030, Loss: -0.17142, Accuracy: 0.99872, F1: 0.3788, Prec: 0.4187, Rec: 0.3043 lr: 0.00070\n",
      "Epoch 7/Step 1040, Loss: -0.19071, Accuracy: 0.99872, F1: 0.3787, Prec: 0.4188, Rec: 0.3043 lr: 0.00070\n",
      "Epoch 7/Step 1050, Loss: -0.19429, Accuracy: 0.99872, F1: 0.3783, Prec: 0.4187, Rec: 0.3043 lr: 0.00070\n",
      "Epoch 7/Step 1060, Loss: -0.18554, Accuracy: 0.99872, F1: 0.3782, Prec: 0.4186, Rec: 0.3044 lr: 0.00070\n",
      "Epoch 7/Step 1070, Loss: -0.18861, Accuracy: 0.99872, F1: 0.3785, Prec: 0.4187, Rec: 0.3045 lr: 0.00070\n",
      "Epoch 7/Step 1080, Loss: -0.14485, Accuracy: 0.99872, F1: 0.3792, Prec: 0.4189, Rec: 0.3045 lr: 0.00070\n",
      "Epoch 7/Step 1090, Loss: -0.15476, Accuracy: 0.99872, F1: 0.3796, Prec: 0.4188, Rec: 0.3045 lr: 0.00070\n",
      "Epoch 7/Step 1100, Loss: -0.17475, Accuracy: 0.99872, F1: 0.3797, Prec: 0.4188, Rec: 0.3045 lr: 0.00070\n",
      "Epoch 7/Step 1110, Loss: -0.15265, Accuracy: 0.99872, F1: 0.3796, Prec: 0.4189, Rec: 0.3046 lr: 0.00070\n",
      "Epoch 7/Step 1120, Loss: -0.15534, Accuracy: 0.99872, F1: 0.3794, Prec: 0.4189, Rec: 0.3046 lr: 0.00070\n",
      "Epoch 7/Step 1130, Loss: -0.16998, Accuracy: 0.99872, F1: 0.3794, Prec: 0.4191, Rec: 0.3048 lr: 0.00070\n",
      "Epoch 7/Step 1140, Loss: -0.16122, Accuracy: 0.99872, F1: 0.3795, Prec: 0.4193, Rec: 0.3047 lr: 0.00070\n",
      "Epoch 7/Step 1150, Loss: -0.18495, Accuracy: 0.99872, F1: 0.3794, Prec: 0.4192, Rec: 0.3049 lr: 0.00070\n",
      "Epoch 7/Step 1160, Loss: -0.14009, Accuracy: 0.99872, F1: 0.3797, Prec: 0.4194, Rec: 0.3052 lr: 0.00070\n",
      "Epoch 7/Step 1170, Loss: -0.16192, Accuracy: 0.99872, F1: 0.3806, Prec: 0.4195, Rec: 0.3051 lr: 0.00070\n",
      "Epoch 7/Step 1180, Loss: -0.13501, Accuracy: 0.99872, F1: 0.3812, Prec: 0.4196, Rec: 0.3051 lr: 0.00070\n",
      "Epoch 7/Step 1190, Loss: -0.17760, Accuracy: 0.99872, F1: 0.3814, Prec: 0.4196, Rec: 0.3050 lr: 0.00070\n",
      "Epoch 7/Step 1200, Loss: -0.18073, Accuracy: 0.99872, F1: 0.3816, Prec: 0.4199, Rec: 0.3051 lr: 0.00070\n",
      "Epoch 7/Step 1210, Loss: -0.16715, Accuracy: 0.99872, F1: 0.3816, Prec: 0.4200, Rec: 0.3053 lr: 0.00070\n",
      "Epoch 7/Step 1220, Loss: -0.20003, Accuracy: 0.99872, F1: 0.3814, Prec: 0.4199, Rec: 0.3054 lr: 0.00070\n",
      "Epoch 7/Step 1230, Loss: -0.18743, Accuracy: 0.99872, F1: 0.3821, Prec: 0.4201, Rec: 0.3053 lr: 0.00070\n",
      "Epoch 7/Step 1240, Loss: -0.21620, Accuracy: 0.99872, F1: 0.3828, Prec: 0.4201, Rec: 0.3054 lr: 0.00070\n",
      "Epoch 7/Step 1250, Loss: -0.13190, Accuracy: 0.99872, F1: 0.3830, Prec: 0.4200, Rec: 0.3056 lr: 0.00070\n",
      "Epoch 7/Step 1260, Loss: -0.16386, Accuracy: 0.99872, F1: 0.3831, Prec: 0.4200, Rec: 0.3055 lr: 0.00070\n",
      "Epoch 7/Step 1270, Loss: -0.16037, Accuracy: 0.99872, F1: 0.3827, Prec: 0.4200, Rec: 0.3057 lr: 0.00070\n",
      "Epoch 7/Step 1280, Loss: -0.24155, Accuracy: 0.99872, F1: 0.3830, Prec: 0.4201, Rec: 0.3057 lr: 0.00070\n",
      "Epoch 7/Step 1290, Loss: -0.20091, Accuracy: 0.99872, F1: 0.3834, Prec: 0.4203, Rec: 0.3059 lr: 0.00070\n",
      "Epoch 7/Step 1300, Loss: -0.17008, Accuracy: 0.99872, F1: 0.3837, Prec: 0.4201, Rec: 0.3059 lr: 0.00070\n",
      "Epoch 7/Step 1310, Loss: -0.18438, Accuracy: 0.99872, F1: 0.3842, Prec: 0.4202, Rec: 0.3060 lr: 0.00070\n",
      "Epoch 7/Step 1320, Loss: -0.17706, Accuracy: 0.99872, F1: 0.3843, Prec: 0.4202, Rec: 0.3060 lr: 0.00070\n",
      "Epoch 7/Step 1330, Loss: -0.18963, Accuracy: 0.99872, F1: 0.3843, Prec: 0.4204, Rec: 0.3059 lr: 0.00070\n",
      "Epoch 7/Step 1340, Loss: -0.16306, Accuracy: 0.99872, F1: 0.3844, Prec: 0.4206, Rec: 0.3060 lr: 0.00070\n",
      "Epoch 7/Step 1350, Loss: -0.14460, Accuracy: 0.99872, F1: 0.3845, Prec: 0.4204, Rec: 0.3060 lr: 0.00070\n",
      "Epoch 7/Step 1360, Loss: -0.15081, Accuracy: 0.99872, F1: 0.3846, Prec: 0.4206, Rec: 0.3059 lr: 0.00070\n",
      "Epoch 7/Step 1370, Loss: -0.16256, Accuracy: 0.99872, F1: 0.3844, Prec: 0.4207, Rec: 0.3060 lr: 0.00070\n",
      "Epoch 7/Step 1380, Loss: -0.16767, Accuracy: 0.99873, F1: 0.3840, Prec: 0.4206, Rec: 0.3061 lr: 0.00070\n",
      "Epoch 7/Step 1390, Loss: -0.19704, Accuracy: 0.99873, F1: 0.3837, Prec: 0.4205, Rec: 0.3060 lr: 0.00070\n",
      "Epoch 7/Step 1400, Loss: -0.19717, Accuracy: 0.99873, F1: 0.3840, Prec: 0.4207, Rec: 0.3061 lr: 0.00070\n",
      "Epoch 7/Step 1410, Loss: -0.17789, Accuracy: 0.99873, F1: 0.3843, Prec: 0.4207, Rec: 0.3060 lr: 0.00070\n",
      "Epoch 7/Step 1420, Loss: -0.16453, Accuracy: 0.99873, F1: 0.3844, Prec: 0.4207, Rec: 0.3059 lr: 0.00070\n",
      "Epoch 7/Step 1430, Loss: -0.16056, Accuracy: 0.99873, F1: 0.3848, Prec: 0.4209, Rec: 0.3058 lr: 0.00070\n",
      "Epoch 7/Step 1440, Loss: -0.15682, Accuracy: 0.99873, F1: 0.3848, Prec: 0.4207, Rec: 0.3059 lr: 0.00070\n",
      "Epoch 7/Step 1450, Loss: -0.16567, Accuracy: 0.99873, F1: 0.3850, Prec: 0.4210, Rec: 0.3059 lr: 0.00070\n",
      "Epoch 7/Step 1460, Loss: -0.16005, Accuracy: 0.99873, F1: 0.3853, Prec: 0.4211, Rec: 0.3057 lr: 0.00070\n",
      "Epoch 7/Step 1470, Loss: -0.17612, Accuracy: 0.99873, F1: 0.3857, Prec: 0.4210, Rec: 0.3058 lr: 0.00070\n",
      "Epoch 7/Step 1480, Loss: -0.17719, Accuracy: 0.99873, F1: 0.3860, Prec: 0.4211, Rec: 0.3058 lr: 0.00070\n",
      "Epoch 7/Step 1490, Loss: -0.15671, Accuracy: 0.99873, F1: 0.3863, Prec: 0.4210, Rec: 0.3057 lr: 0.00070\n",
      "Epoch 7/Step 1500, Loss: -0.18527, Accuracy: 0.99873, F1: 0.3861, Prec: 0.4211, Rec: 0.3059 lr: 0.00070\n",
      "Epoch 7/Step 1510, Loss: -0.16247, Accuracy: 0.99873, F1: 0.3863, Prec: 0.4214, Rec: 0.3058 lr: 0.00070\n",
      "Epoch 7/Step 1520, Loss: -0.21111, Accuracy: 0.99873, F1: 0.3864, Prec: 0.4214, Rec: 0.3060 lr: 0.00070\n",
      "Epoch 7/Step 1530, Loss: -0.16488, Accuracy: 0.99873, F1: 0.3869, Prec: 0.4217, Rec: 0.3062 lr: 0.00070\n",
      "Epoch 7/Step 1540, Loss: -0.14195, Accuracy: 0.99873, F1: 0.3871, Prec: 0.4218, Rec: 0.3059 lr: 0.00070\n",
      "Epoch 7/Step 1550, Loss: -0.17732, Accuracy: 0.99873, F1: 0.3872, Prec: 0.4218, Rec: 0.3059 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9985\n",
      "Validation f1: 0.3530\n",
      "Validation precision: 0.3177\n",
      "Validation recall: 0.2487\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_6_valF1Score0.353/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_6_valF1Score0.353/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 8\n",
      "Epoch 8/Step 0, Loss: -0.18486, Accuracy: 0.99885, F1: 0.5083, Prec: 0.4618, Rec: 0.3261 lr: 0.00070\n",
      "Epoch 8/Step 10, Loss: -0.19841, Accuracy: 0.99866, F1: 0.4373, Prec: 0.4444, Rec: 0.3342 lr: 0.00070\n",
      "Epoch 8/Step 20, Loss: -0.17580, Accuracy: 0.99874, F1: 0.4515, Prec: 0.4511, Rec: 0.3241 lr: 0.00070\n",
      "Epoch 8/Step 30, Loss: -0.16678, Accuracy: 0.99877, F1: 0.4282, Prec: 0.4458, Rec: 0.3260 lr: 0.00070\n",
      "Epoch 8/Step 40, Loss: -0.16702, Accuracy: 0.99876, F1: 0.4189, Prec: 0.4530, Rec: 0.3248 lr: 0.00070\n",
      "Epoch 8/Step 50, Loss: -0.18213, Accuracy: 0.99877, F1: 0.4126, Prec: 0.4536, Rec: 0.3229 lr: 0.00070\n",
      "Epoch 8/Step 60, Loss: -0.20602, Accuracy: 0.99877, F1: 0.4132, Prec: 0.4478, Rec: 0.3268 lr: 0.00070\n",
      "Epoch 8/Step 70, Loss: -0.17850, Accuracy: 0.99879, F1: 0.4307, Prec: 0.4507, Rec: 0.3260 lr: 0.00070\n",
      "Epoch 8/Step 80, Loss: -0.16952, Accuracy: 0.99880, F1: 0.4383, Prec: 0.4502, Rec: 0.3230 lr: 0.00070\n",
      "Epoch 8/Step 90, Loss: -0.17057, Accuracy: 0.99879, F1: 0.4458, Prec: 0.4507, Rec: 0.3235 lr: 0.00070\n",
      "Epoch 8/Step 100, Loss: -0.20349, Accuracy: 0.99880, F1: 0.4510, Prec: 0.4525, Rec: 0.3258 lr: 0.00070\n",
      "Epoch 8/Step 110, Loss: -0.17854, Accuracy: 0.99879, F1: 0.4570, Prec: 0.4539, Rec: 0.3250 lr: 0.00070\n",
      "Epoch 8/Step 120, Loss: -0.15855, Accuracy: 0.99878, F1: 0.4577, Prec: 0.4525, Rec: 0.3244 lr: 0.00070\n",
      "Epoch 8/Step 130, Loss: -0.14938, Accuracy: 0.99879, F1: 0.4588, Prec: 0.4526, Rec: 0.3244 lr: 0.00070\n",
      "Epoch 8/Step 140, Loss: -0.17230, Accuracy: 0.99878, F1: 0.4566, Prec: 0.4533, Rec: 0.3215 lr: 0.00070\n",
      "Epoch 8/Step 150, Loss: -0.16655, Accuracy: 0.99877, F1: 0.4538, Prec: 0.4510, Rec: 0.3196 lr: 0.00070\n",
      "Epoch 8/Step 160, Loss: -0.18575, Accuracy: 0.99876, F1: 0.4479, Prec: 0.4462, Rec: 0.3204 lr: 0.00070\n",
      "Epoch 8/Step 170, Loss: -0.16559, Accuracy: 0.99875, F1: 0.4441, Prec: 0.4412, Rec: 0.3194 lr: 0.00070\n",
      "Epoch 8/Step 180, Loss: -0.19197, Accuracy: 0.99876, F1: 0.4454, Prec: 0.4427, Rec: 0.3196 lr: 0.00070\n",
      "Epoch 8/Step 190, Loss: -0.17578, Accuracy: 0.99876, F1: 0.4436, Prec: 0.4436, Rec: 0.3185 lr: 0.00070\n",
      "Epoch 8/Step 200, Loss: -0.17500, Accuracy: 0.99875, F1: 0.4392, Prec: 0.4432, Rec: 0.3182 lr: 0.00070\n",
      "Epoch 8/Step 210, Loss: -0.14864, Accuracy: 0.99874, F1: 0.4347, Prec: 0.4418, Rec: 0.3180 lr: 0.00070\n",
      "Epoch 8/Step 220, Loss: -0.20250, Accuracy: 0.99874, F1: 0.4334, Prec: 0.4420, Rec: 0.3179 lr: 0.00070\n",
      "Epoch 8/Step 230, Loss: -0.15758, Accuracy: 0.99874, F1: 0.4349, Prec: 0.4423, Rec: 0.3172 lr: 0.00070\n",
      "Epoch 8/Step 240, Loss: -0.21156, Accuracy: 0.99874, F1: 0.4380, Prec: 0.4434, Rec: 0.3172 lr: 0.00070\n",
      "Epoch 8/Step 250, Loss: -0.19599, Accuracy: 0.99874, F1: 0.4388, Prec: 0.4435, Rec: 0.3167 lr: 0.00070\n",
      "Epoch 8/Step 260, Loss: -0.19631, Accuracy: 0.99873, F1: 0.4386, Prec: 0.4419, Rec: 0.3173 lr: 0.00070\n",
      "Epoch 8/Step 270, Loss: -0.21803, Accuracy: 0.99873, F1: 0.4400, Prec: 0.4407, Rec: 0.3173 lr: 0.00070\n",
      "Epoch 8/Step 280, Loss: -0.20153, Accuracy: 0.99873, F1: 0.4425, Prec: 0.4415, Rec: 0.3159 lr: 0.00070\n",
      "Epoch 8/Step 290, Loss: -0.18226, Accuracy: 0.99873, F1: 0.4439, Prec: 0.4418, Rec: 0.3157 lr: 0.00070\n",
      "Epoch 8/Step 300, Loss: -0.19296, Accuracy: 0.99873, F1: 0.4431, Prec: 0.4427, Rec: 0.3157 lr: 0.00070\n",
      "Epoch 8/Step 310, Loss: -0.19074, Accuracy: 0.99874, F1: 0.4410, Prec: 0.4423, Rec: 0.3160 lr: 0.00070\n",
      "Epoch 8/Step 320, Loss: -0.17225, Accuracy: 0.99874, F1: 0.4411, Prec: 0.4435, Rec: 0.3164 lr: 0.00070\n",
      "Epoch 8/Step 330, Loss: -0.20591, Accuracy: 0.99874, F1: 0.4437, Prec: 0.4448, Rec: 0.3162 lr: 0.00070\n",
      "Epoch 8/Step 340, Loss: -0.18013, Accuracy: 0.99874, F1: 0.4443, Prec: 0.4447, Rec: 0.3165 lr: 0.00070\n",
      "Epoch 8/Step 350, Loss: -0.16429, Accuracy: 0.99874, F1: 0.4452, Prec: 0.4463, Rec: 0.3166 lr: 0.00070\n",
      "Epoch 8/Step 360, Loss: -0.18899, Accuracy: 0.99874, F1: 0.4456, Prec: 0.4469, Rec: 0.3173 lr: 0.00070\n",
      "Epoch 8/Step 370, Loss: -0.19065, Accuracy: 0.99874, F1: 0.4463, Prec: 0.4462, Rec: 0.3175 lr: 0.00070\n",
      "Epoch 8/Step 380, Loss: -0.20087, Accuracy: 0.99875, F1: 0.4497, Prec: 0.4468, Rec: 0.3173 lr: 0.00070\n",
      "Epoch 8/Step 390, Loss: -0.16861, Accuracy: 0.99875, F1: 0.4522, Prec: 0.4476, Rec: 0.3169 lr: 0.00070\n",
      "Epoch 8/Step 400, Loss: -0.14369, Accuracy: 0.99875, F1: 0.4530, Prec: 0.4481, Rec: 0.3166 lr: 0.00070\n",
      "Epoch 8/Step 410, Loss: -0.14957, Accuracy: 0.99875, F1: 0.4516, Prec: 0.4473, Rec: 0.3166 lr: 0.00070\n",
      "Epoch 8/Step 420, Loss: -0.19334, Accuracy: 0.99876, F1: 0.4534, Prec: 0.4483, Rec: 0.3168 lr: 0.00070\n",
      "Epoch 8/Step 430, Loss: -0.17346, Accuracy: 0.99876, F1: 0.4553, Prec: 0.4487, Rec: 0.3163 lr: 0.00070\n",
      "Epoch 8/Step 440, Loss: -0.17941, Accuracy: 0.99875, F1: 0.4558, Prec: 0.4473, Rec: 0.3169 lr: 0.00070\n",
      "Epoch 8/Step 450, Loss: -0.19135, Accuracy: 0.99875, F1: 0.4560, Prec: 0.4476, Rec: 0.3170 lr: 0.00070\n",
      "Epoch 8/Step 460, Loss: -0.17873, Accuracy: 0.99875, F1: 0.4565, Prec: 0.4475, Rec: 0.3167 lr: 0.00070\n",
      "Epoch 8/Step 470, Loss: -0.18265, Accuracy: 0.99876, F1: 0.4571, Prec: 0.4479, Rec: 0.3167 lr: 0.00070\n",
      "Epoch 8/Step 480, Loss: -0.17956, Accuracy: 0.99876, F1: 0.4576, Prec: 0.4476, Rec: 0.3161 lr: 0.00070\n",
      "Epoch 8/Step 490, Loss: -0.17291, Accuracy: 0.99875, F1: 0.4575, Prec: 0.4474, Rec: 0.3158 lr: 0.00070\n",
      "Epoch 8/Step 500, Loss: -0.17849, Accuracy: 0.99875, F1: 0.4574, Prec: 0.4473, Rec: 0.3158 lr: 0.00070\n",
      "Epoch 8/Step 510, Loss: -0.21878, Accuracy: 0.99875, F1: 0.4583, Prec: 0.4469, Rec: 0.3161 lr: 0.00070\n",
      "Epoch 8/Step 520, Loss: -0.15037, Accuracy: 0.99876, F1: 0.4592, Prec: 0.4477, Rec: 0.3161 lr: 0.00070\n",
      "Epoch 8/Step 530, Loss: -0.17652, Accuracy: 0.99876, F1: 0.4596, Prec: 0.4476, Rec: 0.3158 lr: 0.00070\n",
      "Epoch 8/Step 540, Loss: -0.17642, Accuracy: 0.99875, F1: 0.4606, Prec: 0.4477, Rec: 0.3158 lr: 0.00070\n",
      "Epoch 8/Step 550, Loss: -0.21503, Accuracy: 0.99875, F1: 0.4609, Prec: 0.4475, Rec: 0.3162 lr: 0.00070\n",
      "Epoch 8/Step 560, Loss: -0.16733, Accuracy: 0.99875, F1: 0.4621, Prec: 0.4476, Rec: 0.3162 lr: 0.00070\n",
      "Epoch 8/Step 570, Loss: -0.18739, Accuracy: 0.99875, F1: 0.4628, Prec: 0.4477, Rec: 0.3163 lr: 0.00070\n",
      "Epoch 8/Step 580, Loss: -0.16472, Accuracy: 0.99875, F1: 0.4624, Prec: 0.4479, Rec: 0.3161 lr: 0.00070\n",
      "Epoch 8/Step 590, Loss: -0.14138, Accuracy: 0.99875, F1: 0.4620, Prec: 0.4478, Rec: 0.3160 lr: 0.00070\n",
      "Epoch 8/Step 600, Loss: -0.16163, Accuracy: 0.99875, F1: 0.4619, Prec: 0.4482, Rec: 0.3159 lr: 0.00070\n",
      "Epoch 8/Step 610, Loss: -0.22820, Accuracy: 0.99875, F1: 0.4620, Prec: 0.4485, Rec: 0.3160 lr: 0.00070\n",
      "Epoch 8/Step 620, Loss: -0.19955, Accuracy: 0.99875, F1: 0.4623, Prec: 0.4490, Rec: 0.3164 lr: 0.00070\n",
      "Epoch 8/Step 630, Loss: -0.17196, Accuracy: 0.99875, F1: 0.4620, Prec: 0.4489, Rec: 0.3164 lr: 0.00070\n",
      "Epoch 8/Step 640, Loss: -0.17242, Accuracy: 0.99875, F1: 0.4619, Prec: 0.4493, Rec: 0.3163 lr: 0.00070\n",
      "Epoch 8/Step 650, Loss: -0.16622, Accuracy: 0.99875, F1: 0.4633, Prec: 0.4495, Rec: 0.3163 lr: 0.00070\n",
      "Epoch 8/Step 660, Loss: -0.19975, Accuracy: 0.99876, F1: 0.4642, Prec: 0.4496, Rec: 0.3164 lr: 0.00070\n",
      "Epoch 8/Step 670, Loss: -0.15146, Accuracy: 0.99876, F1: 0.4645, Prec: 0.4495, Rec: 0.3165 lr: 0.00070\n",
      "Epoch 8/Step 680, Loss: -0.15311, Accuracy: 0.99876, F1: 0.4647, Prec: 0.4497, Rec: 0.3166 lr: 0.00070\n",
      "Epoch 8/Step 690, Loss: -0.20256, Accuracy: 0.99876, F1: 0.4648, Prec: 0.4496, Rec: 0.3166 lr: 0.00070\n",
      "Epoch 8/Step 700, Loss: -0.18454, Accuracy: 0.99876, F1: 0.4657, Prec: 0.4498, Rec: 0.3163 lr: 0.00070\n",
      "Epoch 8/Step 710, Loss: -0.20231, Accuracy: 0.99876, F1: 0.4662, Prec: 0.4500, Rec: 0.3170 lr: 0.00070\n",
      "Epoch 8/Step 720, Loss: -0.19844, Accuracy: 0.99876, F1: 0.4669, Prec: 0.4502, Rec: 0.3167 lr: 0.00070\n",
      "Epoch 8/Step 730, Loss: -0.17018, Accuracy: 0.99876, F1: 0.4677, Prec: 0.4503, Rec: 0.3167 lr: 0.00070\n",
      "Epoch 8/Step 740, Loss: -0.19385, Accuracy: 0.99876, F1: 0.4676, Prec: 0.4499, Rec: 0.3166 lr: 0.00070\n",
      "Epoch 8/Step 750, Loss: -0.15779, Accuracy: 0.99876, F1: 0.4679, Prec: 0.4500, Rec: 0.3165 lr: 0.00070\n",
      "Epoch 8/Step 760, Loss: -0.18573, Accuracy: 0.99876, F1: 0.4688, Prec: 0.4501, Rec: 0.3163 lr: 0.00070\n",
      "Epoch 8/Step 770, Loss: -0.20159, Accuracy: 0.99876, F1: 0.4701, Prec: 0.4503, Rec: 0.3165 lr: 0.00070\n",
      "Epoch 8/Step 780, Loss: -0.17225, Accuracy: 0.99876, F1: 0.4725, Prec: 0.4514, Rec: 0.3166 lr: 0.00070\n",
      "Epoch 8/Step 790, Loss: -0.19383, Accuracy: 0.99876, F1: 0.4727, Prec: 0.4512, Rec: 0.3164 lr: 0.00070\n",
      "Epoch 8/Step 800, Loss: -0.15969, Accuracy: 0.99876, F1: 0.4725, Prec: 0.4509, Rec: 0.3162 lr: 0.00070\n",
      "Epoch 8/Step 810, Loss: -0.12898, Accuracy: 0.99876, F1: 0.4731, Prec: 0.4507, Rec: 0.3161 lr: 0.00070\n",
      "Epoch 8/Step 820, Loss: -0.18405, Accuracy: 0.99876, F1: 0.4735, Prec: 0.4502, Rec: 0.3160 lr: 0.00070\n",
      "Epoch 8/Step 830, Loss: -0.19289, Accuracy: 0.99876, F1: 0.4738, Prec: 0.4503, Rec: 0.3161 lr: 0.00070\n",
      "Epoch 8/Step 840, Loss: -0.20687, Accuracy: 0.99876, F1: 0.4743, Prec: 0.4504, Rec: 0.3161 lr: 0.00070\n",
      "Epoch 8/Step 850, Loss: -0.17463, Accuracy: 0.99876, F1: 0.4746, Prec: 0.4501, Rec: 0.3160 lr: 0.00070\n",
      "Epoch 8/Step 860, Loss: -0.18623, Accuracy: 0.99876, F1: 0.4749, Prec: 0.4502, Rec: 0.3159 lr: 0.00070\n",
      "Epoch 8/Step 870, Loss: -0.18274, Accuracy: 0.99876, F1: 0.4750, Prec: 0.4502, Rec: 0.3154 lr: 0.00070\n",
      "Epoch 8/Step 880, Loss: -0.16260, Accuracy: 0.99876, F1: 0.4751, Prec: 0.4498, Rec: 0.3156 lr: 0.00070\n",
      "Epoch 8/Step 890, Loss: -0.17036, Accuracy: 0.99876, F1: 0.4742, Prec: 0.4494, Rec: 0.3155 lr: 0.00070\n",
      "Epoch 8/Step 900, Loss: -0.24064, Accuracy: 0.99876, F1: 0.4744, Prec: 0.4501, Rec: 0.3157 lr: 0.00070\n",
      "Epoch 8/Step 910, Loss: -0.15795, Accuracy: 0.99876, F1: 0.4748, Prec: 0.4503, Rec: 0.3154 lr: 0.00070\n",
      "Epoch 8/Step 920, Loss: -0.18052, Accuracy: 0.99876, F1: 0.4748, Prec: 0.4501, Rec: 0.3153 lr: 0.00070\n",
      "Epoch 8/Step 930, Loss: -0.17325, Accuracy: 0.99876, F1: 0.4745, Prec: 0.4500, Rec: 0.3155 lr: 0.00070\n",
      "Epoch 8/Step 940, Loss: -0.17897, Accuracy: 0.99877, F1: 0.4743, Prec: 0.4498, Rec: 0.3155 lr: 0.00070\n",
      "Epoch 8/Step 950, Loss: -0.20059, Accuracy: 0.99877, F1: 0.4743, Prec: 0.4500, Rec: 0.3157 lr: 0.00070\n",
      "Epoch 8/Step 960, Loss: -0.21248, Accuracy: 0.99877, F1: 0.4737, Prec: 0.4495, Rec: 0.3158 lr: 0.00070\n",
      "Epoch 8/Step 970, Loss: -0.15632, Accuracy: 0.99877, F1: 0.4736, Prec: 0.4497, Rec: 0.3153 lr: 0.00070\n",
      "Epoch 8/Step 980, Loss: -0.18336, Accuracy: 0.99877, F1: 0.4734, Prec: 0.4497, Rec: 0.3150 lr: 0.00070\n",
      "Epoch 8/Step 990, Loss: -0.17726, Accuracy: 0.99877, F1: 0.4732, Prec: 0.4490, Rec: 0.3150 lr: 0.00070\n",
      "Epoch 8/Step 1000, Loss: -0.19689, Accuracy: 0.99877, F1: 0.4735, Prec: 0.4491, Rec: 0.3153 lr: 0.00070\n",
      "Epoch 8/Step 1010, Loss: -0.20718, Accuracy: 0.99877, F1: 0.4742, Prec: 0.4495, Rec: 0.3155 lr: 0.00070\n",
      "Epoch 8/Step 1020, Loss: -0.16056, Accuracy: 0.99877, F1: 0.4747, Prec: 0.4493, Rec: 0.3155 lr: 0.00070\n",
      "Epoch 8/Step 1030, Loss: -0.18638, Accuracy: 0.99877, F1: 0.4750, Prec: 0.4492, Rec: 0.3155 lr: 0.00070\n",
      "Epoch 8/Step 1040, Loss: -0.20001, Accuracy: 0.99877, F1: 0.4749, Prec: 0.4494, Rec: 0.3154 lr: 0.00070\n",
      "Epoch 8/Step 1050, Loss: -0.21136, Accuracy: 0.99877, F1: 0.4745, Prec: 0.4492, Rec: 0.3155 lr: 0.00070\n",
      "Epoch 8/Step 1060, Loss: -0.19438, Accuracy: 0.99877, F1: 0.4744, Prec: 0.4492, Rec: 0.3156 lr: 0.00070\n",
      "Epoch 8/Step 1070, Loss: -0.19641, Accuracy: 0.99877, F1: 0.4751, Prec: 0.4495, Rec: 0.3156 lr: 0.00070\n",
      "Epoch 8/Step 1080, Loss: -0.16007, Accuracy: 0.99877, F1: 0.4758, Prec: 0.4493, Rec: 0.3157 lr: 0.00070\n",
      "Epoch 8/Step 1090, Loss: -0.17498, Accuracy: 0.99877, F1: 0.4766, Prec: 0.4493, Rec: 0.3156 lr: 0.00070\n",
      "Epoch 8/Step 1100, Loss: -0.18138, Accuracy: 0.99877, F1: 0.4770, Prec: 0.4492, Rec: 0.3156 lr: 0.00070\n",
      "Epoch 8/Step 1110, Loss: -0.16100, Accuracy: 0.99877, F1: 0.4771, Prec: 0.4492, Rec: 0.3158 lr: 0.00070\n",
      "Epoch 8/Step 1120, Loss: -0.15806, Accuracy: 0.99877, F1: 0.4771, Prec: 0.4492, Rec: 0.3157 lr: 0.00070\n",
      "Epoch 8/Step 1130, Loss: -0.17758, Accuracy: 0.99877, F1: 0.4767, Prec: 0.4493, Rec: 0.3159 lr: 0.00070\n",
      "Epoch 8/Step 1140, Loss: -0.16680, Accuracy: 0.99877, F1: 0.4765, Prec: 0.4496, Rec: 0.3158 lr: 0.00070\n",
      "Epoch 8/Step 1150, Loss: -0.19286, Accuracy: 0.99877, F1: 0.4763, Prec: 0.4497, Rec: 0.3160 lr: 0.00070\n",
      "Epoch 8/Step 1160, Loss: -0.14587, Accuracy: 0.99877, F1: 0.4763, Prec: 0.4497, Rec: 0.3164 lr: 0.00070\n",
      "Epoch 8/Step 1170, Loss: -0.16619, Accuracy: 0.99877, F1: 0.4771, Prec: 0.4499, Rec: 0.3162 lr: 0.00070\n",
      "Epoch 8/Step 1180, Loss: -0.14739, Accuracy: 0.99877, F1: 0.4778, Prec: 0.4500, Rec: 0.3162 lr: 0.00070\n",
      "Epoch 8/Step 1190, Loss: -0.18581, Accuracy: 0.99877, F1: 0.4778, Prec: 0.4498, Rec: 0.3160 lr: 0.00070\n",
      "Epoch 8/Step 1200, Loss: -0.17978, Accuracy: 0.99877, F1: 0.4782, Prec: 0.4501, Rec: 0.3162 lr: 0.00070\n",
      "Epoch 8/Step 1210, Loss: -0.19172, Accuracy: 0.99877, F1: 0.4783, Prec: 0.4504, Rec: 0.3162 lr: 0.00070\n",
      "Epoch 8/Step 1220, Loss: -0.20265, Accuracy: 0.99878, F1: 0.4776, Prec: 0.4501, Rec: 0.3164 lr: 0.00070\n",
      "Epoch 8/Step 1230, Loss: -0.19228, Accuracy: 0.99878, F1: 0.4781, Prec: 0.4504, Rec: 0.3163 lr: 0.00070\n",
      "Epoch 8/Step 1240, Loss: -0.22615, Accuracy: 0.99878, F1: 0.4786, Prec: 0.4504, Rec: 0.3162 lr: 0.00070\n",
      "Epoch 8/Step 1250, Loss: -0.13962, Accuracy: 0.99878, F1: 0.4790, Prec: 0.4501, Rec: 0.3164 lr: 0.00070\n",
      "Epoch 8/Step 1260, Loss: -0.17647, Accuracy: 0.99878, F1: 0.4796, Prec: 0.4503, Rec: 0.3164 lr: 0.00070\n",
      "Epoch 8/Step 1270, Loss: -0.15830, Accuracy: 0.99878, F1: 0.4793, Prec: 0.4502, Rec: 0.3165 lr: 0.00070\n",
      "Epoch 8/Step 1280, Loss: -0.24757, Accuracy: 0.99878, F1: 0.4791, Prec: 0.4501, Rec: 0.3166 lr: 0.00070\n",
      "Epoch 8/Step 1290, Loss: -0.20361, Accuracy: 0.99878, F1: 0.4794, Prec: 0.4504, Rec: 0.3166 lr: 0.00070\n",
      "Epoch 8/Step 1300, Loss: -0.17589, Accuracy: 0.99878, F1: 0.4797, Prec: 0.4501, Rec: 0.3167 lr: 0.00070\n",
      "Epoch 8/Step 1310, Loss: -0.19355, Accuracy: 0.99878, F1: 0.4802, Prec: 0.4501, Rec: 0.3168 lr: 0.00070\n",
      "Epoch 8/Step 1320, Loss: -0.18319, Accuracy: 0.99878, F1: 0.4805, Prec: 0.4503, Rec: 0.3167 lr: 0.00070\n",
      "Epoch 8/Step 1330, Loss: -0.19988, Accuracy: 0.99878, F1: 0.4803, Prec: 0.4501, Rec: 0.3166 lr: 0.00070\n",
      "Epoch 8/Step 1340, Loss: -0.17563, Accuracy: 0.99878, F1: 0.4804, Prec: 0.4504, Rec: 0.3168 lr: 0.00070\n",
      "Epoch 8/Step 1350, Loss: -0.14730, Accuracy: 0.99878, F1: 0.4804, Prec: 0.4501, Rec: 0.3168 lr: 0.00070\n",
      "Epoch 8/Step 1360, Loss: -0.16771, Accuracy: 0.99878, F1: 0.4807, Prec: 0.4504, Rec: 0.3167 lr: 0.00070\n",
      "Epoch 8/Step 1370, Loss: -0.17559, Accuracy: 0.99878, F1: 0.4807, Prec: 0.4505, Rec: 0.3168 lr: 0.00070\n",
      "Epoch 8/Step 1380, Loss: -0.18480, Accuracy: 0.99878, F1: 0.4804, Prec: 0.4506, Rec: 0.3168 lr: 0.00070\n",
      "Epoch 8/Step 1390, Loss: -0.20154, Accuracy: 0.99878, F1: 0.4799, Prec: 0.4504, Rec: 0.3167 lr: 0.00070\n",
      "Epoch 8/Step 1400, Loss: -0.21029, Accuracy: 0.99878, F1: 0.4799, Prec: 0.4506, Rec: 0.3168 lr: 0.00070\n",
      "Epoch 8/Step 1410, Loss: -0.17741, Accuracy: 0.99878, F1: 0.4800, Prec: 0.4508, Rec: 0.3167 lr: 0.00070\n",
      "Epoch 8/Step 1420, Loss: -0.16704, Accuracy: 0.99878, F1: 0.4797, Prec: 0.4505, Rec: 0.3166 lr: 0.00070\n",
      "Epoch 8/Step 1430, Loss: -0.16901, Accuracy: 0.99878, F1: 0.4800, Prec: 0.4508, Rec: 0.3165 lr: 0.00070\n",
      "Epoch 8/Step 1440, Loss: -0.17208, Accuracy: 0.99878, F1: 0.4800, Prec: 0.4507, Rec: 0.3166 lr: 0.00070\n",
      "Epoch 8/Step 1450, Loss: -0.17320, Accuracy: 0.99878, F1: 0.4803, Prec: 0.4509, Rec: 0.3166 lr: 0.00070\n",
      "Epoch 8/Step 1460, Loss: -0.17086, Accuracy: 0.99878, F1: 0.4805, Prec: 0.4510, Rec: 0.3164 lr: 0.00070\n",
      "Epoch 8/Step 1470, Loss: -0.17601, Accuracy: 0.99878, F1: 0.4807, Prec: 0.4509, Rec: 0.3165 lr: 0.00070\n",
      "Epoch 8/Step 1480, Loss: -0.18651, Accuracy: 0.99878, F1: 0.4809, Prec: 0.4509, Rec: 0.3165 lr: 0.00070\n",
      "Epoch 8/Step 1490, Loss: -0.17071, Accuracy: 0.99878, F1: 0.4814, Prec: 0.4510, Rec: 0.3164 lr: 0.00070\n",
      "Epoch 8/Step 1500, Loss: -0.19910, Accuracy: 0.99878, F1: 0.4813, Prec: 0.4511, Rec: 0.3165 lr: 0.00070\n",
      "Epoch 8/Step 1510, Loss: -0.17239, Accuracy: 0.99878, F1: 0.4817, Prec: 0.4514, Rec: 0.3165 lr: 0.00070\n",
      "Epoch 8/Step 1520, Loss: -0.22240, Accuracy: 0.99878, F1: 0.4817, Prec: 0.4516, Rec: 0.3166 lr: 0.00070\n",
      "Epoch 8/Step 1530, Loss: -0.17247, Accuracy: 0.99878, F1: 0.4819, Prec: 0.4517, Rec: 0.3168 lr: 0.00070\n",
      "Epoch 8/Step 1540, Loss: -0.15538, Accuracy: 0.99878, F1: 0.4826, Prec: 0.4519, Rec: 0.3166 lr: 0.00070\n",
      "Epoch 8/Step 1550, Loss: -0.18806, Accuracy: 0.99878, F1: 0.4831, Prec: 0.4520, Rec: 0.3165 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9985\n",
      "Validation f1: 0.4395\n",
      "Validation precision: 0.3118\n",
      "Validation recall: 0.2536\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_7_valF1Score0.440/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_7_valF1Score0.440/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 9\n",
      "Epoch 9/Step 0, Loss: -0.19373, Accuracy: 0.99883, F1: 0.5614, Prec: 0.4543, Rec: 0.3592 lr: 0.00070\n",
      "Epoch 9/Step 10, Loss: -0.21604, Accuracy: 0.99870, F1: 0.5328, Prec: 0.4636, Rec: 0.3474 lr: 0.00070\n",
      "Epoch 9/Step 20, Loss: -0.19314, Accuracy: 0.99878, F1: 0.5764, Prec: 0.4744, Rec: 0.3363 lr: 0.00070\n",
      "Epoch 9/Step 30, Loss: -0.18044, Accuracy: 0.99882, F1: 0.5563, Prec: 0.4786, Rec: 0.3353 lr: 0.00070\n",
      "Epoch 9/Step 40, Loss: -0.17261, Accuracy: 0.99882, F1: 0.5439, Prec: 0.4875, Rec: 0.3346 lr: 0.00070\n",
      "Epoch 9/Step 50, Loss: -0.18753, Accuracy: 0.99883, F1: 0.5306, Prec: 0.4884, Rec: 0.3324 lr: 0.00070\n",
      "Epoch 9/Step 60, Loss: -0.20631, Accuracy: 0.99883, F1: 0.5233, Prec: 0.4841, Rec: 0.3353 lr: 0.00070\n",
      "Epoch 9/Step 70, Loss: -0.18632, Accuracy: 0.99885, F1: 0.5374, Prec: 0.4835, Rec: 0.3357 lr: 0.00070\n",
      "Epoch 9/Step 80, Loss: -0.17674, Accuracy: 0.99885, F1: 0.5529, Prec: 0.4843, Rec: 0.3320 lr: 0.00070\n",
      "Epoch 9/Step 90, Loss: -0.17345, Accuracy: 0.99885, F1: 0.5617, Prec: 0.4835, Rec: 0.3330 lr: 0.00070\n",
      "Epoch 9/Step 100, Loss: -0.21392, Accuracy: 0.99885, F1: 0.5743, Prec: 0.4856, Rec: 0.3349 lr: 0.00070\n",
      "Epoch 9/Step 110, Loss: -0.19196, Accuracy: 0.99885, F1: 0.5835, Prec: 0.4891, Rec: 0.3339 lr: 0.00070\n",
      "Epoch 9/Step 120, Loss: -0.16627, Accuracy: 0.99884, F1: 0.5844, Prec: 0.4887, Rec: 0.3333 lr: 0.00070\n",
      "Epoch 9/Step 130, Loss: -0.15424, Accuracy: 0.99884, F1: 0.5854, Prec: 0.4872, Rec: 0.3339 lr: 0.00070\n",
      "Epoch 9/Step 140, Loss: -0.17557, Accuracy: 0.99883, F1: 0.5878, Prec: 0.4877, Rec: 0.3306 lr: 0.00070\n",
      "Epoch 9/Step 150, Loss: -0.17099, Accuracy: 0.99882, F1: 0.5924, Prec: 0.4864, Rec: 0.3288 lr: 0.00070\n",
      "Epoch 9/Step 160, Loss: -0.18909, Accuracy: 0.99882, F1: 0.5862, Prec: 0.4818, Rec: 0.3297 lr: 0.00070\n",
      "Epoch 9/Step 170, Loss: -0.17751, Accuracy: 0.99882, F1: 0.5819, Prec: 0.4775, Rec: 0.3284 lr: 0.00070\n",
      "Epoch 9/Step 180, Loss: -0.20334, Accuracy: 0.99882, F1: 0.5832, Prec: 0.4782, Rec: 0.3286 lr: 0.00070\n",
      "Epoch 9/Step 190, Loss: -0.18026, Accuracy: 0.99882, F1: 0.5811, Prec: 0.4779, Rec: 0.3279 lr: 0.00070\n",
      "Epoch 9/Step 200, Loss: -0.19563, Accuracy: 0.99880, F1: 0.5736, Prec: 0.4770, Rec: 0.3270 lr: 0.00070\n",
      "Epoch 9/Step 210, Loss: -0.15941, Accuracy: 0.99880, F1: 0.5644, Prec: 0.4749, Rec: 0.3269 lr: 0.00070\n",
      "Epoch 9/Step 220, Loss: -0.21127, Accuracy: 0.99880, F1: 0.5588, Prec: 0.4742, Rec: 0.3269 lr: 0.00070\n",
      "Epoch 9/Step 230, Loss: -0.16775, Accuracy: 0.99880, F1: 0.5581, Prec: 0.4734, Rec: 0.3265 lr: 0.00070\n",
      "Epoch 9/Step 240, Loss: -0.22589, Accuracy: 0.99879, F1: 0.5601, Prec: 0.4743, Rec: 0.3266 lr: 0.00070\n",
      "Epoch 9/Step 250, Loss: -0.20126, Accuracy: 0.99879, F1: 0.5613, Prec: 0.4746, Rec: 0.3261 lr: 0.00070\n",
      "Epoch 9/Step 260, Loss: -0.21346, Accuracy: 0.99879, F1: 0.5618, Prec: 0.4742, Rec: 0.3264 lr: 0.00070\n",
      "Epoch 9/Step 270, Loss: -0.21971, Accuracy: 0.99879, F1: 0.5617, Prec: 0.4726, Rec: 0.3265 lr: 0.00070\n",
      "Epoch 9/Step 280, Loss: -0.21093, Accuracy: 0.99878, F1: 0.5632, Prec: 0.4729, Rec: 0.3254 lr: 0.00070\n",
      "Epoch 9/Step 290, Loss: -0.19072, Accuracy: 0.99879, F1: 0.5658, Prec: 0.4739, Rec: 0.3251 lr: 0.00070\n",
      "Epoch 9/Step 300, Loss: -0.20385, Accuracy: 0.99879, F1: 0.5663, Prec: 0.4740, Rec: 0.3253 lr: 0.00070\n",
      "Epoch 9/Step 310, Loss: -0.19370, Accuracy: 0.99879, F1: 0.5645, Prec: 0.4740, Rec: 0.3251 lr: 0.00070\n",
      "Epoch 9/Step 320, Loss: -0.17960, Accuracy: 0.99879, F1: 0.5649, Prec: 0.4752, Rec: 0.3254 lr: 0.00070\n",
      "Epoch 9/Step 330, Loss: -0.21459, Accuracy: 0.99880, F1: 0.5670, Prec: 0.4763, Rec: 0.3252 lr: 0.00070\n",
      "Epoch 9/Step 340, Loss: -0.19215, Accuracy: 0.99879, F1: 0.5679, Prec: 0.4765, Rec: 0.3252 lr: 0.00070\n",
      "Epoch 9/Step 350, Loss: -0.17101, Accuracy: 0.99880, F1: 0.5697, Prec: 0.4780, Rec: 0.3256 lr: 0.00070\n",
      "Epoch 9/Step 360, Loss: -0.20329, Accuracy: 0.99880, F1: 0.5716, Prec: 0.4791, Rec: 0.3263 lr: 0.00070\n",
      "Epoch 9/Step 370, Loss: -0.19714, Accuracy: 0.99880, F1: 0.5721, Prec: 0.4788, Rec: 0.3264 lr: 0.00070\n",
      "Epoch 9/Step 380, Loss: -0.20631, Accuracy: 0.99880, F1: 0.5740, Prec: 0.4792, Rec: 0.3260 lr: 0.00070\n",
      "Epoch 9/Step 390, Loss: -0.17912, Accuracy: 0.99881, F1: 0.5758, Prec: 0.4800, Rec: 0.3254 lr: 0.00070\n",
      "Epoch 9/Step 400, Loss: -0.14826, Accuracy: 0.99881, F1: 0.5758, Prec: 0.4801, Rec: 0.3251 lr: 0.00070\n",
      "Epoch 9/Step 410, Loss: -0.15383, Accuracy: 0.99881, F1: 0.5738, Prec: 0.4792, Rec: 0.3253 lr: 0.00070\n",
      "Epoch 9/Step 420, Loss: -0.20431, Accuracy: 0.99881, F1: 0.5747, Prec: 0.4804, Rec: 0.3254 lr: 0.00070\n",
      "Epoch 9/Step 430, Loss: -0.18175, Accuracy: 0.99881, F1: 0.5754, Prec: 0.4804, Rec: 0.3252 lr: 0.00070\n",
      "Epoch 9/Step 440, Loss: -0.19078, Accuracy: 0.99881, F1: 0.5759, Prec: 0.4796, Rec: 0.3253 lr: 0.00070\n",
      "Epoch 9/Step 450, Loss: -0.19995, Accuracy: 0.99880, F1: 0.5751, Prec: 0.4789, Rec: 0.3257 lr: 0.00070\n",
      "Epoch 9/Step 460, Loss: -0.18075, Accuracy: 0.99881, F1: 0.5743, Prec: 0.4788, Rec: 0.3253 lr: 0.00070\n",
      "Epoch 9/Step 470, Loss: -0.19053, Accuracy: 0.99881, F1: 0.5748, Prec: 0.4794, Rec: 0.3251 lr: 0.00070\n",
      "Epoch 9/Step 480, Loss: -0.18045, Accuracy: 0.99881, F1: 0.5742, Prec: 0.4786, Rec: 0.3244 lr: 0.00070\n",
      "Epoch 9/Step 490, Loss: -0.18565, Accuracy: 0.99880, F1: 0.5730, Prec: 0.4778, Rec: 0.3245 lr: 0.00070\n",
      "Epoch 9/Step 500, Loss: -0.19738, Accuracy: 0.99881, F1: 0.5722, Prec: 0.4781, Rec: 0.3243 lr: 0.00070\n",
      "Epoch 9/Step 510, Loss: -0.23322, Accuracy: 0.99881, F1: 0.5726, Prec: 0.4780, Rec: 0.3247 lr: 0.00070\n",
      "Epoch 9/Step 520, Loss: -0.16460, Accuracy: 0.99881, F1: 0.5734, Prec: 0.4787, Rec: 0.3249 lr: 0.00070\n",
      "Epoch 9/Step 530, Loss: -0.18184, Accuracy: 0.99881, F1: 0.5740, Prec: 0.4789, Rec: 0.3243 lr: 0.00070\n",
      "Epoch 9/Step 540, Loss: -0.18635, Accuracy: 0.99881, F1: 0.5747, Prec: 0.4788, Rec: 0.3244 lr: 0.00070\n",
      "Epoch 9/Step 550, Loss: -0.22311, Accuracy: 0.99881, F1: 0.5751, Prec: 0.4792, Rec: 0.3244 lr: 0.00070\n",
      "Epoch 9/Step 560, Loss: -0.17700, Accuracy: 0.99881, F1: 0.5749, Prec: 0.4790, Rec: 0.3244 lr: 0.00070\n",
      "Epoch 9/Step 570, Loss: -0.20137, Accuracy: 0.99881, F1: 0.5751, Prec: 0.4791, Rec: 0.3246 lr: 0.00070\n",
      "Epoch 9/Step 580, Loss: -0.16735, Accuracy: 0.99881, F1: 0.5749, Prec: 0.4793, Rec: 0.3243 lr: 0.00070\n",
      "Epoch 9/Step 590, Loss: -0.14851, Accuracy: 0.99881, F1: 0.5740, Prec: 0.4790, Rec: 0.3243 lr: 0.00070\n",
      "Epoch 9/Step 600, Loss: -0.16879, Accuracy: 0.99881, F1: 0.5743, Prec: 0.4793, Rec: 0.3243 lr: 0.00070\n",
      "Epoch 9/Step 610, Loss: -0.23213, Accuracy: 0.99880, F1: 0.5743, Prec: 0.4794, Rec: 0.3243 lr: 0.00070\n",
      "Epoch 9/Step 620, Loss: -0.20562, Accuracy: 0.99880, F1: 0.5745, Prec: 0.4800, Rec: 0.3247 lr: 0.00070\n",
      "Epoch 9/Step 630, Loss: -0.17640, Accuracy: 0.99880, F1: 0.5740, Prec: 0.4799, Rec: 0.3246 lr: 0.00070\n",
      "Epoch 9/Step 640, Loss: -0.17512, Accuracy: 0.99880, F1: 0.5729, Prec: 0.4799, Rec: 0.3246 lr: 0.00070\n",
      "Epoch 9/Step 650, Loss: -0.17043, Accuracy: 0.99881, F1: 0.5734, Prec: 0.4799, Rec: 0.3246 lr: 0.00070\n",
      "Epoch 9/Step 660, Loss: -0.20672, Accuracy: 0.99881, F1: 0.5751, Prec: 0.4801, Rec: 0.3245 lr: 0.00070\n",
      "Epoch 9/Step 670, Loss: -0.16982, Accuracy: 0.99881, F1: 0.5762, Prec: 0.4800, Rec: 0.3247 lr: 0.00070\n",
      "Epoch 9/Step 680, Loss: -0.16079, Accuracy: 0.99881, F1: 0.5772, Prec: 0.4803, Rec: 0.3248 lr: 0.00070\n",
      "Epoch 9/Step 690, Loss: -0.20797, Accuracy: 0.99881, F1: 0.5777, Prec: 0.4800, Rec: 0.3248 lr: 0.00070\n",
      "Epoch 9/Step 700, Loss: -0.18686, Accuracy: 0.99881, F1: 0.5786, Prec: 0.4801, Rec: 0.3245 lr: 0.00070\n",
      "Epoch 9/Step 710, Loss: -0.20720, Accuracy: 0.99881, F1: 0.5791, Prec: 0.4804, Rec: 0.3250 lr: 0.00070\n",
      "Epoch 9/Step 720, Loss: -0.21511, Accuracy: 0.99881, F1: 0.5796, Prec: 0.4804, Rec: 0.3250 lr: 0.00070\n",
      "Epoch 9/Step 730, Loss: -0.17575, Accuracy: 0.99881, F1: 0.5802, Prec: 0.4807, Rec: 0.3248 lr: 0.00070\n",
      "Epoch 9/Step 740, Loss: -0.19389, Accuracy: 0.99881, F1: 0.5801, Prec: 0.4804, Rec: 0.3248 lr: 0.00070\n",
      "Epoch 9/Step 750, Loss: -0.17818, Accuracy: 0.99881, F1: 0.5801, Prec: 0.4802, Rec: 0.3248 lr: 0.00070\n",
      "Epoch 9/Step 760, Loss: -0.19639, Accuracy: 0.99881, F1: 0.5807, Prec: 0.4804, Rec: 0.3244 lr: 0.00070\n",
      "Epoch 9/Step 770, Loss: -0.21223, Accuracy: 0.99881, F1: 0.5814, Prec: 0.4805, Rec: 0.3246 lr: 0.00070\n",
      "Epoch 9/Step 780, Loss: -0.16653, Accuracy: 0.99881, F1: 0.5841, Prec: 0.4816, Rec: 0.3246 lr: 0.00070\n",
      "Epoch 9/Step 790, Loss: -0.20363, Accuracy: 0.99881, F1: 0.5841, Prec: 0.4813, Rec: 0.3243 lr: 0.00070\n",
      "Epoch 9/Step 800, Loss: -0.16703, Accuracy: 0.99881, F1: 0.5831, Prec: 0.4808, Rec: 0.3243 lr: 0.00070\n",
      "Epoch 9/Step 810, Loss: -0.13058, Accuracy: 0.99881, F1: 0.5833, Prec: 0.4808, Rec: 0.3242 lr: 0.00070\n",
      "Epoch 9/Step 820, Loss: -0.19921, Accuracy: 0.99881, F1: 0.5833, Prec: 0.4802, Rec: 0.3241 lr: 0.00070\n",
      "Epoch 9/Step 830, Loss: -0.21062, Accuracy: 0.99881, F1: 0.5836, Prec: 0.4806, Rec: 0.3242 lr: 0.00070\n",
      "Epoch 9/Step 840, Loss: -0.21669, Accuracy: 0.99881, F1: 0.5842, Prec: 0.4807, Rec: 0.3243 lr: 0.00070\n",
      "Epoch 9/Step 850, Loss: -0.18485, Accuracy: 0.99881, F1: 0.5846, Prec: 0.4803, Rec: 0.3241 lr: 0.00070\n",
      "Epoch 9/Step 860, Loss: -0.19163, Accuracy: 0.99881, F1: 0.5847, Prec: 0.4803, Rec: 0.3242 lr: 0.00070\n",
      "Epoch 9/Step 870, Loss: -0.18807, Accuracy: 0.99881, F1: 0.5848, Prec: 0.4802, Rec: 0.3237 lr: 0.00070\n",
      "Epoch 9/Step 880, Loss: -0.17097, Accuracy: 0.99881, F1: 0.5847, Prec: 0.4799, Rec: 0.3239 lr: 0.00070\n",
      "Epoch 9/Step 890, Loss: -0.17126, Accuracy: 0.99881, F1: 0.5838, Prec: 0.4795, Rec: 0.3237 lr: 0.00070\n",
      "Epoch 9/Step 900, Loss: -0.24568, Accuracy: 0.99881, F1: 0.5836, Prec: 0.4800, Rec: 0.3239 lr: 0.00070\n",
      "Epoch 9/Step 910, Loss: -0.17003, Accuracy: 0.99881, F1: 0.5840, Prec: 0.4802, Rec: 0.3237 lr: 0.00070\n",
      "Epoch 9/Step 920, Loss: -0.19348, Accuracy: 0.99881, F1: 0.5846, Prec: 0.4801, Rec: 0.3234 lr: 0.00070\n",
      "Epoch 9/Step 930, Loss: -0.18723, Accuracy: 0.99881, F1: 0.5844, Prec: 0.4800, Rec: 0.3236 lr: 0.00070\n",
      "Epoch 9/Step 940, Loss: -0.18539, Accuracy: 0.99882, F1: 0.5839, Prec: 0.4797, Rec: 0.3237 lr: 0.00070\n",
      "Epoch 9/Step 950, Loss: -0.21104, Accuracy: 0.99882, F1: 0.5836, Prec: 0.4802, Rec: 0.3236 lr: 0.00070\n",
      "Epoch 9/Step 960, Loss: -0.21253, Accuracy: 0.99882, F1: 0.5823, Prec: 0.4795, Rec: 0.3238 lr: 0.00070\n",
      "Epoch 9/Step 970, Loss: -0.16349, Accuracy: 0.99882, F1: 0.5819, Prec: 0.4795, Rec: 0.3235 lr: 0.00070\n",
      "Epoch 9/Step 980, Loss: -0.19375, Accuracy: 0.99882, F1: 0.5820, Prec: 0.4796, Rec: 0.3231 lr: 0.00070\n",
      "Epoch 9/Step 990, Loss: -0.18421, Accuracy: 0.99882, F1: 0.5818, Prec: 0.4789, Rec: 0.3231 lr: 0.00070\n",
      "Epoch 9/Step 1000, Loss: -0.20488, Accuracy: 0.99882, F1: 0.5818, Prec: 0.4787, Rec: 0.3234 lr: 0.00070\n",
      "Epoch 9/Step 1010, Loss: -0.20684, Accuracy: 0.99882, F1: 0.5824, Prec: 0.4793, Rec: 0.3236 lr: 0.00070\n",
      "Epoch 9/Step 1020, Loss: -0.15336, Accuracy: 0.99882, F1: 0.5829, Prec: 0.4790, Rec: 0.3235 lr: 0.00070\n",
      "Epoch 9/Step 1030, Loss: -0.19459, Accuracy: 0.99882, F1: 0.5833, Prec: 0.4791, Rec: 0.3235 lr: 0.00070\n",
      "Epoch 9/Step 1040, Loss: -0.20781, Accuracy: 0.99882, F1: 0.5836, Prec: 0.4792, Rec: 0.3234 lr: 0.00070\n",
      "Epoch 9/Step 1050, Loss: -0.22132, Accuracy: 0.99882, F1: 0.5832, Prec: 0.4792, Rec: 0.3235 lr: 0.00070\n",
      "Epoch 9/Step 1060, Loss: -0.19982, Accuracy: 0.99882, F1: 0.5829, Prec: 0.4791, Rec: 0.3235 lr: 0.00070\n",
      "Epoch 9/Step 1070, Loss: -0.20298, Accuracy: 0.99882, F1: 0.5834, Prec: 0.4794, Rec: 0.3236 lr: 0.00070\n",
      "Epoch 9/Step 1080, Loss: -0.17031, Accuracy: 0.99882, F1: 0.5839, Prec: 0.4793, Rec: 0.3237 lr: 0.00070\n",
      "Epoch 9/Step 1090, Loss: -0.18836, Accuracy: 0.99882, F1: 0.5845, Prec: 0.4792, Rec: 0.3236 lr: 0.00070\n",
      "Epoch 9/Step 1100, Loss: -0.18966, Accuracy: 0.99882, F1: 0.5849, Prec: 0.4791, Rec: 0.3236 lr: 0.00070\n",
      "Epoch 9/Step 1110, Loss: -0.16321, Accuracy: 0.99882, F1: 0.5847, Prec: 0.4791, Rec: 0.3237 lr: 0.00070\n",
      "Epoch 9/Step 1120, Loss: -0.16593, Accuracy: 0.99882, F1: 0.5842, Prec: 0.4791, Rec: 0.3237 lr: 0.00070\n",
      "Epoch 9/Step 1130, Loss: -0.18733, Accuracy: 0.99882, F1: 0.5837, Prec: 0.4793, Rec: 0.3238 lr: 0.00070\n",
      "Epoch 9/Step 1140, Loss: -0.17933, Accuracy: 0.99882, F1: 0.5834, Prec: 0.4792, Rec: 0.3239 lr: 0.00070\n",
      "Epoch 9/Step 1150, Loss: -0.21372, Accuracy: 0.99882, F1: 0.5833, Prec: 0.4796, Rec: 0.3238 lr: 0.00070\n",
      "Epoch 9/Step 1160, Loss: -0.15289, Accuracy: 0.99882, F1: 0.5832, Prec: 0.4797, Rec: 0.3242 lr: 0.00070\n",
      "Epoch 9/Step 1170, Loss: -0.17639, Accuracy: 0.99882, F1: 0.5833, Prec: 0.4796, Rec: 0.3240 lr: 0.00070\n",
      "Epoch 9/Step 1180, Loss: -0.15730, Accuracy: 0.99882, F1: 0.5841, Prec: 0.4799, Rec: 0.3239 lr: 0.00070\n",
      "Epoch 9/Step 1190, Loss: -0.19286, Accuracy: 0.99882, F1: 0.5839, Prec: 0.4795, Rec: 0.3239 lr: 0.00070\n",
      "Epoch 9/Step 1200, Loss: -0.19317, Accuracy: 0.99882, F1: 0.5843, Prec: 0.4797, Rec: 0.3240 lr: 0.00070\n",
      "Epoch 9/Step 1210, Loss: -0.19446, Accuracy: 0.99882, F1: 0.5850, Prec: 0.4800, Rec: 0.3241 lr: 0.00070\n",
      "Epoch 9/Step 1220, Loss: -0.20482, Accuracy: 0.99883, F1: 0.5843, Prec: 0.4797, Rec: 0.3243 lr: 0.00070\n",
      "Epoch 9/Step 1230, Loss: -0.20153, Accuracy: 0.99883, F1: 0.5841, Prec: 0.4796, Rec: 0.3243 lr: 0.00070\n",
      "Epoch 9/Step 1240, Loss: -0.23442, Accuracy: 0.99883, F1: 0.5848, Prec: 0.4799, Rec: 0.3239 lr: 0.00070\n",
      "Epoch 9/Step 1250, Loss: -0.14105, Accuracy: 0.99883, F1: 0.5847, Prec: 0.4796, Rec: 0.3242 lr: 0.00070\n",
      "Epoch 9/Step 1260, Loss: -0.18468, Accuracy: 0.99883, F1: 0.5850, Prec: 0.4796, Rec: 0.3242 lr: 0.00070\n",
      "Epoch 9/Step 1270, Loss: -0.17893, Accuracy: 0.99883, F1: 0.5850, Prec: 0.4798, Rec: 0.3242 lr: 0.00070\n",
      "Epoch 9/Step 1280, Loss: -0.25916, Accuracy: 0.99883, F1: 0.5847, Prec: 0.4797, Rec: 0.3242 lr: 0.00070\n",
      "Epoch 9/Step 1290, Loss: -0.20599, Accuracy: 0.99883, F1: 0.5841, Prec: 0.4799, Rec: 0.3244 lr: 0.00070\n",
      "Epoch 9/Step 1300, Loss: -0.17765, Accuracy: 0.99883, F1: 0.5843, Prec: 0.4798, Rec: 0.3242 lr: 0.00070\n",
      "Epoch 9/Step 1310, Loss: -0.20633, Accuracy: 0.99883, F1: 0.5846, Prec: 0.4797, Rec: 0.3244 lr: 0.00070\n",
      "Epoch 9/Step 1320, Loss: -0.19165, Accuracy: 0.99883, F1: 0.5848, Prec: 0.4799, Rec: 0.3244 lr: 0.00070\n",
      "Epoch 9/Step 1330, Loss: -0.20830, Accuracy: 0.99883, F1: 0.5844, Prec: 0.4800, Rec: 0.3241 lr: 0.00070\n",
      "Epoch 9/Step 1340, Loss: -0.18632, Accuracy: 0.99883, F1: 0.5839, Prec: 0.4801, Rec: 0.3244 lr: 0.00070\n",
      "Epoch 9/Step 1350, Loss: -0.14608, Accuracy: 0.99883, F1: 0.5837, Prec: 0.4799, Rec: 0.3244 lr: 0.00070\n",
      "Epoch 9/Step 1360, Loss: -0.17584, Accuracy: 0.99883, F1: 0.5838, Prec: 0.4800, Rec: 0.3243 lr: 0.00070\n",
      "Epoch 9/Step 1370, Loss: -0.18301, Accuracy: 0.99883, F1: 0.5836, Prec: 0.4801, Rec: 0.3245 lr: 0.00070\n",
      "Epoch 9/Step 1380, Loss: -0.18780, Accuracy: 0.99883, F1: 0.5834, Prec: 0.4802, Rec: 0.3246 lr: 0.00070\n",
      "Epoch 9/Step 1390, Loss: -0.20398, Accuracy: 0.99883, F1: 0.5832, Prec: 0.4801, Rec: 0.3244 lr: 0.00070\n",
      "Epoch 9/Step 1400, Loss: -0.21664, Accuracy: 0.99883, F1: 0.5831, Prec: 0.4802, Rec: 0.3246 lr: 0.00070\n",
      "Epoch 9/Step 1410, Loss: -0.17889, Accuracy: 0.99883, F1: 0.5833, Prec: 0.4803, Rec: 0.3244 lr: 0.00070\n",
      "Epoch 9/Step 1420, Loss: -0.17908, Accuracy: 0.99883, F1: 0.5830, Prec: 0.4802, Rec: 0.3243 lr: 0.00070\n",
      "Epoch 9/Step 1430, Loss: -0.17640, Accuracy: 0.99883, F1: 0.5830, Prec: 0.4803, Rec: 0.3243 lr: 0.00070\n",
      "Epoch 9/Step 1440, Loss: -0.17327, Accuracy: 0.99883, F1: 0.5827, Prec: 0.4803, Rec: 0.3243 lr: 0.00070\n",
      "Epoch 9/Step 1450, Loss: -0.17513, Accuracy: 0.99883, F1: 0.5827, Prec: 0.4805, Rec: 0.3244 lr: 0.00070\n",
      "Epoch 9/Step 1460, Loss: -0.18116, Accuracy: 0.99883, F1: 0.5830, Prec: 0.4807, Rec: 0.3242 lr: 0.00070\n",
      "Epoch 9/Step 1470, Loss: -0.17544, Accuracy: 0.99883, F1: 0.5834, Prec: 0.4807, Rec: 0.3241 lr: 0.00070\n",
      "Epoch 9/Step 1480, Loss: -0.19363, Accuracy: 0.99883, F1: 0.5834, Prec: 0.4806, Rec: 0.3242 lr: 0.00070\n",
      "Epoch 9/Step 1490, Loss: -0.17893, Accuracy: 0.99883, F1: 0.5841, Prec: 0.4807, Rec: 0.3241 lr: 0.00070\n",
      "Epoch 9/Step 1500, Loss: -0.20441, Accuracy: 0.99883, F1: 0.5842, Prec: 0.4807, Rec: 0.3242 lr: 0.00070\n",
      "Epoch 9/Step 1510, Loss: -0.18135, Accuracy: 0.99883, F1: 0.5844, Prec: 0.4810, Rec: 0.3242 lr: 0.00070\n",
      "Epoch 9/Step 1520, Loss: -0.22941, Accuracy: 0.99883, F1: 0.5847, Prec: 0.4812, Rec: 0.3243 lr: 0.00070\n",
      "Epoch 9/Step 1530, Loss: -0.17395, Accuracy: 0.99883, F1: 0.5849, Prec: 0.4813, Rec: 0.3246 lr: 0.00070\n",
      "Epoch 9/Step 1540, Loss: -0.16764, Accuracy: 0.99883, F1: 0.5853, Prec: 0.4814, Rec: 0.3244 lr: 0.00070\n",
      "Epoch 9/Step 1550, Loss: -0.19471, Accuracy: 0.99883, F1: 0.5861, Prec: 0.4815, Rec: 0.3243 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9986\n",
      "Validation f1: 0.5112\n",
      "Validation precision: 0.3267\n",
      "Validation recall: 0.2460\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_8_valF1Score0.511/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_8_valF1Score0.511/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 10\n",
      "Epoch 10/Step 0, Loss: -0.20549, Accuracy: 0.99894, F1: 0.7314, Prec: 0.5164, Rec: 0.3606 lr: 0.00070\n",
      "Epoch 10/Step 10, Loss: -0.22289, Accuracy: 0.99874, F1: 0.6097, Prec: 0.4851, Rec: 0.3556 lr: 0.00070\n",
      "Epoch 10/Step 20, Loss: -0.20438, Accuracy: 0.99882, F1: 0.6526, Prec: 0.4990, Rec: 0.3457 lr: 0.00070\n",
      "Epoch 10/Step 30, Loss: -0.17948, Accuracy: 0.99886, F1: 0.6499, Prec: 0.5038, Rec: 0.3447 lr: 0.00070\n",
      "Epoch 10/Step 40, Loss: -0.17421, Accuracy: 0.99886, F1: 0.6605, Prec: 0.5134, Rec: 0.3431 lr: 0.00070\n",
      "Epoch 10/Step 50, Loss: -0.19875, Accuracy: 0.99887, F1: 0.6517, Prec: 0.5130, Rec: 0.3448 lr: 0.00070\n",
      "Epoch 10/Step 60, Loss: -0.21388, Accuracy: 0.99887, F1: 0.6441, Prec: 0.5135, Rec: 0.3447 lr: 0.00070\n",
      "Epoch 10/Step 70, Loss: -0.19206, Accuracy: 0.99889, F1: 0.6400, Prec: 0.5089, Rec: 0.3456 lr: 0.00070\n",
      "Epoch 10/Step 80, Loss: -0.18104, Accuracy: 0.99889, F1: 0.6487, Prec: 0.5091, Rec: 0.3411 lr: 0.00070\n",
      "Epoch 10/Step 90, Loss: -0.17959, Accuracy: 0.99888, F1: 0.6439, Prec: 0.5082, Rec: 0.3412 lr: 0.00070\n",
      "Epoch 10/Step 100, Loss: -0.21126, Accuracy: 0.99889, F1: 0.6428, Prec: 0.5085, Rec: 0.3434 lr: 0.00070\n",
      "Epoch 10/Step 110, Loss: -0.19850, Accuracy: 0.99888, F1: 0.6556, Prec: 0.5115, Rec: 0.3422 lr: 0.00070\n",
      "Epoch 10/Step 120, Loss: -0.17677, Accuracy: 0.99888, F1: 0.6617, Prec: 0.5130, Rec: 0.3407 lr: 0.00070\n",
      "Epoch 10/Step 130, Loss: -0.16038, Accuracy: 0.99888, F1: 0.6611, Prec: 0.5090, Rec: 0.3423 lr: 0.00070\n",
      "Epoch 10/Step 140, Loss: -0.16950, Accuracy: 0.99887, F1: 0.6663, Prec: 0.5110, Rec: 0.3382 lr: 0.00070\n",
      "Epoch 10/Step 150, Loss: -0.17896, Accuracy: 0.99886, F1: 0.6716, Prec: 0.5087, Rec: 0.3367 lr: 0.00070\n",
      "Epoch 10/Step 160, Loss: -0.20270, Accuracy: 0.99886, F1: 0.6661, Prec: 0.5048, Rec: 0.3376 lr: 0.00070\n",
      "Epoch 10/Step 170, Loss: -0.17110, Accuracy: 0.99885, F1: 0.6624, Prec: 0.5010, Rec: 0.3361 lr: 0.00070\n",
      "Epoch 10/Step 180, Loss: -0.22244, Accuracy: 0.99885, F1: 0.6614, Prec: 0.5013, Rec: 0.3370 lr: 0.00070\n",
      "Epoch 10/Step 190, Loss: -0.19111, Accuracy: 0.99885, F1: 0.6609, Prec: 0.5015, Rec: 0.3357 lr: 0.00070\n",
      "Epoch 10/Step 200, Loss: -0.20420, Accuracy: 0.99884, F1: 0.6583, Prec: 0.5017, Rec: 0.3345 lr: 0.00070\n",
      "Epoch 10/Step 210, Loss: -0.16370, Accuracy: 0.99884, F1: 0.6501, Prec: 0.4978, Rec: 0.3352 lr: 0.00070\n",
      "Epoch 10/Step 220, Loss: -0.21105, Accuracy: 0.99884, F1: 0.6426, Prec: 0.4976, Rec: 0.3347 lr: 0.00070\n",
      "Epoch 10/Step 230, Loss: -0.17363, Accuracy: 0.99884, F1: 0.6394, Prec: 0.4979, Rec: 0.3339 lr: 0.00070\n",
      "Epoch 10/Step 240, Loss: -0.23574, Accuracy: 0.99883, F1: 0.6398, Prec: 0.4980, Rec: 0.3343 lr: 0.00070\n",
      "Epoch 10/Step 250, Loss: -0.21558, Accuracy: 0.99883, F1: 0.6414, Prec: 0.4985, Rec: 0.3340 lr: 0.00070\n",
      "Epoch 10/Step 260, Loss: -0.22414, Accuracy: 0.99883, F1: 0.6430, Prec: 0.4986, Rec: 0.3341 lr: 0.00070\n",
      "Epoch 10/Step 270, Loss: -0.22433, Accuracy: 0.99883, F1: 0.6435, Prec: 0.4975, Rec: 0.3341 lr: 0.00070\n",
      "Epoch 10/Step 280, Loss: -0.21434, Accuracy: 0.99882, F1: 0.6442, Prec: 0.4973, Rec: 0.3332 lr: 0.00070\n",
      "Epoch 10/Step 290, Loss: -0.19840, Accuracy: 0.99883, F1: 0.6463, Prec: 0.4985, Rec: 0.3327 lr: 0.00070\n",
      "Epoch 10/Step 300, Loss: -0.21029, Accuracy: 0.99883, F1: 0.6487, Prec: 0.4992, Rec: 0.3327 lr: 0.00070\n",
      "Epoch 10/Step 310, Loss: -0.20635, Accuracy: 0.99883, F1: 0.6473, Prec: 0.4983, Rec: 0.3329 lr: 0.00070\n",
      "Epoch 10/Step 320, Loss: -0.18535, Accuracy: 0.99883, F1: 0.6476, Prec: 0.4998, Rec: 0.3329 lr: 0.00070\n",
      "Epoch 10/Step 330, Loss: -0.20694, Accuracy: 0.99883, F1: 0.6494, Prec: 0.5004, Rec: 0.3327 lr: 0.00070\n",
      "Epoch 10/Step 340, Loss: -0.19185, Accuracy: 0.99883, F1: 0.6488, Prec: 0.5001, Rec: 0.3330 lr: 0.00070\n",
      "Epoch 10/Step 350, Loss: -0.17202, Accuracy: 0.99883, F1: 0.6493, Prec: 0.5008, Rec: 0.3334 lr: 0.00070\n",
      "Epoch 10/Step 360, Loss: -0.20544, Accuracy: 0.99883, F1: 0.6513, Prec: 0.5022, Rec: 0.3339 lr: 0.00070\n",
      "Epoch 10/Step 370, Loss: -0.20548, Accuracy: 0.99884, F1: 0.6514, Prec: 0.5020, Rec: 0.3340 lr: 0.00070\n",
      "Epoch 10/Step 380, Loss: -0.22392, Accuracy: 0.99884, F1: 0.6529, Prec: 0.5022, Rec: 0.3338 lr: 0.00070\n",
      "Epoch 10/Step 390, Loss: -0.16960, Accuracy: 0.99884, F1: 0.6547, Prec: 0.5033, Rec: 0.3332 lr: 0.00070\n",
      "Epoch 10/Step 400, Loss: -0.15434, Accuracy: 0.99884, F1: 0.6535, Prec: 0.5041, Rec: 0.3326 lr: 0.00070\n",
      "Epoch 10/Step 410, Loss: -0.15880, Accuracy: 0.99884, F1: 0.6510, Prec: 0.5029, Rec: 0.3327 lr: 0.00070\n",
      "Epoch 10/Step 420, Loss: -0.20486, Accuracy: 0.99884, F1: 0.6521, Prec: 0.5032, Rec: 0.3331 lr: 0.00070\n",
      "Epoch 10/Step 430, Loss: -0.18871, Accuracy: 0.99885, F1: 0.6531, Prec: 0.5037, Rec: 0.3328 lr: 0.00070\n",
      "Epoch 10/Step 440, Loss: -0.19817, Accuracy: 0.99884, F1: 0.6534, Prec: 0.5030, Rec: 0.3330 lr: 0.00070\n",
      "Epoch 10/Step 450, Loss: -0.19949, Accuracy: 0.99884, F1: 0.6525, Prec: 0.5022, Rec: 0.3334 lr: 0.00070\n",
      "Epoch 10/Step 460, Loss: -0.19037, Accuracy: 0.99884, F1: 0.6517, Prec: 0.5021, Rec: 0.3333 lr: 0.00070\n",
      "Epoch 10/Step 470, Loss: -0.19701, Accuracy: 0.99885, F1: 0.6524, Prec: 0.5030, Rec: 0.3328 lr: 0.00070\n",
      "Epoch 10/Step 480, Loss: -0.17630, Accuracy: 0.99884, F1: 0.6509, Prec: 0.5020, Rec: 0.3321 lr: 0.00070\n",
      "Epoch 10/Step 490, Loss: -0.18651, Accuracy: 0.99884, F1: 0.6496, Prec: 0.5011, Rec: 0.3322 lr: 0.00070\n",
      "Epoch 10/Step 500, Loss: -0.19998, Accuracy: 0.99884, F1: 0.6493, Prec: 0.5015, Rec: 0.3322 lr: 0.00070\n",
      "Epoch 10/Step 510, Loss: -0.24718, Accuracy: 0.99884, F1: 0.6506, Prec: 0.5019, Rec: 0.3322 lr: 0.00070\n",
      "Epoch 10/Step 520, Loss: -0.18214, Accuracy: 0.99884, F1: 0.6515, Prec: 0.5025, Rec: 0.3325 lr: 0.00070\n",
      "Epoch 10/Step 530, Loss: -0.19323, Accuracy: 0.99885, F1: 0.6523, Prec: 0.5026, Rec: 0.3321 lr: 0.00070\n",
      "Epoch 10/Step 540, Loss: -0.20215, Accuracy: 0.99884, F1: 0.6519, Prec: 0.5028, Rec: 0.3321 lr: 0.00070\n",
      "Epoch 10/Step 550, Loss: -0.23756, Accuracy: 0.99884, F1: 0.6518, Prec: 0.5031, Rec: 0.3323 lr: 0.00070\n",
      "Epoch 10/Step 560, Loss: -0.18572, Accuracy: 0.99884, F1: 0.6522, Prec: 0.5033, Rec: 0.3321 lr: 0.00070\n",
      "Epoch 10/Step 570, Loss: -0.20707, Accuracy: 0.99884, F1: 0.6523, Prec: 0.5034, Rec: 0.3322 lr: 0.00070\n",
      "Epoch 10/Step 580, Loss: -0.17612, Accuracy: 0.99884, F1: 0.6529, Prec: 0.5038, Rec: 0.3319 lr: 0.00070\n",
      "Epoch 10/Step 590, Loss: -0.15462, Accuracy: 0.99884, F1: 0.6522, Prec: 0.5037, Rec: 0.3318 lr: 0.00070\n",
      "Epoch 10/Step 600, Loss: -0.17423, Accuracy: 0.99884, F1: 0.6527, Prec: 0.5039, Rec: 0.3318 lr: 0.00070\n",
      "Epoch 10/Step 610, Loss: -0.23739, Accuracy: 0.99884, F1: 0.6525, Prec: 0.5039, Rec: 0.3319 lr: 0.00070\n",
      "Epoch 10/Step 620, Loss: -0.22035, Accuracy: 0.99884, F1: 0.6529, Prec: 0.5045, Rec: 0.3324 lr: 0.00070\n",
      "Epoch 10/Step 630, Loss: -0.18317, Accuracy: 0.99884, F1: 0.6523, Prec: 0.5045, Rec: 0.3323 lr: 0.00070\n",
      "Epoch 10/Step 640, Loss: -0.18386, Accuracy: 0.99884, F1: 0.6519, Prec: 0.5044, Rec: 0.3323 lr: 0.00070\n",
      "Epoch 10/Step 650, Loss: -0.17590, Accuracy: 0.99884, F1: 0.6526, Prec: 0.5046, Rec: 0.3324 lr: 0.00070\n",
      "Epoch 10/Step 660, Loss: -0.21231, Accuracy: 0.99884, F1: 0.6538, Prec: 0.5047, Rec: 0.3324 lr: 0.00070\n",
      "Epoch 10/Step 670, Loss: -0.16774, Accuracy: 0.99884, F1: 0.6544, Prec: 0.5046, Rec: 0.3326 lr: 0.00070\n",
      "Epoch 10/Step 680, Loss: -0.16896, Accuracy: 0.99884, F1: 0.6547, Prec: 0.5046, Rec: 0.3327 lr: 0.00070\n",
      "Epoch 10/Step 690, Loss: -0.20878, Accuracy: 0.99884, F1: 0.6545, Prec: 0.5044, Rec: 0.3326 lr: 0.00070\n",
      "Epoch 10/Step 700, Loss: -0.19355, Accuracy: 0.99885, F1: 0.6550, Prec: 0.5045, Rec: 0.3324 lr: 0.00070\n",
      "Epoch 10/Step 710, Loss: -0.21392, Accuracy: 0.99885, F1: 0.6551, Prec: 0.5047, Rec: 0.3328 lr: 0.00070\n",
      "Epoch 10/Step 720, Loss: -0.22838, Accuracy: 0.99885, F1: 0.6552, Prec: 0.5046, Rec: 0.3328 lr: 0.00070\n",
      "Epoch 10/Step 730, Loss: -0.18261, Accuracy: 0.99885, F1: 0.6558, Prec: 0.5048, Rec: 0.3326 lr: 0.00070\n",
      "Epoch 10/Step 740, Loss: -0.20054, Accuracy: 0.99885, F1: 0.6559, Prec: 0.5046, Rec: 0.3324 lr: 0.00070\n",
      "Epoch 10/Step 750, Loss: -0.18080, Accuracy: 0.99885, F1: 0.6554, Prec: 0.5042, Rec: 0.3325 lr: 0.00070\n",
      "Epoch 10/Step 760, Loss: -0.20057, Accuracy: 0.99885, F1: 0.6556, Prec: 0.5043, Rec: 0.3322 lr: 0.00070\n",
      "Epoch 10/Step 770, Loss: -0.21174, Accuracy: 0.99885, F1: 0.6555, Prec: 0.5043, Rec: 0.3323 lr: 0.00070\n",
      "Epoch 10/Step 780, Loss: -0.17729, Accuracy: 0.99885, F1: 0.6574, Prec: 0.5052, Rec: 0.3324 lr: 0.00070\n",
      "Epoch 10/Step 790, Loss: -0.21365, Accuracy: 0.99885, F1: 0.6583, Prec: 0.5049, Rec: 0.3320 lr: 0.00070\n",
      "Epoch 10/Step 800, Loss: -0.18278, Accuracy: 0.99885, F1: 0.6579, Prec: 0.5041, Rec: 0.3322 lr: 0.00070\n",
      "Epoch 10/Step 810, Loss: -0.13642, Accuracy: 0.99885, F1: 0.6574, Prec: 0.5041, Rec: 0.3321 lr: 0.00070\n",
      "Epoch 10/Step 820, Loss: -0.20014, Accuracy: 0.99885, F1: 0.6571, Prec: 0.5037, Rec: 0.3320 lr: 0.00070\n",
      "Epoch 10/Step 830, Loss: -0.21124, Accuracy: 0.99885, F1: 0.6571, Prec: 0.5039, Rec: 0.3321 lr: 0.00070\n",
      "Epoch 10/Step 840, Loss: -0.22171, Accuracy: 0.99885, F1: 0.6575, Prec: 0.5043, Rec: 0.3322 lr: 0.00070\n",
      "Epoch 10/Step 850, Loss: -0.19282, Accuracy: 0.99885, F1: 0.6576, Prec: 0.5039, Rec: 0.3320 lr: 0.00070\n",
      "Epoch 10/Step 860, Loss: -0.20070, Accuracy: 0.99885, F1: 0.6575, Prec: 0.5040, Rec: 0.3319 lr: 0.00070\n",
      "Epoch 10/Step 870, Loss: -0.19009, Accuracy: 0.99885, F1: 0.6572, Prec: 0.5038, Rec: 0.3315 lr: 0.00070\n",
      "Epoch 10/Step 880, Loss: -0.17841, Accuracy: 0.99885, F1: 0.6573, Prec: 0.5036, Rec: 0.3317 lr: 0.00070\n",
      "Epoch 10/Step 890, Loss: -0.18689, Accuracy: 0.99885, F1: 0.6567, Prec: 0.5032, Rec: 0.3315 lr: 0.00070\n",
      "Epoch 10/Step 900, Loss: -0.24822, Accuracy: 0.99885, F1: 0.6569, Prec: 0.5037, Rec: 0.3317 lr: 0.00070\n",
      "Epoch 10/Step 910, Loss: -0.17671, Accuracy: 0.99885, F1: 0.6576, Prec: 0.5040, Rec: 0.3315 lr: 0.00070\n",
      "Epoch 10/Step 920, Loss: -0.19598, Accuracy: 0.99885, F1: 0.6577, Prec: 0.5039, Rec: 0.3312 lr: 0.00070\n",
      "Epoch 10/Step 930, Loss: -0.19759, Accuracy: 0.99885, F1: 0.6572, Prec: 0.5039, Rec: 0.3314 lr: 0.00070\n",
      "Epoch 10/Step 940, Loss: -0.19228, Accuracy: 0.99885, F1: 0.6565, Prec: 0.5038, Rec: 0.3314 lr: 0.00070\n",
      "Epoch 10/Step 950, Loss: -0.21613, Accuracy: 0.99885, F1: 0.6567, Prec: 0.5042, Rec: 0.3315 lr: 0.00070\n",
      "Epoch 10/Step 960, Loss: -0.22161, Accuracy: 0.99885, F1: 0.6558, Prec: 0.5037, Rec: 0.3316 lr: 0.00070\n",
      "Epoch 10/Step 970, Loss: -0.17566, Accuracy: 0.99885, F1: 0.6548, Prec: 0.5036, Rec: 0.3313 lr: 0.00070\n",
      "Epoch 10/Step 980, Loss: -0.19850, Accuracy: 0.99885, F1: 0.6546, Prec: 0.5037, Rec: 0.3308 lr: 0.00070\n",
      "Epoch 10/Step 990, Loss: -0.18934, Accuracy: 0.99885, F1: 0.6541, Prec: 0.5030, Rec: 0.3308 lr: 0.00070\n",
      "Epoch 10/Step 1000, Loss: -0.21099, Accuracy: 0.99885, F1: 0.6538, Prec: 0.5027, Rec: 0.3312 lr: 0.00070\n",
      "Epoch 10/Step 1010, Loss: -0.21736, Accuracy: 0.99885, F1: 0.6549, Prec: 0.5034, Rec: 0.3313 lr: 0.00070\n",
      "Epoch 10/Step 1020, Loss: -0.15888, Accuracy: 0.99886, F1: 0.6552, Prec: 0.5032, Rec: 0.3312 lr: 0.00070\n",
      "Epoch 10/Step 1030, Loss: -0.20935, Accuracy: 0.99886, F1: 0.6557, Prec: 0.5033, Rec: 0.3311 lr: 0.00070\n",
      "Epoch 10/Step 1040, Loss: -0.21470, Accuracy: 0.99886, F1: 0.6554, Prec: 0.5034, Rec: 0.3311 lr: 0.00070\n",
      "Epoch 10/Step 1050, Loss: -0.22797, Accuracy: 0.99886, F1: 0.6550, Prec: 0.5032, Rec: 0.3311 lr: 0.00070\n",
      "Epoch 10/Step 1060, Loss: -0.21112, Accuracy: 0.99886, F1: 0.6547, Prec: 0.5032, Rec: 0.3313 lr: 0.00070\n",
      "Epoch 10/Step 1070, Loss: -0.20165, Accuracy: 0.99886, F1: 0.6555, Prec: 0.5034, Rec: 0.3313 lr: 0.00070\n",
      "Epoch 10/Step 1080, Loss: -0.17782, Accuracy: 0.99886, F1: 0.6564, Prec: 0.5034, Rec: 0.3313 lr: 0.00070\n",
      "Epoch 10/Step 1090, Loss: -0.19665, Accuracy: 0.99886, F1: 0.6554, Prec: 0.5031, Rec: 0.3313 lr: 0.00070\n",
      "Epoch 10/Step 1100, Loss: -0.19812, Accuracy: 0.99886, F1: 0.6557, Prec: 0.5030, Rec: 0.3313 lr: 0.00070\n",
      "Epoch 10/Step 1110, Loss: -0.16510, Accuracy: 0.99886, F1: 0.6558, Prec: 0.5030, Rec: 0.3314 lr: 0.00070\n",
      "Epoch 10/Step 1120, Loss: -0.17781, Accuracy: 0.99886, F1: 0.6558, Prec: 0.5029, Rec: 0.3313 lr: 0.00070\n",
      "Epoch 10/Step 1130, Loss: -0.18308, Accuracy: 0.99886, F1: 0.6553, Prec: 0.5031, Rec: 0.3315 lr: 0.00070\n",
      "Epoch 10/Step 1140, Loss: -0.18481, Accuracy: 0.99886, F1: 0.6547, Prec: 0.5031, Rec: 0.3316 lr: 0.00070\n",
      "Epoch 10/Step 1150, Loss: -0.21712, Accuracy: 0.99886, F1: 0.6548, Prec: 0.5034, Rec: 0.3316 lr: 0.00070\n",
      "Epoch 10/Step 1160, Loss: -0.16117, Accuracy: 0.99886, F1: 0.6552, Prec: 0.5037, Rec: 0.3318 lr: 0.00070\n",
      "Epoch 10/Step 1170, Loss: -0.17901, Accuracy: 0.99886, F1: 0.6549, Prec: 0.5035, Rec: 0.3318 lr: 0.00070\n",
      "Epoch 10/Step 1180, Loss: -0.16434, Accuracy: 0.99886, F1: 0.6551, Prec: 0.5038, Rec: 0.3316 lr: 0.00070\n",
      "Epoch 10/Step 1190, Loss: -0.19161, Accuracy: 0.99886, F1: 0.6546, Prec: 0.5036, Rec: 0.3315 lr: 0.00070\n",
      "Epoch 10/Step 1200, Loss: -0.19142, Accuracy: 0.99886, F1: 0.6544, Prec: 0.5034, Rec: 0.3318 lr: 0.00070\n",
      "Epoch 10/Step 1210, Loss: -0.20284, Accuracy: 0.99886, F1: 0.6553, Prec: 0.5038, Rec: 0.3318 lr: 0.00070\n",
      "Epoch 10/Step 1220, Loss: -0.20498, Accuracy: 0.99886, F1: 0.6548, Prec: 0.5037, Rec: 0.3320 lr: 0.00070\n",
      "Epoch 10/Step 1230, Loss: -0.20568, Accuracy: 0.99886, F1: 0.6545, Prec: 0.5038, Rec: 0.3320 lr: 0.00070\n",
      "Epoch 10/Step 1240, Loss: -0.23945, Accuracy: 0.99886, F1: 0.6550, Prec: 0.5040, Rec: 0.3318 lr: 0.00070\n",
      "Epoch 10/Step 1250, Loss: -0.14106, Accuracy: 0.99886, F1: 0.6548, Prec: 0.5037, Rec: 0.3319 lr: 0.00070\n",
      "Epoch 10/Step 1260, Loss: -0.19184, Accuracy: 0.99886, F1: 0.6548, Prec: 0.5035, Rec: 0.3320 lr: 0.00070\n",
      "Epoch 10/Step 1270, Loss: -0.18276, Accuracy: 0.99886, F1: 0.6549, Prec: 0.5038, Rec: 0.3320 lr: 0.00070\n",
      "Epoch 10/Step 1280, Loss: -0.25879, Accuracy: 0.99886, F1: 0.6550, Prec: 0.5039, Rec: 0.3320 lr: 0.00070\n",
      "Epoch 10/Step 1290, Loss: -0.21645, Accuracy: 0.99886, F1: 0.6546, Prec: 0.5039, Rec: 0.3322 lr: 0.00070\n",
      "Epoch 10/Step 1300, Loss: -0.18931, Accuracy: 0.99887, F1: 0.6549, Prec: 0.5038, Rec: 0.3321 lr: 0.00070\n",
      "Epoch 10/Step 1310, Loss: -0.20744, Accuracy: 0.99887, F1: 0.6553, Prec: 0.5039, Rec: 0.3321 lr: 0.00070\n",
      "Epoch 10/Step 1320, Loss: -0.20431, Accuracy: 0.99886, F1: 0.6554, Prec: 0.5040, Rec: 0.3321 lr: 0.00070\n",
      "Epoch 10/Step 1330, Loss: -0.21130, Accuracy: 0.99886, F1: 0.6555, Prec: 0.5040, Rec: 0.3319 lr: 0.00070\n",
      "Epoch 10/Step 1340, Loss: -0.19900, Accuracy: 0.99886, F1: 0.6552, Prec: 0.5041, Rec: 0.3321 lr: 0.00070\n",
      "Epoch 10/Step 1350, Loss: -0.15602, Accuracy: 0.99887, F1: 0.6553, Prec: 0.5042, Rec: 0.3320 lr: 0.00070\n",
      "Epoch 10/Step 1360, Loss: -0.17729, Accuracy: 0.99887, F1: 0.6557, Prec: 0.5043, Rec: 0.3320 lr: 0.00070\n",
      "Epoch 10/Step 1370, Loss: -0.18853, Accuracy: 0.99887, F1: 0.6555, Prec: 0.5042, Rec: 0.3321 lr: 0.00070\n",
      "Epoch 10/Step 1380, Loss: -0.19574, Accuracy: 0.99887, F1: 0.6554, Prec: 0.5044, Rec: 0.3322 lr: 0.00070\n",
      "Epoch 10/Step 1390, Loss: -0.21033, Accuracy: 0.99887, F1: 0.6551, Prec: 0.5043, Rec: 0.3321 lr: 0.00070\n",
      "Epoch 10/Step 1400, Loss: -0.22086, Accuracy: 0.99887, F1: 0.6551, Prec: 0.5045, Rec: 0.3322 lr: 0.00070\n",
      "Epoch 10/Step 1410, Loss: -0.18978, Accuracy: 0.99887, F1: 0.6554, Prec: 0.5046, Rec: 0.3322 lr: 0.00070\n",
      "Epoch 10/Step 1420, Loss: -0.19091, Accuracy: 0.99887, F1: 0.6553, Prec: 0.5045, Rec: 0.3320 lr: 0.00070\n",
      "Epoch 10/Step 1430, Loss: -0.17864, Accuracy: 0.99887, F1: 0.6559, Prec: 0.5047, Rec: 0.3319 lr: 0.00070\n",
      "Epoch 10/Step 1440, Loss: -0.18652, Accuracy: 0.99887, F1: 0.6558, Prec: 0.5048, Rec: 0.3319 lr: 0.00070\n",
      "Epoch 10/Step 1450, Loss: -0.18406, Accuracy: 0.99887, F1: 0.6557, Prec: 0.5049, Rec: 0.3319 lr: 0.00070\n",
      "Epoch 10/Step 1460, Loss: -0.18973, Accuracy: 0.99887, F1: 0.6558, Prec: 0.5050, Rec: 0.3318 lr: 0.00070\n",
      "Epoch 10/Step 1470, Loss: -0.18264, Accuracy: 0.99887, F1: 0.6565, Prec: 0.5052, Rec: 0.3317 lr: 0.00070\n",
      "Epoch 10/Step 1480, Loss: -0.19485, Accuracy: 0.99887, F1: 0.6564, Prec: 0.5049, Rec: 0.3317 lr: 0.00070\n",
      "Epoch 10/Step 1490, Loss: -0.18707, Accuracy: 0.99887, F1: 0.6565, Prec: 0.5046, Rec: 0.3317 lr: 0.00070\n",
      "Epoch 10/Step 1500, Loss: -0.21620, Accuracy: 0.99887, F1: 0.6564, Prec: 0.5048, Rec: 0.3317 lr: 0.00070\n",
      "Epoch 10/Step 1510, Loss: -0.18114, Accuracy: 0.99887, F1: 0.6569, Prec: 0.5051, Rec: 0.3317 lr: 0.00070\n",
      "Epoch 10/Step 1520, Loss: -0.23508, Accuracy: 0.99887, F1: 0.6572, Prec: 0.5054, Rec: 0.3318 lr: 0.00070\n",
      "Epoch 10/Step 1530, Loss: -0.18146, Accuracy: 0.99887, F1: 0.6572, Prec: 0.5055, Rec: 0.3320 lr: 0.00070\n",
      "Epoch 10/Step 1540, Loss: -0.16686, Accuracy: 0.99887, F1: 0.6575, Prec: 0.5056, Rec: 0.3317 lr: 0.00070\n",
      "Epoch 10/Step 1550, Loss: -0.20381, Accuracy: 0.99887, F1: 0.6577, Prec: 0.5057, Rec: 0.3317 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9986\n",
      "Validation f1: 0.5683\n",
      "Validation precision: 0.3436\n",
      "Validation recall: 0.2319\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_9_valF1Score0.568/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_9_valF1Score0.568/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 11\n",
      "Epoch 11/Step 0, Loss: -0.22240, Accuracy: 0.99903, F1: 0.8341, Prec: 0.5838, Rec: 0.3741 lr: 0.00070\n",
      "Epoch 11/Step 10, Loss: -0.23403, Accuracy: 0.99880, F1: 0.6183, Prec: 0.5206, Rec: 0.3567 lr: 0.00070\n",
      "Epoch 11/Step 20, Loss: -0.20867, Accuracy: 0.99887, F1: 0.6478, Prec: 0.5270, Rec: 0.3509 lr: 0.00070\n",
      "Epoch 11/Step 30, Loss: -0.18931, Accuracy: 0.99891, F1: 0.6741, Prec: 0.5340, Rec: 0.3496 lr: 0.00070\n",
      "Epoch 11/Step 40, Loss: -0.18370, Accuracy: 0.99890, F1: 0.7019, Prec: 0.5413, Rec: 0.3493 lr: 0.00070\n",
      "Epoch 11/Step 50, Loss: -0.20482, Accuracy: 0.99892, F1: 0.7130, Prec: 0.5459, Rec: 0.3497 lr: 0.00070\n",
      "Epoch 11/Step 60, Loss: -0.21915, Accuracy: 0.99892, F1: 0.7060, Prec: 0.5439, Rec: 0.3508 lr: 0.00070\n",
      "Epoch 11/Step 70, Loss: -0.19339, Accuracy: 0.99893, F1: 0.7057, Prec: 0.5415, Rec: 0.3511 lr: 0.00070\n",
      "Epoch 11/Step 80, Loss: -0.18354, Accuracy: 0.99894, F1: 0.7027, Prec: 0.5408, Rec: 0.3467 lr: 0.00070\n",
      "Epoch 11/Step 90, Loss: -0.18195, Accuracy: 0.99893, F1: 0.6765, Prec: 0.5419, Rec: 0.3454 lr: 0.00070\n",
      "Epoch 11/Step 100, Loss: -0.21747, Accuracy: 0.99893, F1: 0.6583, Prec: 0.5388, Rec: 0.3481 lr: 0.00070\n",
      "Epoch 11/Step 110, Loss: -0.20058, Accuracy: 0.99892, F1: 0.6401, Prec: 0.5395, Rec: 0.3472 lr: 0.00070\n",
      "Epoch 11/Step 120, Loss: -0.19020, Accuracy: 0.99892, F1: 0.6449, Prec: 0.5408, Rec: 0.3454 lr: 0.00070\n",
      "Epoch 11/Step 130, Loss: -0.16541, Accuracy: 0.99892, F1: 0.6380, Prec: 0.5367, Rec: 0.3469 lr: 0.00070\n",
      "Epoch 11/Step 140, Loss: -0.17976, Accuracy: 0.99891, F1: 0.6272, Prec: 0.5364, Rec: 0.3434 lr: 0.00070\n",
      "Epoch 11/Step 150, Loss: -0.18887, Accuracy: 0.99890, F1: 0.6230, Prec: 0.5368, Rec: 0.3400 lr: 0.00070\n",
      "Epoch 11/Step 160, Loss: -0.20516, Accuracy: 0.99889, F1: 0.6114, Prec: 0.5318, Rec: 0.3409 lr: 0.00070\n",
      "Epoch 11/Step 170, Loss: -0.18652, Accuracy: 0.99889, F1: 0.6106, Prec: 0.5265, Rec: 0.3408 lr: 0.00070\n",
      "Epoch 11/Step 180, Loss: -0.23571, Accuracy: 0.99889, F1: 0.6106, Prec: 0.5275, Rec: 0.3412 lr: 0.00070\n",
      "Epoch 11/Step 190, Loss: -0.19256, Accuracy: 0.99889, F1: 0.6172, Prec: 0.5270, Rec: 0.3406 lr: 0.00070\n",
      "Epoch 11/Step 200, Loss: -0.21452, Accuracy: 0.99888, F1: 0.6218, Prec: 0.5279, Rec: 0.3395 lr: 0.00070\n",
      "Epoch 11/Step 210, Loss: -0.17323, Accuracy: 0.99888, F1: 0.6234, Prec: 0.5251, Rec: 0.3395 lr: 0.00070\n",
      "Epoch 11/Step 220, Loss: -0.21654, Accuracy: 0.99888, F1: 0.6207, Prec: 0.5232, Rec: 0.3398 lr: 0.00070\n",
      "Epoch 11/Step 230, Loss: -0.17721, Accuracy: 0.99887, F1: 0.6265, Prec: 0.5237, Rec: 0.3385 lr: 0.00070\n",
      "Epoch 11/Step 240, Loss: -0.24389, Accuracy: 0.99887, F1: 0.6278, Prec: 0.5241, Rec: 0.3388 lr: 0.00070\n",
      "Epoch 11/Step 250, Loss: -0.21820, Accuracy: 0.99887, F1: 0.6318, Prec: 0.5243, Rec: 0.3384 lr: 0.00070\n",
      "Epoch 11/Step 260, Loss: -0.22735, Accuracy: 0.99887, F1: 0.6377, Prec: 0.5245, Rec: 0.3383 lr: 0.00070\n",
      "Epoch 11/Step 270, Loss: -0.23081, Accuracy: 0.99886, F1: 0.6412, Prec: 0.5224, Rec: 0.3385 lr: 0.00070\n",
      "Epoch 11/Step 280, Loss: -0.21290, Accuracy: 0.99886, F1: 0.6385, Prec: 0.5220, Rec: 0.3376 lr: 0.00070\n",
      "Epoch 11/Step 290, Loss: -0.19852, Accuracy: 0.99886, F1: 0.6358, Prec: 0.5227, Rec: 0.3374 lr: 0.00070\n",
      "Epoch 11/Step 300, Loss: -0.22480, Accuracy: 0.99887, F1: 0.6414, Prec: 0.5232, Rec: 0.3373 lr: 0.00070\n",
      "Epoch 11/Step 310, Loss: -0.21487, Accuracy: 0.99887, F1: 0.6415, Prec: 0.5218, Rec: 0.3376 lr: 0.00070\n",
      "Epoch 11/Step 320, Loss: -0.18492, Accuracy: 0.99887, F1: 0.6404, Prec: 0.5222, Rec: 0.3381 lr: 0.00070\n",
      "Epoch 11/Step 330, Loss: -0.22206, Accuracy: 0.99887, F1: 0.6378, Prec: 0.5237, Rec: 0.3376 lr: 0.00070\n",
      "Epoch 11/Step 340, Loss: -0.19483, Accuracy: 0.99887, F1: 0.6391, Prec: 0.5238, Rec: 0.3375 lr: 0.00070\n",
      "Epoch 11/Step 350, Loss: -0.17407, Accuracy: 0.99887, F1: 0.6385, Prec: 0.5243, Rec: 0.3382 lr: 0.00070\n",
      "Epoch 11/Step 360, Loss: -0.19903, Accuracy: 0.99887, F1: 0.6418, Prec: 0.5253, Rec: 0.3388 lr: 0.00070\n",
      "Epoch 11/Step 370, Loss: -0.21134, Accuracy: 0.99887, F1: 0.6416, Prec: 0.5253, Rec: 0.3388 lr: 0.00070\n",
      "Epoch 11/Step 380, Loss: -0.22831, Accuracy: 0.99887, F1: 0.6436, Prec: 0.5250, Rec: 0.3387 lr: 0.00070\n",
      "Epoch 11/Step 390, Loss: -0.17647, Accuracy: 0.99888, F1: 0.6435, Prec: 0.5257, Rec: 0.3383 lr: 0.00070\n",
      "Epoch 11/Step 400, Loss: -0.15766, Accuracy: 0.99888, F1: 0.6405, Prec: 0.5264, Rec: 0.3378 lr: 0.00070\n",
      "Epoch 11/Step 410, Loss: -0.16275, Accuracy: 0.99888, F1: 0.6397, Prec: 0.5257, Rec: 0.3378 lr: 0.00070\n",
      "Epoch 11/Step 420, Loss: -0.21362, Accuracy: 0.99888, F1: 0.6392, Prec: 0.5251, Rec: 0.3383 lr: 0.00070\n",
      "Epoch 11/Step 430, Loss: -0.19034, Accuracy: 0.99888, F1: 0.6416, Prec: 0.5256, Rec: 0.3381 lr: 0.00070\n",
      "Epoch 11/Step 440, Loss: -0.19927, Accuracy: 0.99888, F1: 0.6411, Prec: 0.5255, Rec: 0.3379 lr: 0.00070\n",
      "Epoch 11/Step 450, Loss: -0.20182, Accuracy: 0.99887, F1: 0.6416, Prec: 0.5244, Rec: 0.3382 lr: 0.00070\n",
      "Epoch 11/Step 460, Loss: -0.19116, Accuracy: 0.99888, F1: 0.6420, Prec: 0.5238, Rec: 0.3382 lr: 0.00070\n",
      "Epoch 11/Step 470, Loss: -0.19983, Accuracy: 0.99888, F1: 0.6432, Prec: 0.5249, Rec: 0.3376 lr: 0.00070\n",
      "Epoch 11/Step 480, Loss: -0.18749, Accuracy: 0.99888, F1: 0.6435, Prec: 0.5242, Rec: 0.3369 lr: 0.00070\n",
      "Epoch 11/Step 490, Loss: -0.18712, Accuracy: 0.99887, F1: 0.6428, Prec: 0.5228, Rec: 0.3372 lr: 0.00070\n",
      "Epoch 11/Step 500, Loss: -0.21214, Accuracy: 0.99888, F1: 0.6435, Prec: 0.5233, Rec: 0.3372 lr: 0.00070\n",
      "Epoch 11/Step 510, Loss: -0.24121, Accuracy: 0.99888, F1: 0.6456, Prec: 0.5234, Rec: 0.3373 lr: 0.00070\n",
      "Epoch 11/Step 520, Loss: -0.18384, Accuracy: 0.99888, F1: 0.6472, Prec: 0.5240, Rec: 0.3376 lr: 0.00070\n",
      "Epoch 11/Step 530, Loss: -0.19988, Accuracy: 0.99888, F1: 0.6468, Prec: 0.5238, Rec: 0.3374 lr: 0.00070\n",
      "Epoch 11/Step 540, Loss: -0.20055, Accuracy: 0.99888, F1: 0.6461, Prec: 0.5242, Rec: 0.3374 lr: 0.00070\n",
      "Epoch 11/Step 550, Loss: -0.24092, Accuracy: 0.99888, F1: 0.6473, Prec: 0.5246, Rec: 0.3375 lr: 0.00070\n",
      "Epoch 11/Step 560, Loss: -0.19511, Accuracy: 0.99888, F1: 0.6485, Prec: 0.5247, Rec: 0.3376 lr: 0.00070\n",
      "Epoch 11/Step 570, Loss: -0.21491, Accuracy: 0.99888, F1: 0.6483, Prec: 0.5247, Rec: 0.3376 lr: 0.00070\n",
      "Epoch 11/Step 580, Loss: -0.18170, Accuracy: 0.99888, F1: 0.6489, Prec: 0.5248, Rec: 0.3375 lr: 0.00070\n",
      "Epoch 11/Step 590, Loss: -0.16115, Accuracy: 0.99888, F1: 0.6491, Prec: 0.5251, Rec: 0.3373 lr: 0.00070\n",
      "Epoch 11/Step 600, Loss: -0.18097, Accuracy: 0.99888, F1: 0.6506, Prec: 0.5253, Rec: 0.3373 lr: 0.00070\n",
      "Epoch 11/Step 610, Loss: -0.24383, Accuracy: 0.99887, F1: 0.6499, Prec: 0.5251, Rec: 0.3375 lr: 0.00070\n",
      "Epoch 11/Step 620, Loss: -0.22586, Accuracy: 0.99887, F1: 0.6519, Prec: 0.5257, Rec: 0.3378 lr: 0.00070\n",
      "Epoch 11/Step 630, Loss: -0.19113, Accuracy: 0.99887, F1: 0.6531, Prec: 0.5258, Rec: 0.3378 lr: 0.00070\n",
      "Epoch 11/Step 640, Loss: -0.19215, Accuracy: 0.99887, F1: 0.6536, Prec: 0.5257, Rec: 0.3378 lr: 0.00070\n",
      "Epoch 11/Step 650, Loss: -0.19023, Accuracy: 0.99888, F1: 0.6545, Prec: 0.5258, Rec: 0.3379 lr: 0.00070\n",
      "Epoch 11/Step 660, Loss: -0.20651, Accuracy: 0.99888, F1: 0.6562, Prec: 0.5261, Rec: 0.3379 lr: 0.00070\n",
      "Epoch 11/Step 670, Loss: -0.17896, Accuracy: 0.99888, F1: 0.6578, Prec: 0.5265, Rec: 0.3378 lr: 0.00070\n",
      "Epoch 11/Step 680, Loss: -0.16585, Accuracy: 0.99888, F1: 0.6578, Prec: 0.5261, Rec: 0.3381 lr: 0.00070\n",
      "Epoch 11/Step 690, Loss: -0.22333, Accuracy: 0.99888, F1: 0.6585, Prec: 0.5260, Rec: 0.3380 lr: 0.00070\n",
      "Epoch 11/Step 700, Loss: -0.20267, Accuracy: 0.99888, F1: 0.6571, Prec: 0.5261, Rec: 0.3378 lr: 0.00070\n",
      "Epoch 11/Step 710, Loss: -0.21749, Accuracy: 0.99888, F1: 0.6571, Prec: 0.5262, Rec: 0.3383 lr: 0.00070\n",
      "Epoch 11/Step 720, Loss: -0.22727, Accuracy: 0.99888, F1: 0.6582, Prec: 0.5261, Rec: 0.3382 lr: 0.00070\n",
      "Epoch 11/Step 730, Loss: -0.18632, Accuracy: 0.99888, F1: 0.6579, Prec: 0.5265, Rec: 0.3380 lr: 0.00070\n",
      "Epoch 11/Step 740, Loss: -0.20741, Accuracy: 0.99888, F1: 0.6580, Prec: 0.5265, Rec: 0.3379 lr: 0.00070\n",
      "Epoch 11/Step 750, Loss: -0.19278, Accuracy: 0.99888, F1: 0.6589, Prec: 0.5261, Rec: 0.3379 lr: 0.00070\n",
      "Epoch 11/Step 760, Loss: -0.21364, Accuracy: 0.99888, F1: 0.6600, Prec: 0.5263, Rec: 0.3377 lr: 0.00070\n",
      "Epoch 11/Step 770, Loss: -0.22061, Accuracy: 0.99888, F1: 0.6609, Prec: 0.5264, Rec: 0.3378 lr: 0.00070\n",
      "Epoch 11/Step 780, Loss: -0.18050, Accuracy: 0.99888, F1: 0.6620, Prec: 0.5270, Rec: 0.3380 lr: 0.00070\n",
      "Epoch 11/Step 790, Loss: -0.21691, Accuracy: 0.99888, F1: 0.6610, Prec: 0.5272, Rec: 0.3376 lr: 0.00070\n",
      "Epoch 11/Step 800, Loss: -0.18939, Accuracy: 0.99888, F1: 0.6596, Prec: 0.5269, Rec: 0.3375 lr: 0.00070\n",
      "Epoch 11/Step 810, Loss: -0.14809, Accuracy: 0.99888, F1: 0.6586, Prec: 0.5264, Rec: 0.3377 lr: 0.00070\n",
      "Epoch 11/Step 820, Loss: -0.20721, Accuracy: 0.99888, F1: 0.6586, Prec: 0.5264, Rec: 0.3375 lr: 0.00070\n",
      "Epoch 11/Step 830, Loss: -0.21097, Accuracy: 0.99888, F1: 0.6586, Prec: 0.5267, Rec: 0.3375 lr: 0.00070\n",
      "Epoch 11/Step 840, Loss: -0.24010, Accuracy: 0.99888, F1: 0.6592, Prec: 0.5266, Rec: 0.3378 lr: 0.00070\n",
      "Epoch 11/Step 850, Loss: -0.19963, Accuracy: 0.99888, F1: 0.6593, Prec: 0.5262, Rec: 0.3377 lr: 0.00070\n",
      "Epoch 11/Step 860, Loss: -0.20525, Accuracy: 0.99888, F1: 0.6594, Prec: 0.5262, Rec: 0.3377 lr: 0.00070\n",
      "Epoch 11/Step 870, Loss: -0.20614, Accuracy: 0.99888, F1: 0.6601, Prec: 0.5260, Rec: 0.3373 lr: 0.00070\n",
      "Epoch 11/Step 880, Loss: -0.17798, Accuracy: 0.99888, F1: 0.6603, Prec: 0.5258, Rec: 0.3374 lr: 0.00070\n",
      "Epoch 11/Step 890, Loss: -0.18956, Accuracy: 0.99888, F1: 0.6602, Prec: 0.5254, Rec: 0.3373 lr: 0.00070\n",
      "Epoch 11/Step 900, Loss: -0.25965, Accuracy: 0.99888, F1: 0.6614, Prec: 0.5258, Rec: 0.3375 lr: 0.00070\n",
      "Epoch 11/Step 910, Loss: -0.17474, Accuracy: 0.99888, F1: 0.6628, Prec: 0.5261, Rec: 0.3373 lr: 0.00070\n",
      "Epoch 11/Step 920, Loss: -0.20073, Accuracy: 0.99888, F1: 0.6641, Prec: 0.5262, Rec: 0.3370 lr: 0.00070\n",
      "Epoch 11/Step 930, Loss: -0.20312, Accuracy: 0.99888, F1: 0.6642, Prec: 0.5261, Rec: 0.3373 lr: 0.00070\n",
      "Epoch 11/Step 940, Loss: -0.20060, Accuracy: 0.99889, F1: 0.6643, Prec: 0.5259, Rec: 0.3374 lr: 0.00070\n",
      "Epoch 11/Step 950, Loss: -0.23058, Accuracy: 0.99889, F1: 0.6655, Prec: 0.5262, Rec: 0.3375 lr: 0.00070\n",
      "Epoch 11/Step 960, Loss: -0.23603, Accuracy: 0.99889, F1: 0.6661, Prec: 0.5258, Rec: 0.3376 lr: 0.00070\n",
      "Epoch 11/Step 970, Loss: -0.17742, Accuracy: 0.99889, F1: 0.6665, Prec: 0.5256, Rec: 0.3373 lr: 0.00070\n",
      "Epoch 11/Step 980, Loss: -0.21132, Accuracy: 0.99889, F1: 0.6650, Prec: 0.5258, Rec: 0.3369 lr: 0.00070\n",
      "Epoch 11/Step 990, Loss: -0.19111, Accuracy: 0.99889, F1: 0.6644, Prec: 0.5253, Rec: 0.3368 lr: 0.00070\n",
      "Epoch 11/Step 1000, Loss: -0.21240, Accuracy: 0.99889, F1: 0.6644, Prec: 0.5250, Rec: 0.3372 lr: 0.00070\n",
      "Epoch 11/Step 1010, Loss: -0.22797, Accuracy: 0.99889, F1: 0.6656, Prec: 0.5255, Rec: 0.3373 lr: 0.00070\n",
      "Epoch 11/Step 1020, Loss: -0.16526, Accuracy: 0.99889, F1: 0.6648, Prec: 0.5252, Rec: 0.3372 lr: 0.00070\n",
      "Epoch 11/Step 1030, Loss: -0.21774, Accuracy: 0.99889, F1: 0.6635, Prec: 0.5253, Rec: 0.3372 lr: 0.00070\n",
      "Epoch 11/Step 1040, Loss: -0.20688, Accuracy: 0.99889, F1: 0.6628, Prec: 0.5255, Rec: 0.3370 lr: 0.00070\n",
      "Epoch 11/Step 1050, Loss: -0.23146, Accuracy: 0.99889, F1: 0.6625, Prec: 0.5249, Rec: 0.3372 lr: 0.00070\n",
      "Epoch 11/Step 1060, Loss: -0.20996, Accuracy: 0.99889, F1: 0.6630, Prec: 0.5249, Rec: 0.3373 lr: 0.00070\n",
      "Epoch 11/Step 1070, Loss: -0.20444, Accuracy: 0.99889, F1: 0.6639, Prec: 0.5249, Rec: 0.3373 lr: 0.00070\n",
      "Epoch 11/Step 1080, Loss: -0.18360, Accuracy: 0.99889, F1: 0.6648, Prec: 0.5249, Rec: 0.3373 lr: 0.00070\n",
      "Epoch 11/Step 1090, Loss: -0.20133, Accuracy: 0.99889, F1: 0.6624, Prec: 0.5247, Rec: 0.3372 lr: 0.00070\n",
      "Epoch 11/Step 1100, Loss: -0.19812, Accuracy: 0.99889, F1: 0.6611, Prec: 0.5244, Rec: 0.3372 lr: 0.00070\n",
      "Epoch 11/Step 1110, Loss: -0.17032, Accuracy: 0.99889, F1: 0.6614, Prec: 0.5242, Rec: 0.3373 lr: 0.00070\n",
      "Epoch 11/Step 1120, Loss: -0.17973, Accuracy: 0.99889, F1: 0.6616, Prec: 0.5241, Rec: 0.3373 lr: 0.00070\n",
      "Epoch 11/Step 1130, Loss: -0.18441, Accuracy: 0.99889, F1: 0.6618, Prec: 0.5242, Rec: 0.3375 lr: 0.00070\n",
      "Epoch 11/Step 1140, Loss: -0.19475, Accuracy: 0.99889, F1: 0.6622, Prec: 0.5243, Rec: 0.3376 lr: 0.00070\n",
      "Epoch 11/Step 1150, Loss: -0.23052, Accuracy: 0.99889, F1: 0.6623, Prec: 0.5244, Rec: 0.3378 lr: 0.00070\n",
      "Epoch 11/Step 1160, Loss: -0.16233, Accuracy: 0.99889, F1: 0.6617, Prec: 0.5248, Rec: 0.3380 lr: 0.00070\n",
      "Epoch 11/Step 1170, Loss: -0.19227, Accuracy: 0.99889, F1: 0.6615, Prec: 0.5248, Rec: 0.3380 lr: 0.00070\n",
      "Epoch 11/Step 1180, Loss: -0.17308, Accuracy: 0.99889, F1: 0.6616, Prec: 0.5250, Rec: 0.3379 lr: 0.00070\n",
      "Epoch 11/Step 1190, Loss: -0.20675, Accuracy: 0.99889, F1: 0.6612, Prec: 0.5250, Rec: 0.3377 lr: 0.00070\n",
      "Epoch 11/Step 1200, Loss: -0.19889, Accuracy: 0.99889, F1: 0.6615, Prec: 0.5250, Rec: 0.3380 lr: 0.00070\n",
      "Epoch 11/Step 1210, Loss: -0.21665, Accuracy: 0.99889, F1: 0.6606, Prec: 0.5252, Rec: 0.3382 lr: 0.00070\n",
      "Epoch 11/Step 1220, Loss: -0.21341, Accuracy: 0.99890, F1: 0.6605, Prec: 0.5254, Rec: 0.3382 lr: 0.00070\n",
      "Epoch 11/Step 1230, Loss: -0.20120, Accuracy: 0.99890, F1: 0.6606, Prec: 0.5251, Rec: 0.3382 lr: 0.00070\n",
      "Epoch 11/Step 1240, Loss: -0.24463, Accuracy: 0.99889, F1: 0.6613, Prec: 0.5251, Rec: 0.3382 lr: 0.00070\n",
      "Epoch 11/Step 1250, Loss: -0.14183, Accuracy: 0.99890, F1: 0.6616, Prec: 0.5251, Rec: 0.3382 lr: 0.00070\n",
      "Epoch 11/Step 1260, Loss: -0.20112, Accuracy: 0.99890, F1: 0.6620, Prec: 0.5251, Rec: 0.3382 lr: 0.00070\n",
      "Epoch 11/Step 1270, Loss: -0.18099, Accuracy: 0.99890, F1: 0.6614, Prec: 0.5252, Rec: 0.3383 lr: 0.00070\n",
      "Epoch 11/Step 1280, Loss: -0.26806, Accuracy: 0.99890, F1: 0.6621, Prec: 0.5253, Rec: 0.3383 lr: 0.00070\n",
      "Epoch 11/Step 1290, Loss: -0.21939, Accuracy: 0.99890, F1: 0.6620, Prec: 0.5254, Rec: 0.3385 lr: 0.00070\n",
      "Epoch 11/Step 1300, Loss: -0.18520, Accuracy: 0.99890, F1: 0.6617, Prec: 0.5252, Rec: 0.3385 lr: 0.00070\n",
      "Epoch 11/Step 1310, Loss: -0.21346, Accuracy: 0.99890, F1: 0.6626, Prec: 0.5254, Rec: 0.3385 lr: 0.00070\n",
      "Epoch 11/Step 1320, Loss: -0.20236, Accuracy: 0.99890, F1: 0.6624, Prec: 0.5250, Rec: 0.3386 lr: 0.00070\n",
      "Epoch 11/Step 1330, Loss: -0.21252, Accuracy: 0.99890, F1: 0.6623, Prec: 0.5250, Rec: 0.3384 lr: 0.00070\n",
      "Epoch 11/Step 1340, Loss: -0.19985, Accuracy: 0.99890, F1: 0.6628, Prec: 0.5252, Rec: 0.3385 lr: 0.00070\n",
      "Epoch 11/Step 1350, Loss: -0.16134, Accuracy: 0.99890, F1: 0.6629, Prec: 0.5250, Rec: 0.3385 lr: 0.00070\n",
      "Epoch 11/Step 1360, Loss: -0.19168, Accuracy: 0.99890, F1: 0.6630, Prec: 0.5253, Rec: 0.3384 lr: 0.00070\n",
      "Epoch 11/Step 1370, Loss: -0.20408, Accuracy: 0.99890, F1: 0.6633, Prec: 0.5253, Rec: 0.3386 lr: 0.00070\n",
      "Epoch 11/Step 1380, Loss: -0.20400, Accuracy: 0.99890, F1: 0.6637, Prec: 0.5253, Rec: 0.3388 lr: 0.00070\n",
      "Epoch 11/Step 1390, Loss: -0.21787, Accuracy: 0.99890, F1: 0.6642, Prec: 0.5255, Rec: 0.3386 lr: 0.00070\n",
      "Epoch 11/Step 1400, Loss: -0.22769, Accuracy: 0.99890, F1: 0.6647, Prec: 0.5257, Rec: 0.3387 lr: 0.00070\n",
      "Epoch 11/Step 1410, Loss: -0.19561, Accuracy: 0.99890, F1: 0.6647, Prec: 0.5257, Rec: 0.3387 lr: 0.00070\n",
      "Epoch 11/Step 1420, Loss: -0.19012, Accuracy: 0.99890, F1: 0.6649, Prec: 0.5257, Rec: 0.3385 lr: 0.00070\n",
      "Epoch 11/Step 1430, Loss: -0.17899, Accuracy: 0.99890, F1: 0.6657, Prec: 0.5259, Rec: 0.3384 lr: 0.00070\n",
      "Epoch 11/Step 1440, Loss: -0.18535, Accuracy: 0.99890, F1: 0.6656, Prec: 0.5258, Rec: 0.3385 lr: 0.00070\n",
      "Epoch 11/Step 1450, Loss: -0.18596, Accuracy: 0.99890, F1: 0.6654, Prec: 0.5261, Rec: 0.3384 lr: 0.00070\n",
      "Epoch 11/Step 1460, Loss: -0.19307, Accuracy: 0.99890, F1: 0.6659, Prec: 0.5260, Rec: 0.3383 lr: 0.00070\n",
      "Epoch 11/Step 1470, Loss: -0.18159, Accuracy: 0.99890, F1: 0.6651, Prec: 0.5262, Rec: 0.3382 lr: 0.00070\n",
      "Epoch 11/Step 1480, Loss: -0.20536, Accuracy: 0.99890, F1: 0.6653, Prec: 0.5262, Rec: 0.3382 lr: 0.00070\n",
      "Epoch 11/Step 1490, Loss: -0.18913, Accuracy: 0.99890, F1: 0.6656, Prec: 0.5259, Rec: 0.3381 lr: 0.00070\n",
      "Epoch 11/Step 1500, Loss: -0.21590, Accuracy: 0.99890, F1: 0.6659, Prec: 0.5260, Rec: 0.3382 lr: 0.00070\n",
      "Epoch 11/Step 1510, Loss: -0.18684, Accuracy: 0.99890, F1: 0.6666, Prec: 0.5262, Rec: 0.3381 lr: 0.00070\n",
      "Epoch 11/Step 1520, Loss: -0.24436, Accuracy: 0.99890, F1: 0.6671, Prec: 0.5264, Rec: 0.3383 lr: 0.00070\n",
      "Epoch 11/Step 1530, Loss: -0.18936, Accuracy: 0.99890, F1: 0.6667, Prec: 0.5266, Rec: 0.3384 lr: 0.00070\n",
      "Epoch 11/Step 1540, Loss: -0.17609, Accuracy: 0.99890, F1: 0.6666, Prec: 0.5266, Rec: 0.3382 lr: 0.00070\n",
      "Epoch 11/Step 1550, Loss: -0.20157, Accuracy: 0.99890, F1: 0.6660, Prec: 0.5268, Rec: 0.3382 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9986\n",
      "Validation f1: 0.4583\n",
      "Validation precision: 0.3316\n",
      "Validation recall: 0.2367\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_10_valF1Score0.458/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_10_valF1Score0.458/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 12\n",
      "Epoch 12/Step 0, Loss: -0.22473, Accuracy: 0.99902, F1: 0.0000, Prec: 0.5717, Rec: 0.3876 lr: 0.00070\n",
      "Epoch 12/Step 10, Loss: -0.23476, Accuracy: 0.99880, F1: 0.5005, Prec: 0.5209, Rec: 0.3686 lr: 0.00070\n",
      "Epoch 12/Step 20, Loss: -0.21854, Accuracy: 0.99888, F1: 0.4904, Prec: 0.5340, Rec: 0.3627 lr: 0.00070\n",
      "Epoch 12/Step 30, Loss: -0.19471, Accuracy: 0.99893, F1: 0.5351, Prec: 0.5469, Rec: 0.3571 lr: 0.00070\n",
      "Epoch 12/Step 40, Loss: -0.18376, Accuracy: 0.99892, F1: 0.5835, Prec: 0.5526, Rec: 0.3576 lr: 0.00070\n",
      "Epoch 12/Step 50, Loss: -0.20835, Accuracy: 0.99893, F1: 0.6135, Prec: 0.5544, Rec: 0.3580 lr: 0.00070\n",
      "Epoch 12/Step 60, Loss: -0.23099, Accuracy: 0.99894, F1: 0.6329, Prec: 0.5564, Rec: 0.3592 lr: 0.00070\n",
      "Epoch 12/Step 70, Loss: -0.20568, Accuracy: 0.99895, F1: 0.6264, Prec: 0.5543, Rec: 0.3600 lr: 0.00070\n",
      "Epoch 12/Step 80, Loss: -0.18291, Accuracy: 0.99895, F1: 0.6262, Prec: 0.5534, Rec: 0.3558 lr: 0.00070\n",
      "Epoch 12/Step 90, Loss: -0.18629, Accuracy: 0.99895, F1: 0.5900, Prec: 0.5558, Rec: 0.3538 lr: 0.00070\n",
      "Epoch 12/Step 100, Loss: -0.21518, Accuracy: 0.99895, F1: 0.5731, Prec: 0.5524, Rec: 0.3564 lr: 0.00070\n",
      "Epoch 12/Step 110, Loss: -0.20963, Accuracy: 0.99894, F1: 0.5525, Prec: 0.5506, Rec: 0.3565 lr: 0.00070\n",
      "Epoch 12/Step 120, Loss: -0.19612, Accuracy: 0.99893, F1: 0.5581, Prec: 0.5509, Rec: 0.3543 lr: 0.00070\n",
      "Epoch 12/Step 130, Loss: -0.16782, Accuracy: 0.99893, F1: 0.5432, Prec: 0.5476, Rec: 0.3555 lr: 0.00070\n",
      "Epoch 12/Step 140, Loss: -0.18635, Accuracy: 0.99892, F1: 0.5216, Prec: 0.5468, Rec: 0.3528 lr: 0.00070\n",
      "Epoch 12/Step 150, Loss: -0.19243, Accuracy: 0.99892, F1: 0.5153, Prec: 0.5470, Rec: 0.3499 lr: 0.00070\n",
      "Epoch 12/Step 160, Loss: -0.21050, Accuracy: 0.99891, F1: 0.5035, Prec: 0.5432, Rec: 0.3507 lr: 0.00070\n",
      "Epoch 12/Step 170, Loss: -0.19513, Accuracy: 0.99891, F1: 0.5070, Prec: 0.5394, Rec: 0.3502 lr: 0.00070\n",
      "Epoch 12/Step 180, Loss: -0.24551, Accuracy: 0.99891, F1: 0.5006, Prec: 0.5408, Rec: 0.3506 lr: 0.00070\n",
      "Epoch 12/Step 190, Loss: -0.19941, Accuracy: 0.99891, F1: 0.5069, Prec: 0.5415, Rec: 0.3498 lr: 0.00070\n",
      "Epoch 12/Step 200, Loss: -0.21745, Accuracy: 0.99890, F1: 0.5029, Prec: 0.5421, Rec: 0.3491 lr: 0.00070\n",
      "Epoch 12/Step 210, Loss: -0.17701, Accuracy: 0.99890, F1: 0.5022, Prec: 0.5404, Rec: 0.3491 lr: 0.00070\n",
      "Epoch 12/Step 220, Loss: -0.22214, Accuracy: 0.99890, F1: 0.5038, Prec: 0.5403, Rec: 0.3489 lr: 0.00070\n",
      "Epoch 12/Step 230, Loss: -0.17752, Accuracy: 0.99890, F1: 0.5116, Prec: 0.5406, Rec: 0.3478 lr: 0.00070\n",
      "Epoch 12/Step 240, Loss: -0.24668, Accuracy: 0.99889, F1: 0.5147, Prec: 0.5399, Rec: 0.3481 lr: 0.00070\n",
      "Epoch 12/Step 250, Loss: -0.22016, Accuracy: 0.99889, F1: 0.5201, Prec: 0.5395, Rec: 0.3476 lr: 0.00070\n",
      "Epoch 12/Step 260, Loss: -0.23702, Accuracy: 0.99889, F1: 0.5261, Prec: 0.5395, Rec: 0.3477 lr: 0.00070\n",
      "Epoch 12/Step 270, Loss: -0.22990, Accuracy: 0.99889, F1: 0.5215, Prec: 0.5377, Rec: 0.3476 lr: 0.00070\n",
      "Epoch 12/Step 280, Loss: -0.21949, Accuracy: 0.99888, F1: 0.5160, Prec: 0.5372, Rec: 0.3467 lr: 0.00070\n",
      "Epoch 12/Step 290, Loss: -0.20320, Accuracy: 0.99889, F1: 0.5125, Prec: 0.5378, Rec: 0.3465 lr: 0.00070\n",
      "Epoch 12/Step 300, Loss: -0.22667, Accuracy: 0.99889, F1: 0.5039, Prec: 0.5390, Rec: 0.3462 lr: 0.00070\n",
      "Epoch 12/Step 310, Loss: -0.22095, Accuracy: 0.99889, F1: 0.5047, Prec: 0.5383, Rec: 0.3466 lr: 0.00070\n",
      "Epoch 12/Step 320, Loss: -0.20353, Accuracy: 0.99889, F1: 0.5008, Prec: 0.5389, Rec: 0.3468 lr: 0.00070\n",
      "Epoch 12/Step 330, Loss: -0.22589, Accuracy: 0.99889, F1: 0.5001, Prec: 0.5400, Rec: 0.3466 lr: 0.00070\n",
      "Epoch 12/Step 340, Loss: -0.20474, Accuracy: 0.99889, F1: 0.5018, Prec: 0.5403, Rec: 0.3464 lr: 0.00070\n",
      "Epoch 12/Step 350, Loss: -0.18317, Accuracy: 0.99889, F1: 0.4979, Prec: 0.5417, Rec: 0.3468 lr: 0.00070\n",
      "Epoch 12/Step 360, Loss: -0.21370, Accuracy: 0.99889, F1: 0.4975, Prec: 0.5424, Rec: 0.3477 lr: 0.00070\n",
      "Epoch 12/Step 370, Loss: -0.21506, Accuracy: 0.99890, F1: 0.4901, Prec: 0.5428, Rec: 0.3476 lr: 0.00070\n",
      "Epoch 12/Step 380, Loss: -0.23651, Accuracy: 0.99890, F1: 0.4875, Prec: 0.5434, Rec: 0.3470 lr: 0.00070\n",
      "Epoch 12/Step 390, Loss: -0.18331, Accuracy: 0.99890, F1: 0.4883, Prec: 0.5438, Rec: 0.3468 lr: 0.00070\n",
      "Epoch 12/Step 400, Loss: -0.16827, Accuracy: 0.99890, F1: 0.4862, Prec: 0.5445, Rec: 0.3463 lr: 0.00070\n",
      "Epoch 12/Step 410, Loss: -0.16784, Accuracy: 0.99890, F1: 0.4831, Prec: 0.5444, Rec: 0.3461 lr: 0.00070\n",
      "Epoch 12/Step 420, Loss: -0.22101, Accuracy: 0.99891, F1: 0.4839, Prec: 0.5439, Rec: 0.3468 lr: 0.00070\n",
      "Epoch 12/Step 430, Loss: -0.19178, Accuracy: 0.99891, F1: 0.4799, Prec: 0.5443, Rec: 0.3466 lr: 0.00070\n",
      "Epoch 12/Step 440, Loss: -0.21760, Accuracy: 0.99890, F1: 0.4797, Prec: 0.5448, Rec: 0.3459 lr: 0.00070\n",
      "Epoch 12/Step 450, Loss: -0.19481, Accuracy: 0.99890, F1: 0.4828, Prec: 0.5432, Rec: 0.3463 lr: 0.00070\n",
      "Epoch 12/Step 460, Loss: -0.20305, Accuracy: 0.99890, F1: 0.4850, Prec: 0.5416, Rec: 0.3465 lr: 0.00070\n",
      "Epoch 12/Step 470, Loss: -0.17817, Accuracy: 0.99891, F1: 0.4836, Prec: 0.5429, Rec: 0.3456 lr: 0.00070\n",
      "Epoch 12/Step 480, Loss: -0.19740, Accuracy: 0.99890, F1: 0.4854, Prec: 0.5426, Rec: 0.3445 lr: 0.00070\n",
      "Epoch 12/Step 490, Loss: -0.19933, Accuracy: 0.99890, F1: 0.4880, Prec: 0.5408, Rec: 0.3448 lr: 0.00070\n",
      "Epoch 12/Step 500, Loss: -0.21204, Accuracy: 0.99890, F1: 0.4919, Prec: 0.5410, Rec: 0.3448 lr: 0.00070\n",
      "Epoch 12/Step 510, Loss: -0.25464, Accuracy: 0.99890, F1: 0.4955, Prec: 0.5411, Rec: 0.3449 lr: 0.00070\n",
      "Epoch 12/Step 520, Loss: -0.19203, Accuracy: 0.99890, F1: 0.4981, Prec: 0.5421, Rec: 0.3450 lr: 0.00070\n",
      "Epoch 12/Step 530, Loss: -0.20410, Accuracy: 0.99890, F1: 0.4985, Prec: 0.5418, Rec: 0.3447 lr: 0.00070\n",
      "Epoch 12/Step 540, Loss: -0.20685, Accuracy: 0.99890, F1: 0.4977, Prec: 0.5417, Rec: 0.3447 lr: 0.00070\n",
      "Epoch 12/Step 550, Loss: -0.24406, Accuracy: 0.99890, F1: 0.4995, Prec: 0.5420, Rec: 0.3448 lr: 0.00070\n",
      "Epoch 12/Step 560, Loss: -0.20145, Accuracy: 0.99890, F1: 0.4975, Prec: 0.5424, Rec: 0.3448 lr: 0.00070\n",
      "Epoch 12/Step 570, Loss: -0.22382, Accuracy: 0.99890, F1: 0.5013, Prec: 0.5421, Rec: 0.3450 lr: 0.00070\n",
      "Epoch 12/Step 580, Loss: -0.18158, Accuracy: 0.99890, F1: 0.5051, Prec: 0.5424, Rec: 0.3447 lr: 0.00070\n",
      "Epoch 12/Step 590, Loss: -0.16440, Accuracy: 0.99890, F1: 0.5057, Prec: 0.5422, Rec: 0.3448 lr: 0.00070\n",
      "Epoch 12/Step 600, Loss: -0.18058, Accuracy: 0.99890, F1: 0.5067, Prec: 0.5428, Rec: 0.3445 lr: 0.00070\n",
      "Epoch 12/Step 610, Loss: -0.25069, Accuracy: 0.99890, F1: 0.5044, Prec: 0.5426, Rec: 0.3448 lr: 0.00070\n",
      "Epoch 12/Step 620, Loss: -0.23069, Accuracy: 0.99890, F1: 0.5078, Prec: 0.5427, Rec: 0.3454 lr: 0.00070\n",
      "Epoch 12/Step 630, Loss: -0.19310, Accuracy: 0.99890, F1: 0.5059, Prec: 0.5428, Rec: 0.3453 lr: 0.00070\n",
      "Epoch 12/Step 640, Loss: -0.19613, Accuracy: 0.99890, F1: 0.5086, Prec: 0.5430, Rec: 0.3452 lr: 0.00070\n",
      "Epoch 12/Step 650, Loss: -0.19516, Accuracy: 0.99890, F1: 0.5101, Prec: 0.5427, Rec: 0.3453 lr: 0.00070\n",
      "Epoch 12/Step 660, Loss: -0.20844, Accuracy: 0.99890, F1: 0.5102, Prec: 0.5431, Rec: 0.3452 lr: 0.00070\n",
      "Epoch 12/Step 670, Loss: -0.18504, Accuracy: 0.99890, F1: 0.5095, Prec: 0.5437, Rec: 0.3450 lr: 0.00070\n",
      "Epoch 12/Step 680, Loss: -0.17524, Accuracy: 0.99890, F1: 0.5112, Prec: 0.5432, Rec: 0.3454 lr: 0.00070\n",
      "Epoch 12/Step 690, Loss: -0.22363, Accuracy: 0.99890, F1: 0.5093, Prec: 0.5429, Rec: 0.3453 lr: 0.00070\n",
      "Epoch 12/Step 700, Loss: -0.21365, Accuracy: 0.99890, F1: 0.5089, Prec: 0.5431, Rec: 0.3451 lr: 0.00070\n",
      "Epoch 12/Step 710, Loss: -0.22653, Accuracy: 0.99890, F1: 0.5075, Prec: 0.5436, Rec: 0.3455 lr: 0.00070\n",
      "Epoch 12/Step 720, Loss: -0.23742, Accuracy: 0.99891, F1: 0.5086, Prec: 0.5438, Rec: 0.3453 lr: 0.00070\n",
      "Epoch 12/Step 730, Loss: -0.19543, Accuracy: 0.99891, F1: 0.5084, Prec: 0.5440, Rec: 0.3451 lr: 0.00070\n",
      "Epoch 12/Step 740, Loss: -0.21182, Accuracy: 0.99891, F1: 0.5069, Prec: 0.5443, Rec: 0.3449 lr: 0.00070\n",
      "Epoch 12/Step 750, Loss: -0.20202, Accuracy: 0.99891, F1: 0.5068, Prec: 0.5437, Rec: 0.3450 lr: 0.00070\n",
      "Epoch 12/Step 760, Loss: -0.21102, Accuracy: 0.99891, F1: 0.5079, Prec: 0.5436, Rec: 0.3448 lr: 0.00070\n",
      "Epoch 12/Step 770, Loss: -0.22863, Accuracy: 0.99891, F1: 0.5092, Prec: 0.5437, Rec: 0.3449 lr: 0.00070\n",
      "Epoch 12/Step 780, Loss: -0.18188, Accuracy: 0.99891, F1: 0.5081, Prec: 0.5442, Rec: 0.3450 lr: 0.00070\n",
      "Epoch 12/Step 790, Loss: -0.22795, Accuracy: 0.99891, F1: 0.5068, Prec: 0.5437, Rec: 0.3448 lr: 0.00070\n",
      "Epoch 12/Step 800, Loss: -0.19770, Accuracy: 0.99891, F1: 0.5042, Prec: 0.5439, Rec: 0.3445 lr: 0.00070\n",
      "Epoch 12/Step 810, Loss: -0.15381, Accuracy: 0.99891, F1: 0.5046, Prec: 0.5436, Rec: 0.3447 lr: 0.00070\n",
      "Epoch 12/Step 820, Loss: -0.20949, Accuracy: 0.99891, F1: 0.5066, Prec: 0.5434, Rec: 0.3446 lr: 0.00070\n",
      "Epoch 12/Step 830, Loss: -0.21713, Accuracy: 0.99891, F1: 0.5091, Prec: 0.5439, Rec: 0.3446 lr: 0.00070\n",
      "Epoch 12/Step 840, Loss: -0.24027, Accuracy: 0.99891, F1: 0.5100, Prec: 0.5439, Rec: 0.3448 lr: 0.00070\n",
      "Epoch 12/Step 850, Loss: -0.20823, Accuracy: 0.99891, F1: 0.5112, Prec: 0.5434, Rec: 0.3447 lr: 0.00070\n",
      "Epoch 12/Step 860, Loss: -0.21824, Accuracy: 0.99891, F1: 0.5106, Prec: 0.5436, Rec: 0.3446 lr: 0.00070\n",
      "Epoch 12/Step 870, Loss: -0.20634, Accuracy: 0.99891, F1: 0.5099, Prec: 0.5434, Rec: 0.3443 lr: 0.00070\n",
      "Epoch 12/Step 880, Loss: -0.19147, Accuracy: 0.99891, F1: 0.5104, Prec: 0.5433, Rec: 0.3444 lr: 0.00070\n",
      "Epoch 12/Step 890, Loss: -0.20076, Accuracy: 0.99891, F1: 0.5117, Prec: 0.5427, Rec: 0.3443 lr: 0.00070\n",
      "Epoch 12/Step 900, Loss: -0.25646, Accuracy: 0.99891, F1: 0.5132, Prec: 0.5431, Rec: 0.3445 lr: 0.00070\n",
      "Epoch 12/Step 910, Loss: -0.18480, Accuracy: 0.99891, F1: 0.5148, Prec: 0.5433, Rec: 0.3443 lr: 0.00070\n",
      "Epoch 12/Step 920, Loss: -0.20543, Accuracy: 0.99891, F1: 0.5154, Prec: 0.5434, Rec: 0.3440 lr: 0.00070\n",
      "Epoch 12/Step 930, Loss: -0.20081, Accuracy: 0.99891, F1: 0.5152, Prec: 0.5433, Rec: 0.3442 lr: 0.00070\n",
      "Epoch 12/Step 940, Loss: -0.20730, Accuracy: 0.99891, F1: 0.5153, Prec: 0.5427, Rec: 0.3443 lr: 0.00070\n",
      "Epoch 12/Step 950, Loss: -0.23168, Accuracy: 0.99891, F1: 0.5139, Prec: 0.5433, Rec: 0.3442 lr: 0.00070\n",
      "Epoch 12/Step 960, Loss: -0.23983, Accuracy: 0.99891, F1: 0.5163, Prec: 0.5429, Rec: 0.3443 lr: 0.00070\n",
      "Epoch 12/Step 970, Loss: -0.18059, Accuracy: 0.99891, F1: 0.5178, Prec: 0.5425, Rec: 0.3440 lr: 0.00070\n",
      "Epoch 12/Step 980, Loss: -0.21849, Accuracy: 0.99891, F1: 0.5179, Prec: 0.5426, Rec: 0.3436 lr: 0.00070\n",
      "Epoch 12/Step 990, Loss: -0.20734, Accuracy: 0.99891, F1: 0.5193, Prec: 0.5423, Rec: 0.3436 lr: 0.00070\n",
      "Epoch 12/Step 1000, Loss: -0.21921, Accuracy: 0.99891, F1: 0.5206, Prec: 0.5421, Rec: 0.3439 lr: 0.00070\n",
      "Epoch 12/Step 1010, Loss: -0.22487, Accuracy: 0.99891, F1: 0.5223, Prec: 0.5423, Rec: 0.3442 lr: 0.00070\n",
      "Epoch 12/Step 1020, Loss: -0.17251, Accuracy: 0.99891, F1: 0.5203, Prec: 0.5422, Rec: 0.3440 lr: 0.00070\n",
      "Epoch 12/Step 1030, Loss: -0.21349, Accuracy: 0.99891, F1: 0.5183, Prec: 0.5422, Rec: 0.3440 lr: 0.00070\n",
      "Epoch 12/Step 1040, Loss: -0.20684, Accuracy: 0.99891, F1: 0.5156, Prec: 0.5425, Rec: 0.3439 lr: 0.00070\n",
      "Epoch 12/Step 1050, Loss: -0.23327, Accuracy: 0.99891, F1: 0.5150, Prec: 0.5425, Rec: 0.3440 lr: 0.00070\n",
      "Epoch 12/Step 1060, Loss: -0.21738, Accuracy: 0.99891, F1: 0.5161, Prec: 0.5423, Rec: 0.3442 lr: 0.00070\n",
      "Epoch 12/Step 1070, Loss: -0.21000, Accuracy: 0.99892, F1: 0.5175, Prec: 0.5426, Rec: 0.3441 lr: 0.00070\n",
      "Epoch 12/Step 1080, Loss: -0.18478, Accuracy: 0.99892, F1: 0.5177, Prec: 0.5425, Rec: 0.3440 lr: 0.00070\n",
      "Epoch 12/Step 1090, Loss: -0.21191, Accuracy: 0.99892, F1: 0.5173, Prec: 0.5422, Rec: 0.3439 lr: 0.00070\n",
      "Epoch 12/Step 1100, Loss: -0.20209, Accuracy: 0.99891, F1: 0.5147, Prec: 0.5421, Rec: 0.3439 lr: 0.00070\n",
      "Epoch 12/Step 1110, Loss: -0.17336, Accuracy: 0.99891, F1: 0.5159, Prec: 0.5416, Rec: 0.3440 lr: 0.00070\n",
      "Epoch 12/Step 1120, Loss: -0.18398, Accuracy: 0.99891, F1: 0.5151, Prec: 0.5415, Rec: 0.3440 lr: 0.00070\n",
      "Epoch 12/Step 1130, Loss: -0.19011, Accuracy: 0.99892, F1: 0.5150, Prec: 0.5416, Rec: 0.3442 lr: 0.00070\n",
      "Epoch 12/Step 1140, Loss: -0.20245, Accuracy: 0.99892, F1: 0.5173, Prec: 0.5418, Rec: 0.3443 lr: 0.00070\n",
      "Epoch 12/Step 1150, Loss: -0.23893, Accuracy: 0.99892, F1: 0.5176, Prec: 0.5421, Rec: 0.3444 lr: 0.00070\n",
      "Epoch 12/Step 1160, Loss: -0.17408, Accuracy: 0.99892, F1: 0.5179, Prec: 0.5425, Rec: 0.3446 lr: 0.00070\n",
      "Epoch 12/Step 1170, Loss: -0.18857, Accuracy: 0.99892, F1: 0.5197, Prec: 0.5425, Rec: 0.3445 lr: 0.00070\n",
      "Epoch 12/Step 1180, Loss: -0.17928, Accuracy: 0.99892, F1: 0.5211, Prec: 0.5423, Rec: 0.3446 lr: 0.00070\n",
      "Epoch 12/Step 1190, Loss: -0.21232, Accuracy: 0.99892, F1: 0.5213, Prec: 0.5424, Rec: 0.3443 lr: 0.00070\n",
      "Epoch 12/Step 1200, Loss: -0.19852, Accuracy: 0.99892, F1: 0.5213, Prec: 0.5425, Rec: 0.3446 lr: 0.00070\n",
      "Epoch 12/Step 1210, Loss: -0.22337, Accuracy: 0.99892, F1: 0.5229, Prec: 0.5424, Rec: 0.3448 lr: 0.00070\n",
      "Epoch 12/Step 1220, Loss: -0.22385, Accuracy: 0.99892, F1: 0.5222, Prec: 0.5426, Rec: 0.3449 lr: 0.00070\n",
      "Epoch 12/Step 1230, Loss: -0.21655, Accuracy: 0.99892, F1: 0.5240, Prec: 0.5427, Rec: 0.3449 lr: 0.00070\n",
      "Epoch 12/Step 1240, Loss: -0.25344, Accuracy: 0.99892, F1: 0.5260, Prec: 0.5426, Rec: 0.3448 lr: 0.00070\n",
      "Epoch 12/Step 1250, Loss: -0.14508, Accuracy: 0.99892, F1: 0.5277, Prec: 0.5426, Rec: 0.3448 lr: 0.00070\n",
      "Epoch 12/Step 1260, Loss: -0.20748, Accuracy: 0.99892, F1: 0.5289, Prec: 0.5427, Rec: 0.3449 lr: 0.00070\n",
      "Epoch 12/Step 1270, Loss: -0.18786, Accuracy: 0.99892, F1: 0.5291, Prec: 0.5426, Rec: 0.3450 lr: 0.00070\n",
      "Epoch 12/Step 1280, Loss: -0.27065, Accuracy: 0.99892, F1: 0.5295, Prec: 0.5429, Rec: 0.3449 lr: 0.00070\n",
      "Epoch 12/Step 1290, Loss: -0.22611, Accuracy: 0.99892, F1: 0.5299, Prec: 0.5430, Rec: 0.3451 lr: 0.00070\n",
      "Epoch 12/Step 1300, Loss: -0.19789, Accuracy: 0.99892, F1: 0.5305, Prec: 0.5428, Rec: 0.3451 lr: 0.00070\n",
      "Epoch 12/Step 1310, Loss: -0.21591, Accuracy: 0.99892, F1: 0.5324, Prec: 0.5431, Rec: 0.3451 lr: 0.00070\n",
      "Epoch 12/Step 1320, Loss: -0.21206, Accuracy: 0.99892, F1: 0.5329, Prec: 0.5428, Rec: 0.3452 lr: 0.00070\n",
      "Epoch 12/Step 1330, Loss: -0.22458, Accuracy: 0.99892, F1: 0.5330, Prec: 0.5428, Rec: 0.3450 lr: 0.00070\n",
      "Epoch 12/Step 1340, Loss: -0.21257, Accuracy: 0.99892, F1: 0.5330, Prec: 0.5432, Rec: 0.3452 lr: 0.00070\n",
      "Epoch 12/Step 1350, Loss: -0.16775, Accuracy: 0.99892, F1: 0.5339, Prec: 0.5431, Rec: 0.3451 lr: 0.00070\n",
      "Epoch 12/Step 1360, Loss: -0.19740, Accuracy: 0.99892, F1: 0.5334, Prec: 0.5431, Rec: 0.3451 lr: 0.00070\n",
      "Epoch 12/Step 1370, Loss: -0.21363, Accuracy: 0.99892, F1: 0.5338, Prec: 0.5432, Rec: 0.3453 lr: 0.00070\n",
      "Epoch 12/Step 1380, Loss: -0.20358, Accuracy: 0.99892, F1: 0.5332, Prec: 0.5432, Rec: 0.3454 lr: 0.00070\n",
      "Epoch 12/Step 1390, Loss: -0.21869, Accuracy: 0.99892, F1: 0.5340, Prec: 0.5433, Rec: 0.3453 lr: 0.00070\n",
      "Epoch 12/Step 1400, Loss: -0.23030, Accuracy: 0.99893, F1: 0.5353, Prec: 0.5435, Rec: 0.3454 lr: 0.00070\n",
      "Epoch 12/Step 1410, Loss: -0.19483, Accuracy: 0.99893, F1: 0.5360, Prec: 0.5434, Rec: 0.3454 lr: 0.00070\n",
      "Epoch 12/Step 1420, Loss: -0.20134, Accuracy: 0.99893, F1: 0.5369, Prec: 0.5433, Rec: 0.3453 lr: 0.00070\n",
      "Epoch 12/Step 1430, Loss: -0.17723, Accuracy: 0.99893, F1: 0.5388, Prec: 0.5437, Rec: 0.3450 lr: 0.00070\n",
      "Epoch 12/Step 1440, Loss: -0.18834, Accuracy: 0.99893, F1: 0.5380, Prec: 0.5434, Rec: 0.3452 lr: 0.00070\n",
      "Epoch 12/Step 1450, Loss: -0.18676, Accuracy: 0.99893, F1: 0.5375, Prec: 0.5437, Rec: 0.3451 lr: 0.00070\n",
      "Epoch 12/Step 1460, Loss: -0.19591, Accuracy: 0.99893, F1: 0.5378, Prec: 0.5437, Rec: 0.3450 lr: 0.00070\n",
      "Epoch 12/Step 1470, Loss: -0.18567, Accuracy: 0.99893, F1: 0.5368, Prec: 0.5438, Rec: 0.3450 lr: 0.00070\n",
      "Epoch 12/Step 1480, Loss: -0.20472, Accuracy: 0.99893, F1: 0.5352, Prec: 0.5439, Rec: 0.3448 lr: 0.00070\n",
      "Epoch 12/Step 1490, Loss: -0.18648, Accuracy: 0.99893, F1: 0.5360, Prec: 0.5435, Rec: 0.3447 lr: 0.00070\n",
      "Epoch 12/Step 1500, Loss: -0.22424, Accuracy: 0.99893, F1: 0.5373, Prec: 0.5434, Rec: 0.3449 lr: 0.00070\n",
      "Epoch 12/Step 1510, Loss: -0.19060, Accuracy: 0.99893, F1: 0.5382, Prec: 0.5438, Rec: 0.3448 lr: 0.00070\n",
      "Epoch 12/Step 1520, Loss: -0.24832, Accuracy: 0.99893, F1: 0.5387, Prec: 0.5440, Rec: 0.3449 lr: 0.00070\n",
      "Epoch 12/Step 1530, Loss: -0.19776, Accuracy: 0.99893, F1: 0.5397, Prec: 0.5441, Rec: 0.3451 lr: 0.00070\n",
      "Epoch 12/Step 1540, Loss: -0.18627, Accuracy: 0.99893, F1: 0.5392, Prec: 0.5441, Rec: 0.3448 lr: 0.00070\n",
      "Epoch 12/Step 1550, Loss: -0.21350, Accuracy: 0.99893, F1: 0.5383, Prec: 0.5443, Rec: 0.3448 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9986\n",
      "Validation f1: 0.2839\n",
      "Validation precision: 0.3441\n",
      "Validation recall: 0.2284\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_11_valF1Score0.284/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_11_valF1Score0.284/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 13\n",
      "Epoch 13/Step 0, Loss: -0.22203, Accuracy: 0.99901, F1: 0.0000, Prec: 0.5653, Rec: 0.3801 lr: 0.00070\n",
      "Epoch 13/Step 10, Loss: -0.24607, Accuracy: 0.99884, F1: 0.3230, Prec: 0.5460, Rec: 0.3724 lr: 0.00070\n",
      "Epoch 13/Step 20, Loss: -0.21956, Accuracy: 0.99889, F1: 0.3617, Prec: 0.5452, Rec: 0.3665 lr: 0.00070\n",
      "Epoch 13/Step 30, Loss: -0.19471, Accuracy: 0.99894, F1: 0.2757, Prec: 0.5540, Rec: 0.3619 lr: 0.00070\n",
      "Epoch 13/Step 40, Loss: -0.19237, Accuracy: 0.99894, F1: 0.2922, Prec: 0.5679, Rec: 0.3604 lr: 0.00070\n",
      "Epoch 13/Step 50, Loss: -0.22358, Accuracy: 0.99895, F1: 0.3301, Prec: 0.5700, Rec: 0.3633 lr: 0.00070\n",
      "Epoch 13/Step 60, Loss: -0.23572, Accuracy: 0.99896, F1: 0.3617, Prec: 0.5750, Rec: 0.3645 lr: 0.00070\n",
      "Epoch 13/Step 70, Loss: -0.21100, Accuracy: 0.99898, F1: 0.3451, Prec: 0.5762, Rec: 0.3646 lr: 0.00070\n",
      "Epoch 13/Step 80, Loss: -0.19094, Accuracy: 0.99898, F1: 0.3610, Prec: 0.5717, Rec: 0.3612 lr: 0.00070\n",
      "Epoch 13/Step 90, Loss: -0.19545, Accuracy: 0.99898, F1: 0.3448, Prec: 0.5729, Rec: 0.3603 lr: 0.00070\n",
      "Epoch 13/Step 100, Loss: -0.22298, Accuracy: 0.99898, F1: 0.3566, Prec: 0.5730, Rec: 0.3615 lr: 0.00070\n",
      "Epoch 13/Step 110, Loss: -0.20974, Accuracy: 0.99897, F1: 0.3425, Prec: 0.5704, Rec: 0.3617 lr: 0.00070\n",
      "Epoch 13/Step 120, Loss: -0.20616, Accuracy: 0.99896, F1: 0.3464, Prec: 0.5721, Rec: 0.3598 lr: 0.00070\n",
      "Epoch 13/Step 130, Loss: -0.16813, Accuracy: 0.99896, F1: 0.3452, Prec: 0.5695, Rec: 0.3599 lr: 0.00070\n",
      "Epoch 13/Step 140, Loss: -0.18955, Accuracy: 0.99895, F1: 0.3368, Prec: 0.5654, Rec: 0.3574 lr: 0.00070\n",
      "Epoch 13/Step 150, Loss: -0.18293, Accuracy: 0.99894, F1: 0.3202, Prec: 0.5655, Rec: 0.3541 lr: 0.00070\n",
      "Epoch 13/Step 160, Loss: -0.21968, Accuracy: 0.99894, F1: 0.3181, Prec: 0.5631, Rec: 0.3544 lr: 0.00070\n",
      "Epoch 13/Step 170, Loss: -0.19783, Accuracy: 0.99894, F1: 0.3233, Prec: 0.5580, Rec: 0.3542 lr: 0.00070\n",
      "Epoch 13/Step 180, Loss: -0.24824, Accuracy: 0.99894, F1: 0.3231, Prec: 0.5584, Rec: 0.3551 lr: 0.00070\n",
      "Epoch 13/Step 190, Loss: -0.20552, Accuracy: 0.99894, F1: 0.3225, Prec: 0.5593, Rec: 0.3536 lr: 0.00070\n",
      "Epoch 13/Step 200, Loss: -0.22472, Accuracy: 0.99893, F1: 0.3223, Prec: 0.5600, Rec: 0.3532 lr: 0.00070\n",
      "Epoch 13/Step 210, Loss: -0.19159, Accuracy: 0.99893, F1: 0.3279, Prec: 0.5578, Rec: 0.3531 lr: 0.00070\n",
      "Epoch 13/Step 220, Loss: -0.23259, Accuracy: 0.99893, F1: 0.3306, Prec: 0.5578, Rec: 0.3531 lr: 0.00070\n",
      "Epoch 13/Step 230, Loss: -0.19129, Accuracy: 0.99892, F1: 0.3379, Prec: 0.5586, Rec: 0.3520 lr: 0.00070\n",
      "Epoch 13/Step 240, Loss: -0.25262, Accuracy: 0.99892, F1: 0.3416, Prec: 0.5589, Rec: 0.3519 lr: 0.00070\n",
      "Epoch 13/Step 250, Loss: -0.22155, Accuracy: 0.99892, F1: 0.3540, Prec: 0.5574, Rec: 0.3519 lr: 0.00070\n",
      "Epoch 13/Step 260, Loss: -0.23639, Accuracy: 0.99892, F1: 0.3630, Prec: 0.5570, Rec: 0.3520 lr: 0.00070\n",
      "Epoch 13/Step 270, Loss: -0.24051, Accuracy: 0.99891, F1: 0.3588, Prec: 0.5561, Rec: 0.3517 lr: 0.00070\n",
      "Epoch 13/Step 280, Loss: -0.21848, Accuracy: 0.99891, F1: 0.3550, Prec: 0.5556, Rec: 0.3508 lr: 0.00070\n",
      "Epoch 13/Step 290, Loss: -0.21038, Accuracy: 0.99891, F1: 0.3473, Prec: 0.5566, Rec: 0.3506 lr: 0.00070\n",
      "Epoch 13/Step 300, Loss: -0.23670, Accuracy: 0.99892, F1: 0.3384, Prec: 0.5580, Rec: 0.3505 lr: 0.00070\n",
      "Epoch 13/Step 310, Loss: -0.22328, Accuracy: 0.99892, F1: 0.3401, Prec: 0.5574, Rec: 0.3508 lr: 0.00070\n",
      "Epoch 13/Step 320, Loss: -0.20344, Accuracy: 0.99892, F1: 0.3342, Prec: 0.5577, Rec: 0.3511 lr: 0.00070\n",
      "Epoch 13/Step 330, Loss: -0.22686, Accuracy: 0.99892, F1: 0.3341, Prec: 0.5588, Rec: 0.3510 lr: 0.00070\n",
      "Epoch 13/Step 340, Loss: -0.21378, Accuracy: 0.99892, F1: 0.3391, Prec: 0.5592, Rec: 0.3508 lr: 0.00070\n",
      "Epoch 13/Step 350, Loss: -0.18374, Accuracy: 0.99892, F1: 0.3337, Prec: 0.5602, Rec: 0.3513 lr: 0.00070\n",
      "Epoch 13/Step 360, Loss: -0.22051, Accuracy: 0.99892, F1: 0.3318, Prec: 0.5610, Rec: 0.3521 lr: 0.00070\n",
      "Epoch 13/Step 370, Loss: -0.22553, Accuracy: 0.99892, F1: 0.3270, Prec: 0.5608, Rec: 0.3523 lr: 0.00070\n",
      "Epoch 13/Step 380, Loss: -0.23997, Accuracy: 0.99893, F1: 0.3249, Prec: 0.5609, Rec: 0.3519 lr: 0.00070\n",
      "Epoch 13/Step 390, Loss: -0.18804, Accuracy: 0.99893, F1: 0.3228, Prec: 0.5614, Rec: 0.3516 lr: 0.00070\n",
      "Epoch 13/Step 400, Loss: -0.17377, Accuracy: 0.99893, F1: 0.3191, Prec: 0.5621, Rec: 0.3511 lr: 0.00070\n",
      "Epoch 13/Step 410, Loss: -0.17268, Accuracy: 0.99893, F1: 0.3133, Prec: 0.5624, Rec: 0.3508 lr: 0.00070\n",
      "Epoch 13/Step 420, Loss: -0.21227, Accuracy: 0.99893, F1: 0.3093, Prec: 0.5616, Rec: 0.3513 lr: 0.00070\n",
      "Epoch 13/Step 430, Loss: -0.19997, Accuracy: 0.99893, F1: 0.3041, Prec: 0.5608, Rec: 0.3517 lr: 0.00070\n",
      "Epoch 13/Step 440, Loss: -0.22182, Accuracy: 0.99893, F1: 0.3014, Prec: 0.5619, Rec: 0.3510 lr: 0.00070\n",
      "Epoch 13/Step 450, Loss: -0.21499, Accuracy: 0.99893, F1: 0.3048, Prec: 0.5609, Rec: 0.3513 lr: 0.00070\n",
      "Epoch 13/Step 460, Loss: -0.19820, Accuracy: 0.99893, F1: 0.3072, Prec: 0.5587, Rec: 0.3516 lr: 0.00070\n",
      "Epoch 13/Step 470, Loss: -0.20118, Accuracy: 0.99893, F1: 0.3084, Prec: 0.5597, Rec: 0.3510 lr: 0.00070\n",
      "Epoch 13/Step 480, Loss: -0.18993, Accuracy: 0.99893, F1: 0.3121, Prec: 0.5598, Rec: 0.3496 lr: 0.00070\n",
      "Epoch 13/Step 490, Loss: -0.20111, Accuracy: 0.99892, F1: 0.3126, Prec: 0.5584, Rec: 0.3498 lr: 0.00070\n",
      "Epoch 13/Step 500, Loss: -0.21236, Accuracy: 0.99892, F1: 0.3140, Prec: 0.5576, Rec: 0.3500 lr: 0.00070\n",
      "Epoch 13/Step 510, Loss: -0.26394, Accuracy: 0.99893, F1: 0.3136, Prec: 0.5579, Rec: 0.3501 lr: 0.00070\n",
      "Epoch 13/Step 520, Loss: -0.19397, Accuracy: 0.99893, F1: 0.3151, Prec: 0.5589, Rec: 0.3501 lr: 0.00070\n",
      "Epoch 13/Step 530, Loss: -0.20457, Accuracy: 0.99893, F1: 0.3150, Prec: 0.5585, Rec: 0.3498 lr: 0.00070\n",
      "Epoch 13/Step 540, Loss: -0.21372, Accuracy: 0.99893, F1: 0.3155, Prec: 0.5587, Rec: 0.3498 lr: 0.00070\n",
      "Epoch 13/Step 550, Loss: -0.24626, Accuracy: 0.99892, F1: 0.3196, Prec: 0.5588, Rec: 0.3499 lr: 0.00070\n",
      "Epoch 13/Step 560, Loss: -0.20890, Accuracy: 0.99892, F1: 0.3178, Prec: 0.5588, Rec: 0.3500 lr: 0.00070\n",
      "Epoch 13/Step 570, Loss: -0.21562, Accuracy: 0.99893, F1: 0.3177, Prec: 0.5591, Rec: 0.3501 lr: 0.00070\n",
      "Epoch 13/Step 580, Loss: -0.18346, Accuracy: 0.99892, F1: 0.3224, Prec: 0.5589, Rec: 0.3499 lr: 0.00070\n",
      "Epoch 13/Step 590, Loss: -0.16712, Accuracy: 0.99892, F1: 0.3235, Prec: 0.5589, Rec: 0.3498 lr: 0.00070\n",
      "Epoch 13/Step 600, Loss: -0.19712, Accuracy: 0.99892, F1: 0.3252, Prec: 0.5597, Rec: 0.3496 lr: 0.00070\n",
      "Epoch 13/Step 610, Loss: -0.26374, Accuracy: 0.99892, F1: 0.3236, Prec: 0.5595, Rec: 0.3498 lr: 0.00070\n",
      "Epoch 13/Step 620, Loss: -0.22861, Accuracy: 0.99892, F1: 0.3268, Prec: 0.5595, Rec: 0.3502 lr: 0.00070\n",
      "Epoch 13/Step 630, Loss: -0.20448, Accuracy: 0.99892, F1: 0.3269, Prec: 0.5597, Rec: 0.3501 lr: 0.00070\n",
      "Epoch 13/Step 640, Loss: -0.19713, Accuracy: 0.99892, F1: 0.3306, Prec: 0.5600, Rec: 0.3500 lr: 0.00070\n",
      "Epoch 13/Step 650, Loss: -0.19735, Accuracy: 0.99892, F1: 0.3329, Prec: 0.5601, Rec: 0.3501 lr: 0.00070\n",
      "Epoch 13/Step 660, Loss: -0.22780, Accuracy: 0.99892, F1: 0.3332, Prec: 0.5602, Rec: 0.3501 lr: 0.00070\n",
      "Epoch 13/Step 670, Loss: -0.19598, Accuracy: 0.99893, F1: 0.3360, Prec: 0.5608, Rec: 0.3501 lr: 0.00070\n",
      "Epoch 13/Step 680, Loss: -0.17645, Accuracy: 0.99893, F1: 0.3355, Prec: 0.5610, Rec: 0.3502 lr: 0.00070\n",
      "Epoch 13/Step 690, Loss: -0.23678, Accuracy: 0.99893, F1: 0.3349, Prec: 0.5603, Rec: 0.3503 lr: 0.00070\n",
      "Epoch 13/Step 700, Loss: -0.21754, Accuracy: 0.99893, F1: 0.3347, Prec: 0.5605, Rec: 0.3501 lr: 0.00070\n",
      "Epoch 13/Step 710, Loss: -0.22253, Accuracy: 0.99893, F1: 0.3313, Prec: 0.5610, Rec: 0.3504 lr: 0.00070\n",
      "Epoch 13/Step 720, Loss: -0.23942, Accuracy: 0.99893, F1: 0.3299, Prec: 0.5608, Rec: 0.3503 lr: 0.00070\n",
      "Epoch 13/Step 730, Loss: -0.19778, Accuracy: 0.99893, F1: 0.3275, Prec: 0.5610, Rec: 0.3501 lr: 0.00070\n",
      "Epoch 13/Step 740, Loss: -0.21576, Accuracy: 0.99893, F1: 0.3288, Prec: 0.5613, Rec: 0.3500 lr: 0.00070\n",
      "Epoch 13/Step 750, Loss: -0.21150, Accuracy: 0.99893, F1: 0.3277, Prec: 0.5612, Rec: 0.3499 lr: 0.00070\n",
      "Epoch 13/Step 760, Loss: -0.21631, Accuracy: 0.99893, F1: 0.3263, Prec: 0.5606, Rec: 0.3499 lr: 0.00070\n",
      "Epoch 13/Step 770, Loss: -0.22719, Accuracy: 0.99893, F1: 0.3240, Prec: 0.5604, Rec: 0.3500 lr: 0.00070\n",
      "Epoch 13/Step 780, Loss: -0.18486, Accuracy: 0.99893, F1: 0.3232, Prec: 0.5612, Rec: 0.3501 lr: 0.00070\n",
      "Epoch 13/Step 790, Loss: -0.23303, Accuracy: 0.99893, F1: 0.3210, Prec: 0.5604, Rec: 0.3500 lr: 0.00070\n",
      "Epoch 13/Step 800, Loss: -0.20337, Accuracy: 0.99893, F1: 0.3180, Prec: 0.5602, Rec: 0.3500 lr: 0.00070\n",
      "Epoch 13/Step 810, Loss: -0.16439, Accuracy: 0.99893, F1: 0.3149, Prec: 0.5602, Rec: 0.3500 lr: 0.00070\n",
      "Epoch 13/Step 820, Loss: -0.22005, Accuracy: 0.99893, F1: 0.3127, Prec: 0.5600, Rec: 0.3500 lr: 0.00070\n",
      "Epoch 13/Step 830, Loss: -0.22617, Accuracy: 0.99893, F1: 0.3100, Prec: 0.5606, Rec: 0.3499 lr: 0.00070\n",
      "Epoch 13/Step 840, Loss: -0.23970, Accuracy: 0.99893, F1: 0.3109, Prec: 0.5611, Rec: 0.3500 lr: 0.00070\n",
      "Epoch 13/Step 850, Loss: -0.20765, Accuracy: 0.99893, F1: 0.3107, Prec: 0.5605, Rec: 0.3499 lr: 0.00070\n",
      "Epoch 13/Step 860, Loss: -0.22629, Accuracy: 0.99893, F1: 0.3110, Prec: 0.5605, Rec: 0.3500 lr: 0.00070\n",
      "Epoch 13/Step 870, Loss: -0.21378, Accuracy: 0.99893, F1: 0.3101, Prec: 0.5603, Rec: 0.3497 lr: 0.00070\n",
      "Epoch 13/Step 880, Loss: -0.19005, Accuracy: 0.99893, F1: 0.3093, Prec: 0.5603, Rec: 0.3498 lr: 0.00070\n",
      "Epoch 13/Step 890, Loss: -0.20502, Accuracy: 0.99893, F1: 0.3101, Prec: 0.5598, Rec: 0.3497 lr: 0.00070\n",
      "Epoch 13/Step 900, Loss: -0.26088, Accuracy: 0.99893, F1: 0.3131, Prec: 0.5599, Rec: 0.3499 lr: 0.00070\n",
      "Epoch 13/Step 910, Loss: -0.18335, Accuracy: 0.99893, F1: 0.3115, Prec: 0.5603, Rec: 0.3497 lr: 0.00070\n",
      "Epoch 13/Step 920, Loss: -0.21081, Accuracy: 0.99893, F1: 0.3120, Prec: 0.5604, Rec: 0.3494 lr: 0.00070\n",
      "Epoch 13/Step 930, Loss: -0.20807, Accuracy: 0.99893, F1: 0.3126, Prec: 0.5604, Rec: 0.3496 lr: 0.00070\n",
      "Epoch 13/Step 940, Loss: -0.20680, Accuracy: 0.99893, F1: 0.3139, Prec: 0.5599, Rec: 0.3497 lr: 0.00070\n",
      "Epoch 13/Step 950, Loss: -0.24042, Accuracy: 0.99893, F1: 0.3140, Prec: 0.5601, Rec: 0.3498 lr: 0.00070\n",
      "Epoch 13/Step 960, Loss: -0.23910, Accuracy: 0.99894, F1: 0.3192, Prec: 0.5602, Rec: 0.3496 lr: 0.00070\n",
      "Epoch 13/Step 970, Loss: -0.18099, Accuracy: 0.99893, F1: 0.3233, Prec: 0.5595, Rec: 0.3494 lr: 0.00070\n",
      "Epoch 13/Step 980, Loss: -0.21988, Accuracy: 0.99893, F1: 0.3254, Prec: 0.5593, Rec: 0.3491 lr: 0.00070\n",
      "Epoch 13/Step 990, Loss: -0.20433, Accuracy: 0.99893, F1: 0.3276, Prec: 0.5591, Rec: 0.3489 lr: 0.00070\n",
      "Epoch 13/Step 1000, Loss: -0.22374, Accuracy: 0.99894, F1: 0.3313, Prec: 0.5592, Rec: 0.3491 lr: 0.00070\n",
      "Epoch 13/Step 1010, Loss: -0.22987, Accuracy: 0.99894, F1: 0.3357, Prec: 0.5594, Rec: 0.3494 lr: 0.00070\n",
      "Epoch 13/Step 1020, Loss: -0.17083, Accuracy: 0.99894, F1: 0.3371, Prec: 0.5592, Rec: 0.3493 lr: 0.00070\n",
      "Epoch 13/Step 1030, Loss: -0.21809, Accuracy: 0.99894, F1: 0.3386, Prec: 0.5591, Rec: 0.3492 lr: 0.00070\n",
      "Epoch 13/Step 1040, Loss: -0.21685, Accuracy: 0.99894, F1: 0.3412, Prec: 0.5591, Rec: 0.3492 lr: 0.00070\n",
      "Epoch 13/Step 1050, Loss: -0.25130, Accuracy: 0.99894, F1: 0.3433, Prec: 0.5594, Rec: 0.3492 lr: 0.00070\n",
      "Epoch 13/Step 1060, Loss: -0.21761, Accuracy: 0.99894, F1: 0.3465, Prec: 0.5592, Rec: 0.3495 lr: 0.00070\n",
      "Epoch 13/Step 1070, Loss: -0.20893, Accuracy: 0.99894, F1: 0.3488, Prec: 0.5594, Rec: 0.3494 lr: 0.00070\n",
      "Epoch 13/Step 1080, Loss: -0.19208, Accuracy: 0.99894, F1: 0.3506, Prec: 0.5596, Rec: 0.3493 lr: 0.00070\n",
      "Epoch 13/Step 1090, Loss: -0.21232, Accuracy: 0.99894, F1: 0.3517, Prec: 0.5591, Rec: 0.3493 lr: 0.00070\n",
      "Epoch 13/Step 1100, Loss: -0.20937, Accuracy: 0.99894, F1: 0.3499, Prec: 0.5591, Rec: 0.3492 lr: 0.00070\n",
      "Epoch 13/Step 1110, Loss: -0.17845, Accuracy: 0.99894, F1: 0.3523, Prec: 0.5589, Rec: 0.3493 lr: 0.00070\n",
      "Epoch 13/Step 1120, Loss: -0.18599, Accuracy: 0.99894, F1: 0.3525, Prec: 0.5586, Rec: 0.3493 lr: 0.00070\n",
      "Epoch 13/Step 1130, Loss: -0.20325, Accuracy: 0.99894, F1: 0.3529, Prec: 0.5589, Rec: 0.3495 lr: 0.00070\n",
      "Epoch 13/Step 1140, Loss: -0.20811, Accuracy: 0.99894, F1: 0.3539, Prec: 0.5589, Rec: 0.3496 lr: 0.00070\n",
      "Epoch 13/Step 1150, Loss: -0.23699, Accuracy: 0.99894, F1: 0.3538, Prec: 0.5593, Rec: 0.3497 lr: 0.00070\n",
      "Epoch 13/Step 1160, Loss: -0.17097, Accuracy: 0.99894, F1: 0.3553, Prec: 0.5595, Rec: 0.3500 lr: 0.00070\n",
      "Epoch 13/Step 1170, Loss: -0.19008, Accuracy: 0.99894, F1: 0.3568, Prec: 0.5597, Rec: 0.3498 lr: 0.00070\n",
      "Epoch 13/Step 1180, Loss: -0.18419, Accuracy: 0.99894, F1: 0.3590, Prec: 0.5597, Rec: 0.3498 lr: 0.00070\n",
      "Epoch 13/Step 1190, Loss: -0.21758, Accuracy: 0.99894, F1: 0.3595, Prec: 0.5595, Rec: 0.3497 lr: 0.00070\n",
      "Epoch 13/Step 1200, Loss: -0.20866, Accuracy: 0.99894, F1: 0.3597, Prec: 0.5597, Rec: 0.3500 lr: 0.00070\n",
      "Epoch 13/Step 1210, Loss: -0.22995, Accuracy: 0.99894, F1: 0.3608, Prec: 0.5598, Rec: 0.3502 lr: 0.00070\n",
      "Epoch 13/Step 1220, Loss: -0.23539, Accuracy: 0.99894, F1: 0.3603, Prec: 0.5599, Rec: 0.3502 lr: 0.00070\n",
      "Epoch 13/Step 1230, Loss: -0.21953, Accuracy: 0.99895, F1: 0.3606, Prec: 0.5601, Rec: 0.3501 lr: 0.00070\n",
      "Epoch 13/Step 1240, Loss: -0.25575, Accuracy: 0.99895, F1: 0.3625, Prec: 0.5602, Rec: 0.3500 lr: 0.00070\n",
      "Epoch 13/Step 1250, Loss: -0.15344, Accuracy: 0.99895, F1: 0.3643, Prec: 0.5601, Rec: 0.3501 lr: 0.00070\n",
      "Epoch 13/Step 1260, Loss: -0.22486, Accuracy: 0.99895, F1: 0.3651, Prec: 0.5602, Rec: 0.3501 lr: 0.00070\n",
      "Epoch 13/Step 1270, Loss: -0.20118, Accuracy: 0.99895, F1: 0.3647, Prec: 0.5602, Rec: 0.3502 lr: 0.00070\n",
      "Epoch 13/Step 1280, Loss: -0.28168, Accuracy: 0.99895, F1: 0.3666, Prec: 0.5604, Rec: 0.3502 lr: 0.00070\n",
      "Epoch 13/Step 1290, Loss: -0.23144, Accuracy: 0.99895, F1: 0.3681, Prec: 0.5607, Rec: 0.3503 lr: 0.00070\n",
      "Epoch 13/Step 1300, Loss: -0.19289, Accuracy: 0.99895, F1: 0.3676, Prec: 0.5603, Rec: 0.3503 lr: 0.00070\n",
      "Epoch 13/Step 1310, Loss: -0.22490, Accuracy: 0.99895, F1: 0.3680, Prec: 0.5604, Rec: 0.3504 lr: 0.00070\n",
      "Epoch 13/Step 1320, Loss: -0.21840, Accuracy: 0.99895, F1: 0.3690, Prec: 0.5604, Rec: 0.3504 lr: 0.00070\n",
      "Epoch 13/Step 1330, Loss: -0.23464, Accuracy: 0.99895, F1: 0.3690, Prec: 0.5601, Rec: 0.3503 lr: 0.00070\n",
      "Epoch 13/Step 1340, Loss: -0.21476, Accuracy: 0.99895, F1: 0.3692, Prec: 0.5605, Rec: 0.3504 lr: 0.00070\n",
      "Epoch 13/Step 1350, Loss: -0.16642, Accuracy: 0.99895, F1: 0.3691, Prec: 0.5604, Rec: 0.3503 lr: 0.00070\n",
      "Epoch 13/Step 1360, Loss: -0.20626, Accuracy: 0.99895, F1: 0.3677, Prec: 0.5603, Rec: 0.3504 lr: 0.00070\n",
      "Epoch 13/Step 1370, Loss: -0.21635, Accuracy: 0.99895, F1: 0.3678, Prec: 0.5604, Rec: 0.3505 lr: 0.00070\n",
      "Epoch 13/Step 1380, Loss: -0.21593, Accuracy: 0.99895, F1: 0.3669, Prec: 0.5604, Rec: 0.3506 lr: 0.00070\n",
      "Epoch 13/Step 1390, Loss: -0.22380, Accuracy: 0.99895, F1: 0.3661, Prec: 0.5605, Rec: 0.3505 lr: 0.00070\n",
      "Epoch 13/Step 1400, Loss: -0.23549, Accuracy: 0.99895, F1: 0.3665, Prec: 0.5608, Rec: 0.3506 lr: 0.00070\n",
      "Epoch 13/Step 1410, Loss: -0.19787, Accuracy: 0.99895, F1: 0.3676, Prec: 0.5608, Rec: 0.3506 lr: 0.00070\n",
      "Epoch 13/Step 1420, Loss: -0.20872, Accuracy: 0.99895, F1: 0.3683, Prec: 0.5607, Rec: 0.3504 lr: 0.00070\n",
      "Epoch 13/Step 1430, Loss: -0.18435, Accuracy: 0.99895, F1: 0.3676, Prec: 0.5610, Rec: 0.3502 lr: 0.00070\n",
      "Epoch 13/Step 1440, Loss: -0.19449, Accuracy: 0.99895, F1: 0.3671, Prec: 0.5609, Rec: 0.3503 lr: 0.00070\n",
      "Epoch 13/Step 1450, Loss: -0.19072, Accuracy: 0.99895, F1: 0.3651, Prec: 0.5608, Rec: 0.3503 lr: 0.00070\n",
      "Epoch 13/Step 1460, Loss: -0.19750, Accuracy: 0.99895, F1: 0.3655, Prec: 0.5608, Rec: 0.3502 lr: 0.00070\n",
      "Epoch 13/Step 1470, Loss: -0.19675, Accuracy: 0.99895, F1: 0.3640, Prec: 0.5608, Rec: 0.3502 lr: 0.00070\n",
      "Epoch 13/Step 1480, Loss: -0.21287, Accuracy: 0.99895, F1: 0.3627, Prec: 0.5608, Rec: 0.3501 lr: 0.00070\n",
      "Epoch 13/Step 1490, Loss: -0.19320, Accuracy: 0.99895, F1: 0.3618, Prec: 0.5607, Rec: 0.3499 lr: 0.00070\n",
      "Epoch 13/Step 1500, Loss: -0.22597, Accuracy: 0.99895, F1: 0.3608, Prec: 0.5605, Rec: 0.3501 lr: 0.00070\n",
      "Epoch 13/Step 1510, Loss: -0.18871, Accuracy: 0.99895, F1: 0.3604, Prec: 0.5608, Rec: 0.3500 lr: 0.00070\n",
      "Epoch 13/Step 1520, Loss: -0.25686, Accuracy: 0.99895, F1: 0.3600, Prec: 0.5611, Rec: 0.3501 lr: 0.00070\n",
      "Epoch 13/Step 1530, Loss: -0.19829, Accuracy: 0.99895, F1: 0.3602, Prec: 0.5612, Rec: 0.3503 lr: 0.00070\n",
      "Epoch 13/Step 1540, Loss: -0.18718, Accuracy: 0.99895, F1: 0.3610, Prec: 0.5612, Rec: 0.3501 lr: 0.00070\n",
      "Epoch 13/Step 1550, Loss: -0.21380, Accuracy: 0.99895, F1: 0.3609, Prec: 0.5614, Rec: 0.3500 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9987\n",
      "Validation f1: 0.2333\n",
      "Validation precision: 0.3629\n",
      "Validation recall: 0.2187\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_12_valF1Score0.233/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_12_valF1Score0.233/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 14\n",
      "Epoch 14/Step 0, Loss: -0.23841, Accuracy: 0.99908, F1: 0.0000, Prec: 0.6194, Rec: 0.4011 lr: 0.00070\n",
      "Epoch 14/Step 10, Loss: -0.24987, Accuracy: 0.99890, F1: 0.1372, Prec: 0.5900, Rec: 0.3693 lr: 0.00070\n",
      "Epoch 14/Step 20, Loss: -0.22273, Accuracy: 0.99894, F1: 0.1542, Prec: 0.5767, Rec: 0.3673 lr: 0.00070\n",
      "Epoch 14/Step 30, Loss: -0.20654, Accuracy: 0.99898, F1: 0.1354, Prec: 0.5851, Rec: 0.3646 lr: 0.00070\n",
      "Epoch 14/Step 40, Loss: -0.19326, Accuracy: 0.99898, F1: 0.1024, Prec: 0.5950, Rec: 0.3623 lr: 0.00070\n",
      "Epoch 14/Step 50, Loss: -0.22776, Accuracy: 0.99898, F1: 0.0993, Prec: 0.5966, Rec: 0.3638 lr: 0.00070\n",
      "Epoch 14/Step 60, Loss: -0.23870, Accuracy: 0.99899, F1: 0.1109, Prec: 0.5973, Rec: 0.3661 lr: 0.00070\n",
      "Epoch 14/Step 70, Loss: -0.21505, Accuracy: 0.99901, F1: 0.0953, Prec: 0.5976, Rec: 0.3670 lr: 0.00070\n",
      "Epoch 14/Step 80, Loss: -0.20536, Accuracy: 0.99901, F1: 0.1345, Prec: 0.5958, Rec: 0.3632 lr: 0.00070\n",
      "Epoch 14/Step 90, Loss: -0.20132, Accuracy: 0.99900, F1: 0.1447, Prec: 0.5962, Rec: 0.3622 lr: 0.00070\n",
      "Epoch 14/Step 100, Loss: -0.22786, Accuracy: 0.99901, F1: 0.1677, Prec: 0.5948, Rec: 0.3644 lr: 0.00070\n",
      "Epoch 14/Step 110, Loss: -0.22048, Accuracy: 0.99899, F1: 0.1590, Prec: 0.5929, Rec: 0.3643 lr: 0.00070\n",
      "Epoch 14/Step 120, Loss: -0.21453, Accuracy: 0.99899, F1: 0.1844, Prec: 0.5923, Rec: 0.3632 lr: 0.00070\n",
      "Epoch 14/Step 130, Loss: -0.17975, Accuracy: 0.99899, F1: 0.1900, Prec: 0.5917, Rec: 0.3631 lr: 0.00070\n",
      "Epoch 14/Step 140, Loss: -0.19618, Accuracy: 0.99898, F1: 0.1873, Prec: 0.5872, Rec: 0.3608 lr: 0.00070\n",
      "Epoch 14/Step 150, Loss: -0.19957, Accuracy: 0.99897, F1: 0.1806, Prec: 0.5853, Rec: 0.3592 lr: 0.00070\n",
      "Epoch 14/Step 160, Loss: -0.22135, Accuracy: 0.99897, F1: 0.1743, Prec: 0.5843, Rec: 0.3586 lr: 0.00070\n",
      "Epoch 14/Step 170, Loss: -0.19731, Accuracy: 0.99896, F1: 0.1765, Prec: 0.5778, Rec: 0.3585 lr: 0.00070\n",
      "Epoch 14/Step 180, Loss: -0.25178, Accuracy: 0.99896, F1: 0.1795, Prec: 0.5773, Rec: 0.3600 lr: 0.00070\n",
      "Epoch 14/Step 190, Loss: -0.20353, Accuracy: 0.99896, F1: 0.1786, Prec: 0.5782, Rec: 0.3590 lr: 0.00070\n",
      "Epoch 14/Step 200, Loss: -0.22674, Accuracy: 0.99895, F1: 0.1780, Prec: 0.5788, Rec: 0.3581 lr: 0.00070\n",
      "Epoch 14/Step 210, Loss: -0.19461, Accuracy: 0.99895, F1: 0.1863, Prec: 0.5761, Rec: 0.3584 lr: 0.00070\n",
      "Epoch 14/Step 220, Loss: -0.23358, Accuracy: 0.99895, F1: 0.1843, Prec: 0.5753, Rec: 0.3587 lr: 0.00070\n",
      "Epoch 14/Step 230, Loss: -0.20157, Accuracy: 0.99895, F1: 0.1806, Prec: 0.5771, Rec: 0.3577 lr: 0.00070\n",
      "Epoch 14/Step 240, Loss: -0.25173, Accuracy: 0.99895, F1: 0.1769, Prec: 0.5779, Rec: 0.3573 lr: 0.00070\n",
      "Epoch 14/Step 250, Loss: -0.22471, Accuracy: 0.99894, F1: 0.1937, Prec: 0.5764, Rec: 0.3573 lr: 0.00070\n",
      "Epoch 14/Step 260, Loss: -0.24628, Accuracy: 0.99894, F1: 0.1996, Prec: 0.5759, Rec: 0.3578 lr: 0.00070\n",
      "Epoch 14/Step 270, Loss: -0.24617, Accuracy: 0.99894, F1: 0.1951, Prec: 0.5748, Rec: 0.3576 lr: 0.00070\n",
      "Epoch 14/Step 280, Loss: -0.21995, Accuracy: 0.99894, F1: 0.1939, Prec: 0.5739, Rec: 0.3565 lr: 0.00070\n",
      "Epoch 14/Step 290, Loss: -0.22096, Accuracy: 0.99894, F1: 0.1915, Prec: 0.5741, Rec: 0.3565 lr: 0.00070\n",
      "Epoch 14/Step 300, Loss: -0.23887, Accuracy: 0.99894, F1: 0.1880, Prec: 0.5753, Rec: 0.3563 lr: 0.00070\n",
      "Epoch 14/Step 310, Loss: -0.22973, Accuracy: 0.99894, F1: 0.1872, Prec: 0.5756, Rec: 0.3563 lr: 0.00070\n",
      "Epoch 14/Step 320, Loss: -0.20712, Accuracy: 0.99894, F1: 0.1838, Prec: 0.5753, Rec: 0.3568 lr: 0.00070\n",
      "Epoch 14/Step 330, Loss: -0.22971, Accuracy: 0.99894, F1: 0.1838, Prec: 0.5760, Rec: 0.3566 lr: 0.00070\n",
      "Epoch 14/Step 340, Loss: -0.21337, Accuracy: 0.99894, F1: 0.1809, Prec: 0.5767, Rec: 0.3564 lr: 0.00070\n",
      "Epoch 14/Step 350, Loss: -0.19200, Accuracy: 0.99894, F1: 0.1758, Prec: 0.5776, Rec: 0.3569 lr: 0.00070\n",
      "Epoch 14/Step 360, Loss: -0.21991, Accuracy: 0.99894, F1: 0.1752, Prec: 0.5779, Rec: 0.3576 lr: 0.00070\n",
      "Epoch 14/Step 370, Loss: -0.23507, Accuracy: 0.99895, F1: 0.1727, Prec: 0.5782, Rec: 0.3576 lr: 0.00070\n",
      "Epoch 14/Step 380, Loss: -0.24164, Accuracy: 0.99895, F1: 0.1748, Prec: 0.5783, Rec: 0.3572 lr: 0.00070\n",
      "Epoch 14/Step 390, Loss: -0.18846, Accuracy: 0.99895, F1: 0.1719, Prec: 0.5787, Rec: 0.3569 lr: 0.00070\n",
      "Epoch 14/Step 400, Loss: -0.17335, Accuracy: 0.99895, F1: 0.1698, Prec: 0.5793, Rec: 0.3565 lr: 0.00070\n",
      "Epoch 14/Step 410, Loss: -0.17721, Accuracy: 0.99895, F1: 0.1657, Prec: 0.5794, Rec: 0.3561 lr: 0.00070\n",
      "Epoch 14/Step 420, Loss: -0.22272, Accuracy: 0.99895, F1: 0.1658, Prec: 0.5792, Rec: 0.3567 lr: 0.00070\n",
      "Epoch 14/Step 430, Loss: -0.20713, Accuracy: 0.99895, F1: 0.1620, Prec: 0.5785, Rec: 0.3571 lr: 0.00070\n",
      "Epoch 14/Step 440, Loss: -0.23072, Accuracy: 0.99895, F1: 0.1622, Prec: 0.5790, Rec: 0.3566 lr: 0.00070\n",
      "Epoch 14/Step 450, Loss: -0.21551, Accuracy: 0.99895, F1: 0.1598, Prec: 0.5786, Rec: 0.3565 lr: 0.00070\n",
      "Epoch 14/Step 460, Loss: -0.20075, Accuracy: 0.99895, F1: 0.1608, Prec: 0.5760, Rec: 0.3570 lr: 0.00070\n",
      "Epoch 14/Step 470, Loss: -0.20751, Accuracy: 0.99895, F1: 0.1627, Prec: 0.5766, Rec: 0.3565 lr: 0.00070\n",
      "Epoch 14/Step 480, Loss: -0.20021, Accuracy: 0.99895, F1: 0.1611, Prec: 0.5773, Rec: 0.3547 lr: 0.00070\n",
      "Epoch 14/Step 490, Loss: -0.19606, Accuracy: 0.99895, F1: 0.1590, Prec: 0.5762, Rec: 0.3547 lr: 0.00070\n",
      "Epoch 14/Step 500, Loss: -0.21750, Accuracy: 0.99895, F1: 0.1595, Prec: 0.5753, Rec: 0.3550 lr: 0.00070\n",
      "Epoch 14/Step 510, Loss: -0.26560, Accuracy: 0.99895, F1: 0.1590, Prec: 0.5749, Rec: 0.3553 lr: 0.00070\n",
      "Epoch 14/Step 520, Loss: -0.20206, Accuracy: 0.99895, F1: 0.1641, Prec: 0.5755, Rec: 0.3554 lr: 0.00070\n",
      "Epoch 14/Step 530, Loss: -0.20823, Accuracy: 0.99895, F1: 0.1638, Prec: 0.5751, Rec: 0.3550 lr: 0.00070\n",
      "Epoch 14/Step 540, Loss: -0.21424, Accuracy: 0.99895, F1: 0.1638, Prec: 0.5751, Rec: 0.3550 lr: 0.00070\n",
      "Epoch 14/Step 550, Loss: -0.25189, Accuracy: 0.99895, F1: 0.1670, Prec: 0.5753, Rec: 0.3550 lr: 0.00070\n",
      "Epoch 14/Step 560, Loss: -0.20445, Accuracy: 0.99895, F1: 0.1652, Prec: 0.5754, Rec: 0.3549 lr: 0.00070\n",
      "Epoch 14/Step 570, Loss: -0.21735, Accuracy: 0.99895, F1: 0.1638, Prec: 0.5753, Rec: 0.3549 lr: 0.00070\n",
      "Epoch 14/Step 580, Loss: -0.18240, Accuracy: 0.99895, F1: 0.1648, Prec: 0.5754, Rec: 0.3547 lr: 0.00070\n",
      "Epoch 14/Step 590, Loss: -0.17193, Accuracy: 0.99895, F1: 0.1685, Prec: 0.5752, Rec: 0.3547 lr: 0.00070\n",
      "Epoch 14/Step 600, Loss: -0.20848, Accuracy: 0.99895, F1: 0.1700, Prec: 0.5758, Rec: 0.3545 lr: 0.00070\n",
      "Epoch 14/Step 610, Loss: -0.26692, Accuracy: 0.99895, F1: 0.1711, Prec: 0.5759, Rec: 0.3547 lr: 0.00070\n",
      "Epoch 14/Step 620, Loss: -0.23872, Accuracy: 0.99894, F1: 0.1755, Prec: 0.5756, Rec: 0.3553 lr: 0.00070\n",
      "Epoch 14/Step 630, Loss: -0.20910, Accuracy: 0.99894, F1: 0.1764, Prec: 0.5758, Rec: 0.3552 lr: 0.00070\n",
      "Epoch 14/Step 640, Loss: -0.19669, Accuracy: 0.99894, F1: 0.1798, Prec: 0.5758, Rec: 0.3550 lr: 0.00070\n",
      "Epoch 14/Step 650, Loss: -0.20075, Accuracy: 0.99895, F1: 0.1845, Prec: 0.5757, Rec: 0.3552 lr: 0.00070\n",
      "Epoch 14/Step 660, Loss: -0.22865, Accuracy: 0.99895, F1: 0.1833, Prec: 0.5761, Rec: 0.3551 lr: 0.00070\n",
      "Epoch 14/Step 670, Loss: -0.19976, Accuracy: 0.99895, F1: 0.1819, Prec: 0.5767, Rec: 0.3550 lr: 0.00070\n",
      "Epoch 14/Step 680, Loss: -0.18178, Accuracy: 0.99895, F1: 0.1815, Prec: 0.5770, Rec: 0.3551 lr: 0.00070\n",
      "Epoch 14/Step 690, Loss: -0.24306, Accuracy: 0.99895, F1: 0.1811, Prec: 0.5761, Rec: 0.3551 lr: 0.00070\n",
      "Epoch 14/Step 700, Loss: -0.22509, Accuracy: 0.99895, F1: 0.1807, Prec: 0.5762, Rec: 0.3550 lr: 0.00070\n",
      "Epoch 14/Step 710, Loss: -0.22081, Accuracy: 0.99895, F1: 0.1781, Prec: 0.5770, Rec: 0.3552 lr: 0.00070\n",
      "Epoch 14/Step 720, Loss: -0.24289, Accuracy: 0.99895, F1: 0.1757, Prec: 0.5770, Rec: 0.3551 lr: 0.00070\n",
      "Epoch 14/Step 730, Loss: -0.20203, Accuracy: 0.99895, F1: 0.1733, Prec: 0.5767, Rec: 0.3551 lr: 0.00070\n",
      "Epoch 14/Step 740, Loss: -0.22952, Accuracy: 0.99895, F1: 0.1731, Prec: 0.5769, Rec: 0.3549 lr: 0.00070\n",
      "Epoch 14/Step 750, Loss: -0.21507, Accuracy: 0.99895, F1: 0.1708, Prec: 0.5767, Rec: 0.3549 lr: 0.00070\n",
      "Epoch 14/Step 760, Loss: -0.22163, Accuracy: 0.99895, F1: 0.1706, Prec: 0.5764, Rec: 0.3548 lr: 0.00070\n",
      "Epoch 14/Step 770, Loss: -0.24018, Accuracy: 0.99895, F1: 0.1692, Prec: 0.5762, Rec: 0.3548 lr: 0.00070\n",
      "Epoch 14/Step 780, Loss: -0.19000, Accuracy: 0.99895, F1: 0.1682, Prec: 0.5773, Rec: 0.3547 lr: 0.00070\n",
      "Epoch 14/Step 790, Loss: -0.23682, Accuracy: 0.99895, F1: 0.1669, Prec: 0.5771, Rec: 0.3545 lr: 0.00070\n",
      "Epoch 14/Step 800, Loss: -0.19984, Accuracy: 0.99895, F1: 0.1649, Prec: 0.5771, Rec: 0.3545 lr: 0.00070\n",
      "Epoch 14/Step 810, Loss: -0.16175, Accuracy: 0.99895, F1: 0.1628, Prec: 0.5772, Rec: 0.3545 lr: 0.00070\n",
      "Epoch 14/Step 820, Loss: -0.21566, Accuracy: 0.99895, F1: 0.1616, Prec: 0.5770, Rec: 0.3544 lr: 0.00070\n",
      "Epoch 14/Step 830, Loss: -0.23550, Accuracy: 0.99895, F1: 0.1607, Prec: 0.5774, Rec: 0.3545 lr: 0.00070\n",
      "Epoch 14/Step 840, Loss: -0.24425, Accuracy: 0.99895, F1: 0.1627, Prec: 0.5778, Rec: 0.3545 lr: 0.00070\n",
      "Epoch 14/Step 850, Loss: -0.21917, Accuracy: 0.99895, F1: 0.1626, Prec: 0.5773, Rec: 0.3545 lr: 0.00070\n",
      "Epoch 14/Step 860, Loss: -0.22073, Accuracy: 0.99896, F1: 0.1627, Prec: 0.5774, Rec: 0.3545 lr: 0.00070\n",
      "Epoch 14/Step 870, Loss: -0.21273, Accuracy: 0.99895, F1: 0.1615, Prec: 0.5772, Rec: 0.3541 lr: 0.00070\n",
      "Epoch 14/Step 880, Loss: -0.19947, Accuracy: 0.99895, F1: 0.1617, Prec: 0.5772, Rec: 0.3542 lr: 0.00070\n",
      "Epoch 14/Step 890, Loss: -0.21421, Accuracy: 0.99895, F1: 0.1599, Prec: 0.5770, Rec: 0.3540 lr: 0.00070\n",
      "Epoch 14/Step 900, Loss: -0.27206, Accuracy: 0.99895, F1: 0.1603, Prec: 0.5772, Rec: 0.3543 lr: 0.00070\n",
      "Epoch 14/Step 910, Loss: -0.18300, Accuracy: 0.99895, F1: 0.1594, Prec: 0.5773, Rec: 0.3541 lr: 0.00070\n",
      "Epoch 14/Step 920, Loss: -0.21084, Accuracy: 0.99895, F1: 0.1577, Prec: 0.5776, Rec: 0.3537 lr: 0.00070\n",
      "Epoch 14/Step 930, Loss: -0.21257, Accuracy: 0.99896, F1: 0.1569, Prec: 0.5776, Rec: 0.3539 lr: 0.00070\n",
      "Epoch 14/Step 940, Loss: -0.21531, Accuracy: 0.99896, F1: 0.1553, Prec: 0.5772, Rec: 0.3540 lr: 0.00070\n",
      "Epoch 14/Step 950, Loss: -0.24307, Accuracy: 0.99896, F1: 0.1545, Prec: 0.5775, Rec: 0.3542 lr: 0.00070\n",
      "Epoch 14/Step 960, Loss: -0.25746, Accuracy: 0.99896, F1: 0.1572, Prec: 0.5776, Rec: 0.3541 lr: 0.00070\n",
      "Epoch 14/Step 970, Loss: -0.18376, Accuracy: 0.99896, F1: 0.1575, Prec: 0.5774, Rec: 0.3537 lr: 0.00070\n",
      "Epoch 14/Step 980, Loss: -0.22394, Accuracy: 0.99896, F1: 0.1581, Prec: 0.5769, Rec: 0.3535 lr: 0.00070\n",
      "Epoch 14/Step 990, Loss: -0.21861, Accuracy: 0.99896, F1: 0.1591, Prec: 0.5767, Rec: 0.3534 lr: 0.00070\n",
      "Epoch 14/Step 1000, Loss: -0.22124, Accuracy: 0.99896, F1: 0.1622, Prec: 0.5769, Rec: 0.3536 lr: 0.00070\n",
      "Epoch 14/Step 1010, Loss: -0.22759, Accuracy: 0.99896, F1: 0.1639, Prec: 0.5771, Rec: 0.3538 lr: 0.00070\n",
      "Epoch 14/Step 1020, Loss: -0.17944, Accuracy: 0.99896, F1: 0.1638, Prec: 0.5765, Rec: 0.3538 lr: 0.00070\n",
      "Epoch 14/Step 1030, Loss: -0.22668, Accuracy: 0.99896, F1: 0.1642, Prec: 0.5767, Rec: 0.3535 lr: 0.00070\n",
      "Epoch 14/Step 1040, Loss: -0.22258, Accuracy: 0.99896, F1: 0.1641, Prec: 0.5768, Rec: 0.3535 lr: 0.00070\n",
      "Epoch 14/Step 1050, Loss: -0.25267, Accuracy: 0.99896, F1: 0.1641, Prec: 0.5768, Rec: 0.3536 lr: 0.00070\n",
      "Epoch 14/Step 1060, Loss: -0.22524, Accuracy: 0.99896, F1: 0.1657, Prec: 0.5771, Rec: 0.3537 lr: 0.00070\n",
      "Epoch 14/Step 1070, Loss: -0.21828, Accuracy: 0.99896, F1: 0.1671, Prec: 0.5769, Rec: 0.3538 lr: 0.00070\n",
      "Epoch 14/Step 1080, Loss: -0.19718, Accuracy: 0.99896, F1: 0.1669, Prec: 0.5769, Rec: 0.3537 lr: 0.00070\n",
      "Epoch 14/Step 1090, Loss: -0.21846, Accuracy: 0.99896, F1: 0.1667, Prec: 0.5766, Rec: 0.3537 lr: 0.00070\n",
      "Epoch 14/Step 1100, Loss: -0.22055, Accuracy: 0.99896, F1: 0.1652, Prec: 0.5766, Rec: 0.3537 lr: 0.00070\n",
      "Epoch 14/Step 1110, Loss: -0.18779, Accuracy: 0.99896, F1: 0.1653, Prec: 0.5764, Rec: 0.3537 lr: 0.00070\n",
      "Epoch 14/Step 1120, Loss: -0.19078, Accuracy: 0.99896, F1: 0.1657, Prec: 0.5760, Rec: 0.3538 lr: 0.00070\n",
      "Epoch 14/Step 1130, Loss: -0.20144, Accuracy: 0.99896, F1: 0.1658, Prec: 0.5762, Rec: 0.3539 lr: 0.00070\n",
      "Epoch 14/Step 1140, Loss: -0.20612, Accuracy: 0.99896, F1: 0.1643, Prec: 0.5763, Rec: 0.3540 lr: 0.00070\n",
      "Epoch 14/Step 1150, Loss: -0.24863, Accuracy: 0.99896, F1: 0.1637, Prec: 0.5765, Rec: 0.3542 lr: 0.00070\n",
      "Epoch 14/Step 1160, Loss: -0.18706, Accuracy: 0.99897, F1: 0.1636, Prec: 0.5768, Rec: 0.3544 lr: 0.00070\n",
      "Epoch 14/Step 1170, Loss: -0.19397, Accuracy: 0.99897, F1: 0.1660, Prec: 0.5768, Rec: 0.3543 lr: 0.00070\n",
      "Epoch 14/Step 1180, Loss: -0.18195, Accuracy: 0.99897, F1: 0.1680, Prec: 0.5769, Rec: 0.3542 lr: 0.00070\n",
      "Epoch 14/Step 1190, Loss: -0.22724, Accuracy: 0.99896, F1: 0.1682, Prec: 0.5766, Rec: 0.3541 lr: 0.00070\n",
      "Epoch 14/Step 1200, Loss: -0.21514, Accuracy: 0.99897, F1: 0.1676, Prec: 0.5768, Rec: 0.3543 lr: 0.00070\n",
      "Epoch 14/Step 1210, Loss: -0.23071, Accuracy: 0.99897, F1: 0.1662, Prec: 0.5768, Rec: 0.3545 lr: 0.00070\n",
      "Epoch 14/Step 1220, Loss: -0.23672, Accuracy: 0.99897, F1: 0.1662, Prec: 0.5769, Rec: 0.3546 lr: 0.00070\n",
      "Epoch 14/Step 1230, Loss: -0.22162, Accuracy: 0.99897, F1: 0.1648, Prec: 0.5770, Rec: 0.3545 lr: 0.00070\n",
      "Epoch 14/Step 1240, Loss: -0.25843, Accuracy: 0.99897, F1: 0.1642, Prec: 0.5770, Rec: 0.3544 lr: 0.00070\n",
      "Epoch 14/Step 1250, Loss: -0.15875, Accuracy: 0.99897, F1: 0.1656, Prec: 0.5770, Rec: 0.3544 lr: 0.00070\n",
      "Epoch 14/Step 1260, Loss: -0.23060, Accuracy: 0.99897, F1: 0.1676, Prec: 0.5771, Rec: 0.3544 lr: 0.00070\n",
      "Epoch 14/Step 1270, Loss: -0.20099, Accuracy: 0.99897, F1: 0.1669, Prec: 0.5770, Rec: 0.3545 lr: 0.00070\n",
      "Epoch 14/Step 1280, Loss: -0.27519, Accuracy: 0.99897, F1: 0.1674, Prec: 0.5768, Rec: 0.3546 lr: 0.00070\n",
      "Epoch 14/Step 1290, Loss: -0.23121, Accuracy: 0.99897, F1: 0.1682, Prec: 0.5772, Rec: 0.3546 lr: 0.00070\n",
      "Epoch 14/Step 1300, Loss: -0.19519, Accuracy: 0.99897, F1: 0.1686, Prec: 0.5769, Rec: 0.3546 lr: 0.00070\n",
      "Epoch 14/Step 1310, Loss: -0.22111, Accuracy: 0.99897, F1: 0.1707, Prec: 0.5769, Rec: 0.3547 lr: 0.00070\n",
      "Epoch 14/Step 1320, Loss: -0.22322, Accuracy: 0.99897, F1: 0.1720, Prec: 0.5768, Rec: 0.3547 lr: 0.00070\n",
      "Epoch 14/Step 1330, Loss: -0.24106, Accuracy: 0.99897, F1: 0.1744, Prec: 0.5767, Rec: 0.3545 lr: 0.00070\n",
      "Epoch 14/Step 1340, Loss: -0.21788, Accuracy: 0.99897, F1: 0.1755, Prec: 0.5770, Rec: 0.3547 lr: 0.00070\n",
      "Epoch 14/Step 1350, Loss: -0.17591, Accuracy: 0.99897, F1: 0.1755, Prec: 0.5771, Rec: 0.3546 lr: 0.00070\n",
      "Epoch 14/Step 1360, Loss: -0.20623, Accuracy: 0.99897, F1: 0.1770, Prec: 0.5773, Rec: 0.3546 lr: 0.00070\n",
      "Epoch 14/Step 1370, Loss: -0.22392, Accuracy: 0.99897, F1: 0.1786, Prec: 0.5773, Rec: 0.3548 lr: 0.00070\n",
      "Epoch 14/Step 1380, Loss: -0.21520, Accuracy: 0.99897, F1: 0.1773, Prec: 0.5774, Rec: 0.3549 lr: 0.00070\n",
      "Epoch 14/Step 1390, Loss: -0.22855, Accuracy: 0.99897, F1: 0.1773, Prec: 0.5774, Rec: 0.3548 lr: 0.00070\n",
      "Epoch 14/Step 1400, Loss: -0.24127, Accuracy: 0.99897, F1: 0.1779, Prec: 0.5778, Rec: 0.3549 lr: 0.00070\n",
      "Epoch 14/Step 1410, Loss: -0.20307, Accuracy: 0.99897, F1: 0.1779, Prec: 0.5777, Rec: 0.3548 lr: 0.00070\n",
      "Epoch 14/Step 1420, Loss: -0.20918, Accuracy: 0.99897, F1: 0.1794, Prec: 0.5775, Rec: 0.3547 lr: 0.00070\n",
      "Epoch 14/Step 1430, Loss: -0.18752, Accuracy: 0.99897, F1: 0.1808, Prec: 0.5778, Rec: 0.3545 lr: 0.00070\n",
      "Epoch 14/Step 1440, Loss: -0.20181, Accuracy: 0.99897, F1: 0.1807, Prec: 0.5779, Rec: 0.3545 lr: 0.00070\n",
      "Epoch 14/Step 1450, Loss: -0.20284, Accuracy: 0.99897, F1: 0.1800, Prec: 0.5778, Rec: 0.3546 lr: 0.00070\n",
      "Epoch 14/Step 1460, Loss: -0.20647, Accuracy: 0.99897, F1: 0.1806, Prec: 0.5779, Rec: 0.3545 lr: 0.00070\n",
      "Epoch 14/Step 1470, Loss: -0.19822, Accuracy: 0.99897, F1: 0.1799, Prec: 0.5779, Rec: 0.3544 lr: 0.00070\n",
      "Epoch 14/Step 1480, Loss: -0.21568, Accuracy: 0.99897, F1: 0.1792, Prec: 0.5778, Rec: 0.3544 lr: 0.00070\n",
      "Epoch 14/Step 1490, Loss: -0.19954, Accuracy: 0.99897, F1: 0.1795, Prec: 0.5776, Rec: 0.3542 lr: 0.00070\n",
      "Epoch 14/Step 1500, Loss: -0.23084, Accuracy: 0.99897, F1: 0.1793, Prec: 0.5775, Rec: 0.3544 lr: 0.00070\n",
      "Epoch 14/Step 1510, Loss: -0.19414, Accuracy: 0.99897, F1: 0.1794, Prec: 0.5779, Rec: 0.3543 lr: 0.00070\n",
      "Epoch 14/Step 1520, Loss: -0.25881, Accuracy: 0.99897, F1: 0.1792, Prec: 0.5782, Rec: 0.3543 lr: 0.00070\n",
      "Epoch 14/Step 1530, Loss: -0.19419, Accuracy: 0.99897, F1: 0.1807, Prec: 0.5781, Rec: 0.3545 lr: 0.00070\n",
      "Epoch 14/Step 1540, Loss: -0.19214, Accuracy: 0.99897, F1: 0.1816, Prec: 0.5780, Rec: 0.3543 lr: 0.00070\n",
      "Epoch 14/Step 1550, Loss: -0.21848, Accuracy: 0.99897, F1: 0.1827, Prec: 0.5783, Rec: 0.3542 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9986\n",
      "Validation f1: 0.2377\n",
      "Validation precision: 0.3497\n",
      "Validation recall: 0.2287\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_13_valF1Score0.238/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_13_valF1Score0.238/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 15\n",
      "Epoch 15/Step 0, Loss: -0.24133, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6301, Rec: 0.4072 lr: 0.00070\n",
      "Epoch 15/Step 10, Loss: -0.25452, Accuracy: 0.99889, F1: 0.1940, Prec: 0.5755, Rec: 0.3875 lr: 0.00070\n",
      "Epoch 15/Step 20, Loss: -0.23337, Accuracy: 0.99894, F1: 0.1829, Prec: 0.5737, Rec: 0.3796 lr: 0.00070\n",
      "Epoch 15/Step 30, Loss: -0.20427, Accuracy: 0.99898, F1: 0.1555, Prec: 0.5806, Rec: 0.3762 lr: 0.00070\n",
      "Epoch 15/Step 40, Loss: -0.19934, Accuracy: 0.99898, F1: 0.1176, Prec: 0.5973, Rec: 0.3717 lr: 0.00070\n",
      "Epoch 15/Step 50, Loss: -0.22690, Accuracy: 0.99899, F1: 0.0945, Prec: 0.5993, Rec: 0.3741 lr: 0.00070\n",
      "Epoch 15/Step 60, Loss: -0.23389, Accuracy: 0.99900, F1: 0.0938, Prec: 0.6018, Rec: 0.3743 lr: 0.00070\n",
      "Epoch 15/Step 70, Loss: -0.21255, Accuracy: 0.99901, F1: 0.0806, Prec: 0.5999, Rec: 0.3759 lr: 0.00070\n",
      "Epoch 15/Step 80, Loss: -0.21388, Accuracy: 0.99902, F1: 0.1144, Prec: 0.6007, Rec: 0.3717 lr: 0.00070\n",
      "Epoch 15/Step 90, Loss: -0.20094, Accuracy: 0.99901, F1: 0.1194, Prec: 0.6002, Rec: 0.3707 lr: 0.00070\n",
      "Epoch 15/Step 100, Loss: -0.23093, Accuracy: 0.99901, F1: 0.1230, Prec: 0.5980, Rec: 0.3723 lr: 0.00070\n",
      "Epoch 15/Step 110, Loss: -0.21577, Accuracy: 0.99900, F1: 0.1189, Prec: 0.5969, Rec: 0.3712 lr: 0.00070\n",
      "Epoch 15/Step 120, Loss: -0.21546, Accuracy: 0.99899, F1: 0.1269, Prec: 0.5946, Rec: 0.3701 lr: 0.00070\n",
      "Epoch 15/Step 130, Loss: -0.18057, Accuracy: 0.99900, F1: 0.1373, Prec: 0.5948, Rec: 0.3699 lr: 0.00070\n",
      "Epoch 15/Step 140, Loss: -0.19458, Accuracy: 0.99899, F1: 0.1330, Prec: 0.5931, Rec: 0.3667 lr: 0.00070\n",
      "Epoch 15/Step 150, Loss: -0.20380, Accuracy: 0.99897, F1: 0.1242, Prec: 0.5899, Rec: 0.3649 lr: 0.00070\n",
      "Epoch 15/Step 160, Loss: -0.23108, Accuracy: 0.99897, F1: 0.1214, Prec: 0.5885, Rec: 0.3651 lr: 0.00070\n",
      "Epoch 15/Step 170, Loss: -0.20622, Accuracy: 0.99897, F1: 0.1219, Prec: 0.5862, Rec: 0.3639 lr: 0.00070\n",
      "Epoch 15/Step 180, Loss: -0.25916, Accuracy: 0.99897, F1: 0.1249, Prec: 0.5839, Rec: 0.3655 lr: 0.00070\n",
      "Epoch 15/Step 190, Loss: -0.21303, Accuracy: 0.99897, F1: 0.1229, Prec: 0.5840, Rec: 0.3646 lr: 0.00070\n",
      "Epoch 15/Step 200, Loss: -0.23409, Accuracy: 0.99896, F1: 0.1256, Prec: 0.5863, Rec: 0.3627 lr: 0.00070\n",
      "Epoch 15/Step 210, Loss: -0.19385, Accuracy: 0.99896, F1: 0.1271, Prec: 0.5849, Rec: 0.3628 lr: 0.00070\n",
      "Epoch 15/Step 220, Loss: -0.24250, Accuracy: 0.99896, F1: 0.1244, Prec: 0.5843, Rec: 0.3630 lr: 0.00070\n",
      "Epoch 15/Step 230, Loss: -0.20474, Accuracy: 0.99896, F1: 0.1229, Prec: 0.5848, Rec: 0.3626 lr: 0.00070\n",
      "Epoch 15/Step 240, Loss: -0.25487, Accuracy: 0.99896, F1: 0.1218, Prec: 0.5861, Rec: 0.3622 lr: 0.00070\n",
      "Epoch 15/Step 250, Loss: -0.23415, Accuracy: 0.99896, F1: 0.1300, Prec: 0.5863, Rec: 0.3618 lr: 0.00070\n",
      "Epoch 15/Step 260, Loss: -0.25068, Accuracy: 0.99896, F1: 0.1356, Prec: 0.5863, Rec: 0.3621 lr: 0.00070\n",
      "Epoch 15/Step 270, Loss: -0.24390, Accuracy: 0.99895, F1: 0.1335, Prec: 0.5855, Rec: 0.3618 lr: 0.00070\n",
      "Epoch 15/Step 280, Loss: -0.22407, Accuracy: 0.99895, F1: 0.1348, Prec: 0.5845, Rec: 0.3607 lr: 0.00070\n",
      "Epoch 15/Step 290, Loss: -0.22374, Accuracy: 0.99895, F1: 0.1321, Prec: 0.5837, Rec: 0.3609 lr: 0.00070\n",
      "Epoch 15/Step 300, Loss: -0.24297, Accuracy: 0.99895, F1: 0.1307, Prec: 0.5851, Rec: 0.3605 lr: 0.00070\n",
      "Epoch 15/Step 310, Loss: -0.23130, Accuracy: 0.99896, F1: 0.1322, Prec: 0.5850, Rec: 0.3606 lr: 0.00070\n",
      "Epoch 15/Step 320, Loss: -0.21130, Accuracy: 0.99896, F1: 0.1307, Prec: 0.5848, Rec: 0.3612 lr: 0.00070\n",
      "Epoch 15/Step 330, Loss: -0.22961, Accuracy: 0.99896, F1: 0.1290, Prec: 0.5854, Rec: 0.3612 lr: 0.00070\n",
      "Epoch 15/Step 340, Loss: -0.21937, Accuracy: 0.99896, F1: 0.1280, Prec: 0.5859, Rec: 0.3609 lr: 0.00070\n",
      "Epoch 15/Step 350, Loss: -0.19293, Accuracy: 0.99896, F1: 0.1265, Prec: 0.5866, Rec: 0.3616 lr: 0.00070\n",
      "Epoch 15/Step 360, Loss: -0.22806, Accuracy: 0.99896, F1: 0.1256, Prec: 0.5868, Rec: 0.3626 lr: 0.00070\n",
      "Epoch 15/Step 370, Loss: -0.22755, Accuracy: 0.99896, F1: 0.1222, Prec: 0.5865, Rec: 0.3627 lr: 0.00070\n",
      "Epoch 15/Step 380, Loss: -0.24101, Accuracy: 0.99896, F1: 0.1214, Prec: 0.5869, Rec: 0.3621 lr: 0.00070\n",
      "Epoch 15/Step 390, Loss: -0.19394, Accuracy: 0.99896, F1: 0.1201, Prec: 0.5875, Rec: 0.3617 lr: 0.00070\n",
      "Epoch 15/Step 400, Loss: -0.17875, Accuracy: 0.99896, F1: 0.1193, Prec: 0.5878, Rec: 0.3613 lr: 0.00070\n",
      "Epoch 15/Step 410, Loss: -0.18042, Accuracy: 0.99896, F1: 0.1164, Prec: 0.5878, Rec: 0.3611 lr: 0.00070\n",
      "Epoch 15/Step 420, Loss: -0.22773, Accuracy: 0.99897, F1: 0.1155, Prec: 0.5884, Rec: 0.3614 lr: 0.00070\n",
      "Epoch 15/Step 430, Loss: -0.21466, Accuracy: 0.99897, F1: 0.1128, Prec: 0.5879, Rec: 0.3618 lr: 0.00070\n",
      "Epoch 15/Step 440, Loss: -0.23676, Accuracy: 0.99896, F1: 0.1143, Prec: 0.5882, Rec: 0.3616 lr: 0.00070\n",
      "Epoch 15/Step 450, Loss: -0.22506, Accuracy: 0.99896, F1: 0.1118, Prec: 0.5884, Rec: 0.3614 lr: 0.00070\n",
      "Epoch 15/Step 460, Loss: -0.19922, Accuracy: 0.99896, F1: 0.1127, Prec: 0.5862, Rec: 0.3618 lr: 0.00070\n",
      "Epoch 15/Step 470, Loss: -0.20495, Accuracy: 0.99897, F1: 0.1158, Prec: 0.5863, Rec: 0.3615 lr: 0.00070\n",
      "Epoch 15/Step 480, Loss: -0.20288, Accuracy: 0.99897, F1: 0.1152, Prec: 0.5869, Rec: 0.3600 lr: 0.00070\n",
      "Epoch 15/Step 490, Loss: -0.20140, Accuracy: 0.99896, F1: 0.1157, Prec: 0.5863, Rec: 0.3597 lr: 0.00070\n",
      "Epoch 15/Step 500, Loss: -0.21859, Accuracy: 0.99896, F1: 0.1169, Prec: 0.5846, Rec: 0.3601 lr: 0.00070\n",
      "Epoch 15/Step 510, Loss: -0.27441, Accuracy: 0.99896, F1: 0.1171, Prec: 0.5841, Rec: 0.3604 lr: 0.00070\n",
      "Epoch 15/Step 520, Loss: -0.20296, Accuracy: 0.99896, F1: 0.1183, Prec: 0.5852, Rec: 0.3604 lr: 0.00070\n",
      "Epoch 15/Step 530, Loss: -0.21416, Accuracy: 0.99896, F1: 0.1174, Prec: 0.5845, Rec: 0.3601 lr: 0.00070\n",
      "Epoch 15/Step 540, Loss: -0.21798, Accuracy: 0.99896, F1: 0.1152, Prec: 0.5842, Rec: 0.3601 lr: 0.00070\n",
      "Epoch 15/Step 550, Loss: -0.25206, Accuracy: 0.99896, F1: 0.1195, Prec: 0.5844, Rec: 0.3602 lr: 0.00070\n",
      "Epoch 15/Step 560, Loss: -0.21637, Accuracy: 0.99896, F1: 0.1206, Prec: 0.5844, Rec: 0.3603 lr: 0.00070\n",
      "Epoch 15/Step 570, Loss: -0.22807, Accuracy: 0.99896, F1: 0.1214, Prec: 0.5843, Rec: 0.3604 lr: 0.00070\n",
      "Epoch 15/Step 580, Loss: -0.19155, Accuracy: 0.99896, F1: 0.1205, Prec: 0.5844, Rec: 0.3600 lr: 0.00070\n",
      "Epoch 15/Step 590, Loss: -0.18192, Accuracy: 0.99896, F1: 0.1237, Prec: 0.5839, Rec: 0.3601 lr: 0.00070\n",
      "Epoch 15/Step 600, Loss: -0.20531, Accuracy: 0.99896, F1: 0.1260, Prec: 0.5846, Rec: 0.3600 lr: 0.00070\n",
      "Epoch 15/Step 610, Loss: -0.26829, Accuracy: 0.99896, F1: 0.1254, Prec: 0.5849, Rec: 0.3600 lr: 0.00070\n",
      "Epoch 15/Step 620, Loss: -0.24240, Accuracy: 0.99896, F1: 0.1289, Prec: 0.5848, Rec: 0.3605 lr: 0.00070\n",
      "Epoch 15/Step 630, Loss: -0.20786, Accuracy: 0.99896, F1: 0.1281, Prec: 0.5849, Rec: 0.3604 lr: 0.00070\n",
      "Epoch 15/Step 640, Loss: -0.20157, Accuracy: 0.99896, F1: 0.1287, Prec: 0.5851, Rec: 0.3603 lr: 0.00070\n",
      "Epoch 15/Step 650, Loss: -0.20312, Accuracy: 0.99896, F1: 0.1303, Prec: 0.5852, Rec: 0.3604 lr: 0.00070\n",
      "Epoch 15/Step 660, Loss: -0.23616, Accuracy: 0.99896, F1: 0.1328, Prec: 0.5853, Rec: 0.3605 lr: 0.00070\n",
      "Epoch 15/Step 670, Loss: -0.20758, Accuracy: 0.99896, F1: 0.1322, Prec: 0.5861, Rec: 0.3603 lr: 0.00070\n",
      "Epoch 15/Step 680, Loss: -0.17696, Accuracy: 0.99896, F1: 0.1338, Prec: 0.5863, Rec: 0.3604 lr: 0.00070\n",
      "Epoch 15/Step 690, Loss: -0.24215, Accuracy: 0.99896, F1: 0.1363, Prec: 0.5860, Rec: 0.3604 lr: 0.00070\n",
      "Epoch 15/Step 700, Loss: -0.22856, Accuracy: 0.99896, F1: 0.1366, Prec: 0.5859, Rec: 0.3603 lr: 0.00070\n",
      "Epoch 15/Step 710, Loss: -0.22541, Accuracy: 0.99896, F1: 0.1346, Prec: 0.5866, Rec: 0.3605 lr: 0.00070\n",
      "Epoch 15/Step 720, Loss: -0.24722, Accuracy: 0.99896, F1: 0.1341, Prec: 0.5870, Rec: 0.3602 lr: 0.00070\n",
      "Epoch 15/Step 730, Loss: -0.19880, Accuracy: 0.99896, F1: 0.1334, Prec: 0.5866, Rec: 0.3602 lr: 0.00070\n",
      "Epoch 15/Step 740, Loss: -0.21827, Accuracy: 0.99897, F1: 0.1360, Prec: 0.5866, Rec: 0.3601 lr: 0.00070\n",
      "Epoch 15/Step 750, Loss: -0.22329, Accuracy: 0.99897, F1: 0.1354, Prec: 0.5868, Rec: 0.3599 lr: 0.00070\n",
      "Epoch 15/Step 760, Loss: -0.22670, Accuracy: 0.99897, F1: 0.1368, Prec: 0.5867, Rec: 0.3597 lr: 0.00070\n",
      "Epoch 15/Step 770, Loss: -0.23836, Accuracy: 0.99897, F1: 0.1376, Prec: 0.5861, Rec: 0.3599 lr: 0.00070\n",
      "Epoch 15/Step 780, Loss: -0.18255, Accuracy: 0.99897, F1: 0.1370, Prec: 0.5871, Rec: 0.3598 lr: 0.00070\n",
      "Epoch 15/Step 790, Loss: -0.23817, Accuracy: 0.99897, F1: 0.1353, Prec: 0.5871, Rec: 0.3595 lr: 0.00070\n",
      "Epoch 15/Step 800, Loss: -0.20840, Accuracy: 0.99897, F1: 0.1336, Prec: 0.5871, Rec: 0.3595 lr: 0.00070\n",
      "Epoch 15/Step 810, Loss: -0.16401, Accuracy: 0.99897, F1: 0.1319, Prec: 0.5869, Rec: 0.3596 lr: 0.00070\n",
      "Epoch 15/Step 820, Loss: -0.22084, Accuracy: 0.99897, F1: 0.1311, Prec: 0.5869, Rec: 0.3595 lr: 0.00070\n",
      "Epoch 15/Step 830, Loss: -0.24308, Accuracy: 0.99897, F1: 0.1305, Prec: 0.5875, Rec: 0.3595 lr: 0.00070\n",
      "Epoch 15/Step 840, Loss: -0.25789, Accuracy: 0.99897, F1: 0.1328, Prec: 0.5880, Rec: 0.3596 lr: 0.00070\n",
      "Epoch 15/Step 850, Loss: -0.22468, Accuracy: 0.99897, F1: 0.1330, Prec: 0.5876, Rec: 0.3595 lr: 0.00070\n",
      "Epoch 15/Step 860, Loss: -0.21748, Accuracy: 0.99897, F1: 0.1335, Prec: 0.5877, Rec: 0.3594 lr: 0.00070\n",
      "Epoch 15/Step 870, Loss: -0.21985, Accuracy: 0.99897, F1: 0.1320, Prec: 0.5873, Rec: 0.3592 lr: 0.00070\n",
      "Epoch 15/Step 880, Loss: -0.19877, Accuracy: 0.99897, F1: 0.1326, Prec: 0.5873, Rec: 0.3592 lr: 0.00070\n",
      "Epoch 15/Step 890, Loss: -0.21010, Accuracy: 0.99897, F1: 0.1319, Prec: 0.5871, Rec: 0.3590 lr: 0.00070\n",
      "Epoch 15/Step 900, Loss: -0.26308, Accuracy: 0.99897, F1: 0.1316, Prec: 0.5874, Rec: 0.3591 lr: 0.00070\n",
      "Epoch 15/Step 910, Loss: -0.18533, Accuracy: 0.99897, F1: 0.1302, Prec: 0.5875, Rec: 0.3589 lr: 0.00070\n",
      "Epoch 15/Step 920, Loss: -0.20857, Accuracy: 0.99897, F1: 0.1306, Prec: 0.5875, Rec: 0.3586 lr: 0.00070\n",
      "Epoch 15/Step 930, Loss: -0.22027, Accuracy: 0.99897, F1: 0.1302, Prec: 0.5879, Rec: 0.3587 lr: 0.00070\n",
      "Epoch 15/Step 940, Loss: -0.21874, Accuracy: 0.99897, F1: 0.1302, Prec: 0.5874, Rec: 0.3588 lr: 0.00070\n",
      "Epoch 15/Step 950, Loss: -0.24321, Accuracy: 0.99897, F1: 0.1298, Prec: 0.5877, Rec: 0.3589 lr: 0.00070\n",
      "Epoch 15/Step 960, Loss: -0.25727, Accuracy: 0.99897, F1: 0.1318, Prec: 0.5878, Rec: 0.3589 lr: 0.00070\n",
      "Epoch 15/Step 970, Loss: -0.19434, Accuracy: 0.99897, F1: 0.1322, Prec: 0.5876, Rec: 0.3585 lr: 0.00070\n",
      "Epoch 15/Step 980, Loss: -0.23012, Accuracy: 0.99897, F1: 0.1333, Prec: 0.5875, Rec: 0.3583 lr: 0.00070\n",
      "Epoch 15/Step 990, Loss: -0.22072, Accuracy: 0.99897, F1: 0.1338, Prec: 0.5872, Rec: 0.3582 lr: 0.00070\n",
      "Epoch 15/Step 1000, Loss: -0.22172, Accuracy: 0.99897, F1: 0.1366, Prec: 0.5875, Rec: 0.3583 lr: 0.00070\n",
      "Epoch 15/Step 1010, Loss: -0.23475, Accuracy: 0.99897, F1: 0.1368, Prec: 0.5876, Rec: 0.3586 lr: 0.00070\n",
      "Epoch 15/Step 1020, Loss: -0.18626, Accuracy: 0.99897, F1: 0.1370, Prec: 0.5873, Rec: 0.3585 lr: 0.00070\n",
      "Epoch 15/Step 1030, Loss: -0.23084, Accuracy: 0.99898, F1: 0.1376, Prec: 0.5875, Rec: 0.3583 lr: 0.00070\n",
      "Epoch 15/Step 1040, Loss: -0.22229, Accuracy: 0.99898, F1: 0.1377, Prec: 0.5876, Rec: 0.3583 lr: 0.00070\n",
      "Epoch 15/Step 1050, Loss: -0.25436, Accuracy: 0.99898, F1: 0.1378, Prec: 0.5876, Rec: 0.3583 lr: 0.00070\n",
      "Epoch 15/Step 1060, Loss: -0.24000, Accuracy: 0.99898, F1: 0.1397, Prec: 0.5879, Rec: 0.3586 lr: 0.00070\n",
      "Epoch 15/Step 1070, Loss: -0.22134, Accuracy: 0.99898, F1: 0.1416, Prec: 0.5881, Rec: 0.3586 lr: 0.00070\n",
      "Epoch 15/Step 1080, Loss: -0.20619, Accuracy: 0.99898, F1: 0.1409, Prec: 0.5882, Rec: 0.3586 lr: 0.00070\n",
      "Epoch 15/Step 1090, Loss: -0.22606, Accuracy: 0.99898, F1: 0.1409, Prec: 0.5880, Rec: 0.3586 lr: 0.00070\n",
      "Epoch 15/Step 1100, Loss: -0.22261, Accuracy: 0.99898, F1: 0.1397, Prec: 0.5882, Rec: 0.3585 lr: 0.00070\n",
      "Epoch 15/Step 1110, Loss: -0.18769, Accuracy: 0.99898, F1: 0.1407, Prec: 0.5882, Rec: 0.3585 lr: 0.00070\n",
      "Epoch 15/Step 1120, Loss: -0.19832, Accuracy: 0.99898, F1: 0.1401, Prec: 0.5879, Rec: 0.3585 lr: 0.00070\n",
      "Epoch 15/Step 1130, Loss: -0.20601, Accuracy: 0.99898, F1: 0.1396, Prec: 0.5880, Rec: 0.3587 lr: 0.00070\n",
      "Epoch 15/Step 1140, Loss: -0.21698, Accuracy: 0.99898, F1: 0.1384, Prec: 0.5883, Rec: 0.3588 lr: 0.00070\n",
      "Epoch 15/Step 1150, Loss: -0.25113, Accuracy: 0.99898, F1: 0.1388, Prec: 0.5884, Rec: 0.3589 lr: 0.00070\n",
      "Epoch 15/Step 1160, Loss: -0.18683, Accuracy: 0.99898, F1: 0.1384, Prec: 0.5887, Rec: 0.3591 lr: 0.00070\n",
      "Epoch 15/Step 1170, Loss: -0.19395, Accuracy: 0.99898, F1: 0.1394, Prec: 0.5888, Rec: 0.3590 lr: 0.00070\n",
      "Epoch 15/Step 1180, Loss: -0.19061, Accuracy: 0.99898, F1: 0.1409, Prec: 0.5888, Rec: 0.3590 lr: 0.00070\n",
      "Epoch 15/Step 1190, Loss: -0.22880, Accuracy: 0.99898, F1: 0.1397, Prec: 0.5888, Rec: 0.3588 lr: 0.00070\n",
      "Epoch 15/Step 1200, Loss: -0.21187, Accuracy: 0.99898, F1: 0.1393, Prec: 0.5890, Rec: 0.3590 lr: 0.00070\n",
      "Epoch 15/Step 1210, Loss: -0.23992, Accuracy: 0.99898, F1: 0.1382, Prec: 0.5891, Rec: 0.3592 lr: 0.00070\n",
      "Epoch 15/Step 1220, Loss: -0.23620, Accuracy: 0.99898, F1: 0.1370, Prec: 0.5890, Rec: 0.3592 lr: 0.00070\n",
      "Epoch 15/Step 1230, Loss: -0.22747, Accuracy: 0.99899, F1: 0.1366, Prec: 0.5892, Rec: 0.3592 lr: 0.00070\n",
      "Epoch 15/Step 1240, Loss: -0.26741, Accuracy: 0.99898, F1: 0.1355, Prec: 0.5892, Rec: 0.3591 lr: 0.00070\n",
      "Epoch 15/Step 1250, Loss: -0.16212, Accuracy: 0.99898, F1: 0.1352, Prec: 0.5892, Rec: 0.3591 lr: 0.00070\n",
      "Epoch 15/Step 1260, Loss: -0.23152, Accuracy: 0.99899, F1: 0.1349, Prec: 0.5894, Rec: 0.3592 lr: 0.00070\n",
      "Epoch 15/Step 1270, Loss: -0.20815, Accuracy: 0.99899, F1: 0.1345, Prec: 0.5895, Rec: 0.3593 lr: 0.00070\n",
      "Epoch 15/Step 1280, Loss: -0.28331, Accuracy: 0.99899, F1: 0.1341, Prec: 0.5897, Rec: 0.3593 lr: 0.00070\n",
      "Epoch 15/Step 1290, Loss: -0.23668, Accuracy: 0.99899, F1: 0.1342, Prec: 0.5899, Rec: 0.3594 lr: 0.00070\n",
      "Epoch 15/Step 1300, Loss: -0.21142, Accuracy: 0.99899, F1: 0.1331, Prec: 0.5898, Rec: 0.3594 lr: 0.00070\n",
      "Epoch 15/Step 1310, Loss: -0.22143, Accuracy: 0.99899, F1: 0.1335, Prec: 0.5899, Rec: 0.3594 lr: 0.00070\n",
      "Epoch 15/Step 1320, Loss: -0.23507, Accuracy: 0.99899, F1: 0.1332, Prec: 0.5899, Rec: 0.3594 lr: 0.00070\n",
      "Epoch 15/Step 1330, Loss: -0.24295, Accuracy: 0.99899, F1: 0.1346, Prec: 0.5897, Rec: 0.3593 lr: 0.00070\n",
      "Epoch 15/Step 1340, Loss: -0.22435, Accuracy: 0.99899, F1: 0.1343, Prec: 0.5898, Rec: 0.3595 lr: 0.00070\n",
      "Epoch 15/Step 1350, Loss: -0.18006, Accuracy: 0.99899, F1: 0.1333, Prec: 0.5900, Rec: 0.3594 lr: 0.00070\n",
      "Epoch 15/Step 1360, Loss: -0.21274, Accuracy: 0.99899, F1: 0.1330, Prec: 0.5900, Rec: 0.3595 lr: 0.00070\n",
      "Epoch 15/Step 1370, Loss: -0.22182, Accuracy: 0.99899, F1: 0.1332, Prec: 0.5902, Rec: 0.3596 lr: 0.00070\n",
      "Epoch 15/Step 1380, Loss: -0.21446, Accuracy: 0.99899, F1: 0.1322, Prec: 0.5901, Rec: 0.3597 lr: 0.00070\n",
      "Epoch 15/Step 1390, Loss: -0.22999, Accuracy: 0.99899, F1: 0.1331, Prec: 0.5901, Rec: 0.3596 lr: 0.00070\n",
      "Epoch 15/Step 1400, Loss: -0.23956, Accuracy: 0.99899, F1: 0.1336, Prec: 0.5905, Rec: 0.3597 lr: 0.00070\n",
      "Epoch 15/Step 1410, Loss: -0.20585, Accuracy: 0.99899, F1: 0.1340, Prec: 0.5906, Rec: 0.3596 lr: 0.00070\n",
      "Epoch 15/Step 1420, Loss: -0.21473, Accuracy: 0.99899, F1: 0.1341, Prec: 0.5903, Rec: 0.3595 lr: 0.00070\n",
      "Epoch 15/Step 1430, Loss: -0.20944, Accuracy: 0.99899, F1: 0.1357, Prec: 0.5906, Rec: 0.3593 lr: 0.00070\n",
      "Epoch 15/Step 1440, Loss: -0.20630, Accuracy: 0.99899, F1: 0.1367, Prec: 0.5908, Rec: 0.3593 lr: 0.00070\n",
      "Epoch 15/Step 1450, Loss: -0.21212, Accuracy: 0.99899, F1: 0.1362, Prec: 0.5909, Rec: 0.3594 lr: 0.00070\n",
      "Epoch 15/Step 1460, Loss: -0.21253, Accuracy: 0.99899, F1: 0.1380, Prec: 0.5907, Rec: 0.3594 lr: 0.00070\n",
      "Epoch 15/Step 1470, Loss: -0.20609, Accuracy: 0.99899, F1: 0.1371, Prec: 0.5909, Rec: 0.3592 lr: 0.00070\n",
      "Epoch 15/Step 1480, Loss: -0.21722, Accuracy: 0.99899, F1: 0.1377, Prec: 0.5907, Rec: 0.3593 lr: 0.00070\n",
      "Epoch 15/Step 1490, Loss: -0.19868, Accuracy: 0.99899, F1: 0.1373, Prec: 0.5905, Rec: 0.3592 lr: 0.00070\n",
      "Epoch 15/Step 1500, Loss: -0.23023, Accuracy: 0.99899, F1: 0.1369, Prec: 0.5905, Rec: 0.3592 lr: 0.00070\n",
      "Epoch 15/Step 1510, Loss: -0.20220, Accuracy: 0.99899, F1: 0.1367, Prec: 0.5906, Rec: 0.3592 lr: 0.00070\n",
      "Epoch 15/Step 1520, Loss: -0.26919, Accuracy: 0.99899, F1: 0.1363, Prec: 0.5909, Rec: 0.3593 lr: 0.00070\n",
      "Epoch 15/Step 1530, Loss: -0.19256, Accuracy: 0.99899, F1: 0.1365, Prec: 0.5910, Rec: 0.3595 lr: 0.00070\n",
      "Epoch 15/Step 1540, Loss: -0.19270, Accuracy: 0.99899, F1: 0.1361, Prec: 0.5909, Rec: 0.3593 lr: 0.00070\n",
      "Epoch 15/Step 1550, Loss: -0.22100, Accuracy: 0.99899, F1: 0.1374, Prec: 0.5911, Rec: 0.3592 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9987\n",
      "Validation f1: 0.1364\n",
      "Validation precision: 0.3724\n",
      "Validation recall: 0.2117\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_14_valF1Score0.136/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_14_valF1Score0.136/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 16\n",
      "Epoch 16/Step 0, Loss: -0.23773, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6647, Rec: 0.3815 lr: 0.00070\n",
      "Epoch 16/Step 10, Loss: -0.26056, Accuracy: 0.99893, F1: 0.0732, Prec: 0.6036, Rec: 0.3849 lr: 0.00070\n",
      "Epoch 16/Step 20, Loss: -0.23945, Accuracy: 0.99897, F1: 0.1260, Prec: 0.5977, Rec: 0.3836 lr: 0.00070\n",
      "Epoch 16/Step 30, Loss: -0.20607, Accuracy: 0.99901, F1: 0.1166, Prec: 0.6056, Rec: 0.3793 lr: 0.00070\n",
      "Epoch 16/Step 40, Loss: -0.19399, Accuracy: 0.99901, F1: 0.0882, Prec: 0.6172, Rec: 0.3745 lr: 0.00070\n",
      "Epoch 16/Step 50, Loss: -0.23425, Accuracy: 0.99901, F1: 0.0709, Prec: 0.6172, Rec: 0.3764 lr: 0.00070\n",
      "Epoch 16/Step 60, Loss: -0.23208, Accuracy: 0.99902, F1: 0.0734, Prec: 0.6170, Rec: 0.3773 lr: 0.00070\n",
      "Epoch 16/Step 70, Loss: -0.22209, Accuracy: 0.99904, F1: 0.0630, Prec: 0.6198, Rec: 0.3780 lr: 0.00070\n",
      "Epoch 16/Step 80, Loss: -0.21607, Accuracy: 0.99904, F1: 0.0996, Prec: 0.6190, Rec: 0.3744 lr: 0.00070\n",
      "Epoch 16/Step 90, Loss: -0.20164, Accuracy: 0.99903, F1: 0.1060, Prec: 0.6199, Rec: 0.3730 lr: 0.00070\n",
      "Epoch 16/Step 100, Loss: -0.23436, Accuracy: 0.99904, F1: 0.1108, Prec: 0.6175, Rec: 0.3747 lr: 0.00070\n",
      "Epoch 16/Step 110, Loss: -0.22927, Accuracy: 0.99902, F1: 0.1078, Prec: 0.6155, Rec: 0.3740 lr: 0.00070\n",
      "Epoch 16/Step 120, Loss: -0.21871, Accuracy: 0.99902, F1: 0.1045, Prec: 0.6149, Rec: 0.3724 lr: 0.00070\n",
      "Epoch 16/Step 130, Loss: -0.18048, Accuracy: 0.99902, F1: 0.1162, Prec: 0.6120, Rec: 0.3728 lr: 0.00070\n",
      "Epoch 16/Step 140, Loss: -0.20018, Accuracy: 0.99901, F1: 0.1200, Prec: 0.6115, Rec: 0.3686 lr: 0.00070\n",
      "Epoch 16/Step 150, Loss: -0.20560, Accuracy: 0.99900, F1: 0.1121, Prec: 0.6085, Rec: 0.3669 lr: 0.00070\n",
      "Epoch 16/Step 160, Loss: -0.23614, Accuracy: 0.99900, F1: 0.1051, Prec: 0.6067, Rec: 0.3672 lr: 0.00070\n",
      "Epoch 16/Step 170, Loss: -0.21813, Accuracy: 0.99900, F1: 0.1070, Prec: 0.6049, Rec: 0.3663 lr: 0.00070\n",
      "Epoch 16/Step 180, Loss: -0.26696, Accuracy: 0.99900, F1: 0.1056, Prec: 0.6031, Rec: 0.3680 lr: 0.00070\n",
      "Epoch 16/Step 190, Loss: -0.22200, Accuracy: 0.99899, F1: 0.1049, Prec: 0.6033, Rec: 0.3671 lr: 0.00070\n",
      "Epoch 16/Step 200, Loss: -0.23927, Accuracy: 0.99899, F1: 0.0997, Prec: 0.6055, Rec: 0.3655 lr: 0.00070\n",
      "Epoch 16/Step 210, Loss: -0.19814, Accuracy: 0.99899, F1: 0.1028, Prec: 0.6035, Rec: 0.3657 lr: 0.00070\n",
      "Epoch 16/Step 220, Loss: -0.24228, Accuracy: 0.99898, F1: 0.0982, Prec: 0.6022, Rec: 0.3662 lr: 0.00070\n",
      "Epoch 16/Step 230, Loss: -0.20510, Accuracy: 0.99898, F1: 0.0939, Prec: 0.6032, Rec: 0.3654 lr: 0.00070\n",
      "Epoch 16/Step 240, Loss: -0.26146, Accuracy: 0.99898, F1: 0.0939, Prec: 0.6045, Rec: 0.3652 lr: 0.00070\n",
      "Epoch 16/Step 250, Loss: -0.23308, Accuracy: 0.99898, F1: 0.0997, Prec: 0.6041, Rec: 0.3648 lr: 0.00070\n",
      "Epoch 16/Step 260, Loss: -0.25229, Accuracy: 0.99898, F1: 0.0991, Prec: 0.6031, Rec: 0.3652 lr: 0.00070\n",
      "Epoch 16/Step 270, Loss: -0.25287, Accuracy: 0.99898, F1: 0.0954, Prec: 0.6029, Rec: 0.3647 lr: 0.00070\n",
      "Epoch 16/Step 280, Loss: -0.22648, Accuracy: 0.99897, F1: 0.0978, Prec: 0.6023, Rec: 0.3634 lr: 0.00070\n",
      "Epoch 16/Step 290, Loss: -0.22145, Accuracy: 0.99897, F1: 0.0964, Prec: 0.6017, Rec: 0.3636 lr: 0.00070\n",
      "Epoch 16/Step 300, Loss: -0.24844, Accuracy: 0.99898, F1: 0.0959, Prec: 0.6026, Rec: 0.3636 lr: 0.00070\n",
      "Epoch 16/Step 310, Loss: -0.23353, Accuracy: 0.99898, F1: 0.0964, Prec: 0.6031, Rec: 0.3636 lr: 0.00070\n",
      "Epoch 16/Step 320, Loss: -0.21714, Accuracy: 0.99898, F1: 0.0960, Prec: 0.6029, Rec: 0.3644 lr: 0.00070\n",
      "Epoch 16/Step 330, Loss: -0.23742, Accuracy: 0.99898, F1: 0.0931, Prec: 0.6028, Rec: 0.3646 lr: 0.00070\n",
      "Epoch 16/Step 340, Loss: -0.21080, Accuracy: 0.99898, F1: 0.0931, Prec: 0.6038, Rec: 0.3643 lr: 0.00070\n",
      "Epoch 16/Step 350, Loss: -0.19451, Accuracy: 0.99898, F1: 0.0904, Prec: 0.6050, Rec: 0.3646 lr: 0.00070\n",
      "Epoch 16/Step 360, Loss: -0.23327, Accuracy: 0.99898, F1: 0.0879, Prec: 0.6045, Rec: 0.3657 lr: 0.00070\n",
      "Epoch 16/Step 370, Loss: -0.22713, Accuracy: 0.99898, F1: 0.0856, Prec: 0.6040, Rec: 0.3659 lr: 0.00070\n",
      "Epoch 16/Step 380, Loss: -0.23972, Accuracy: 0.99898, F1: 0.0857, Prec: 0.6043, Rec: 0.3654 lr: 0.00070\n",
      "Epoch 16/Step 390, Loss: -0.19454, Accuracy: 0.99898, F1: 0.0852, Prec: 0.6045, Rec: 0.3652 lr: 0.00070\n",
      "Epoch 16/Step 400, Loss: -0.18284, Accuracy: 0.99898, F1: 0.0831, Prec: 0.6048, Rec: 0.3648 lr: 0.00070\n",
      "Epoch 16/Step 410, Loss: -0.18872, Accuracy: 0.99899, F1: 0.0811, Prec: 0.6052, Rec: 0.3646 lr: 0.00070\n",
      "Epoch 16/Step 420, Loss: -0.22807, Accuracy: 0.99899, F1: 0.0791, Prec: 0.6058, Rec: 0.3649 lr: 0.00070\n",
      "Epoch 16/Step 430, Loss: -0.21307, Accuracy: 0.99899, F1: 0.0773, Prec: 0.6057, Rec: 0.3651 lr: 0.00070\n",
      "Epoch 16/Step 440, Loss: -0.24158, Accuracy: 0.99899, F1: 0.0775, Prec: 0.6061, Rec: 0.3649 lr: 0.00070\n",
      "Epoch 16/Step 450, Loss: -0.23375, Accuracy: 0.99899, F1: 0.0758, Prec: 0.6061, Rec: 0.3649 lr: 0.00070\n",
      "Epoch 16/Step 460, Loss: -0.20074, Accuracy: 0.99899, F1: 0.0742, Prec: 0.6041, Rec: 0.3651 lr: 0.00070\n",
      "Epoch 16/Step 470, Loss: -0.21594, Accuracy: 0.99899, F1: 0.0726, Prec: 0.6036, Rec: 0.3650 lr: 0.00070\n",
      "Epoch 16/Step 480, Loss: -0.21233, Accuracy: 0.99899, F1: 0.0711, Prec: 0.6040, Rec: 0.3636 lr: 0.00070\n",
      "Epoch 16/Step 490, Loss: -0.20925, Accuracy: 0.99898, F1: 0.0696, Prec: 0.6037, Rec: 0.3633 lr: 0.00070\n",
      "Epoch 16/Step 500, Loss: -0.22673, Accuracy: 0.99899, F1: 0.0683, Prec: 0.6032, Rec: 0.3634 lr: 0.00070\n",
      "Epoch 16/Step 510, Loss: -0.27867, Accuracy: 0.99898, F1: 0.0680, Prec: 0.6023, Rec: 0.3638 lr: 0.00070\n",
      "Epoch 16/Step 520, Loss: -0.21131, Accuracy: 0.99899, F1: 0.0667, Prec: 0.6028, Rec: 0.3640 lr: 0.00070\n",
      "Epoch 16/Step 530, Loss: -0.22042, Accuracy: 0.99899, F1: 0.0668, Prec: 0.6027, Rec: 0.3634 lr: 0.00070\n",
      "Epoch 16/Step 540, Loss: -0.22559, Accuracy: 0.99898, F1: 0.0655, Prec: 0.6026, Rec: 0.3635 lr: 0.00070\n",
      "Epoch 16/Step 550, Loss: -0.25538, Accuracy: 0.99898, F1: 0.0690, Prec: 0.6027, Rec: 0.3636 lr: 0.00070\n",
      "Epoch 16/Step 560, Loss: -0.21444, Accuracy: 0.99898, F1: 0.0678, Prec: 0.6029, Rec: 0.3635 lr: 0.00070\n",
      "Epoch 16/Step 570, Loss: -0.22874, Accuracy: 0.99898, F1: 0.0680, Prec: 0.6028, Rec: 0.3635 lr: 0.00070\n",
      "Epoch 16/Step 580, Loss: -0.19399, Accuracy: 0.99898, F1: 0.0680, Prec: 0.6027, Rec: 0.3632 lr: 0.00070\n",
      "Epoch 16/Step 590, Loss: -0.18540, Accuracy: 0.99898, F1: 0.0708, Prec: 0.6022, Rec: 0.3631 lr: 0.00070\n",
      "Epoch 16/Step 600, Loss: -0.22414, Accuracy: 0.99898, F1: 0.0713, Prec: 0.6026, Rec: 0.3631 lr: 0.00070\n",
      "Epoch 16/Step 610, Loss: -0.26350, Accuracy: 0.99898, F1: 0.0716, Prec: 0.6029, Rec: 0.3631 lr: 0.00070\n",
      "Epoch 16/Step 620, Loss: -0.24092, Accuracy: 0.99898, F1: 0.0762, Prec: 0.6024, Rec: 0.3637 lr: 0.00070\n",
      "Epoch 16/Step 630, Loss: -0.21231, Accuracy: 0.99898, F1: 0.0762, Prec: 0.6022, Rec: 0.3636 lr: 0.00070\n",
      "Epoch 16/Step 640, Loss: -0.20864, Accuracy: 0.99898, F1: 0.0776, Prec: 0.6025, Rec: 0.3633 lr: 0.00070\n",
      "Epoch 16/Step 650, Loss: -0.20256, Accuracy: 0.99898, F1: 0.0790, Prec: 0.6023, Rec: 0.3634 lr: 0.00070\n",
      "Epoch 16/Step 660, Loss: -0.24372, Accuracy: 0.99898, F1: 0.0794, Prec: 0.6021, Rec: 0.3635 lr: 0.00070\n",
      "Epoch 16/Step 670, Loss: -0.21475, Accuracy: 0.99898, F1: 0.0796, Prec: 0.6028, Rec: 0.3634 lr: 0.00070\n",
      "Epoch 16/Step 680, Loss: -0.19140, Accuracy: 0.99898, F1: 0.0796, Prec: 0.6033, Rec: 0.3636 lr: 0.00070\n",
      "Epoch 16/Step 690, Loss: -0.24923, Accuracy: 0.99898, F1: 0.0795, Prec: 0.6033, Rec: 0.3635 lr: 0.00070\n",
      "Epoch 16/Step 700, Loss: -0.23024, Accuracy: 0.99898, F1: 0.0796, Prec: 0.6032, Rec: 0.3634 lr: 0.00070\n",
      "Epoch 16/Step 710, Loss: -0.22852, Accuracy: 0.99899, F1: 0.0785, Prec: 0.6037, Rec: 0.3637 lr: 0.00070\n",
      "Epoch 16/Step 720, Loss: -0.25576, Accuracy: 0.99899, F1: 0.0774, Prec: 0.6038, Rec: 0.3634 lr: 0.00070\n",
      "Epoch 16/Step 730, Loss: -0.20230, Accuracy: 0.99899, F1: 0.0763, Prec: 0.6036, Rec: 0.3633 lr: 0.00070\n",
      "Epoch 16/Step 740, Loss: -0.21986, Accuracy: 0.99899, F1: 0.0773, Prec: 0.6035, Rec: 0.3632 lr: 0.00070\n",
      "Epoch 16/Step 750, Loss: -0.23205, Accuracy: 0.99899, F1: 0.0776, Prec: 0.6038, Rec: 0.3631 lr: 0.00070\n",
      "Epoch 16/Step 760, Loss: -0.22539, Accuracy: 0.99899, F1: 0.0789, Prec: 0.6038, Rec: 0.3629 lr: 0.00070\n",
      "Epoch 16/Step 770, Loss: -0.24485, Accuracy: 0.99899, F1: 0.0797, Prec: 0.6030, Rec: 0.3630 lr: 0.00070\n",
      "Epoch 16/Step 780, Loss: -0.18727, Accuracy: 0.99899, F1: 0.0787, Prec: 0.6036, Rec: 0.3632 lr: 0.00070\n",
      "Epoch 16/Step 790, Loss: -0.24699, Accuracy: 0.99899, F1: 0.0777, Prec: 0.6037, Rec: 0.3628 lr: 0.00070\n",
      "Epoch 16/Step 800, Loss: -0.20347, Accuracy: 0.99899, F1: 0.0768, Prec: 0.6039, Rec: 0.3627 lr: 0.00070\n",
      "Epoch 16/Step 810, Loss: -0.16276, Accuracy: 0.99899, F1: 0.0758, Prec: 0.6037, Rec: 0.3628 lr: 0.00070\n",
      "Epoch 16/Step 820, Loss: -0.22414, Accuracy: 0.99899, F1: 0.0758, Prec: 0.6034, Rec: 0.3627 lr: 0.00070\n",
      "Epoch 16/Step 830, Loss: -0.24376, Accuracy: 0.99899, F1: 0.0760, Prec: 0.6038, Rec: 0.3628 lr: 0.00070\n",
      "Epoch 16/Step 840, Loss: -0.26632, Accuracy: 0.99899, F1: 0.0770, Prec: 0.6042, Rec: 0.3630 lr: 0.00070\n",
      "Epoch 16/Step 850, Loss: -0.22409, Accuracy: 0.99899, F1: 0.0770, Prec: 0.6036, Rec: 0.3629 lr: 0.00070\n",
      "Epoch 16/Step 860, Loss: -0.22838, Accuracy: 0.99899, F1: 0.0771, Prec: 0.6039, Rec: 0.3629 lr: 0.00070\n",
      "Epoch 16/Step 870, Loss: -0.22175, Accuracy: 0.99899, F1: 0.0762, Prec: 0.6036, Rec: 0.3626 lr: 0.00070\n",
      "Epoch 16/Step 880, Loss: -0.20586, Accuracy: 0.99899, F1: 0.0764, Prec: 0.6036, Rec: 0.3627 lr: 0.00070\n",
      "Epoch 16/Step 890, Loss: -0.21460, Accuracy: 0.99899, F1: 0.0756, Prec: 0.6031, Rec: 0.3625 lr: 0.00070\n",
      "Epoch 16/Step 900, Loss: -0.27807, Accuracy: 0.99899, F1: 0.0747, Prec: 0.6034, Rec: 0.3627 lr: 0.00070\n",
      "Epoch 16/Step 910, Loss: -0.18439, Accuracy: 0.99899, F1: 0.0739, Prec: 0.6034, Rec: 0.3624 lr: 0.00070\n",
      "Epoch 16/Step 920, Loss: -0.21649, Accuracy: 0.99899, F1: 0.0731, Prec: 0.6035, Rec: 0.3621 lr: 0.00070\n",
      "Epoch 16/Step 930, Loss: -0.22286, Accuracy: 0.99899, F1: 0.0723, Prec: 0.6037, Rec: 0.3622 lr: 0.00070\n",
      "Epoch 16/Step 940, Loss: -0.22039, Accuracy: 0.99899, F1: 0.0716, Prec: 0.6034, Rec: 0.3624 lr: 0.00070\n",
      "Epoch 16/Step 950, Loss: -0.24512, Accuracy: 0.99899, F1: 0.0708, Prec: 0.6036, Rec: 0.3625 lr: 0.00070\n",
      "Epoch 16/Step 960, Loss: -0.25815, Accuracy: 0.99899, F1: 0.0709, Prec: 0.6037, Rec: 0.3624 lr: 0.00070\n",
      "Epoch 16/Step 970, Loss: -0.19412, Accuracy: 0.99899, F1: 0.0711, Prec: 0.6034, Rec: 0.3621 lr: 0.00070\n",
      "Epoch 16/Step 980, Loss: -0.23321, Accuracy: 0.99899, F1: 0.0704, Prec: 0.6032, Rec: 0.3618 lr: 0.00070\n",
      "Epoch 16/Step 990, Loss: -0.22205, Accuracy: 0.99899, F1: 0.0704, Prec: 0.6025, Rec: 0.3618 lr: 0.00070\n",
      "Epoch 16/Step 1000, Loss: -0.21848, Accuracy: 0.99899, F1: 0.0726, Prec: 0.6028, Rec: 0.3619 lr: 0.00070\n",
      "Epoch 16/Step 1010, Loss: -0.23701, Accuracy: 0.99899, F1: 0.0735, Prec: 0.6033, Rec: 0.3619 lr: 0.00070\n",
      "Epoch 16/Step 1020, Loss: -0.18311, Accuracy: 0.99899, F1: 0.0734, Prec: 0.6021, Rec: 0.3620 lr: 0.00070\n",
      "Epoch 16/Step 1030, Loss: -0.23566, Accuracy: 0.99899, F1: 0.0747, Prec: 0.6022, Rec: 0.3619 lr: 0.00070\n",
      "Epoch 16/Step 1040, Loss: -0.22529, Accuracy: 0.99899, F1: 0.0756, Prec: 0.6022, Rec: 0.3617 lr: 0.00070\n",
      "Epoch 16/Step 1050, Loss: -0.26442, Accuracy: 0.99899, F1: 0.0763, Prec: 0.6019, Rec: 0.3619 lr: 0.00070\n",
      "Epoch 16/Step 1060, Loss: -0.24948, Accuracy: 0.99900, F1: 0.0771, Prec: 0.6021, Rec: 0.3622 lr: 0.00070\n",
      "Epoch 16/Step 1070, Loss: -0.22279, Accuracy: 0.99900, F1: 0.0790, Prec: 0.6024, Rec: 0.3621 lr: 0.00070\n",
      "Epoch 16/Step 1080, Loss: -0.21162, Accuracy: 0.99900, F1: 0.0798, Prec: 0.6020, Rec: 0.3623 lr: 0.00070\n",
      "Epoch 16/Step 1090, Loss: -0.22843, Accuracy: 0.99900, F1: 0.0805, Prec: 0.6020, Rec: 0.3622 lr: 0.00070\n",
      "Epoch 16/Step 1100, Loss: -0.22581, Accuracy: 0.99900, F1: 0.0798, Prec: 0.6021, Rec: 0.3621 lr: 0.00070\n",
      "Epoch 16/Step 1110, Loss: -0.18233, Accuracy: 0.99900, F1: 0.0814, Prec: 0.6020, Rec: 0.3621 lr: 0.00070\n",
      "Epoch 16/Step 1120, Loss: -0.19247, Accuracy: 0.99900, F1: 0.0814, Prec: 0.6019, Rec: 0.3621 lr: 0.00070\n",
      "Epoch 16/Step 1130, Loss: -0.21243, Accuracy: 0.99900, F1: 0.0814, Prec: 0.6019, Rec: 0.3623 lr: 0.00070\n",
      "Epoch 16/Step 1140, Loss: -0.21919, Accuracy: 0.99900, F1: 0.0807, Prec: 0.6021, Rec: 0.3625 lr: 0.00070\n",
      "Epoch 16/Step 1150, Loss: -0.25603, Accuracy: 0.99900, F1: 0.0808, Prec: 0.6023, Rec: 0.3626 lr: 0.00070\n",
      "Epoch 16/Step 1160, Loss: -0.19179, Accuracy: 0.99900, F1: 0.0807, Prec: 0.6027, Rec: 0.3629 lr: 0.00070\n",
      "Epoch 16/Step 1170, Loss: -0.19875, Accuracy: 0.99900, F1: 0.0823, Prec: 0.6028, Rec: 0.3627 lr: 0.00070\n",
      "Epoch 16/Step 1180, Loss: -0.19394, Accuracy: 0.99900, F1: 0.0837, Prec: 0.6026, Rec: 0.3627 lr: 0.00070\n",
      "Epoch 16/Step 1190, Loss: -0.24493, Accuracy: 0.99900, F1: 0.0830, Prec: 0.6024, Rec: 0.3626 lr: 0.00070\n",
      "Epoch 16/Step 1200, Loss: -0.21608, Accuracy: 0.99900, F1: 0.0831, Prec: 0.6028, Rec: 0.3628 lr: 0.00070\n",
      "Epoch 16/Step 1210, Loss: -0.24276, Accuracy: 0.99900, F1: 0.0824, Prec: 0.6029, Rec: 0.3629 lr: 0.00070\n",
      "Epoch 16/Step 1220, Loss: -0.24093, Accuracy: 0.99900, F1: 0.0825, Prec: 0.6028, Rec: 0.3630 lr: 0.00070\n",
      "Epoch 16/Step 1230, Loss: -0.23616, Accuracy: 0.99900, F1: 0.0825, Prec: 0.6030, Rec: 0.3629 lr: 0.00070\n",
      "Epoch 16/Step 1240, Loss: -0.26397, Accuracy: 0.99900, F1: 0.0824, Prec: 0.6030, Rec: 0.3628 lr: 0.00070\n",
      "Epoch 16/Step 1250, Loss: -0.16836, Accuracy: 0.99900, F1: 0.0830, Prec: 0.6027, Rec: 0.3630 lr: 0.00070\n",
      "Epoch 16/Step 1260, Loss: -0.23977, Accuracy: 0.99900, F1: 0.0832, Prec: 0.6031, Rec: 0.3630 lr: 0.00070\n",
      "Epoch 16/Step 1270, Loss: -0.20910, Accuracy: 0.99900, F1: 0.0825, Prec: 0.6033, Rec: 0.3630 lr: 0.00070\n",
      "Epoch 16/Step 1280, Loss: -0.28682, Accuracy: 0.99900, F1: 0.0819, Prec: 0.6033, Rec: 0.3630 lr: 0.00070\n",
      "Epoch 16/Step 1290, Loss: -0.23177, Accuracy: 0.99900, F1: 0.0826, Prec: 0.6036, Rec: 0.3631 lr: 0.00070\n",
      "Epoch 16/Step 1300, Loss: -0.21153, Accuracy: 0.99900, F1: 0.0820, Prec: 0.6036, Rec: 0.3630 lr: 0.00070\n",
      "Epoch 16/Step 1310, Loss: -0.22757, Accuracy: 0.99900, F1: 0.0827, Prec: 0.6035, Rec: 0.3631 lr: 0.00070\n",
      "Epoch 16/Step 1320, Loss: -0.24172, Accuracy: 0.99900, F1: 0.0828, Prec: 0.6034, Rec: 0.3632 lr: 0.00070\n",
      "Epoch 16/Step 1330, Loss: -0.25053, Accuracy: 0.99900, F1: 0.0828, Prec: 0.6033, Rec: 0.3631 lr: 0.00070\n",
      "Epoch 16/Step 1340, Loss: -0.23170, Accuracy: 0.99900, F1: 0.0828, Prec: 0.6036, Rec: 0.3632 lr: 0.00070\n",
      "Epoch 16/Step 1350, Loss: -0.18871, Accuracy: 0.99900, F1: 0.0822, Prec: 0.6036, Rec: 0.3632 lr: 0.00070\n",
      "Epoch 16/Step 1360, Loss: -0.21593, Accuracy: 0.99900, F1: 0.0823, Prec: 0.6039, Rec: 0.3631 lr: 0.00070\n",
      "Epoch 16/Step 1370, Loss: -0.22606, Accuracy: 0.99900, F1: 0.0829, Prec: 0.6039, Rec: 0.3634 lr: 0.00070\n",
      "Epoch 16/Step 1380, Loss: -0.21499, Accuracy: 0.99901, F1: 0.0823, Prec: 0.6040, Rec: 0.3634 lr: 0.00070\n",
      "Epoch 16/Step 1390, Loss: -0.23081, Accuracy: 0.99901, F1: 0.0817, Prec: 0.6038, Rec: 0.3633 lr: 0.00070\n",
      "Epoch 16/Step 1400, Loss: -0.23716, Accuracy: 0.99901, F1: 0.0818, Prec: 0.6041, Rec: 0.3634 lr: 0.00070\n",
      "Epoch 16/Step 1410, Loss: -0.20978, Accuracy: 0.99901, F1: 0.0812, Prec: 0.6043, Rec: 0.3633 lr: 0.00070\n",
      "Epoch 16/Step 1420, Loss: -0.21248, Accuracy: 0.99901, F1: 0.0812, Prec: 0.6041, Rec: 0.3632 lr: 0.00070\n",
      "Epoch 16/Step 1430, Loss: -0.21043, Accuracy: 0.99901, F1: 0.0820, Prec: 0.6042, Rec: 0.3630 lr: 0.00070\n",
      "Epoch 16/Step 1440, Loss: -0.21016, Accuracy: 0.99901, F1: 0.0822, Prec: 0.6043, Rec: 0.3631 lr: 0.00070\n",
      "Epoch 16/Step 1450, Loss: -0.20494, Accuracy: 0.99901, F1: 0.0821, Prec: 0.6042, Rec: 0.3631 lr: 0.00070\n",
      "Epoch 16/Step 1460, Loss: -0.21354, Accuracy: 0.99901, F1: 0.0815, Prec: 0.6039, Rec: 0.3631 lr: 0.00070\n",
      "Epoch 16/Step 1470, Loss: -0.20987, Accuracy: 0.99901, F1: 0.0810, Prec: 0.6042, Rec: 0.3630 lr: 0.00070\n",
      "Epoch 16/Step 1480, Loss: -0.22482, Accuracy: 0.99901, F1: 0.0809, Prec: 0.6042, Rec: 0.3630 lr: 0.00070\n",
      "Epoch 16/Step 1490, Loss: -0.20494, Accuracy: 0.99901, F1: 0.0804, Prec: 0.6039, Rec: 0.3629 lr: 0.00070\n",
      "Epoch 16/Step 1500, Loss: -0.23568, Accuracy: 0.99901, F1: 0.0799, Prec: 0.6039, Rec: 0.3629 lr: 0.00070\n",
      "Epoch 16/Step 1510, Loss: -0.21001, Accuracy: 0.99901, F1: 0.0793, Prec: 0.6041, Rec: 0.3630 lr: 0.00070\n",
      "Epoch 16/Step 1520, Loss: -0.26678, Accuracy: 0.99901, F1: 0.0793, Prec: 0.6044, Rec: 0.3631 lr: 0.00070\n",
      "Epoch 16/Step 1530, Loss: -0.20627, Accuracy: 0.99901, F1: 0.0794, Prec: 0.6046, Rec: 0.3632 lr: 0.00070\n",
      "Epoch 16/Step 1540, Loss: -0.19156, Accuracy: 0.99901, F1: 0.0795, Prec: 0.6043, Rec: 0.3630 lr: 0.00070\n",
      "Epoch 16/Step 1550, Loss: -0.22265, Accuracy: 0.99901, F1: 0.0805, Prec: 0.6044, Rec: 0.3630 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9987\n",
      "Validation f1: 0.1186\n",
      "Validation precision: 0.4036\n",
      "Validation recall: 0.1965\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_15_valF1Score0.119/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_15_valF1Score0.119/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 17\n",
      "Epoch 17/Step 0, Loss: -0.24295, Accuracy: 0.99914, F1: 0.0000, Prec: 0.6800, Rec: 0.3889 lr: 0.00070\n",
      "Epoch 17/Step 10, Loss: -0.26680, Accuracy: 0.99897, F1: 0.0000, Prec: 0.6516, Rec: 0.3660 lr: 0.00070\n",
      "Epoch 17/Step 20, Loss: -0.24066, Accuracy: 0.99898, F1: 0.0403, Prec: 0.6113, Rec: 0.3748 lr: 0.00070\n",
      "Epoch 17/Step 30, Loss: -0.21088, Accuracy: 0.99901, F1: 0.0581, Prec: 0.6109, Rec: 0.3760 lr: 0.00070\n",
      "Epoch 17/Step 40, Loss: -0.19949, Accuracy: 0.99902, F1: 0.0440, Prec: 0.6310, Rec: 0.3720 lr: 0.00070\n",
      "Epoch 17/Step 50, Loss: -0.23925, Accuracy: 0.99903, F1: 0.0353, Prec: 0.6384, Rec: 0.3735 lr: 0.00070\n",
      "Epoch 17/Step 60, Loss: -0.23952, Accuracy: 0.99903, F1: 0.0422, Prec: 0.6306, Rec: 0.3776 lr: 0.00070\n",
      "Epoch 17/Step 70, Loss: -0.22191, Accuracy: 0.99905, F1: 0.0363, Prec: 0.6298, Rec: 0.3798 lr: 0.00070\n",
      "Epoch 17/Step 80, Loss: -0.21874, Accuracy: 0.99905, F1: 0.0771, Prec: 0.6298, Rec: 0.3764 lr: 0.00070\n",
      "Epoch 17/Step 90, Loss: -0.20770, Accuracy: 0.99905, F1: 0.0958, Prec: 0.6297, Rec: 0.3757 lr: 0.00070\n",
      "Epoch 17/Step 100, Loss: -0.23528, Accuracy: 0.99905, F1: 0.1017, Prec: 0.6276, Rec: 0.3772 lr: 0.00070\n",
      "Epoch 17/Step 110, Loss: -0.22582, Accuracy: 0.99904, F1: 0.1002, Prec: 0.6256, Rec: 0.3765 lr: 0.00070\n",
      "Epoch 17/Step 120, Loss: -0.21802, Accuracy: 0.99903, F1: 0.1032, Prec: 0.6233, Rec: 0.3749 lr: 0.00070\n",
      "Epoch 17/Step 130, Loss: -0.18640, Accuracy: 0.99903, F1: 0.1152, Prec: 0.6211, Rec: 0.3752 lr: 0.00070\n",
      "Epoch 17/Step 140, Loss: -0.20733, Accuracy: 0.99902, F1: 0.1129, Prec: 0.6182, Rec: 0.3725 lr: 0.00070\n",
      "Epoch 17/Step 150, Loss: -0.21860, Accuracy: 0.99901, F1: 0.1054, Prec: 0.6158, Rec: 0.3709 lr: 0.00070\n",
      "Epoch 17/Step 160, Loss: -0.24359, Accuracy: 0.99901, F1: 0.0989, Prec: 0.6147, Rec: 0.3710 lr: 0.00070\n",
      "Epoch 17/Step 170, Loss: -0.22369, Accuracy: 0.99901, F1: 0.1017, Prec: 0.6135, Rec: 0.3701 lr: 0.00070\n",
      "Epoch 17/Step 180, Loss: -0.26795, Accuracy: 0.99901, F1: 0.0961, Prec: 0.6136, Rec: 0.3712 lr: 0.00070\n",
      "Epoch 17/Step 190, Loss: -0.22081, Accuracy: 0.99901, F1: 0.0955, Prec: 0.6119, Rec: 0.3707 lr: 0.00070\n",
      "Epoch 17/Step 200, Loss: -0.24596, Accuracy: 0.99900, F1: 0.0907, Prec: 0.6134, Rec: 0.3695 lr: 0.00070\n",
      "Epoch 17/Step 210, Loss: -0.19936, Accuracy: 0.99900, F1: 0.0908, Prec: 0.6125, Rec: 0.3695 lr: 0.00070\n",
      "Epoch 17/Step 220, Loss: -0.24207, Accuracy: 0.99900, F1: 0.0867, Prec: 0.6110, Rec: 0.3702 lr: 0.00070\n",
      "Epoch 17/Step 230, Loss: -0.20995, Accuracy: 0.99900, F1: 0.0871, Prec: 0.6115, Rec: 0.3695 lr: 0.00070\n",
      "Epoch 17/Step 240, Loss: -0.26484, Accuracy: 0.99899, F1: 0.0835, Prec: 0.6129, Rec: 0.3690 lr: 0.00070\n",
      "Epoch 17/Step 250, Loss: -0.24490, Accuracy: 0.99899, F1: 0.0868, Prec: 0.6134, Rec: 0.3683 lr: 0.00070\n",
      "Epoch 17/Step 260, Loss: -0.26071, Accuracy: 0.99899, F1: 0.0834, Prec: 0.6118, Rec: 0.3690 lr: 0.00070\n",
      "Epoch 17/Step 270, Loss: -0.25989, Accuracy: 0.99899, F1: 0.0804, Prec: 0.6108, Rec: 0.3687 lr: 0.00070\n",
      "Epoch 17/Step 280, Loss: -0.22628, Accuracy: 0.99898, F1: 0.0804, Prec: 0.6111, Rec: 0.3674 lr: 0.00070\n",
      "Epoch 17/Step 290, Loss: -0.22027, Accuracy: 0.99899, F1: 0.0777, Prec: 0.6103, Rec: 0.3676 lr: 0.00070\n",
      "Epoch 17/Step 300, Loss: -0.24639, Accuracy: 0.99899, F1: 0.0779, Prec: 0.6112, Rec: 0.3674 lr: 0.00070\n",
      "Epoch 17/Step 310, Loss: -0.23692, Accuracy: 0.99899, F1: 0.0788, Prec: 0.6119, Rec: 0.3673 lr: 0.00070\n",
      "Epoch 17/Step 320, Loss: -0.22342, Accuracy: 0.99899, F1: 0.0787, Prec: 0.6121, Rec: 0.3678 lr: 0.00070\n",
      "Epoch 17/Step 330, Loss: -0.23463, Accuracy: 0.99899, F1: 0.0763, Prec: 0.6111, Rec: 0.3682 lr: 0.00070\n",
      "Epoch 17/Step 340, Loss: -0.21967, Accuracy: 0.99899, F1: 0.0741, Prec: 0.6116, Rec: 0.3680 lr: 0.00070\n",
      "Epoch 17/Step 350, Loss: -0.20435, Accuracy: 0.99899, F1: 0.0720, Prec: 0.6129, Rec: 0.3683 lr: 0.00070\n",
      "Epoch 17/Step 360, Loss: -0.23233, Accuracy: 0.99899, F1: 0.0700, Prec: 0.6133, Rec: 0.3692 lr: 0.00070\n",
      "Epoch 17/Step 370, Loss: -0.23683, Accuracy: 0.99899, F1: 0.0681, Prec: 0.6134, Rec: 0.3694 lr: 0.00070\n",
      "Epoch 17/Step 380, Loss: -0.24189, Accuracy: 0.99900, F1: 0.0688, Prec: 0.6138, Rec: 0.3688 lr: 0.00070\n",
      "Epoch 17/Step 390, Loss: -0.20155, Accuracy: 0.99900, F1: 0.0691, Prec: 0.6146, Rec: 0.3683 lr: 0.00070\n",
      "Epoch 17/Step 400, Loss: -0.18821, Accuracy: 0.99900, F1: 0.0674, Prec: 0.6146, Rec: 0.3680 lr: 0.00070\n",
      "Epoch 17/Step 410, Loss: -0.18546, Accuracy: 0.99900, F1: 0.0657, Prec: 0.6150, Rec: 0.3677 lr: 0.00070\n",
      "Epoch 17/Step 420, Loss: -0.23723, Accuracy: 0.99900, F1: 0.0642, Prec: 0.6156, Rec: 0.3680 lr: 0.00070\n",
      "Epoch 17/Step 430, Loss: -0.22566, Accuracy: 0.99900, F1: 0.0627, Prec: 0.6147, Rec: 0.3685 lr: 0.00070\n",
      "Epoch 17/Step 440, Loss: -0.24518, Accuracy: 0.99900, F1: 0.0654, Prec: 0.6151, Rec: 0.3682 lr: 0.00070\n",
      "Epoch 17/Step 450, Loss: -0.23877, Accuracy: 0.99900, F1: 0.0639, Prec: 0.6152, Rec: 0.3683 lr: 0.00070\n",
      "Epoch 17/Step 460, Loss: -0.21041, Accuracy: 0.99900, F1: 0.0625, Prec: 0.6140, Rec: 0.3684 lr: 0.00070\n",
      "Epoch 17/Step 470, Loss: -0.21872, Accuracy: 0.99900, F1: 0.0612, Prec: 0.6137, Rec: 0.3682 lr: 0.00070\n",
      "Epoch 17/Step 480, Loss: -0.21316, Accuracy: 0.99900, F1: 0.0618, Prec: 0.6132, Rec: 0.3672 lr: 0.00070\n",
      "Epoch 17/Step 490, Loss: -0.20920, Accuracy: 0.99900, F1: 0.0606, Prec: 0.6133, Rec: 0.3666 lr: 0.00070\n",
      "Epoch 17/Step 500, Loss: -0.22289, Accuracy: 0.99900, F1: 0.0608, Prec: 0.6131, Rec: 0.3666 lr: 0.00070\n",
      "Epoch 17/Step 510, Loss: -0.27321, Accuracy: 0.99900, F1: 0.0607, Prec: 0.6114, Rec: 0.3672 lr: 0.00070\n",
      "Epoch 17/Step 520, Loss: -0.21225, Accuracy: 0.99900, F1: 0.0595, Prec: 0.6121, Rec: 0.3674 lr: 0.00070\n",
      "Epoch 17/Step 530, Loss: -0.22118, Accuracy: 0.99900, F1: 0.0597, Prec: 0.6120, Rec: 0.3667 lr: 0.00070\n",
      "Epoch 17/Step 540, Loss: -0.22123, Accuracy: 0.99900, F1: 0.0586, Prec: 0.6116, Rec: 0.3669 lr: 0.00070\n",
      "Epoch 17/Step 550, Loss: -0.26007, Accuracy: 0.99899, F1: 0.0608, Prec: 0.6117, Rec: 0.3670 lr: 0.00070\n",
      "Epoch 17/Step 560, Loss: -0.21732, Accuracy: 0.99899, F1: 0.0597, Prec: 0.6119, Rec: 0.3669 lr: 0.00070\n",
      "Epoch 17/Step 570, Loss: -0.23201, Accuracy: 0.99900, F1: 0.0587, Prec: 0.6122, Rec: 0.3666 lr: 0.00070\n",
      "Epoch 17/Step 580, Loss: -0.19366, Accuracy: 0.99899, F1: 0.0590, Prec: 0.6118, Rec: 0.3664 lr: 0.00070\n",
      "Epoch 17/Step 590, Loss: -0.17827, Accuracy: 0.99899, F1: 0.0593, Prec: 0.6112, Rec: 0.3663 lr: 0.00070\n",
      "Epoch 17/Step 600, Loss: -0.21138, Accuracy: 0.99899, F1: 0.0599, Prec: 0.6116, Rec: 0.3661 lr: 0.00070\n",
      "Epoch 17/Step 610, Loss: -0.26655, Accuracy: 0.99899, F1: 0.0590, Prec: 0.6119, Rec: 0.3661 lr: 0.00070\n",
      "Epoch 17/Step 620, Loss: -0.24714, Accuracy: 0.99899, F1: 0.0611, Prec: 0.6119, Rec: 0.3666 lr: 0.00070\n",
      "Epoch 17/Step 630, Loss: -0.20697, Accuracy: 0.99899, F1: 0.0601, Prec: 0.6112, Rec: 0.3666 lr: 0.00070\n",
      "Epoch 17/Step 640, Loss: -0.21507, Accuracy: 0.99899, F1: 0.0617, Prec: 0.6110, Rec: 0.3666 lr: 0.00070\n",
      "Epoch 17/Step 650, Loss: -0.19982, Accuracy: 0.99899, F1: 0.0608, Prec: 0.6113, Rec: 0.3666 lr: 0.00070\n",
      "Epoch 17/Step 660, Loss: -0.23943, Accuracy: 0.99899, F1: 0.0614, Prec: 0.6110, Rec: 0.3667 lr: 0.00070\n",
      "Epoch 17/Step 670, Loss: -0.21586, Accuracy: 0.99899, F1: 0.0605, Prec: 0.6116, Rec: 0.3666 lr: 0.00070\n",
      "Epoch 17/Step 680, Loss: -0.19194, Accuracy: 0.99899, F1: 0.0607, Prec: 0.6121, Rec: 0.3667 lr: 0.00070\n",
      "Epoch 17/Step 690, Loss: -0.24638, Accuracy: 0.99899, F1: 0.0622, Prec: 0.6118, Rec: 0.3667 lr: 0.00070\n",
      "Epoch 17/Step 700, Loss: -0.23390, Accuracy: 0.99900, F1: 0.0625, Prec: 0.6116, Rec: 0.3666 lr: 0.00070\n",
      "Epoch 17/Step 710, Loss: -0.23103, Accuracy: 0.99900, F1: 0.0616, Prec: 0.6122, Rec: 0.3669 lr: 0.00070\n",
      "Epoch 17/Step 720, Loss: -0.26228, Accuracy: 0.99900, F1: 0.0608, Prec: 0.6123, Rec: 0.3667 lr: 0.00070\n",
      "Epoch 17/Step 730, Loss: -0.20476, Accuracy: 0.99900, F1: 0.0599, Prec: 0.6120, Rec: 0.3666 lr: 0.00070\n",
      "Epoch 17/Step 740, Loss: -0.23147, Accuracy: 0.99900, F1: 0.0602, Prec: 0.6120, Rec: 0.3665 lr: 0.00070\n",
      "Epoch 17/Step 750, Loss: -0.23845, Accuracy: 0.99900, F1: 0.0594, Prec: 0.6122, Rec: 0.3664 lr: 0.00070\n",
      "Epoch 17/Step 760, Loss: -0.23549, Accuracy: 0.99900, F1: 0.0609, Prec: 0.6124, Rec: 0.3661 lr: 0.00070\n",
      "Epoch 17/Step 770, Loss: -0.24672, Accuracy: 0.99900, F1: 0.0620, Prec: 0.6121, Rec: 0.3662 lr: 0.00070\n",
      "Epoch 17/Step 780, Loss: -0.19149, Accuracy: 0.99900, F1: 0.0612, Prec: 0.6125, Rec: 0.3664 lr: 0.00070\n",
      "Epoch 17/Step 790, Loss: -0.24095, Accuracy: 0.99900, F1: 0.0604, Prec: 0.6127, Rec: 0.3660 lr: 0.00070\n",
      "Epoch 17/Step 800, Loss: -0.20876, Accuracy: 0.99900, F1: 0.0597, Prec: 0.6127, Rec: 0.3659 lr: 0.00070\n",
      "Epoch 17/Step 810, Loss: -0.16748, Accuracy: 0.99900, F1: 0.0589, Prec: 0.6121, Rec: 0.3661 lr: 0.00070\n",
      "Epoch 17/Step 820, Loss: -0.22206, Accuracy: 0.99900, F1: 0.0582, Prec: 0.6120, Rec: 0.3659 lr: 0.00070\n",
      "Epoch 17/Step 830, Loss: -0.25036, Accuracy: 0.99900, F1: 0.0586, Prec: 0.6126, Rec: 0.3659 lr: 0.00070\n",
      "Epoch 17/Step 840, Loss: -0.26233, Accuracy: 0.99900, F1: 0.0579, Prec: 0.6129, Rec: 0.3662 lr: 0.00070\n",
      "Epoch 17/Step 850, Loss: -0.22631, Accuracy: 0.99900, F1: 0.0582, Prec: 0.6125, Rec: 0.3660 lr: 0.00070\n",
      "Epoch 17/Step 860, Loss: -0.22355, Accuracy: 0.99900, F1: 0.0596, Prec: 0.6126, Rec: 0.3660 lr: 0.00070\n",
      "Epoch 17/Step 870, Loss: -0.22200, Accuracy: 0.99900, F1: 0.0589, Prec: 0.6122, Rec: 0.3657 lr: 0.00070\n",
      "Epoch 17/Step 880, Loss: -0.20341, Accuracy: 0.99900, F1: 0.0583, Prec: 0.6121, Rec: 0.3657 lr: 0.00070\n",
      "Epoch 17/Step 890, Loss: -0.21804, Accuracy: 0.99900, F1: 0.0576, Prec: 0.6117, Rec: 0.3656 lr: 0.00070\n",
      "Epoch 17/Step 900, Loss: -0.27027, Accuracy: 0.99900, F1: 0.0570, Prec: 0.6120, Rec: 0.3657 lr: 0.00070\n",
      "Epoch 17/Step 910, Loss: -0.19266, Accuracy: 0.99900, F1: 0.0563, Prec: 0.6121, Rec: 0.3655 lr: 0.00070\n",
      "Epoch 17/Step 920, Loss: -0.22653, Accuracy: 0.99900, F1: 0.0557, Prec: 0.6121, Rec: 0.3651 lr: 0.00070\n",
      "Epoch 17/Step 930, Loss: -0.22061, Accuracy: 0.99900, F1: 0.0551, Prec: 0.6122, Rec: 0.3653 lr: 0.00070\n",
      "Epoch 17/Step 940, Loss: -0.21970, Accuracy: 0.99900, F1: 0.0545, Prec: 0.6119, Rec: 0.3654 lr: 0.00070\n",
      "Epoch 17/Step 950, Loss: -0.24886, Accuracy: 0.99900, F1: 0.0540, Prec: 0.6121, Rec: 0.3656 lr: 0.00070\n",
      "Epoch 17/Step 960, Loss: -0.25610, Accuracy: 0.99900, F1: 0.0543, Prec: 0.6120, Rec: 0.3656 lr: 0.00070\n",
      "Epoch 17/Step 970, Loss: -0.19789, Accuracy: 0.99900, F1: 0.0547, Prec: 0.6119, Rec: 0.3652 lr: 0.00070\n",
      "Epoch 17/Step 980, Loss: -0.23935, Accuracy: 0.99900, F1: 0.0541, Prec: 0.6118, Rec: 0.3649 lr: 0.00070\n",
      "Epoch 17/Step 990, Loss: -0.22239, Accuracy: 0.99900, F1: 0.0544, Prec: 0.6111, Rec: 0.3649 lr: 0.00070\n",
      "Epoch 17/Step 1000, Loss: -0.22860, Accuracy: 0.99901, F1: 0.0557, Prec: 0.6116, Rec: 0.3650 lr: 0.00070\n",
      "Epoch 17/Step 1010, Loss: -0.24096, Accuracy: 0.99900, F1: 0.0568, Prec: 0.6121, Rec: 0.3651 lr: 0.00070\n",
      "Epoch 17/Step 1020, Loss: -0.18872, Accuracy: 0.99901, F1: 0.0570, Prec: 0.6115, Rec: 0.3652 lr: 0.00070\n",
      "Epoch 17/Step 1030, Loss: -0.24023, Accuracy: 0.99901, F1: 0.0565, Prec: 0.6115, Rec: 0.3651 lr: 0.00070\n",
      "Epoch 17/Step 1040, Loss: -0.22705, Accuracy: 0.99901, F1: 0.0559, Prec: 0.6119, Rec: 0.3649 lr: 0.00070\n",
      "Epoch 17/Step 1050, Loss: -0.25631, Accuracy: 0.99901, F1: 0.0563, Prec: 0.6117, Rec: 0.3649 lr: 0.00070\n",
      "Epoch 17/Step 1060, Loss: -0.25082, Accuracy: 0.99901, F1: 0.0565, Prec: 0.6115, Rec: 0.3653 lr: 0.00070\n",
      "Epoch 17/Step 1070, Loss: -0.22138, Accuracy: 0.99901, F1: 0.0586, Prec: 0.6120, Rec: 0.3651 lr: 0.00070\n",
      "Epoch 17/Step 1080, Loss: -0.21443, Accuracy: 0.99901, F1: 0.0587, Prec: 0.6118, Rec: 0.3652 lr: 0.00070\n",
      "Epoch 17/Step 1090, Loss: -0.22366, Accuracy: 0.99901, F1: 0.0582, Prec: 0.6112, Rec: 0.3653 lr: 0.00070\n",
      "Epoch 17/Step 1100, Loss: -0.23669, Accuracy: 0.99901, F1: 0.0576, Prec: 0.6115, Rec: 0.3652 lr: 0.00070\n",
      "Epoch 17/Step 1110, Loss: -0.19419, Accuracy: 0.99901, F1: 0.0571, Prec: 0.6114, Rec: 0.3652 lr: 0.00070\n",
      "Epoch 17/Step 1120, Loss: -0.19879, Accuracy: 0.99901, F1: 0.0573, Prec: 0.6111, Rec: 0.3652 lr: 0.00070\n",
      "Epoch 17/Step 1130, Loss: -0.20988, Accuracy: 0.99901, F1: 0.0576, Prec: 0.6112, Rec: 0.3654 lr: 0.00070\n",
      "Epoch 17/Step 1140, Loss: -0.22436, Accuracy: 0.99901, F1: 0.0571, Prec: 0.6113, Rec: 0.3655 lr: 0.00070\n",
      "Epoch 17/Step 1150, Loss: -0.26426, Accuracy: 0.99901, F1: 0.0574, Prec: 0.6118, Rec: 0.3655 lr: 0.00070\n",
      "Epoch 17/Step 1160, Loss: -0.19395, Accuracy: 0.99901, F1: 0.0569, Prec: 0.6119, Rec: 0.3659 lr: 0.00070\n",
      "Epoch 17/Step 1170, Loss: -0.20513, Accuracy: 0.99901, F1: 0.0573, Prec: 0.6120, Rec: 0.3659 lr: 0.00070\n",
      "Epoch 17/Step 1180, Loss: -0.19192, Accuracy: 0.99901, F1: 0.0576, Prec: 0.6122, Rec: 0.3657 lr: 0.00070\n",
      "Epoch 17/Step 1190, Loss: -0.23852, Accuracy: 0.99901, F1: 0.0572, Prec: 0.6120, Rec: 0.3657 lr: 0.00070\n",
      "Epoch 17/Step 1200, Loss: -0.21801, Accuracy: 0.99901, F1: 0.0567, Prec: 0.6124, Rec: 0.3659 lr: 0.00070\n",
      "Epoch 17/Step 1210, Loss: -0.24935, Accuracy: 0.99901, F1: 0.0562, Prec: 0.6128, Rec: 0.3659 lr: 0.00070\n",
      "Epoch 17/Step 1220, Loss: -0.24231, Accuracy: 0.99901, F1: 0.0558, Prec: 0.6124, Rec: 0.3661 lr: 0.00070\n",
      "Epoch 17/Step 1230, Loss: -0.22989, Accuracy: 0.99901, F1: 0.0553, Prec: 0.6122, Rec: 0.3661 lr: 0.00070\n",
      "Epoch 17/Step 1240, Loss: -0.27818, Accuracy: 0.99901, F1: 0.0549, Prec: 0.6125, Rec: 0.3659 lr: 0.00070\n",
      "Epoch 17/Step 1250, Loss: -0.16913, Accuracy: 0.99901, F1: 0.0551, Prec: 0.6124, Rec: 0.3660 lr: 0.00070\n",
      "Epoch 17/Step 1260, Loss: -0.24126, Accuracy: 0.99901, F1: 0.0552, Prec: 0.6123, Rec: 0.3661 lr: 0.00070\n",
      "Epoch 17/Step 1270, Loss: -0.20732, Accuracy: 0.99901, F1: 0.0554, Prec: 0.6125, Rec: 0.3661 lr: 0.00070\n",
      "Epoch 17/Step 1280, Loss: -0.28654, Accuracy: 0.99902, F1: 0.0570, Prec: 0.6126, Rec: 0.3661 lr: 0.00070\n",
      "Epoch 17/Step 1290, Loss: -0.23803, Accuracy: 0.99902, F1: 0.0579, Prec: 0.6126, Rec: 0.3662 lr: 0.00070\n",
      "Epoch 17/Step 1300, Loss: -0.20511, Accuracy: 0.99902, F1: 0.0574, Prec: 0.6125, Rec: 0.3662 lr: 0.00070\n",
      "Epoch 17/Step 1310, Loss: -0.22993, Accuracy: 0.99902, F1: 0.0584, Prec: 0.6125, Rec: 0.3662 lr: 0.00070\n",
      "Epoch 17/Step 1320, Loss: -0.24740, Accuracy: 0.99902, F1: 0.0588, Prec: 0.6124, Rec: 0.3664 lr: 0.00070\n",
      "Epoch 17/Step 1330, Loss: -0.24095, Accuracy: 0.99901, F1: 0.0590, Prec: 0.6124, Rec: 0.3662 lr: 0.00070\n",
      "Epoch 17/Step 1340, Loss: -0.22757, Accuracy: 0.99901, F1: 0.0586, Prec: 0.6125, Rec: 0.3663 lr: 0.00070\n",
      "Epoch 17/Step 1350, Loss: -0.19226, Accuracy: 0.99902, F1: 0.0582, Prec: 0.6125, Rec: 0.3664 lr: 0.00070\n",
      "Epoch 17/Step 1360, Loss: -0.21902, Accuracy: 0.99902, F1: 0.0590, Prec: 0.6128, Rec: 0.3664 lr: 0.00070\n",
      "Epoch 17/Step 1370, Loss: -0.22770, Accuracy: 0.99902, F1: 0.0592, Prec: 0.6130, Rec: 0.3666 lr: 0.00070\n",
      "Epoch 17/Step 1380, Loss: -0.21798, Accuracy: 0.99902, F1: 0.0588, Prec: 0.6128, Rec: 0.3667 lr: 0.00070\n",
      "Epoch 17/Step 1390, Loss: -0.23547, Accuracy: 0.99902, F1: 0.0589, Prec: 0.6128, Rec: 0.3666 lr: 0.00070\n",
      "Epoch 17/Step 1400, Loss: -0.24389, Accuracy: 0.99902, F1: 0.0591, Prec: 0.6131, Rec: 0.3667 lr: 0.00070\n",
      "Epoch 17/Step 1410, Loss: -0.21730, Accuracy: 0.99902, F1: 0.0587, Prec: 0.6134, Rec: 0.3666 lr: 0.00070\n",
      "Epoch 17/Step 1420, Loss: -0.21445, Accuracy: 0.99902, F1: 0.0588, Prec: 0.6133, Rec: 0.3665 lr: 0.00070\n",
      "Epoch 17/Step 1430, Loss: -0.20808, Accuracy: 0.99902, F1: 0.0584, Prec: 0.6135, Rec: 0.3663 lr: 0.00070\n",
      "Epoch 17/Step 1440, Loss: -0.21692, Accuracy: 0.99902, F1: 0.0587, Prec: 0.6136, Rec: 0.3663 lr: 0.00070\n",
      "Epoch 17/Step 1450, Loss: -0.21950, Accuracy: 0.99902, F1: 0.0583, Prec: 0.6137, Rec: 0.3664 lr: 0.00070\n",
      "Epoch 17/Step 1460, Loss: -0.21600, Accuracy: 0.99902, F1: 0.0579, Prec: 0.6134, Rec: 0.3664 lr: 0.00070\n",
      "Epoch 17/Step 1470, Loss: -0.21636, Accuracy: 0.99902, F1: 0.0575, Prec: 0.6136, Rec: 0.3663 lr: 0.00070\n",
      "Epoch 17/Step 1480, Loss: -0.22478, Accuracy: 0.99902, F1: 0.0583, Prec: 0.6137, Rec: 0.3663 lr: 0.00070\n",
      "Epoch 17/Step 1490, Loss: -0.21085, Accuracy: 0.99902, F1: 0.0579, Prec: 0.6134, Rec: 0.3662 lr: 0.00070\n",
      "Epoch 17/Step 1500, Loss: -0.22392, Accuracy: 0.99902, F1: 0.0585, Prec: 0.6135, Rec: 0.3663 lr: 0.00070\n",
      "Epoch 17/Step 1510, Loss: -0.21370, Accuracy: 0.99902, F1: 0.0581, Prec: 0.6134, Rec: 0.3663 lr: 0.00070\n",
      "Epoch 17/Step 1520, Loss: -0.27123, Accuracy: 0.99902, F1: 0.0582, Prec: 0.6137, Rec: 0.3665 lr: 0.00070\n",
      "Epoch 17/Step 1530, Loss: -0.20806, Accuracy: 0.99902, F1: 0.0585, Prec: 0.6139, Rec: 0.3665 lr: 0.00070\n",
      "Epoch 17/Step 1540, Loss: -0.20077, Accuracy: 0.99902, F1: 0.0588, Prec: 0.6139, Rec: 0.3663 lr: 0.00070\n",
      "Epoch 17/Step 1550, Loss: -0.21833, Accuracy: 0.99902, F1: 0.0606, Prec: 0.6137, Rec: 0.3663 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9987\n",
      "Validation f1: 0.1350\n",
      "Validation precision: 0.3924\n",
      "Validation recall: 0.2011\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_16_valF1Score0.135/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_16_valF1Score0.135/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 18\n",
      "Epoch 18/Step 0, Loss: -0.25093, Accuracy: 0.99917, F1: 0.0000, Prec: 0.7027, Rec: 0.4038 lr: 0.00070\n",
      "Epoch 18/Step 10, Loss: -0.26519, Accuracy: 0.99899, F1: 0.0847, Prec: 0.6648, Rec: 0.3757 lr: 0.00070\n",
      "Epoch 18/Step 20, Loss: -0.24545, Accuracy: 0.99902, F1: 0.0877, Prec: 0.6393, Rec: 0.3789 lr: 0.00070\n",
      "Epoch 18/Step 30, Loss: -0.21160, Accuracy: 0.99904, F1: 0.0905, Prec: 0.6328, Rec: 0.3808 lr: 0.00070\n",
      "Epoch 18/Step 40, Loss: -0.20306, Accuracy: 0.99904, F1: 0.0684, Prec: 0.6525, Rec: 0.3742 lr: 0.00070\n",
      "Epoch 18/Step 50, Loss: -0.23625, Accuracy: 0.99905, F1: 0.0550, Prec: 0.6575, Rec: 0.3760 lr: 0.00070\n",
      "Epoch 18/Step 60, Loss: -0.23998, Accuracy: 0.99906, F1: 0.0593, Prec: 0.6506, Rec: 0.3799 lr: 0.00070\n",
      "Epoch 18/Step 70, Loss: -0.23567, Accuracy: 0.99907, F1: 0.0510, Prec: 0.6496, Rec: 0.3819 lr: 0.00070\n",
      "Epoch 18/Step 80, Loss: -0.21831, Accuracy: 0.99907, F1: 0.0681, Prec: 0.6484, Rec: 0.3785 lr: 0.00070\n",
      "Epoch 18/Step 90, Loss: -0.21016, Accuracy: 0.99906, F1: 0.0778, Prec: 0.6441, Rec: 0.3785 lr: 0.00070\n",
      "Epoch 18/Step 100, Loss: -0.23459, Accuracy: 0.99907, F1: 0.0869, Prec: 0.6441, Rec: 0.3796 lr: 0.00070\n",
      "Epoch 18/Step 110, Loss: -0.23225, Accuracy: 0.99906, F1: 0.0922, Prec: 0.6430, Rec: 0.3794 lr: 0.00070\n",
      "Epoch 18/Step 120, Loss: -0.21668, Accuracy: 0.99905, F1: 0.0907, Prec: 0.6410, Rec: 0.3784 lr: 0.00070\n",
      "Epoch 18/Step 130, Loss: -0.18686, Accuracy: 0.99905, F1: 0.1104, Prec: 0.6384, Rec: 0.3788 lr: 0.00070\n",
      "Epoch 18/Step 140, Loss: -0.20487, Accuracy: 0.99904, F1: 0.1086, Prec: 0.6356, Rec: 0.3760 lr: 0.00070\n",
      "Epoch 18/Step 150, Loss: -0.21992, Accuracy: 0.99903, F1: 0.1014, Prec: 0.6328, Rec: 0.3744 lr: 0.00070\n",
      "Epoch 18/Step 160, Loss: -0.24953, Accuracy: 0.99903, F1: 0.1001, Prec: 0.6302, Rec: 0.3749 lr: 0.00070\n",
      "Epoch 18/Step 170, Loss: -0.22091, Accuracy: 0.99903, F1: 0.1032, Prec: 0.6296, Rec: 0.3736 lr: 0.00070\n",
      "Epoch 18/Step 180, Loss: -0.27207, Accuracy: 0.99903, F1: 0.0975, Prec: 0.6276, Rec: 0.3749 lr: 0.00070\n",
      "Epoch 18/Step 190, Loss: -0.21332, Accuracy: 0.99902, F1: 0.0971, Prec: 0.6249, Rec: 0.3749 lr: 0.00070\n",
      "Epoch 18/Step 200, Loss: -0.24958, Accuracy: 0.99902, F1: 0.1011, Prec: 0.6266, Rec: 0.3739 lr: 0.00070\n",
      "Epoch 18/Step 210, Loss: -0.19555, Accuracy: 0.99902, F1: 0.1044, Prec: 0.6262, Rec: 0.3730 lr: 0.00070\n",
      "Epoch 18/Step 220, Loss: -0.24593, Accuracy: 0.99901, F1: 0.0997, Prec: 0.6236, Rec: 0.3740 lr: 0.00070\n",
      "Epoch 18/Step 230, Loss: -0.20616, Accuracy: 0.99901, F1: 0.0953, Prec: 0.6242, Rec: 0.3732 lr: 0.00070\n",
      "Epoch 18/Step 240, Loss: -0.26764, Accuracy: 0.99901, F1: 0.0914, Prec: 0.6260, Rec: 0.3725 lr: 0.00070\n",
      "Epoch 18/Step 250, Loss: -0.24558, Accuracy: 0.99901, F1: 0.0944, Prec: 0.6256, Rec: 0.3723 lr: 0.00070\n",
      "Epoch 18/Step 260, Loss: -0.25927, Accuracy: 0.99901, F1: 0.0908, Prec: 0.6244, Rec: 0.3729 lr: 0.00070\n",
      "Epoch 18/Step 270, Loss: -0.26093, Accuracy: 0.99900, F1: 0.0875, Prec: 0.6244, Rec: 0.3726 lr: 0.00070\n",
      "Epoch 18/Step 280, Loss: -0.23267, Accuracy: 0.99900, F1: 0.0844, Prec: 0.6245, Rec: 0.3713 lr: 0.00070\n",
      "Epoch 18/Step 290, Loss: -0.22105, Accuracy: 0.99900, F1: 0.0836, Prec: 0.6238, Rec: 0.3716 lr: 0.00070\n",
      "Epoch 18/Step 300, Loss: -0.25099, Accuracy: 0.99900, F1: 0.0837, Prec: 0.6244, Rec: 0.3715 lr: 0.00070\n",
      "Epoch 18/Step 310, Loss: -0.23833, Accuracy: 0.99901, F1: 0.0845, Prec: 0.6253, Rec: 0.3712 lr: 0.00070\n",
      "Epoch 18/Step 320, Loss: -0.22848, Accuracy: 0.99901, F1: 0.0846, Prec: 0.6265, Rec: 0.3714 lr: 0.00070\n",
      "Epoch 18/Step 330, Loss: -0.23868, Accuracy: 0.99901, F1: 0.0820, Prec: 0.6253, Rec: 0.3717 lr: 0.00070\n",
      "Epoch 18/Step 340, Loss: -0.22754, Accuracy: 0.99901, F1: 0.0796, Prec: 0.6252, Rec: 0.3717 lr: 0.00070\n",
      "Epoch 18/Step 350, Loss: -0.19875, Accuracy: 0.99901, F1: 0.0773, Prec: 0.6267, Rec: 0.3719 lr: 0.00070\n",
      "Epoch 18/Step 360, Loss: -0.23484, Accuracy: 0.99901, F1: 0.0752, Prec: 0.6266, Rec: 0.3727 lr: 0.00070\n",
      "Epoch 18/Step 370, Loss: -0.23911, Accuracy: 0.99901, F1: 0.0732, Prec: 0.6260, Rec: 0.3730 lr: 0.00070\n",
      "Epoch 18/Step 380, Loss: -0.24645, Accuracy: 0.99901, F1: 0.0739, Prec: 0.6259, Rec: 0.3727 lr: 0.00070\n",
      "Epoch 18/Step 390, Loss: -0.20447, Accuracy: 0.99901, F1: 0.0738, Prec: 0.6268, Rec: 0.3723 lr: 0.00070\n",
      "Epoch 18/Step 400, Loss: -0.18769, Accuracy: 0.99901, F1: 0.0720, Prec: 0.6273, Rec: 0.3717 lr: 0.00070\n",
      "Epoch 18/Step 410, Loss: -0.19418, Accuracy: 0.99901, F1: 0.0702, Prec: 0.6269, Rec: 0.3717 lr: 0.00070\n",
      "Epoch 18/Step 420, Loss: -0.24425, Accuracy: 0.99901, F1: 0.0686, Prec: 0.6275, Rec: 0.3720 lr: 0.00070\n",
      "Epoch 18/Step 430, Loss: -0.22561, Accuracy: 0.99902, F1: 0.0670, Prec: 0.6271, Rec: 0.3723 lr: 0.00070\n",
      "Epoch 18/Step 440, Loss: -0.24704, Accuracy: 0.99901, F1: 0.0694, Prec: 0.6269, Rec: 0.3722 lr: 0.00070\n",
      "Epoch 18/Step 450, Loss: -0.24036, Accuracy: 0.99901, F1: 0.0678, Prec: 0.6276, Rec: 0.3720 lr: 0.00070\n",
      "Epoch 18/Step 460, Loss: -0.20719, Accuracy: 0.99901, F1: 0.0664, Prec: 0.6259, Rec: 0.3722 lr: 0.00070\n",
      "Epoch 18/Step 470, Loss: -0.22593, Accuracy: 0.99901, F1: 0.0650, Prec: 0.6256, Rec: 0.3721 lr: 0.00070\n",
      "Epoch 18/Step 480, Loss: -0.21635, Accuracy: 0.99901, F1: 0.0655, Prec: 0.6252, Rec: 0.3710 lr: 0.00070\n",
      "Epoch 18/Step 490, Loss: -0.22177, Accuracy: 0.99901, F1: 0.0642, Prec: 0.6254, Rec: 0.3705 lr: 0.00070\n",
      "Epoch 18/Step 500, Loss: -0.23606, Accuracy: 0.99901, F1: 0.0629, Prec: 0.6254, Rec: 0.3706 lr: 0.00070\n",
      "Epoch 18/Step 510, Loss: -0.27707, Accuracy: 0.99901, F1: 0.0628, Prec: 0.6241, Rec: 0.3710 lr: 0.00070\n",
      "Epoch 18/Step 520, Loss: -0.21645, Accuracy: 0.99901, F1: 0.0616, Prec: 0.6245, Rec: 0.3712 lr: 0.00070\n",
      "Epoch 18/Step 530, Loss: -0.22409, Accuracy: 0.99901, F1: 0.0617, Prec: 0.6242, Rec: 0.3706 lr: 0.00070\n",
      "Epoch 18/Step 540, Loss: -0.22441, Accuracy: 0.99901, F1: 0.0606, Prec: 0.6239, Rec: 0.3705 lr: 0.00070\n",
      "Epoch 18/Step 550, Loss: -0.25996, Accuracy: 0.99901, F1: 0.0623, Prec: 0.6233, Rec: 0.3707 lr: 0.00070\n",
      "Epoch 18/Step 560, Loss: -0.21535, Accuracy: 0.99901, F1: 0.0612, Prec: 0.6231, Rec: 0.3707 lr: 0.00070\n",
      "Epoch 18/Step 570, Loss: -0.22782, Accuracy: 0.99901, F1: 0.0601, Prec: 0.6229, Rec: 0.3705 lr: 0.00070\n",
      "Epoch 18/Step 580, Loss: -0.19748, Accuracy: 0.99901, F1: 0.0604, Prec: 0.6224, Rec: 0.3705 lr: 0.00070\n",
      "Epoch 18/Step 590, Loss: -0.17900, Accuracy: 0.99901, F1: 0.0618, Prec: 0.6217, Rec: 0.3704 lr: 0.00070\n",
      "Epoch 18/Step 600, Loss: -0.21933, Accuracy: 0.99901, F1: 0.0626, Prec: 0.6217, Rec: 0.3703 lr: 0.00070\n",
      "Epoch 18/Step 610, Loss: -0.27281, Accuracy: 0.99901, F1: 0.0615, Prec: 0.6219, Rec: 0.3704 lr: 0.00070\n",
      "Epoch 18/Step 620, Loss: -0.25539, Accuracy: 0.99900, F1: 0.0622, Prec: 0.6221, Rec: 0.3708 lr: 0.00070\n",
      "Epoch 18/Step 630, Loss: -0.21280, Accuracy: 0.99900, F1: 0.0612, Prec: 0.6215, Rec: 0.3709 lr: 0.00070\n",
      "Epoch 18/Step 640, Loss: -0.21070, Accuracy: 0.99900, F1: 0.0629, Prec: 0.6214, Rec: 0.3708 lr: 0.00070\n",
      "Epoch 18/Step 650, Loss: -0.21094, Accuracy: 0.99901, F1: 0.0619, Prec: 0.6217, Rec: 0.3708 lr: 0.00070\n",
      "Epoch 18/Step 660, Loss: -0.24338, Accuracy: 0.99901, F1: 0.0627, Prec: 0.6214, Rec: 0.3709 lr: 0.00070\n",
      "Epoch 18/Step 670, Loss: -0.22388, Accuracy: 0.99901, F1: 0.0618, Prec: 0.6216, Rec: 0.3709 lr: 0.00070\n",
      "Epoch 18/Step 680, Loss: -0.19433, Accuracy: 0.99901, F1: 0.0620, Prec: 0.6222, Rec: 0.3710 lr: 0.00070\n",
      "Epoch 18/Step 690, Loss: -0.25735, Accuracy: 0.99901, F1: 0.0611, Prec: 0.6217, Rec: 0.3710 lr: 0.00070\n",
      "Epoch 18/Step 700, Loss: -0.23574, Accuracy: 0.99901, F1: 0.0602, Prec: 0.6213, Rec: 0.3710 lr: 0.00070\n",
      "Epoch 18/Step 710, Loss: -0.24141, Accuracy: 0.99901, F1: 0.0594, Prec: 0.6217, Rec: 0.3714 lr: 0.00070\n",
      "Epoch 18/Step 720, Loss: -0.25170, Accuracy: 0.99901, F1: 0.0585, Prec: 0.6222, Rec: 0.3710 lr: 0.00070\n",
      "Epoch 18/Step 730, Loss: -0.21386, Accuracy: 0.99901, F1: 0.0577, Prec: 0.6219, Rec: 0.3708 lr: 0.00070\n",
      "Epoch 18/Step 740, Loss: -0.23029, Accuracy: 0.99901, F1: 0.0581, Prec: 0.6217, Rec: 0.3708 lr: 0.00070\n",
      "Epoch 18/Step 750, Loss: -0.24234, Accuracy: 0.99901, F1: 0.0573, Prec: 0.6217, Rec: 0.3707 lr: 0.00070\n",
      "Epoch 18/Step 760, Loss: -0.23951, Accuracy: 0.99901, F1: 0.0577, Prec: 0.6219, Rec: 0.3704 lr: 0.00070\n",
      "Epoch 18/Step 770, Loss: -0.24963, Accuracy: 0.99901, F1: 0.0570, Prec: 0.6214, Rec: 0.3706 lr: 0.00070\n",
      "Epoch 18/Step 780, Loss: -0.18557, Accuracy: 0.99901, F1: 0.0563, Prec: 0.6221, Rec: 0.3708 lr: 0.00070\n",
      "Epoch 18/Step 790, Loss: -0.25168, Accuracy: 0.99901, F1: 0.0555, Prec: 0.6223, Rec: 0.3704 lr: 0.00070\n",
      "Epoch 18/Step 800, Loss: -0.20438, Accuracy: 0.99901, F1: 0.0548, Prec: 0.6227, Rec: 0.3702 lr: 0.00070\n",
      "Epoch 18/Step 810, Loss: -0.16717, Accuracy: 0.99901, F1: 0.0542, Prec: 0.6222, Rec: 0.3703 lr: 0.00070\n",
      "Epoch 18/Step 820, Loss: -0.22773, Accuracy: 0.99901, F1: 0.0535, Prec: 0.6219, Rec: 0.3703 lr: 0.00070\n",
      "Epoch 18/Step 830, Loss: -0.25370, Accuracy: 0.99901, F1: 0.0529, Prec: 0.6227, Rec: 0.3703 lr: 0.00070\n",
      "Epoch 18/Step 840, Loss: -0.27207, Accuracy: 0.99901, F1: 0.0522, Prec: 0.6230, Rec: 0.3705 lr: 0.00070\n",
      "Epoch 18/Step 850, Loss: -0.23082, Accuracy: 0.99901, F1: 0.0516, Prec: 0.6224, Rec: 0.3704 lr: 0.00070\n",
      "Epoch 18/Step 860, Loss: -0.23384, Accuracy: 0.99901, F1: 0.0521, Prec: 0.6227, Rec: 0.3704 lr: 0.00070\n",
      "Epoch 18/Step 870, Loss: -0.23111, Accuracy: 0.99901, F1: 0.0515, Prec: 0.6223, Rec: 0.3700 lr: 0.00070\n",
      "Epoch 18/Step 880, Loss: -0.20545, Accuracy: 0.99901, F1: 0.0509, Prec: 0.6224, Rec: 0.3701 lr: 0.00070\n",
      "Epoch 18/Step 890, Loss: -0.21949, Accuracy: 0.99901, F1: 0.0503, Prec: 0.6222, Rec: 0.3699 lr: 0.00070\n",
      "Epoch 18/Step 900, Loss: -0.27522, Accuracy: 0.99901, F1: 0.0498, Prec: 0.6227, Rec: 0.3699 lr: 0.00070\n",
      "Epoch 18/Step 910, Loss: -0.19102, Accuracy: 0.99901, F1: 0.0492, Prec: 0.6226, Rec: 0.3696 lr: 0.00070\n",
      "Epoch 18/Step 920, Loss: -0.22709, Accuracy: 0.99901, F1: 0.0487, Prec: 0.6227, Rec: 0.3693 lr: 0.00070\n",
      "Epoch 18/Step 930, Loss: -0.22626, Accuracy: 0.99901, F1: 0.0481, Prec: 0.6228, Rec: 0.3694 lr: 0.00070\n",
      "Epoch 18/Step 940, Loss: -0.22458, Accuracy: 0.99902, F1: 0.0476, Prec: 0.6226, Rec: 0.3695 lr: 0.00070\n",
      "Epoch 18/Step 950, Loss: -0.25190, Accuracy: 0.99902, F1: 0.0471, Prec: 0.6226, Rec: 0.3696 lr: 0.00070\n",
      "Epoch 18/Step 960, Loss: -0.25461, Accuracy: 0.99902, F1: 0.0466, Prec: 0.6226, Rec: 0.3696 lr: 0.00070\n",
      "Epoch 18/Step 970, Loss: -0.19760, Accuracy: 0.99902, F1: 0.0462, Prec: 0.6223, Rec: 0.3693 lr: 0.00070\n",
      "Epoch 18/Step 980, Loss: -0.23550, Accuracy: 0.99902, F1: 0.0457, Prec: 0.6222, Rec: 0.3690 lr: 0.00070\n",
      "Epoch 18/Step 990, Loss: -0.22176, Accuracy: 0.99902, F1: 0.0452, Prec: 0.6215, Rec: 0.3690 lr: 0.00070\n",
      "Epoch 18/Step 1000, Loss: -0.23250, Accuracy: 0.99902, F1: 0.0448, Prec: 0.6217, Rec: 0.3692 lr: 0.00070\n",
      "Epoch 18/Step 1010, Loss: -0.24256, Accuracy: 0.99902, F1: 0.0443, Prec: 0.6222, Rec: 0.3693 lr: 0.00070\n",
      "Epoch 18/Step 1020, Loss: -0.19228, Accuracy: 0.99902, F1: 0.0439, Prec: 0.6217, Rec: 0.3693 lr: 0.00070\n",
      "Epoch 18/Step 1030, Loss: -0.23580, Accuracy: 0.99902, F1: 0.0444, Prec: 0.6216, Rec: 0.3692 lr: 0.00070\n",
      "Epoch 18/Step 1040, Loss: -0.22888, Accuracy: 0.99902, F1: 0.0440, Prec: 0.6217, Rec: 0.3691 lr: 0.00070\n",
      "Epoch 18/Step 1050, Loss: -0.26612, Accuracy: 0.99902, F1: 0.0436, Prec: 0.6219, Rec: 0.3691 lr: 0.00070\n",
      "Epoch 18/Step 1060, Loss: -0.25170, Accuracy: 0.99902, F1: 0.0432, Prec: 0.6219, Rec: 0.3694 lr: 0.00070\n",
      "Epoch 18/Step 1070, Loss: -0.23276, Accuracy: 0.99902, F1: 0.0436, Prec: 0.6221, Rec: 0.3694 lr: 0.00070\n",
      "Epoch 18/Step 1080, Loss: -0.21636, Accuracy: 0.99902, F1: 0.0439, Prec: 0.6221, Rec: 0.3695 lr: 0.00070\n",
      "Epoch 18/Step 1090, Loss: -0.23137, Accuracy: 0.99902, F1: 0.0435, Prec: 0.6218, Rec: 0.3695 lr: 0.00070\n",
      "Epoch 18/Step 1100, Loss: -0.23353, Accuracy: 0.99902, F1: 0.0432, Prec: 0.6218, Rec: 0.3695 lr: 0.00070\n",
      "Epoch 18/Step 1110, Loss: -0.19315, Accuracy: 0.99902, F1: 0.0428, Prec: 0.6219, Rec: 0.3694 lr: 0.00070\n",
      "Epoch 18/Step 1120, Loss: -0.20731, Accuracy: 0.99902, F1: 0.0430, Prec: 0.6218, Rec: 0.3694 lr: 0.00070\n",
      "Epoch 18/Step 1130, Loss: -0.20247, Accuracy: 0.99902, F1: 0.0426, Prec: 0.6216, Rec: 0.3696 lr: 0.00070\n",
      "Epoch 18/Step 1140, Loss: -0.23073, Accuracy: 0.99902, F1: 0.0423, Prec: 0.6218, Rec: 0.3697 lr: 0.00070\n",
      "Epoch 18/Step 1150, Loss: -0.26027, Accuracy: 0.99902, F1: 0.0427, Prec: 0.6222, Rec: 0.3697 lr: 0.00070\n",
      "Epoch 18/Step 1160, Loss: -0.19193, Accuracy: 0.99902, F1: 0.0424, Prec: 0.6222, Rec: 0.3701 lr: 0.00070\n",
      "Epoch 18/Step 1170, Loss: -0.20877, Accuracy: 0.99902, F1: 0.0420, Prec: 0.6223, Rec: 0.3700 lr: 0.00070\n",
      "Epoch 18/Step 1180, Loss: -0.19054, Accuracy: 0.99902, F1: 0.0416, Prec: 0.6224, Rec: 0.3699 lr: 0.00070\n",
      "Epoch 18/Step 1190, Loss: -0.24777, Accuracy: 0.99902, F1: 0.0413, Prec: 0.6221, Rec: 0.3698 lr: 0.00070\n",
      "Epoch 18/Step 1200, Loss: -0.22435, Accuracy: 0.99902, F1: 0.0409, Prec: 0.6224, Rec: 0.3701 lr: 0.00070\n",
      "Epoch 18/Step 1210, Loss: -0.25236, Accuracy: 0.99903, F1: 0.0406, Prec: 0.6226, Rec: 0.3702 lr: 0.00070\n",
      "Epoch 18/Step 1220, Loss: -0.25401, Accuracy: 0.99903, F1: 0.0403, Prec: 0.6226, Rec: 0.3703 lr: 0.00070\n",
      "Epoch 18/Step 1230, Loss: -0.22608, Accuracy: 0.99903, F1: 0.0399, Prec: 0.6226, Rec: 0.3703 lr: 0.00070\n",
      "Epoch 18/Step 1240, Loss: -0.27406, Accuracy: 0.99903, F1: 0.0396, Prec: 0.6227, Rec: 0.3702 lr: 0.00070\n",
      "Epoch 18/Step 1250, Loss: -0.17158, Accuracy: 0.99903, F1: 0.0393, Prec: 0.6226, Rec: 0.3702 lr: 0.00070\n",
      "Epoch 18/Step 1260, Loss: -0.24398, Accuracy: 0.99903, F1: 0.0390, Prec: 0.6226, Rec: 0.3704 lr: 0.00070\n",
      "Epoch 18/Step 1270, Loss: -0.22880, Accuracy: 0.99903, F1: 0.0387, Prec: 0.6229, Rec: 0.3703 lr: 0.00070\n",
      "Epoch 18/Step 1280, Loss: -0.29403, Accuracy: 0.99903, F1: 0.0384, Prec: 0.6230, Rec: 0.3703 lr: 0.00070\n",
      "Epoch 18/Step 1290, Loss: -0.24602, Accuracy: 0.99903, F1: 0.0389, Prec: 0.6231, Rec: 0.3704 lr: 0.00070\n",
      "Epoch 18/Step 1300, Loss: -0.21194, Accuracy: 0.99903, F1: 0.0386, Prec: 0.6230, Rec: 0.3704 lr: 0.00070\n",
      "Epoch 18/Step 1310, Loss: -0.23164, Accuracy: 0.99903, F1: 0.0383, Prec: 0.6232, Rec: 0.3704 lr: 0.00070\n",
      "Epoch 18/Step 1320, Loss: -0.25232, Accuracy: 0.99903, F1: 0.0380, Prec: 0.6232, Rec: 0.3705 lr: 0.00070\n",
      "Epoch 18/Step 1330, Loss: -0.25047, Accuracy: 0.99903, F1: 0.0384, Prec: 0.6231, Rec: 0.3704 lr: 0.00070\n",
      "Epoch 18/Step 1340, Loss: -0.23499, Accuracy: 0.99903, F1: 0.0381, Prec: 0.6233, Rec: 0.3705 lr: 0.00070\n",
      "Epoch 18/Step 1350, Loss: -0.18740, Accuracy: 0.99903, F1: 0.0378, Prec: 0.6233, Rec: 0.3705 lr: 0.00070\n",
      "Epoch 18/Step 1360, Loss: -0.21789, Accuracy: 0.99903, F1: 0.0382, Prec: 0.6234, Rec: 0.3705 lr: 0.00070\n",
      "Epoch 18/Step 1370, Loss: -0.23026, Accuracy: 0.99903, F1: 0.0386, Prec: 0.6237, Rec: 0.3707 lr: 0.00070\n",
      "Epoch 18/Step 1380, Loss: -0.23029, Accuracy: 0.99903, F1: 0.0383, Prec: 0.6236, Rec: 0.3709 lr: 0.00070\n",
      "Epoch 18/Step 1390, Loss: -0.23839, Accuracy: 0.99903, F1: 0.0380, Prec: 0.6235, Rec: 0.3708 lr: 0.00070\n",
      "Epoch 18/Step 1400, Loss: -0.24991, Accuracy: 0.99903, F1: 0.0378, Prec: 0.6237, Rec: 0.3709 lr: 0.00070\n",
      "Epoch 18/Step 1410, Loss: -0.20935, Accuracy: 0.99903, F1: 0.0375, Prec: 0.6239, Rec: 0.3708 lr: 0.00070\n",
      "Epoch 18/Step 1420, Loss: -0.22258, Accuracy: 0.99903, F1: 0.0378, Prec: 0.6238, Rec: 0.3707 lr: 0.00070\n",
      "Epoch 18/Step 1430, Loss: -0.21682, Accuracy: 0.99903, F1: 0.0375, Prec: 0.6239, Rec: 0.3705 lr: 0.00070\n",
      "Epoch 18/Step 1440, Loss: -0.21477, Accuracy: 0.99903, F1: 0.0380, Prec: 0.6240, Rec: 0.3706 lr: 0.00070\n",
      "Epoch 18/Step 1450, Loss: -0.22052, Accuracy: 0.99903, F1: 0.0378, Prec: 0.6241, Rec: 0.3707 lr: 0.00070\n",
      "Epoch 18/Step 1460, Loss: -0.21914, Accuracy: 0.99903, F1: 0.0375, Prec: 0.6240, Rec: 0.3706 lr: 0.00070\n",
      "Epoch 18/Step 1470, Loss: -0.21767, Accuracy: 0.99903, F1: 0.0372, Prec: 0.6241, Rec: 0.3706 lr: 0.00070\n",
      "Epoch 18/Step 1480, Loss: -0.22655, Accuracy: 0.99903, F1: 0.0370, Prec: 0.6241, Rec: 0.3706 lr: 0.00070\n",
      "Epoch 18/Step 1490, Loss: -0.21325, Accuracy: 0.99903, F1: 0.0367, Prec: 0.6239, Rec: 0.3704 lr: 0.00070\n",
      "Epoch 18/Step 1500, Loss: -0.22948, Accuracy: 0.99903, F1: 0.0375, Prec: 0.6239, Rec: 0.3705 lr: 0.00070\n",
      "Epoch 18/Step 1510, Loss: -0.21397, Accuracy: 0.99903, F1: 0.0373, Prec: 0.6238, Rec: 0.3706 lr: 0.00070\n",
      "Epoch 18/Step 1520, Loss: -0.26777, Accuracy: 0.99903, F1: 0.0375, Prec: 0.6238, Rec: 0.3707 lr: 0.00070\n",
      "Epoch 18/Step 1530, Loss: -0.20976, Accuracy: 0.99903, F1: 0.0379, Prec: 0.6240, Rec: 0.3708 lr: 0.00070\n",
      "Epoch 18/Step 1540, Loss: -0.19432, Accuracy: 0.99903, F1: 0.0376, Prec: 0.6239, Rec: 0.3706 lr: 0.00070\n",
      "Epoch 18/Step 1550, Loss: -0.22528, Accuracy: 0.99903, F1: 0.0390, Prec: 0.6238, Rec: 0.3706 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9987\n",
      "Validation f1: 0.1519\n",
      "Validation precision: 0.3910\n",
      "Validation recall: 0.1988\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_17_valF1Score0.152/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_17_valF1Score0.152/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 19\n",
      "Epoch 19/Step 0, Loss: -0.24494, Accuracy: 0.99914, F1: 0.0000, Prec: 0.6751, Rec: 0.3957 lr: 0.00070\n",
      "Epoch 19/Step 10, Loss: -0.27334, Accuracy: 0.99899, F1: 0.0000, Prec: 0.6606, Rec: 0.3805 lr: 0.00070\n",
      "Epoch 19/Step 20, Loss: -0.23457, Accuracy: 0.99901, F1: 0.0378, Prec: 0.6305, Rec: 0.3855 lr: 0.00070\n",
      "Epoch 19/Step 30, Loss: -0.21046, Accuracy: 0.99903, F1: 0.0548, Prec: 0.6214, Rec: 0.3871 lr: 0.00070\n",
      "Epoch 19/Step 40, Loss: -0.20444, Accuracy: 0.99904, F1: 0.0414, Prec: 0.6388, Rec: 0.3839 lr: 0.00070\n",
      "Epoch 19/Step 50, Loss: -0.23953, Accuracy: 0.99905, F1: 0.0333, Prec: 0.6516, Rec: 0.3822 lr: 0.00070\n",
      "Epoch 19/Step 60, Loss: -0.24577, Accuracy: 0.99906, F1: 0.0415, Prec: 0.6510, Rec: 0.3852 lr: 0.00070\n",
      "Epoch 19/Step 70, Loss: -0.23072, Accuracy: 0.99907, F1: 0.0356, Prec: 0.6440, Rec: 0.3885 lr: 0.00070\n",
      "Epoch 19/Step 80, Loss: -0.22197, Accuracy: 0.99907, F1: 0.0443, Prec: 0.6461, Rec: 0.3846 lr: 0.00070\n",
      "Epoch 19/Step 90, Loss: -0.21130, Accuracy: 0.99906, F1: 0.0564, Prec: 0.6433, Rec: 0.3842 lr: 0.00070\n",
      "Epoch 19/Step 100, Loss: -0.23985, Accuracy: 0.99907, F1: 0.0587, Prec: 0.6397, Rec: 0.3866 lr: 0.00070\n",
      "Epoch 19/Step 110, Loss: -0.22985, Accuracy: 0.99905, F1: 0.0605, Prec: 0.6394, Rec: 0.3852 lr: 0.00070\n",
      "Epoch 19/Step 120, Loss: -0.22675, Accuracy: 0.99905, F1: 0.0617, Prec: 0.6398, Rec: 0.3837 lr: 0.00070\n",
      "Epoch 19/Step 130, Loss: -0.18693, Accuracy: 0.99905, F1: 0.0785, Prec: 0.6387, Rec: 0.3836 lr: 0.00070\n",
      "Epoch 19/Step 140, Loss: -0.20777, Accuracy: 0.99904, F1: 0.0792, Prec: 0.6376, Rec: 0.3806 lr: 0.00070\n",
      "Epoch 19/Step 150, Loss: -0.22273, Accuracy: 0.99903, F1: 0.0739, Prec: 0.6367, Rec: 0.3784 lr: 0.00070\n",
      "Epoch 19/Step 160, Loss: -0.25764, Accuracy: 0.99903, F1: 0.0745, Prec: 0.6346, Rec: 0.3789 lr: 0.00070\n",
      "Epoch 19/Step 170, Loss: -0.23235, Accuracy: 0.99904, F1: 0.0792, Prec: 0.6344, Rec: 0.3778 lr: 0.00070\n",
      "Epoch 19/Step 180, Loss: -0.27359, Accuracy: 0.99904, F1: 0.0748, Prec: 0.6350, Rec: 0.3786 lr: 0.00070\n",
      "Epoch 19/Step 190, Loss: -0.21535, Accuracy: 0.99903, F1: 0.0756, Prec: 0.6330, Rec: 0.3781 lr: 0.00070\n",
      "Epoch 19/Step 200, Loss: -0.24845, Accuracy: 0.99902, F1: 0.0806, Prec: 0.6332, Rec: 0.3776 lr: 0.00070\n",
      "Epoch 19/Step 210, Loss: -0.19965, Accuracy: 0.99903, F1: 0.0851, Prec: 0.6339, Rec: 0.3769 lr: 0.00070\n",
      "Epoch 19/Step 220, Loss: -0.24652, Accuracy: 0.99902, F1: 0.0812, Prec: 0.6323, Rec: 0.3776 lr: 0.00070\n",
      "Epoch 19/Step 230, Loss: -0.20730, Accuracy: 0.99902, F1: 0.0777, Prec: 0.6294, Rec: 0.3776 lr: 0.00070\n",
      "Epoch 19/Step 240, Loss: -0.26751, Accuracy: 0.99902, F1: 0.0745, Prec: 0.6308, Rec: 0.3770 lr: 0.00070\n",
      "Epoch 19/Step 250, Loss: -0.24604, Accuracy: 0.99902, F1: 0.0785, Prec: 0.6321, Rec: 0.3760 lr: 0.00070\n",
      "Epoch 19/Step 260, Loss: -0.26162, Accuracy: 0.99901, F1: 0.0755, Prec: 0.6305, Rec: 0.3769 lr: 0.00070\n",
      "Epoch 19/Step 270, Loss: -0.25701, Accuracy: 0.99901, F1: 0.0727, Prec: 0.6299, Rec: 0.3767 lr: 0.00070\n",
      "Epoch 19/Step 280, Loss: -0.23164, Accuracy: 0.99901, F1: 0.0701, Prec: 0.6303, Rec: 0.3752 lr: 0.00070\n",
      "Epoch 19/Step 290, Loss: -0.22747, Accuracy: 0.99901, F1: 0.0699, Prec: 0.6297, Rec: 0.3755 lr: 0.00070\n",
      "Epoch 19/Step 300, Loss: -0.25484, Accuracy: 0.99901, F1: 0.0707, Prec: 0.6310, Rec: 0.3753 lr: 0.00070\n",
      "Epoch 19/Step 310, Loss: -0.24438, Accuracy: 0.99902, F1: 0.0717, Prec: 0.6314, Rec: 0.3752 lr: 0.00070\n",
      "Epoch 19/Step 320, Loss: -0.22825, Accuracy: 0.99902, F1: 0.0722, Prec: 0.6319, Rec: 0.3758 lr: 0.00070\n",
      "Epoch 19/Step 330, Loss: -0.24208, Accuracy: 0.99902, F1: 0.0700, Prec: 0.6317, Rec: 0.3759 lr: 0.00070\n",
      "Epoch 19/Step 340, Loss: -0.23479, Accuracy: 0.99902, F1: 0.0679, Prec: 0.6315, Rec: 0.3762 lr: 0.00070\n",
      "Epoch 19/Step 350, Loss: -0.20876, Accuracy: 0.99902, F1: 0.0660, Prec: 0.6334, Rec: 0.3764 lr: 0.00070\n",
      "Epoch 19/Step 360, Loss: -0.23545, Accuracy: 0.99902, F1: 0.0642, Prec: 0.6335, Rec: 0.3769 lr: 0.00070\n",
      "Epoch 19/Step 370, Loss: -0.23852, Accuracy: 0.99902, F1: 0.0624, Prec: 0.6319, Rec: 0.3774 lr: 0.00070\n",
      "Epoch 19/Step 380, Loss: -0.25019, Accuracy: 0.99902, F1: 0.0608, Prec: 0.6322, Rec: 0.3769 lr: 0.00070\n",
      "Epoch 19/Step 390, Loss: -0.20461, Accuracy: 0.99902, F1: 0.0610, Prec: 0.6328, Rec: 0.3765 lr: 0.00070\n",
      "Epoch 19/Step 400, Loss: -0.19520, Accuracy: 0.99902, F1: 0.0595, Prec: 0.6334, Rec: 0.3757 lr: 0.00070\n",
      "Epoch 19/Step 410, Loss: -0.19394, Accuracy: 0.99902, F1: 0.0580, Prec: 0.6330, Rec: 0.3759 lr: 0.00070\n",
      "Epoch 19/Step 420, Loss: -0.24592, Accuracy: 0.99902, F1: 0.0567, Prec: 0.6329, Rec: 0.3764 lr: 0.00070\n",
      "Epoch 19/Step 430, Loss: -0.22923, Accuracy: 0.99902, F1: 0.0553, Prec: 0.6326, Rec: 0.3766 lr: 0.00070\n",
      "Epoch 19/Step 440, Loss: -0.25694, Accuracy: 0.99902, F1: 0.0541, Prec: 0.6324, Rec: 0.3764 lr: 0.00070\n",
      "Epoch 19/Step 450, Loss: -0.23449, Accuracy: 0.99902, F1: 0.0529, Prec: 0.6329, Rec: 0.3761 lr: 0.00070\n",
      "Epoch 19/Step 460, Loss: -0.21881, Accuracy: 0.99902, F1: 0.0517, Prec: 0.6323, Rec: 0.3760 lr: 0.00070\n",
      "Epoch 19/Step 470, Loss: -0.21954, Accuracy: 0.99902, F1: 0.0506, Prec: 0.6316, Rec: 0.3761 lr: 0.00070\n",
      "Epoch 19/Step 480, Loss: -0.22120, Accuracy: 0.99902, F1: 0.0515, Prec: 0.6308, Rec: 0.3750 lr: 0.00070\n",
      "Epoch 19/Step 490, Loss: -0.21188, Accuracy: 0.99902, F1: 0.0504, Prec: 0.6315, Rec: 0.3745 lr: 0.00070\n",
      "Epoch 19/Step 500, Loss: -0.23240, Accuracy: 0.99902, F1: 0.0494, Prec: 0.6321, Rec: 0.3744 lr: 0.00070\n",
      "Epoch 19/Step 510, Loss: -0.27893, Accuracy: 0.99902, F1: 0.0495, Prec: 0.6307, Rec: 0.3748 lr: 0.00070\n",
      "Epoch 19/Step 520, Loss: -0.21435, Accuracy: 0.99902, F1: 0.0486, Prec: 0.6304, Rec: 0.3750 lr: 0.00070\n",
      "Epoch 19/Step 530, Loss: -0.23354, Accuracy: 0.99902, F1: 0.0491, Prec: 0.6303, Rec: 0.3744 lr: 0.00070\n",
      "Epoch 19/Step 540, Loss: -0.23296, Accuracy: 0.99902, F1: 0.0482, Prec: 0.6300, Rec: 0.3743 lr: 0.00070\n",
      "Epoch 19/Step 550, Loss: -0.26539, Accuracy: 0.99902, F1: 0.0536, Prec: 0.6291, Rec: 0.3746 lr: 0.00070\n",
      "Epoch 19/Step 560, Loss: -0.22209, Accuracy: 0.99902, F1: 0.0526, Prec: 0.6293, Rec: 0.3745 lr: 0.00070\n",
      "Epoch 19/Step 570, Loss: -0.23584, Accuracy: 0.99902, F1: 0.0532, Prec: 0.6291, Rec: 0.3743 lr: 0.00070\n",
      "Epoch 19/Step 580, Loss: -0.20069, Accuracy: 0.99902, F1: 0.0536, Prec: 0.6289, Rec: 0.3742 lr: 0.00070\n",
      "Epoch 19/Step 590, Loss: -0.18256, Accuracy: 0.99902, F1: 0.0552, Prec: 0.6283, Rec: 0.3740 lr: 0.00070\n",
      "Epoch 19/Step 600, Loss: -0.22584, Accuracy: 0.99902, F1: 0.0561, Prec: 0.6287, Rec: 0.3739 lr: 0.00070\n",
      "Epoch 19/Step 610, Loss: -0.27612, Accuracy: 0.99902, F1: 0.0552, Prec: 0.6288, Rec: 0.3741 lr: 0.00070\n",
      "Epoch 19/Step 620, Loss: -0.24565, Accuracy: 0.99901, F1: 0.0560, Prec: 0.6288, Rec: 0.3744 lr: 0.00070\n",
      "Epoch 19/Step 630, Loss: -0.20952, Accuracy: 0.99901, F1: 0.0551, Prec: 0.6280, Rec: 0.3745 lr: 0.00070\n",
      "Epoch 19/Step 640, Loss: -0.21586, Accuracy: 0.99901, F1: 0.0569, Prec: 0.6280, Rec: 0.3744 lr: 0.00070\n",
      "Epoch 19/Step 650, Loss: -0.21576, Accuracy: 0.99901, F1: 0.0560, Prec: 0.6284, Rec: 0.3743 lr: 0.00070\n",
      "Epoch 19/Step 660, Loss: -0.24779, Accuracy: 0.99902, F1: 0.0552, Prec: 0.6284, Rec: 0.3743 lr: 0.00070\n",
      "Epoch 19/Step 670, Loss: -0.23021, Accuracy: 0.99902, F1: 0.0544, Prec: 0.6288, Rec: 0.3743 lr: 0.00070\n",
      "Epoch 19/Step 680, Loss: -0.20369, Accuracy: 0.99902, F1: 0.0536, Prec: 0.6293, Rec: 0.3745 lr: 0.00070\n",
      "Epoch 19/Step 690, Loss: -0.25425, Accuracy: 0.99902, F1: 0.0528, Prec: 0.6295, Rec: 0.3745 lr: 0.00070\n",
      "Epoch 19/Step 700, Loss: -0.23632, Accuracy: 0.99902, F1: 0.0520, Prec: 0.6291, Rec: 0.3744 lr: 0.00070\n",
      "Epoch 19/Step 710, Loss: -0.24190, Accuracy: 0.99902, F1: 0.0513, Prec: 0.6296, Rec: 0.3747 lr: 0.00070\n",
      "Epoch 19/Step 720, Loss: -0.25182, Accuracy: 0.99902, F1: 0.0506, Prec: 0.6298, Rec: 0.3744 lr: 0.00070\n",
      "Epoch 19/Step 730, Loss: -0.21165, Accuracy: 0.99902, F1: 0.0499, Prec: 0.6299, Rec: 0.3741 lr: 0.00070\n",
      "Epoch 19/Step 740, Loss: -0.23936, Accuracy: 0.99902, F1: 0.0492, Prec: 0.6299, Rec: 0.3740 lr: 0.00070\n",
      "Epoch 19/Step 750, Loss: -0.24716, Accuracy: 0.99902, F1: 0.0486, Prec: 0.6299, Rec: 0.3739 lr: 0.00070\n",
      "Epoch 19/Step 760, Loss: -0.24147, Accuracy: 0.99902, F1: 0.0492, Prec: 0.6304, Rec: 0.3736 lr: 0.00070\n",
      "Epoch 19/Step 770, Loss: -0.25630, Accuracy: 0.99902, F1: 0.0486, Prec: 0.6301, Rec: 0.3737 lr: 0.00070\n",
      "Epoch 19/Step 780, Loss: -0.19113, Accuracy: 0.99902, F1: 0.0479, Prec: 0.6305, Rec: 0.3738 lr: 0.00070\n",
      "Epoch 19/Step 790, Loss: -0.25117, Accuracy: 0.99902, F1: 0.0473, Prec: 0.6304, Rec: 0.3735 lr: 0.00070\n",
      "Epoch 19/Step 800, Loss: -0.21692, Accuracy: 0.99902, F1: 0.0467, Prec: 0.6306, Rec: 0.3734 lr: 0.00070\n",
      "Epoch 19/Step 810, Loss: -0.17497, Accuracy: 0.99902, F1: 0.0462, Prec: 0.6303, Rec: 0.3735 lr: 0.00070\n",
      "Epoch 19/Step 820, Loss: -0.22898, Accuracy: 0.99902, F1: 0.0456, Prec: 0.6301, Rec: 0.3734 lr: 0.00070\n",
      "Epoch 19/Step 830, Loss: -0.24015, Accuracy: 0.99902, F1: 0.0451, Prec: 0.6308, Rec: 0.3734 lr: 0.00070\n",
      "Epoch 19/Step 840, Loss: -0.26974, Accuracy: 0.99902, F1: 0.0445, Prec: 0.6315, Rec: 0.3734 lr: 0.00070\n",
      "Epoch 19/Step 850, Loss: -0.23081, Accuracy: 0.99902, F1: 0.0440, Prec: 0.6307, Rec: 0.3734 lr: 0.00070\n",
      "Epoch 19/Step 860, Loss: -0.23640, Accuracy: 0.99902, F1: 0.0435, Prec: 0.6310, Rec: 0.3735 lr: 0.00070\n",
      "Epoch 19/Step 870, Loss: -0.22792, Accuracy: 0.99902, F1: 0.0430, Prec: 0.6308, Rec: 0.3731 lr: 0.00070\n",
      "Epoch 19/Step 880, Loss: -0.20562, Accuracy: 0.99902, F1: 0.0425, Prec: 0.6304, Rec: 0.3733 lr: 0.00070\n",
      "Epoch 19/Step 890, Loss: -0.21830, Accuracy: 0.99902, F1: 0.0420, Prec: 0.6301, Rec: 0.3731 lr: 0.00070\n",
      "Epoch 19/Step 900, Loss: -0.28366, Accuracy: 0.99902, F1: 0.0416, Prec: 0.6303, Rec: 0.3732 lr: 0.00070\n",
      "Epoch 19/Step 910, Loss: -0.19607, Accuracy: 0.99902, F1: 0.0411, Prec: 0.6303, Rec: 0.3729 lr: 0.00070\n",
      "Epoch 19/Step 920, Loss: -0.23052, Accuracy: 0.99902, F1: 0.0407, Prec: 0.6303, Rec: 0.3726 lr: 0.00070\n",
      "Epoch 19/Step 930, Loss: -0.22038, Accuracy: 0.99902, F1: 0.0402, Prec: 0.6304, Rec: 0.3727 lr: 0.00070\n",
      "Epoch 19/Step 940, Loss: -0.23719, Accuracy: 0.99903, F1: 0.0398, Prec: 0.6303, Rec: 0.3728 lr: 0.00070\n",
      "Epoch 19/Step 950, Loss: -0.24995, Accuracy: 0.99903, F1: 0.0394, Prec: 0.6303, Rec: 0.3729 lr: 0.00070\n",
      "Epoch 19/Step 960, Loss: -0.25800, Accuracy: 0.99903, F1: 0.0390, Prec: 0.6303, Rec: 0.3730 lr: 0.00070\n",
      "Epoch 19/Step 970, Loss: -0.20287, Accuracy: 0.99903, F1: 0.0386, Prec: 0.6302, Rec: 0.3724 lr: 0.00070\n",
      "Epoch 19/Step 980, Loss: -0.23709, Accuracy: 0.99903, F1: 0.0382, Prec: 0.6301, Rec: 0.3722 lr: 0.00070\n",
      "Epoch 19/Step 990, Loss: -0.22093, Accuracy: 0.99903, F1: 0.0378, Prec: 0.6293, Rec: 0.3722 lr: 0.00070\n",
      "Epoch 19/Step 1000, Loss: -0.23891, Accuracy: 0.99903, F1: 0.0374, Prec: 0.6294, Rec: 0.3724 lr: 0.00070\n",
      "Epoch 19/Step 1010, Loss: -0.24094, Accuracy: 0.99903, F1: 0.0370, Prec: 0.6298, Rec: 0.3725 lr: 0.00070\n",
      "Epoch 19/Step 1020, Loss: -0.18889, Accuracy: 0.99903, F1: 0.0367, Prec: 0.6293, Rec: 0.3725 lr: 0.00070\n",
      "Epoch 19/Step 1030, Loss: -0.23775, Accuracy: 0.99903, F1: 0.0363, Prec: 0.6291, Rec: 0.3724 lr: 0.00070\n",
      "Epoch 19/Step 1040, Loss: -0.23145, Accuracy: 0.99903, F1: 0.0360, Prec: 0.6293, Rec: 0.3724 lr: 0.00070\n",
      "Epoch 19/Step 1050, Loss: -0.26180, Accuracy: 0.99903, F1: 0.0366, Prec: 0.6296, Rec: 0.3723 lr: 0.00070\n",
      "Epoch 19/Step 1060, Loss: -0.25712, Accuracy: 0.99903, F1: 0.0362, Prec: 0.6295, Rec: 0.3727 lr: 0.00070\n",
      "Epoch 19/Step 1070, Loss: -0.23327, Accuracy: 0.99903, F1: 0.0368, Prec: 0.6296, Rec: 0.3727 lr: 0.00070\n",
      "Epoch 19/Step 1080, Loss: -0.21287, Accuracy: 0.99903, F1: 0.0364, Prec: 0.6298, Rec: 0.3726 lr: 0.00070\n",
      "Epoch 19/Step 1090, Loss: -0.23171, Accuracy: 0.99903, F1: 0.0361, Prec: 0.6295, Rec: 0.3725 lr: 0.00070\n",
      "Epoch 19/Step 1100, Loss: -0.23559, Accuracy: 0.99903, F1: 0.0358, Prec: 0.6295, Rec: 0.3726 lr: 0.00070\n",
      "Epoch 19/Step 1110, Loss: -0.19134, Accuracy: 0.99903, F1: 0.0354, Prec: 0.6296, Rec: 0.3724 lr: 0.00070\n",
      "Epoch 19/Step 1120, Loss: -0.20896, Accuracy: 0.99903, F1: 0.0358, Prec: 0.6295, Rec: 0.3724 lr: 0.00070\n",
      "Epoch 19/Step 1130, Loss: -0.21384, Accuracy: 0.99903, F1: 0.0363, Prec: 0.6297, Rec: 0.3726 lr: 0.00070\n",
      "Epoch 19/Step 1140, Loss: -0.23426, Accuracy: 0.99903, F1: 0.0360, Prec: 0.6297, Rec: 0.3727 lr: 0.00070\n",
      "Epoch 19/Step 1150, Loss: -0.26151, Accuracy: 0.99903, F1: 0.0357, Prec: 0.6300, Rec: 0.3727 lr: 0.00070\n",
      "Epoch 19/Step 1160, Loss: -0.19433, Accuracy: 0.99903, F1: 0.0354, Prec: 0.6303, Rec: 0.3730 lr: 0.00070\n",
      "Epoch 19/Step 1170, Loss: -0.20786, Accuracy: 0.99903, F1: 0.0351, Prec: 0.6302, Rec: 0.3730 lr: 0.00070\n",
      "Epoch 19/Step 1180, Loss: -0.18897, Accuracy: 0.99903, F1: 0.0348, Prec: 0.6300, Rec: 0.3730 lr: 0.00070\n",
      "Epoch 19/Step 1190, Loss: -0.25150, Accuracy: 0.99903, F1: 0.0345, Prec: 0.6298, Rec: 0.3729 lr: 0.00070\n",
      "Epoch 19/Step 1200, Loss: -0.22349, Accuracy: 0.99903, F1: 0.0342, Prec: 0.6301, Rec: 0.3731 lr: 0.00070\n",
      "Epoch 19/Step 1210, Loss: -0.25025, Accuracy: 0.99904, F1: 0.0339, Prec: 0.6303, Rec: 0.3733 lr: 0.00070\n",
      "Epoch 19/Step 1220, Loss: -0.24911, Accuracy: 0.99904, F1: 0.0336, Prec: 0.6302, Rec: 0.3734 lr: 0.00070\n",
      "Epoch 19/Step 1230, Loss: -0.22735, Accuracy: 0.99904, F1: 0.0334, Prec: 0.6300, Rec: 0.3734 lr: 0.00070\n",
      "Epoch 19/Step 1240, Loss: -0.28213, Accuracy: 0.99904, F1: 0.0331, Prec: 0.6302, Rec: 0.3733 lr: 0.00070\n",
      "Epoch 19/Step 1250, Loss: -0.17560, Accuracy: 0.99904, F1: 0.0328, Prec: 0.6302, Rec: 0.3734 lr: 0.00070\n",
      "Epoch 19/Step 1260, Loss: -0.24247, Accuracy: 0.99904, F1: 0.0326, Prec: 0.6300, Rec: 0.3735 lr: 0.00070\n",
      "Epoch 19/Step 1270, Loss: -0.23001, Accuracy: 0.99904, F1: 0.0323, Prec: 0.6300, Rec: 0.3736 lr: 0.00070\n",
      "Epoch 19/Step 1280, Loss: -0.29879, Accuracy: 0.99904, F1: 0.0321, Prec: 0.6301, Rec: 0.3736 lr: 0.00070\n",
      "Epoch 19/Step 1290, Loss: -0.25326, Accuracy: 0.99904, F1: 0.0326, Prec: 0.6303, Rec: 0.3737 lr: 0.00070\n",
      "Epoch 19/Step 1300, Loss: -0.22546, Accuracy: 0.99904, F1: 0.0324, Prec: 0.6301, Rec: 0.3737 lr: 0.00070\n",
      "Epoch 19/Step 1310, Loss: -0.23987, Accuracy: 0.99904, F1: 0.0321, Prec: 0.6304, Rec: 0.3737 lr: 0.00070\n",
      "Epoch 19/Step 1320, Loss: -0.25795, Accuracy: 0.99904, F1: 0.0319, Prec: 0.6305, Rec: 0.3738 lr: 0.00070\n",
      "Epoch 19/Step 1330, Loss: -0.25442, Accuracy: 0.99904, F1: 0.0323, Prec: 0.6305, Rec: 0.3737 lr: 0.00070\n",
      "Epoch 19/Step 1340, Loss: -0.23826, Accuracy: 0.99904, F1: 0.0321, Prec: 0.6306, Rec: 0.3738 lr: 0.00070\n",
      "Epoch 19/Step 1350, Loss: -0.19357, Accuracy: 0.99904, F1: 0.0318, Prec: 0.6307, Rec: 0.3739 lr: 0.00070\n",
      "Epoch 19/Step 1360, Loss: -0.22317, Accuracy: 0.99904, F1: 0.0323, Prec: 0.6309, Rec: 0.3739 lr: 0.00070\n",
      "Epoch 19/Step 1370, Loss: -0.23159, Accuracy: 0.99904, F1: 0.0321, Prec: 0.6311, Rec: 0.3740 lr: 0.00070\n",
      "Epoch 19/Step 1380, Loss: -0.23325, Accuracy: 0.99904, F1: 0.0319, Prec: 0.6309, Rec: 0.3742 lr: 0.00070\n",
      "Epoch 19/Step 1390, Loss: -0.23852, Accuracy: 0.99904, F1: 0.0316, Prec: 0.6308, Rec: 0.3741 lr: 0.00070\n",
      "Epoch 19/Step 1400, Loss: -0.25166, Accuracy: 0.99904, F1: 0.0321, Prec: 0.6311, Rec: 0.3742 lr: 0.00070\n",
      "Epoch 19/Step 1410, Loss: -0.21255, Accuracy: 0.99904, F1: 0.0319, Prec: 0.6312, Rec: 0.3741 lr: 0.00070\n",
      "Epoch 19/Step 1420, Loss: -0.21528, Accuracy: 0.99904, F1: 0.0323, Prec: 0.6311, Rec: 0.3740 lr: 0.00070\n",
      "Epoch 19/Step 1430, Loss: -0.22180, Accuracy: 0.99904, F1: 0.0320, Prec: 0.6312, Rec: 0.3739 lr: 0.00070\n",
      "Epoch 19/Step 1440, Loss: -0.22863, Accuracy: 0.99904, F1: 0.0326, Prec: 0.6313, Rec: 0.3739 lr: 0.00070\n",
      "Epoch 19/Step 1450, Loss: -0.22396, Accuracy: 0.99904, F1: 0.0323, Prec: 0.6315, Rec: 0.3740 lr: 0.00070\n",
      "Epoch 19/Step 1460, Loss: -0.21767, Accuracy: 0.99904, F1: 0.0321, Prec: 0.6313, Rec: 0.3739 lr: 0.00070\n",
      "Epoch 19/Step 1470, Loss: -0.22470, Accuracy: 0.99904, F1: 0.0319, Prec: 0.6313, Rec: 0.3739 lr: 0.00070\n",
      "Epoch 19/Step 1480, Loss: -0.22782, Accuracy: 0.99904, F1: 0.0317, Prec: 0.6314, Rec: 0.3739 lr: 0.00070\n",
      "Epoch 19/Step 1490, Loss: -0.21080, Accuracy: 0.99904, F1: 0.0315, Prec: 0.6313, Rec: 0.3737 lr: 0.00070\n",
      "Epoch 19/Step 1500, Loss: -0.23780, Accuracy: 0.99904, F1: 0.0323, Prec: 0.6313, Rec: 0.3738 lr: 0.00070\n",
      "Epoch 19/Step 1510, Loss: -0.22292, Accuracy: 0.99904, F1: 0.0320, Prec: 0.6315, Rec: 0.3739 lr: 0.00070\n",
      "Epoch 19/Step 1520, Loss: -0.27311, Accuracy: 0.99904, F1: 0.0328, Prec: 0.6318, Rec: 0.3740 lr: 0.00070\n",
      "Epoch 19/Step 1530, Loss: -0.21749, Accuracy: 0.99904, F1: 0.0333, Prec: 0.6320, Rec: 0.3740 lr: 0.00070\n",
      "Epoch 19/Step 1540, Loss: -0.20723, Accuracy: 0.99904, F1: 0.0330, Prec: 0.6320, Rec: 0.3738 lr: 0.00070\n",
      "Epoch 19/Step 1550, Loss: -0.22968, Accuracy: 0.99904, F1: 0.0334, Prec: 0.6320, Rec: 0.3739 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9987\n",
      "Validation f1: 0.0787\n",
      "Validation precision: 0.3828\n",
      "Validation recall: 0.2057\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_18_valF1Score0.079/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_18_valF1Score0.079/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 20\n",
      "Epoch 20/Step 0, Loss: -0.25847, Accuracy: 0.99917, F1: 0.0000, Prec: 0.6990, Rec: 0.4234 lr: 0.00070\n",
      "Epoch 20/Step 10, Loss: -0.26909, Accuracy: 0.99902, F1: 0.0000, Prec: 0.6822, Rec: 0.3879 lr: 0.00070\n",
      "Epoch 20/Step 20, Loss: -0.24443, Accuracy: 0.99905, F1: 0.0000, Prec: 0.6691, Rec: 0.3855 lr: 0.00070\n",
      "Epoch 20/Step 30, Loss: -0.21440, Accuracy: 0.99907, F1: 0.0295, Prec: 0.6572, Rec: 0.3871 lr: 0.00070\n",
      "Epoch 20/Step 40, Loss: -0.20995, Accuracy: 0.99907, F1: 0.0223, Prec: 0.6684, Rec: 0.3857 lr: 0.00070\n",
      "Epoch 20/Step 50, Loss: -0.23777, Accuracy: 0.99908, F1: 0.0179, Prec: 0.6750, Rec: 0.3846 lr: 0.00070\n",
      "Epoch 20/Step 60, Loss: -0.24726, Accuracy: 0.99908, F1: 0.0300, Prec: 0.6759, Rec: 0.3861 lr: 0.00070\n",
      "Epoch 20/Step 70, Loss: -0.22418, Accuracy: 0.99909, F1: 0.0258, Prec: 0.6665, Rec: 0.3891 lr: 0.00070\n",
      "Epoch 20/Step 80, Loss: -0.21697, Accuracy: 0.99909, F1: 0.0362, Prec: 0.6633, Rec: 0.3868 lr: 0.00070\n",
      "Epoch 20/Step 90, Loss: -0.20846, Accuracy: 0.99909, F1: 0.0521, Prec: 0.6649, Rec: 0.3849 lr: 0.00070\n",
      "Epoch 20/Step 100, Loss: -0.24219, Accuracy: 0.99909, F1: 0.0548, Prec: 0.6611, Rec: 0.3874 lr: 0.00070\n",
      "Epoch 20/Step 110, Loss: -0.23400, Accuracy: 0.99908, F1: 0.0569, Prec: 0.6594, Rec: 0.3869 lr: 0.00070\n",
      "Epoch 20/Step 120, Loss: -0.22944, Accuracy: 0.99907, F1: 0.0580, Prec: 0.6584, Rec: 0.3852 lr: 0.00070\n",
      "Epoch 20/Step 130, Loss: -0.19537, Accuracy: 0.99907, F1: 0.0677, Prec: 0.6549, Rec: 0.3862 lr: 0.00070\n",
      "Epoch 20/Step 140, Loss: -0.20864, Accuracy: 0.99906, F1: 0.0690, Prec: 0.6524, Rec: 0.3826 lr: 0.00070\n",
      "Epoch 20/Step 150, Loss: -0.22469, Accuracy: 0.99905, F1: 0.0645, Prec: 0.6505, Rec: 0.3806 lr: 0.00070\n",
      "Epoch 20/Step 160, Loss: -0.25588, Accuracy: 0.99905, F1: 0.0605, Prec: 0.6489, Rec: 0.3807 lr: 0.00070\n",
      "Epoch 20/Step 170, Loss: -0.23259, Accuracy: 0.99905, F1: 0.0608, Prec: 0.6469, Rec: 0.3801 lr: 0.00070\n",
      "Epoch 20/Step 180, Loss: -0.28129, Accuracy: 0.99905, F1: 0.0575, Prec: 0.6465, Rec: 0.3811 lr: 0.00070\n",
      "Epoch 20/Step 190, Loss: -0.21757, Accuracy: 0.99905, F1: 0.0592, Prec: 0.6454, Rec: 0.3801 lr: 0.00070\n",
      "Epoch 20/Step 200, Loss: -0.24798, Accuracy: 0.99904, F1: 0.0606, Prec: 0.6448, Rec: 0.3799 lr: 0.00070\n",
      "Epoch 20/Step 210, Loss: -0.20272, Accuracy: 0.99904, F1: 0.0615, Prec: 0.6441, Rec: 0.3797 lr: 0.00070\n",
      "Epoch 20/Step 220, Loss: -0.25403, Accuracy: 0.99904, F1: 0.0587, Prec: 0.6443, Rec: 0.3798 lr: 0.00070\n",
      "Epoch 20/Step 230, Loss: -0.20839, Accuracy: 0.99904, F1: 0.0561, Prec: 0.6431, Rec: 0.3795 lr: 0.00070\n",
      "Epoch 20/Step 240, Loss: -0.27192, Accuracy: 0.99903, F1: 0.0538, Prec: 0.6433, Rec: 0.3795 lr: 0.00070\n",
      "Epoch 20/Step 250, Loss: -0.24714, Accuracy: 0.99903, F1: 0.0517, Prec: 0.6445, Rec: 0.3785 lr: 0.00070\n",
      "Epoch 20/Step 260, Loss: -0.26192, Accuracy: 0.99903, F1: 0.0497, Prec: 0.6440, Rec: 0.3788 lr: 0.00070\n",
      "Epoch 20/Step 270, Loss: -0.25735, Accuracy: 0.99903, F1: 0.0478, Prec: 0.6410, Rec: 0.3791 lr: 0.00070\n",
      "Epoch 20/Step 280, Loss: -0.22890, Accuracy: 0.99902, F1: 0.0461, Prec: 0.6412, Rec: 0.3776 lr: 0.00070\n",
      "Epoch 20/Step 290, Loss: -0.22698, Accuracy: 0.99902, F1: 0.0446, Prec: 0.6414, Rec: 0.3773 lr: 0.00070\n",
      "Epoch 20/Step 300, Loss: -0.25189, Accuracy: 0.99902, F1: 0.0431, Prec: 0.6407, Rec: 0.3774 lr: 0.00070\n",
      "Epoch 20/Step 310, Loss: -0.24089, Accuracy: 0.99903, F1: 0.0454, Prec: 0.6405, Rec: 0.3773 lr: 0.00070\n",
      "Epoch 20/Step 320, Loss: -0.22628, Accuracy: 0.99903, F1: 0.0467, Prec: 0.6415, Rec: 0.3773 lr: 0.00070\n",
      "Epoch 20/Step 330, Loss: -0.24403, Accuracy: 0.99903, F1: 0.0453, Prec: 0.6396, Rec: 0.3778 lr: 0.00070\n",
      "Epoch 20/Step 340, Loss: -0.23552, Accuracy: 0.99902, F1: 0.0439, Prec: 0.6391, Rec: 0.3781 lr: 0.00070\n",
      "Epoch 20/Step 350, Loss: -0.21042, Accuracy: 0.99903, F1: 0.0427, Prec: 0.6407, Rec: 0.3784 lr: 0.00070\n",
      "Epoch 20/Step 360, Loss: -0.24096, Accuracy: 0.99903, F1: 0.0415, Prec: 0.6415, Rec: 0.3791 lr: 0.00070\n",
      "Epoch 20/Step 370, Loss: -0.24313, Accuracy: 0.99903, F1: 0.0404, Prec: 0.6409, Rec: 0.3794 lr: 0.00070\n",
      "Epoch 20/Step 380, Loss: -0.24653, Accuracy: 0.99903, F1: 0.0393, Prec: 0.6399, Rec: 0.3791 lr: 0.00070\n",
      "Epoch 20/Step 390, Loss: -0.20258, Accuracy: 0.99903, F1: 0.0402, Prec: 0.6406, Rec: 0.3786 lr: 0.00070\n",
      "Epoch 20/Step 400, Loss: -0.20486, Accuracy: 0.99903, F1: 0.0392, Prec: 0.6411, Rec: 0.3779 lr: 0.00070\n",
      "Epoch 20/Step 410, Loss: -0.19363, Accuracy: 0.99903, F1: 0.0382, Prec: 0.6407, Rec: 0.3778 lr: 0.00070\n",
      "Epoch 20/Step 420, Loss: -0.25049, Accuracy: 0.99903, F1: 0.0373, Prec: 0.6410, Rec: 0.3782 lr: 0.00070\n",
      "Epoch 20/Step 430, Loss: -0.23029, Accuracy: 0.99903, F1: 0.0365, Prec: 0.6404, Rec: 0.3786 lr: 0.00070\n",
      "Epoch 20/Step 440, Loss: -0.25829, Accuracy: 0.99903, F1: 0.0356, Prec: 0.6403, Rec: 0.3784 lr: 0.00070\n",
      "Epoch 20/Step 450, Loss: -0.24867, Accuracy: 0.99903, F1: 0.0348, Prec: 0.6405, Rec: 0.3783 lr: 0.00070\n",
      "Epoch 20/Step 460, Loss: -0.22545, Accuracy: 0.99903, F1: 0.0341, Prec: 0.6400, Rec: 0.3782 lr: 0.00070\n",
      "Epoch 20/Step 470, Loss: -0.22217, Accuracy: 0.99903, F1: 0.0334, Prec: 0.6398, Rec: 0.3781 lr: 0.00070\n",
      "Epoch 20/Step 480, Loss: -0.22467, Accuracy: 0.99903, F1: 0.0346, Prec: 0.6392, Rec: 0.3771 lr: 0.00070\n",
      "Epoch 20/Step 490, Loss: -0.21855, Accuracy: 0.99903, F1: 0.0339, Prec: 0.6391, Rec: 0.3769 lr: 0.00070\n",
      "Epoch 20/Step 500, Loss: -0.22896, Accuracy: 0.99903, F1: 0.0332, Prec: 0.6400, Rec: 0.3768 lr: 0.00070\n",
      "Epoch 20/Step 510, Loss: -0.28559, Accuracy: 0.99903, F1: 0.0325, Prec: 0.6397, Rec: 0.3769 lr: 0.00070\n",
      "Epoch 20/Step 520, Loss: -0.21893, Accuracy: 0.99903, F1: 0.0319, Prec: 0.6394, Rec: 0.3772 lr: 0.00070\n",
      "Epoch 20/Step 530, Loss: -0.23437, Accuracy: 0.99903, F1: 0.0313, Prec: 0.6388, Rec: 0.3768 lr: 0.00070\n",
      "Epoch 20/Step 540, Loss: -0.22861, Accuracy: 0.99903, F1: 0.0307, Prec: 0.6389, Rec: 0.3766 lr: 0.00070\n",
      "Epoch 20/Step 550, Loss: -0.26084, Accuracy: 0.99903, F1: 0.0316, Prec: 0.6386, Rec: 0.3767 lr: 0.00070\n",
      "Epoch 20/Step 560, Loss: -0.22763, Accuracy: 0.99903, F1: 0.0310, Prec: 0.6383, Rec: 0.3767 lr: 0.00070\n",
      "Epoch 20/Step 570, Loss: -0.24451, Accuracy: 0.99903, F1: 0.0305, Prec: 0.6381, Rec: 0.3766 lr: 0.00070\n",
      "Epoch 20/Step 580, Loss: -0.19809, Accuracy: 0.99903, F1: 0.0299, Prec: 0.6379, Rec: 0.3764 lr: 0.00070\n",
      "Epoch 20/Step 590, Loss: -0.17960, Accuracy: 0.99903, F1: 0.0294, Prec: 0.6368, Rec: 0.3763 lr: 0.00070\n",
      "Epoch 20/Step 600, Loss: -0.20806, Accuracy: 0.99903, F1: 0.0289, Prec: 0.6368, Rec: 0.3758 lr: 0.00070\n",
      "Epoch 20/Step 610, Loss: -0.27136, Accuracy: 0.99902, F1: 0.0285, Prec: 0.6361, Rec: 0.3760 lr: 0.00070\n",
      "Epoch 20/Step 620, Loss: -0.24545, Accuracy: 0.99902, F1: 0.0280, Prec: 0.6362, Rec: 0.3762 lr: 0.00070\n",
      "Epoch 20/Step 630, Loss: -0.21291, Accuracy: 0.99902, F1: 0.0276, Prec: 0.6361, Rec: 0.3759 lr: 0.00070\n",
      "Epoch 20/Step 640, Loss: -0.21428, Accuracy: 0.99902, F1: 0.0286, Prec: 0.6356, Rec: 0.3759 lr: 0.00070\n",
      "Epoch 20/Step 650, Loss: -0.20947, Accuracy: 0.99902, F1: 0.0282, Prec: 0.6358, Rec: 0.3758 lr: 0.00070\n",
      "Epoch 20/Step 660, Loss: -0.23753, Accuracy: 0.99902, F1: 0.0278, Prec: 0.6355, Rec: 0.3758 lr: 0.00070\n",
      "Epoch 20/Step 670, Loss: -0.23181, Accuracy: 0.99902, F1: 0.0274, Prec: 0.6359, Rec: 0.3758 lr: 0.00070\n",
      "Epoch 20/Step 680, Loss: -0.19745, Accuracy: 0.99902, F1: 0.0270, Prec: 0.6363, Rec: 0.3760 lr: 0.00070\n",
      "Epoch 20/Step 690, Loss: -0.25989, Accuracy: 0.99903, F1: 0.0266, Prec: 0.6364, Rec: 0.3759 lr: 0.00070\n",
      "Epoch 20/Step 700, Loss: -0.24298, Accuracy: 0.99903, F1: 0.0262, Prec: 0.6359, Rec: 0.3759 lr: 0.00070\n",
      "Epoch 20/Step 710, Loss: -0.23602, Accuracy: 0.99903, F1: 0.0258, Prec: 0.6364, Rec: 0.3762 lr: 0.00070\n",
      "Epoch 20/Step 720, Loss: -0.25498, Accuracy: 0.99903, F1: 0.0255, Prec: 0.6367, Rec: 0.3758 lr: 0.00070\n",
      "Epoch 20/Step 730, Loss: -0.21190, Accuracy: 0.99903, F1: 0.0251, Prec: 0.6366, Rec: 0.3756 lr: 0.00070\n",
      "Epoch 20/Step 740, Loss: -0.23586, Accuracy: 0.99903, F1: 0.0248, Prec: 0.6364, Rec: 0.3756 lr: 0.00070\n",
      "Epoch 20/Step 750, Loss: -0.25767, Accuracy: 0.99903, F1: 0.0244, Prec: 0.6362, Rec: 0.3757 lr: 0.00070\n",
      "Epoch 20/Step 760, Loss: -0.24848, Accuracy: 0.99903, F1: 0.0255, Prec: 0.6366, Rec: 0.3753 lr: 0.00070\n",
      "Epoch 20/Step 770, Loss: -0.26358, Accuracy: 0.99903, F1: 0.0251, Prec: 0.6365, Rec: 0.3754 lr: 0.00070\n",
      "Epoch 20/Step 780, Loss: -0.19413, Accuracy: 0.99903, F1: 0.0248, Prec: 0.6369, Rec: 0.3755 lr: 0.00070\n",
      "Epoch 20/Step 790, Loss: -0.25327, Accuracy: 0.99903, F1: 0.0245, Prec: 0.6368, Rec: 0.3752 lr: 0.00070\n",
      "Epoch 20/Step 800, Loss: -0.22502, Accuracy: 0.99903, F1: 0.0242, Prec: 0.6371, Rec: 0.3750 lr: 0.00070\n",
      "Epoch 20/Step 810, Loss: -0.16424, Accuracy: 0.99903, F1: 0.0239, Prec: 0.6368, Rec: 0.3750 lr: 0.00070\n",
      "Epoch 20/Step 820, Loss: -0.22387, Accuracy: 0.99903, F1: 0.0236, Prec: 0.6356, Rec: 0.3751 lr: 0.00070\n",
      "Epoch 20/Step 830, Loss: -0.25470, Accuracy: 0.99903, F1: 0.0233, Prec: 0.6361, Rec: 0.3751 lr: 0.00070\n",
      "Epoch 20/Step 840, Loss: -0.27135, Accuracy: 0.99903, F1: 0.0230, Prec: 0.6365, Rec: 0.3752 lr: 0.00070\n",
      "Epoch 20/Step 850, Loss: -0.21956, Accuracy: 0.99903, F1: 0.0228, Prec: 0.6357, Rec: 0.3752 lr: 0.00070\n",
      "Epoch 20/Step 860, Loss: -0.23531, Accuracy: 0.99903, F1: 0.0235, Prec: 0.6358, Rec: 0.3752 lr: 0.00070\n",
      "Epoch 20/Step 870, Loss: -0.23488, Accuracy: 0.99903, F1: 0.0232, Prec: 0.6356, Rec: 0.3749 lr: 0.00070\n",
      "Epoch 20/Step 880, Loss: -0.20975, Accuracy: 0.99903, F1: 0.0230, Prec: 0.6357, Rec: 0.3749 lr: 0.00070\n",
      "Epoch 20/Step 890, Loss: -0.22749, Accuracy: 0.99903, F1: 0.0227, Prec: 0.6355, Rec: 0.3748 lr: 0.00070\n",
      "Epoch 20/Step 900, Loss: -0.27873, Accuracy: 0.99903, F1: 0.0225, Prec: 0.6357, Rec: 0.3749 lr: 0.00070\n",
      "Epoch 20/Step 910, Loss: -0.20021, Accuracy: 0.99903, F1: 0.0222, Prec: 0.6355, Rec: 0.3747 lr: 0.00070\n",
      "Epoch 20/Step 920, Loss: -0.22896, Accuracy: 0.99903, F1: 0.0220, Prec: 0.6357, Rec: 0.3744 lr: 0.00070\n",
      "Epoch 20/Step 930, Loss: -0.22948, Accuracy: 0.99903, F1: 0.0217, Prec: 0.6360, Rec: 0.3744 lr: 0.00070\n",
      "Epoch 20/Step 940, Loss: -0.23490, Accuracy: 0.99903, F1: 0.0215, Prec: 0.6356, Rec: 0.3746 lr: 0.00070\n",
      "Epoch 20/Step 950, Loss: -0.24407, Accuracy: 0.99903, F1: 0.0213, Prec: 0.6357, Rec: 0.3746 lr: 0.00070\n",
      "Epoch 20/Step 960, Loss: -0.26198, Accuracy: 0.99903, F1: 0.0211, Prec: 0.6357, Rec: 0.3747 lr: 0.00070\n",
      "Epoch 20/Step 970, Loss: -0.20986, Accuracy: 0.99903, F1: 0.0208, Prec: 0.6354, Rec: 0.3743 lr: 0.00070\n",
      "Epoch 20/Step 980, Loss: -0.23629, Accuracy: 0.99903, F1: 0.0206, Prec: 0.6354, Rec: 0.3739 lr: 0.00070\n",
      "Epoch 20/Step 990, Loss: -0.22320, Accuracy: 0.99903, F1: 0.0204, Prec: 0.6345, Rec: 0.3740 lr: 0.00070\n",
      "Epoch 20/Step 1000, Loss: -0.22830, Accuracy: 0.99903, F1: 0.0202, Prec: 0.6344, Rec: 0.3743 lr: 0.00070\n",
      "Epoch 20/Step 1010, Loss: -0.24710, Accuracy: 0.99903, F1: 0.0200, Prec: 0.6349, Rec: 0.3743 lr: 0.00070\n",
      "Epoch 20/Step 1020, Loss: -0.20327, Accuracy: 0.99903, F1: 0.0198, Prec: 0.6347, Rec: 0.3743 lr: 0.00070\n",
      "Epoch 20/Step 1030, Loss: -0.23675, Accuracy: 0.99904, F1: 0.0196, Prec: 0.6347, Rec: 0.3742 lr: 0.00070\n",
      "Epoch 20/Step 1040, Loss: -0.22856, Accuracy: 0.99904, F1: 0.0194, Prec: 0.6350, Rec: 0.3740 lr: 0.00070\n",
      "Epoch 20/Step 1050, Loss: -0.25945, Accuracy: 0.99904, F1: 0.0193, Prec: 0.6350, Rec: 0.3741 lr: 0.00070\n",
      "Epoch 20/Step 1060, Loss: -0.26432, Accuracy: 0.99904, F1: 0.0199, Prec: 0.6349, Rec: 0.3745 lr: 0.00070\n",
      "Epoch 20/Step 1070, Loss: -0.23095, Accuracy: 0.99904, F1: 0.0197, Prec: 0.6351, Rec: 0.3745 lr: 0.00070\n",
      "Epoch 20/Step 1080, Loss: -0.21450, Accuracy: 0.99904, F1: 0.0195, Prec: 0.6355, Rec: 0.3744 lr: 0.00070\n",
      "Epoch 20/Step 1090, Loss: -0.23103, Accuracy: 0.99904, F1: 0.0193, Prec: 0.6353, Rec: 0.3743 lr: 0.00070\n",
      "Epoch 20/Step 1100, Loss: -0.24364, Accuracy: 0.99904, F1: 0.0191, Prec: 0.6351, Rec: 0.3744 lr: 0.00070\n",
      "Epoch 20/Step 1110, Loss: -0.19464, Accuracy: 0.99904, F1: 0.0190, Prec: 0.6352, Rec: 0.3743 lr: 0.00070\n",
      "Epoch 20/Step 1120, Loss: -0.21249, Accuracy: 0.99904, F1: 0.0196, Prec: 0.6352, Rec: 0.3742 lr: 0.00070\n",
      "Epoch 20/Step 1130, Loss: -0.21625, Accuracy: 0.99904, F1: 0.0194, Prec: 0.6350, Rec: 0.3745 lr: 0.00070\n",
      "Epoch 20/Step 1140, Loss: -0.22796, Accuracy: 0.99904, F1: 0.0192, Prec: 0.6351, Rec: 0.3746 lr: 0.00070\n",
      "Epoch 20/Step 1150, Loss: -0.26302, Accuracy: 0.99904, F1: 0.0191, Prec: 0.6353, Rec: 0.3747 lr: 0.00070\n",
      "Epoch 20/Step 1160, Loss: -0.19935, Accuracy: 0.99904, F1: 0.0189, Prec: 0.6357, Rec: 0.3749 lr: 0.00070\n",
      "Epoch 20/Step 1170, Loss: -0.20533, Accuracy: 0.99904, F1: 0.0188, Prec: 0.6357, Rec: 0.3749 lr: 0.00070\n",
      "Epoch 20/Step 1180, Loss: -0.19704, Accuracy: 0.99904, F1: 0.0186, Prec: 0.6356, Rec: 0.3749 lr: 0.00070\n",
      "Epoch 20/Step 1190, Loss: -0.25446, Accuracy: 0.99904, F1: 0.0184, Prec: 0.6355, Rec: 0.3747 lr: 0.00070\n",
      "Epoch 20/Step 1200, Loss: -0.22905, Accuracy: 0.99904, F1: 0.0183, Prec: 0.6358, Rec: 0.3749 lr: 0.00070\n",
      "Epoch 20/Step 1210, Loss: -0.25496, Accuracy: 0.99904, F1: 0.0181, Prec: 0.6360, Rec: 0.3751 lr: 0.00070\n",
      "Epoch 20/Step 1220, Loss: -0.25433, Accuracy: 0.99904, F1: 0.0180, Prec: 0.6359, Rec: 0.3752 lr: 0.00070\n",
      "Epoch 20/Step 1230, Loss: -0.23141, Accuracy: 0.99904, F1: 0.0178, Prec: 0.6358, Rec: 0.3752 lr: 0.00070\n",
      "Epoch 20/Step 1240, Loss: -0.28072, Accuracy: 0.99904, F1: 0.0177, Prec: 0.6358, Rec: 0.3752 lr: 0.00070\n",
      "Epoch 20/Step 1250, Loss: -0.17354, Accuracy: 0.99904, F1: 0.0176, Prec: 0.6358, Rec: 0.3752 lr: 0.00070\n",
      "Epoch 20/Step 1260, Loss: -0.25549, Accuracy: 0.99904, F1: 0.0174, Prec: 0.6359, Rec: 0.3753 lr: 0.00070\n",
      "Epoch 20/Step 1270, Loss: -0.23222, Accuracy: 0.99904, F1: 0.0173, Prec: 0.6358, Rec: 0.3754 lr: 0.00070\n",
      "Epoch 20/Step 1280, Loss: -0.29759, Accuracy: 0.99904, F1: 0.0171, Prec: 0.6360, Rec: 0.3753 lr: 0.00070\n",
      "Epoch 20/Step 1290, Loss: -0.24890, Accuracy: 0.99904, F1: 0.0178, Prec: 0.6360, Rec: 0.3754 lr: 0.00070\n",
      "Epoch 20/Step 1300, Loss: -0.22223, Accuracy: 0.99904, F1: 0.0177, Prec: 0.6358, Rec: 0.3754 lr: 0.00070\n",
      "Epoch 20/Step 1310, Loss: -0.23834, Accuracy: 0.99904, F1: 0.0176, Prec: 0.6359, Rec: 0.3755 lr: 0.00070\n",
      "Epoch 20/Step 1320, Loss: -0.25755, Accuracy: 0.99904, F1: 0.0174, Prec: 0.6360, Rec: 0.3755 lr: 0.00070\n",
      "Epoch 20/Step 1330, Loss: -0.26082, Accuracy: 0.99904, F1: 0.0173, Prec: 0.6360, Rec: 0.3755 lr: 0.00070\n",
      "Epoch 20/Step 1340, Loss: -0.23653, Accuracy: 0.99904, F1: 0.0172, Prec: 0.6363, Rec: 0.3755 lr: 0.00070\n",
      "Epoch 20/Step 1350, Loss: -0.19881, Accuracy: 0.99905, F1: 0.0170, Prec: 0.6361, Rec: 0.3756 lr: 0.00070\n",
      "Epoch 20/Step 1360, Loss: -0.22044, Accuracy: 0.99905, F1: 0.0169, Prec: 0.6363, Rec: 0.3756 lr: 0.00070\n",
      "Epoch 20/Step 1370, Loss: -0.23110, Accuracy: 0.99905, F1: 0.0168, Prec: 0.6366, Rec: 0.3758 lr: 0.00070\n",
      "Epoch 20/Step 1380, Loss: -0.23459, Accuracy: 0.99905, F1: 0.0167, Prec: 0.6365, Rec: 0.3759 lr: 0.00070\n",
      "Epoch 20/Step 1390, Loss: -0.24143, Accuracy: 0.99905, F1: 0.0165, Prec: 0.6362, Rec: 0.3759 lr: 0.00070\n",
      "Epoch 20/Step 1400, Loss: -0.25115, Accuracy: 0.99905, F1: 0.0164, Prec: 0.6366, Rec: 0.3759 lr: 0.00070\n",
      "Epoch 20/Step 1410, Loss: -0.22005, Accuracy: 0.99905, F1: 0.0163, Prec: 0.6368, Rec: 0.3759 lr: 0.00070\n",
      "Epoch 20/Step 1420, Loss: -0.22350, Accuracy: 0.99905, F1: 0.0168, Prec: 0.6368, Rec: 0.3758 lr: 0.00070\n",
      "Epoch 20/Step 1430, Loss: -0.22331, Accuracy: 0.99905, F1: 0.0167, Prec: 0.6370, Rec: 0.3756 lr: 0.00070\n",
      "Epoch 20/Step 1440, Loss: -0.23076, Accuracy: 0.99905, F1: 0.0173, Prec: 0.6371, Rec: 0.3757 lr: 0.00070\n",
      "Epoch 20/Step 1450, Loss: -0.23804, Accuracy: 0.99905, F1: 0.0172, Prec: 0.6372, Rec: 0.3758 lr: 0.00070\n",
      "Epoch 20/Step 1460, Loss: -0.22368, Accuracy: 0.99905, F1: 0.0170, Prec: 0.6372, Rec: 0.3758 lr: 0.00070\n",
      "Epoch 20/Step 1470, Loss: -0.22218, Accuracy: 0.99905, F1: 0.0176, Prec: 0.6372, Rec: 0.3757 lr: 0.00070\n",
      "Epoch 20/Step 1480, Loss: -0.22923, Accuracy: 0.99905, F1: 0.0174, Prec: 0.6372, Rec: 0.3757 lr: 0.00070\n",
      "Epoch 20/Step 1490, Loss: -0.21426, Accuracy: 0.99905, F1: 0.0173, Prec: 0.6372, Rec: 0.3755 lr: 0.00070\n",
      "Epoch 20/Step 1500, Loss: -0.24284, Accuracy: 0.99905, F1: 0.0177, Prec: 0.6372, Rec: 0.3756 lr: 0.00070\n",
      "Epoch 20/Step 1510, Loss: -0.22299, Accuracy: 0.99905, F1: 0.0176, Prec: 0.6372, Rec: 0.3757 lr: 0.00070\n",
      "Epoch 20/Step 1520, Loss: -0.27888, Accuracy: 0.99905, F1: 0.0180, Prec: 0.6376, Rec: 0.3758 lr: 0.00070\n",
      "Epoch 20/Step 1530, Loss: -0.21835, Accuracy: 0.99905, F1: 0.0185, Prec: 0.6378, Rec: 0.3759 lr: 0.00070\n",
      "Epoch 20/Step 1540, Loss: -0.20112, Accuracy: 0.99905, F1: 0.0184, Prec: 0.6378, Rec: 0.3757 lr: 0.00070\n",
      "Epoch 20/Step 1550, Loss: -0.23239, Accuracy: 0.99905, F1: 0.0188, Prec: 0.6379, Rec: 0.3757 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9987\n",
      "Validation f1: 0.1334\n",
      "Validation precision: 0.3893\n",
      "Validation recall: 0.2040\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_19_valF1Score0.133/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_19_valF1Score0.133/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 21\n",
      "Epoch 21/Step 0, Loss: -0.25388, Accuracy: 0.99916, F1: 0.0000, Prec: 0.6900, Rec: 0.4132 lr: 0.00070\n",
      "Epoch 21/Step 10, Loss: -0.27448, Accuracy: 0.99902, F1: 0.0000, Prec: 0.6856, Rec: 0.3912 lr: 0.00070\n",
      "Epoch 21/Step 20, Loss: -0.25180, Accuracy: 0.99905, F1: 0.0521, Prec: 0.6663, Rec: 0.3893 lr: 0.00070\n",
      "Epoch 21/Step 30, Loss: -0.20463, Accuracy: 0.99907, F1: 0.0890, Prec: 0.6510, Rec: 0.3910 lr: 0.00070\n",
      "Epoch 21/Step 40, Loss: -0.20974, Accuracy: 0.99906, F1: 0.0673, Prec: 0.6588, Rec: 0.3905 lr: 0.00070\n",
      "Epoch 21/Step 50, Loss: -0.24536, Accuracy: 0.99907, F1: 0.0541, Prec: 0.6688, Rec: 0.3883 lr: 0.00070\n",
      "Epoch 21/Step 60, Loss: -0.24698, Accuracy: 0.99908, F1: 0.0452, Prec: 0.6715, Rec: 0.3899 lr: 0.00070\n",
      "Epoch 21/Step 70, Loss: -0.22851, Accuracy: 0.99909, F1: 0.0388, Prec: 0.6670, Rec: 0.3917 lr: 0.00070\n",
      "Epoch 21/Step 80, Loss: -0.22965, Accuracy: 0.99910, F1: 0.0340, Prec: 0.6656, Rec: 0.3897 lr: 0.00070\n",
      "Epoch 21/Step 90, Loss: -0.20680, Accuracy: 0.99909, F1: 0.0303, Prec: 0.6682, Rec: 0.3868 lr: 0.00070\n",
      "Epoch 21/Step 100, Loss: -0.23886, Accuracy: 0.99909, F1: 0.0363, Prec: 0.6668, Rec: 0.3880 lr: 0.00070\n",
      "Epoch 21/Step 110, Loss: -0.23743, Accuracy: 0.99908, F1: 0.0399, Prec: 0.6620, Rec: 0.3886 lr: 0.00070\n",
      "Epoch 21/Step 120, Loss: -0.23299, Accuracy: 0.99908, F1: 0.0502, Prec: 0.6621, Rec: 0.3870 lr: 0.00070\n",
      "Epoch 21/Step 130, Loss: -0.19866, Accuracy: 0.99908, F1: 0.0604, Prec: 0.6616, Rec: 0.3873 lr: 0.00070\n",
      "Epoch 21/Step 140, Loss: -0.21536, Accuracy: 0.99907, F1: 0.0619, Prec: 0.6587, Rec: 0.3849 lr: 0.00070\n",
      "Epoch 21/Step 150, Loss: -0.22368, Accuracy: 0.99906, F1: 0.0578, Prec: 0.6564, Rec: 0.3827 lr: 0.00070\n",
      "Epoch 21/Step 160, Loss: -0.26149, Accuracy: 0.99906, F1: 0.0542, Prec: 0.6547, Rec: 0.3828 lr: 0.00070\n",
      "Epoch 21/Step 170, Loss: -0.24692, Accuracy: 0.99906, F1: 0.0603, Prec: 0.6529, Rec: 0.3825 lr: 0.00070\n",
      "Epoch 21/Step 180, Loss: -0.27968, Accuracy: 0.99906, F1: 0.0569, Prec: 0.6534, Rec: 0.3835 lr: 0.00070\n",
      "Epoch 21/Step 190, Loss: -0.21926, Accuracy: 0.99906, F1: 0.0540, Prec: 0.6523, Rec: 0.3831 lr: 0.00070\n",
      "Epoch 21/Step 200, Loss: -0.25188, Accuracy: 0.99905, F1: 0.0513, Prec: 0.6527, Rec: 0.3827 lr: 0.00070\n",
      "Epoch 21/Step 210, Loss: -0.21003, Accuracy: 0.99905, F1: 0.0489, Prec: 0.6528, Rec: 0.3828 lr: 0.00070\n",
      "Epoch 21/Step 220, Loss: -0.25727, Accuracy: 0.99905, F1: 0.0466, Prec: 0.6542, Rec: 0.3826 lr: 0.00070\n",
      "Epoch 21/Step 230, Loss: -0.20487, Accuracy: 0.99905, F1: 0.0446, Prec: 0.6523, Rec: 0.3823 lr: 0.00070\n",
      "Epoch 21/Step 240, Loss: -0.27805, Accuracy: 0.99904, F1: 0.0428, Prec: 0.6523, Rec: 0.3822 lr: 0.00070\n",
      "Epoch 21/Step 250, Loss: -0.25477, Accuracy: 0.99904, F1: 0.0411, Prec: 0.6530, Rec: 0.3815 lr: 0.00070\n",
      "Epoch 21/Step 260, Loss: -0.26818, Accuracy: 0.99904, F1: 0.0395, Prec: 0.6523, Rec: 0.3820 lr: 0.00070\n",
      "Epoch 21/Step 270, Loss: -0.26062, Accuracy: 0.99904, F1: 0.0380, Prec: 0.6520, Rec: 0.3815 lr: 0.00070\n",
      "Epoch 21/Step 280, Loss: -0.23565, Accuracy: 0.99904, F1: 0.0367, Prec: 0.6513, Rec: 0.3805 lr: 0.00070\n",
      "Epoch 21/Step 290, Loss: -0.23430, Accuracy: 0.99904, F1: 0.0354, Prec: 0.6511, Rec: 0.3806 lr: 0.00070\n",
      "Epoch 21/Step 300, Loss: -0.25824, Accuracy: 0.99904, F1: 0.0372, Prec: 0.6521, Rec: 0.3803 lr: 0.00070\n",
      "Epoch 21/Step 310, Loss: -0.24387, Accuracy: 0.99904, F1: 0.0395, Prec: 0.6514, Rec: 0.3804 lr: 0.00070\n",
      "Epoch 21/Step 320, Loss: -0.23519, Accuracy: 0.99904, F1: 0.0382, Prec: 0.6520, Rec: 0.3807 lr: 0.00070\n",
      "Epoch 21/Step 330, Loss: -0.24798, Accuracy: 0.99904, F1: 0.0371, Prec: 0.6518, Rec: 0.3808 lr: 0.00070\n",
      "Epoch 21/Step 340, Loss: -0.23964, Accuracy: 0.99904, F1: 0.0360, Prec: 0.6510, Rec: 0.3811 lr: 0.00070\n",
      "Epoch 21/Step 350, Loss: -0.21141, Accuracy: 0.99904, F1: 0.0350, Prec: 0.6524, Rec: 0.3815 lr: 0.00070\n",
      "Epoch 21/Step 360, Loss: -0.24559, Accuracy: 0.99904, F1: 0.0340, Prec: 0.6529, Rec: 0.3820 lr: 0.00070\n",
      "Epoch 21/Step 370, Loss: -0.24607, Accuracy: 0.99904, F1: 0.0331, Prec: 0.6520, Rec: 0.3822 lr: 0.00070\n",
      "Epoch 21/Step 380, Loss: -0.24514, Accuracy: 0.99904, F1: 0.0322, Prec: 0.6509, Rec: 0.3819 lr: 0.00070\n",
      "Epoch 21/Step 390, Loss: -0.20519, Accuracy: 0.99904, F1: 0.0314, Prec: 0.6512, Rec: 0.3814 lr: 0.00070\n",
      "Epoch 21/Step 400, Loss: -0.20205, Accuracy: 0.99904, F1: 0.0306, Prec: 0.6515, Rec: 0.3807 lr: 0.00070\n",
      "Epoch 21/Step 410, Loss: -0.19196, Accuracy: 0.99904, F1: 0.0299, Prec: 0.6515, Rec: 0.3807 lr: 0.00070\n",
      "Epoch 21/Step 420, Loss: -0.24960, Accuracy: 0.99905, F1: 0.0291, Prec: 0.6521, Rec: 0.3810 lr: 0.00070\n",
      "Epoch 21/Step 430, Loss: -0.23225, Accuracy: 0.99905, F1: 0.0285, Prec: 0.6518, Rec: 0.3812 lr: 0.00070\n",
      "Epoch 21/Step 440, Loss: -0.25806, Accuracy: 0.99904, F1: 0.0278, Prec: 0.6513, Rec: 0.3812 lr: 0.00070\n",
      "Epoch 21/Step 450, Loss: -0.26455, Accuracy: 0.99904, F1: 0.0272, Prec: 0.6519, Rec: 0.3813 lr: 0.00070\n",
      "Epoch 21/Step 460, Loss: -0.21533, Accuracy: 0.99905, F1: 0.0266, Prec: 0.6513, Rec: 0.3810 lr: 0.00070\n",
      "Epoch 21/Step 470, Loss: -0.23130, Accuracy: 0.99905, F1: 0.0261, Prec: 0.6512, Rec: 0.3809 lr: 0.00070\n",
      "Epoch 21/Step 480, Loss: -0.23414, Accuracy: 0.99904, F1: 0.0274, Prec: 0.6502, Rec: 0.3800 lr: 0.00070\n",
      "Epoch 21/Step 490, Loss: -0.21480, Accuracy: 0.99904, F1: 0.0268, Prec: 0.6501, Rec: 0.3798 lr: 0.00070\n",
      "Epoch 21/Step 500, Loss: -0.24369, Accuracy: 0.99904, F1: 0.0263, Prec: 0.6503, Rec: 0.3798 lr: 0.00070\n",
      "Epoch 21/Step 510, Loss: -0.28698, Accuracy: 0.99904, F1: 0.0258, Prec: 0.6498, Rec: 0.3800 lr: 0.00070\n",
      "Epoch 21/Step 520, Loss: -0.22184, Accuracy: 0.99904, F1: 0.0253, Prec: 0.6500, Rec: 0.3802 lr: 0.00070\n",
      "Epoch 21/Step 530, Loss: -0.23658, Accuracy: 0.99904, F1: 0.0248, Prec: 0.6494, Rec: 0.3797 lr: 0.00070\n",
      "Epoch 21/Step 540, Loss: -0.23249, Accuracy: 0.99904, F1: 0.0243, Prec: 0.6495, Rec: 0.3795 lr: 0.00070\n",
      "Epoch 21/Step 550, Loss: -0.27371, Accuracy: 0.99904, F1: 0.0253, Prec: 0.6494, Rec: 0.3796 lr: 0.00070\n",
      "Epoch 21/Step 560, Loss: -0.22512, Accuracy: 0.99904, F1: 0.0248, Prec: 0.6487, Rec: 0.3796 lr: 0.00070\n",
      "Epoch 21/Step 570, Loss: -0.25168, Accuracy: 0.99904, F1: 0.0244, Prec: 0.6486, Rec: 0.3794 lr: 0.00070\n",
      "Epoch 21/Step 580, Loss: -0.19920, Accuracy: 0.99904, F1: 0.0253, Prec: 0.6490, Rec: 0.3791 lr: 0.00070\n",
      "Epoch 21/Step 590, Loss: -0.18311, Accuracy: 0.99904, F1: 0.0262, Prec: 0.6482, Rec: 0.3791 lr: 0.00070\n",
      "Epoch 21/Step 600, Loss: -0.22247, Accuracy: 0.99904, F1: 0.0258, Prec: 0.6475, Rec: 0.3791 lr: 0.00070\n",
      "Epoch 21/Step 610, Loss: -0.27343, Accuracy: 0.99904, F1: 0.0270, Prec: 0.6475, Rec: 0.3790 lr: 0.00070\n",
      "Epoch 21/Step 620, Loss: -0.25862, Accuracy: 0.99904, F1: 0.0282, Prec: 0.6475, Rec: 0.3793 lr: 0.00070\n",
      "Epoch 21/Step 630, Loss: -0.21449, Accuracy: 0.99904, F1: 0.0278, Prec: 0.6477, Rec: 0.3791 lr: 0.00070\n",
      "Epoch 21/Step 640, Loss: -0.21873, Accuracy: 0.99904, F1: 0.0289, Prec: 0.6476, Rec: 0.3790 lr: 0.00070\n",
      "Epoch 21/Step 650, Loss: -0.21262, Accuracy: 0.99904, F1: 0.0284, Prec: 0.6475, Rec: 0.3791 lr: 0.00070\n",
      "Epoch 21/Step 660, Loss: -0.23742, Accuracy: 0.99904, F1: 0.0280, Prec: 0.6476, Rec: 0.3791 lr: 0.00070\n",
      "Epoch 21/Step 670, Loss: -0.22989, Accuracy: 0.99904, F1: 0.0276, Prec: 0.6477, Rec: 0.3792 lr: 0.00070\n",
      "Epoch 21/Step 680, Loss: -0.19453, Accuracy: 0.99904, F1: 0.0284, Prec: 0.6480, Rec: 0.3793 lr: 0.00070\n",
      "Epoch 21/Step 690, Loss: -0.26125, Accuracy: 0.99904, F1: 0.0280, Prec: 0.6482, Rec: 0.3792 lr: 0.00070\n",
      "Epoch 21/Step 700, Loss: -0.24870, Accuracy: 0.99904, F1: 0.0276, Prec: 0.6481, Rec: 0.3791 lr: 0.00070\n",
      "Epoch 21/Step 710, Loss: -0.24112, Accuracy: 0.99904, F1: 0.0272, Prec: 0.6484, Rec: 0.3795 lr: 0.00070\n",
      "Epoch 21/Step 720, Loss: -0.25647, Accuracy: 0.99904, F1: 0.0268, Prec: 0.6485, Rec: 0.3792 lr: 0.00070\n",
      "Epoch 21/Step 730, Loss: -0.21498, Accuracy: 0.99904, F1: 0.0265, Prec: 0.6485, Rec: 0.3790 lr: 0.00070\n",
      "Epoch 21/Step 740, Loss: -0.24126, Accuracy: 0.99904, F1: 0.0261, Prec: 0.6482, Rec: 0.3789 lr: 0.00070\n",
      "Epoch 21/Step 750, Loss: -0.25694, Accuracy: 0.99904, F1: 0.0258, Prec: 0.6480, Rec: 0.3790 lr: 0.00070\n",
      "Epoch 21/Step 760, Loss: -0.24532, Accuracy: 0.99904, F1: 0.0268, Prec: 0.6481, Rec: 0.3787 lr: 0.00070\n",
      "Epoch 21/Step 770, Loss: -0.26190, Accuracy: 0.99904, F1: 0.0264, Prec: 0.6479, Rec: 0.3787 lr: 0.00070\n",
      "Epoch 21/Step 780, Loss: -0.20006, Accuracy: 0.99904, F1: 0.0261, Prec: 0.6485, Rec: 0.3789 lr: 0.00070\n",
      "Epoch 21/Step 790, Loss: -0.25314, Accuracy: 0.99904, F1: 0.0257, Prec: 0.6483, Rec: 0.3787 lr: 0.00070\n",
      "Epoch 21/Step 800, Loss: -0.21943, Accuracy: 0.99904, F1: 0.0254, Prec: 0.6488, Rec: 0.3784 lr: 0.00070\n",
      "Epoch 21/Step 810, Loss: -0.17329, Accuracy: 0.99904, F1: 0.0251, Prec: 0.6489, Rec: 0.3785 lr: 0.00070\n",
      "Epoch 21/Step 820, Loss: -0.22034, Accuracy: 0.99904, F1: 0.0248, Prec: 0.6480, Rec: 0.3785 lr: 0.00070\n",
      "Epoch 21/Step 830, Loss: -0.25423, Accuracy: 0.99905, F1: 0.0256, Prec: 0.6483, Rec: 0.3785 lr: 0.00070\n",
      "Epoch 21/Step 840, Loss: -0.27609, Accuracy: 0.99905, F1: 0.0253, Prec: 0.6487, Rec: 0.3786 lr: 0.00070\n",
      "Epoch 21/Step 850, Loss: -0.23740, Accuracy: 0.99905, F1: 0.0250, Prec: 0.6486, Rec: 0.3784 lr: 0.00070\n",
      "Epoch 21/Step 860, Loss: -0.23666, Accuracy: 0.99905, F1: 0.0258, Prec: 0.6484, Rec: 0.3785 lr: 0.00070\n",
      "Epoch 21/Step 870, Loss: -0.23485, Accuracy: 0.99904, F1: 0.0255, Prec: 0.6478, Rec: 0.3783 lr: 0.00070\n",
      "Epoch 21/Step 880, Loss: -0.20603, Accuracy: 0.99905, F1: 0.0252, Prec: 0.6480, Rec: 0.3783 lr: 0.00070\n",
      "Epoch 21/Step 890, Loss: -0.23136, Accuracy: 0.99905, F1: 0.0249, Prec: 0.6479, Rec: 0.3782 lr: 0.00070\n",
      "Epoch 21/Step 900, Loss: -0.28767, Accuracy: 0.99905, F1: 0.0247, Prec: 0.6479, Rec: 0.3784 lr: 0.00070\n",
      "Epoch 21/Step 910, Loss: -0.19965, Accuracy: 0.99905, F1: 0.0244, Prec: 0.6476, Rec: 0.3782 lr: 0.00070\n",
      "Epoch 21/Step 920, Loss: -0.23526, Accuracy: 0.99904, F1: 0.0241, Prec: 0.6475, Rec: 0.3779 lr: 0.00070\n",
      "Epoch 21/Step 930, Loss: -0.23028, Accuracy: 0.99905, F1: 0.0239, Prec: 0.6476, Rec: 0.3780 lr: 0.00070\n",
      "Epoch 21/Step 940, Loss: -0.23729, Accuracy: 0.99905, F1: 0.0236, Prec: 0.6474, Rec: 0.3781 lr: 0.00070\n",
      "Epoch 21/Step 950, Loss: -0.24467, Accuracy: 0.99905, F1: 0.0234, Prec: 0.6476, Rec: 0.3782 lr: 0.00070\n",
      "Epoch 21/Step 960, Loss: -0.26760, Accuracy: 0.99905, F1: 0.0231, Prec: 0.6476, Rec: 0.3783 lr: 0.00070\n",
      "Epoch 21/Step 970, Loss: -0.21506, Accuracy: 0.99905, F1: 0.0229, Prec: 0.6475, Rec: 0.3778 lr: 0.00070\n",
      "Epoch 21/Step 980, Loss: -0.24757, Accuracy: 0.99905, F1: 0.0227, Prec: 0.6475, Rec: 0.3776 lr: 0.00070\n",
      "Epoch 21/Step 990, Loss: -0.22650, Accuracy: 0.99905, F1: 0.0224, Prec: 0.6468, Rec: 0.3776 lr: 0.00070\n",
      "Epoch 21/Step 1000, Loss: -0.24345, Accuracy: 0.99905, F1: 0.0222, Prec: 0.6469, Rec: 0.3779 lr: 0.00070\n",
      "Epoch 21/Step 1010, Loss: -0.24839, Accuracy: 0.99905, F1: 0.0220, Prec: 0.6475, Rec: 0.3779 lr: 0.00070\n",
      "Epoch 21/Step 1020, Loss: -0.19694, Accuracy: 0.99905, F1: 0.0218, Prec: 0.6473, Rec: 0.3778 lr: 0.00070\n",
      "Epoch 21/Step 1030, Loss: -0.24313, Accuracy: 0.99905, F1: 0.0216, Prec: 0.6473, Rec: 0.3777 lr: 0.00070\n",
      "Epoch 21/Step 1040, Loss: -0.23340, Accuracy: 0.99905, F1: 0.0213, Prec: 0.6474, Rec: 0.3778 lr: 0.00070\n",
      "Epoch 21/Step 1050, Loss: -0.25714, Accuracy: 0.99905, F1: 0.0211, Prec: 0.6474, Rec: 0.3778 lr: 0.00070\n",
      "Epoch 21/Step 1060, Loss: -0.26665, Accuracy: 0.99905, F1: 0.0209, Prec: 0.6475, Rec: 0.3781 lr: 0.00070\n",
      "Epoch 21/Step 1070, Loss: -0.23439, Accuracy: 0.99905, F1: 0.0225, Prec: 0.6476, Rec: 0.3781 lr: 0.00070\n",
      "Epoch 21/Step 1080, Loss: -0.22398, Accuracy: 0.99905, F1: 0.0223, Prec: 0.6477, Rec: 0.3782 lr: 0.00070\n",
      "Epoch 21/Step 1090, Loss: -0.23042, Accuracy: 0.99905, F1: 0.0229, Prec: 0.6474, Rec: 0.3781 lr: 0.00070\n",
      "Epoch 21/Step 1100, Loss: -0.25112, Accuracy: 0.99905, F1: 0.0227, Prec: 0.6475, Rec: 0.3782 lr: 0.00070\n",
      "Epoch 21/Step 1110, Loss: -0.20365, Accuracy: 0.99905, F1: 0.0224, Prec: 0.6474, Rec: 0.3782 lr: 0.00070\n",
      "Epoch 21/Step 1120, Loss: -0.21273, Accuracy: 0.99905, F1: 0.0230, Prec: 0.6474, Rec: 0.3781 lr: 0.00070\n",
      "Epoch 21/Step 1130, Loss: -0.21576, Accuracy: 0.99906, F1: 0.0237, Prec: 0.6475, Rec: 0.3783 lr: 0.00070\n",
      "Epoch 21/Step 1140, Loss: -0.22757, Accuracy: 0.99906, F1: 0.0234, Prec: 0.6473, Rec: 0.3785 lr: 0.00070\n",
      "Epoch 21/Step 1150, Loss: -0.25973, Accuracy: 0.99906, F1: 0.0232, Prec: 0.6475, Rec: 0.3786 lr: 0.00070\n",
      "Epoch 21/Step 1160, Loss: -0.20268, Accuracy: 0.99906, F1: 0.0230, Prec: 0.6480, Rec: 0.3788 lr: 0.00070\n",
      "Epoch 21/Step 1170, Loss: -0.20993, Accuracy: 0.99906, F1: 0.0228, Prec: 0.6481, Rec: 0.3787 lr: 0.00070\n",
      "Epoch 21/Step 1180, Loss: -0.19299, Accuracy: 0.99906, F1: 0.0227, Prec: 0.6478, Rec: 0.3787 lr: 0.00070\n",
      "Epoch 21/Step 1190, Loss: -0.26111, Accuracy: 0.99906, F1: 0.0225, Prec: 0.6476, Rec: 0.3785 lr: 0.00070\n",
      "Epoch 21/Step 1200, Loss: -0.23201, Accuracy: 0.99906, F1: 0.0223, Prec: 0.6480, Rec: 0.3787 lr: 0.00070\n",
      "Epoch 21/Step 1210, Loss: -0.24911, Accuracy: 0.99906, F1: 0.0221, Prec: 0.6483, Rec: 0.3789 lr: 0.00070\n",
      "Epoch 21/Step 1220, Loss: -0.25721, Accuracy: 0.99906, F1: 0.0219, Prec: 0.6483, Rec: 0.3789 lr: 0.00070\n",
      "Epoch 21/Step 1230, Loss: -0.23699, Accuracy: 0.99906, F1: 0.0217, Prec: 0.6481, Rec: 0.3789 lr: 0.00070\n",
      "Epoch 21/Step 1240, Loss: -0.27579, Accuracy: 0.99906, F1: 0.0216, Prec: 0.6481, Rec: 0.3789 lr: 0.00070\n",
      "Epoch 21/Step 1250, Loss: -0.17678, Accuracy: 0.99906, F1: 0.0214, Prec: 0.6481, Rec: 0.3789 lr: 0.00070\n",
      "Epoch 21/Step 1260, Loss: -0.24956, Accuracy: 0.99906, F1: 0.0212, Prec: 0.6479, Rec: 0.3791 lr: 0.00070\n",
      "Epoch 21/Step 1270, Loss: -0.23697, Accuracy: 0.99906, F1: 0.0211, Prec: 0.6477, Rec: 0.3793 lr: 0.00070\n",
      "Epoch 21/Step 1280, Loss: -0.30231, Accuracy: 0.99906, F1: 0.0209, Prec: 0.6479, Rec: 0.3792 lr: 0.00070\n",
      "Epoch 21/Step 1290, Loss: -0.25154, Accuracy: 0.99906, F1: 0.0216, Prec: 0.6482, Rec: 0.3792 lr: 0.00070\n",
      "Epoch 21/Step 1300, Loss: -0.22057, Accuracy: 0.99906, F1: 0.0214, Prec: 0.6478, Rec: 0.3793 lr: 0.00070\n",
      "Epoch 21/Step 1310, Loss: -0.24955, Accuracy: 0.99906, F1: 0.0213, Prec: 0.6480, Rec: 0.3793 lr: 0.00070\n",
      "Epoch 21/Step 1320, Loss: -0.26260, Accuracy: 0.99906, F1: 0.0211, Prec: 0.6482, Rec: 0.3794 lr: 0.00070\n",
      "Epoch 21/Step 1330, Loss: -0.26008, Accuracy: 0.99906, F1: 0.0210, Prec: 0.6482, Rec: 0.3793 lr: 0.00070\n",
      "Epoch 21/Step 1340, Loss: -0.24597, Accuracy: 0.99906, F1: 0.0208, Prec: 0.6484, Rec: 0.3794 lr: 0.00070\n",
      "Epoch 21/Step 1350, Loss: -0.19977, Accuracy: 0.99906, F1: 0.0206, Prec: 0.6486, Rec: 0.3794 lr: 0.00070\n",
      "Epoch 21/Step 1360, Loss: -0.22660, Accuracy: 0.99906, F1: 0.0212, Prec: 0.6486, Rec: 0.3795 lr: 0.00070\n",
      "Epoch 21/Step 1370, Loss: -0.24537, Accuracy: 0.99906, F1: 0.0210, Prec: 0.6488, Rec: 0.3796 lr: 0.00070\n",
      "Epoch 21/Step 1380, Loss: -0.24077, Accuracy: 0.99906, F1: 0.0209, Prec: 0.6487, Rec: 0.3797 lr: 0.00070\n",
      "Epoch 21/Step 1390, Loss: -0.24221, Accuracy: 0.99906, F1: 0.0207, Prec: 0.6485, Rec: 0.3797 lr: 0.00070\n",
      "Epoch 21/Step 1400, Loss: -0.25261, Accuracy: 0.99906, F1: 0.0206, Prec: 0.6486, Rec: 0.3798 lr: 0.00070\n",
      "Epoch 21/Step 1410, Loss: -0.22062, Accuracy: 0.99906, F1: 0.0204, Prec: 0.6488, Rec: 0.3797 lr: 0.00070\n",
      "Epoch 21/Step 1420, Loss: -0.22279, Accuracy: 0.99906, F1: 0.0203, Prec: 0.6487, Rec: 0.3796 lr: 0.00070\n",
      "Epoch 21/Step 1430, Loss: -0.22950, Accuracy: 0.99906, F1: 0.0202, Prec: 0.6489, Rec: 0.3794 lr: 0.00070\n",
      "Epoch 21/Step 1440, Loss: -0.23037, Accuracy: 0.99906, F1: 0.0200, Prec: 0.6489, Rec: 0.3795 lr: 0.00070\n",
      "Epoch 21/Step 1450, Loss: -0.23397, Accuracy: 0.99906, F1: 0.0199, Prec: 0.6491, Rec: 0.3796 lr: 0.00070\n",
      "Epoch 21/Step 1460, Loss: -0.22542, Accuracy: 0.99906, F1: 0.0198, Prec: 0.6490, Rec: 0.3795 lr: 0.00070\n",
      "Epoch 21/Step 1470, Loss: -0.22598, Accuracy: 0.99906, F1: 0.0196, Prec: 0.6489, Rec: 0.3794 lr: 0.00070\n",
      "Epoch 21/Step 1480, Loss: -0.22479, Accuracy: 0.99906, F1: 0.0195, Prec: 0.6489, Rec: 0.3794 lr: 0.00070\n",
      "Epoch 21/Step 1490, Loss: -0.22193, Accuracy: 0.99906, F1: 0.0194, Prec: 0.6488, Rec: 0.3792 lr: 0.00070\n",
      "Epoch 21/Step 1500, Loss: -0.24262, Accuracy: 0.99906, F1: 0.0192, Prec: 0.6488, Rec: 0.3794 lr: 0.00070\n",
      "Epoch 21/Step 1510, Loss: -0.22414, Accuracy: 0.99907, F1: 0.0191, Prec: 0.6490, Rec: 0.3794 lr: 0.00070\n",
      "Epoch 21/Step 1520, Loss: -0.27525, Accuracy: 0.99907, F1: 0.0190, Prec: 0.6492, Rec: 0.3795 lr: 0.00070\n",
      "Epoch 21/Step 1530, Loss: -0.22124, Accuracy: 0.99907, F1: 0.0195, Prec: 0.6493, Rec: 0.3796 lr: 0.00070\n",
      "Epoch 21/Step 1540, Loss: -0.21237, Accuracy: 0.99907, F1: 0.0194, Prec: 0.6491, Rec: 0.3794 lr: 0.00070\n",
      "Epoch 21/Step 1550, Loss: -0.23431, Accuracy: 0.99907, F1: 0.0198, Prec: 0.6493, Rec: 0.3794 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9987\n",
      "Validation f1: 0.0745\n",
      "Validation precision: 0.3940\n",
      "Validation recall: 0.2029\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_20_valF1Score0.074/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_20_valF1Score0.074/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 22\n",
      "Epoch 22/Step 0, Loss: -0.25389, Accuracy: 0.99915, F1: 0.0000, Prec: 0.6810, Rec: 0.4166 lr: 0.00070\n",
      "Epoch 22/Step 10, Loss: -0.28391, Accuracy: 0.99903, F1: 0.0000, Prec: 0.6843, Rec: 0.3954 lr: 0.00070\n",
      "Epoch 22/Step 20, Loss: -0.25138, Accuracy: 0.99907, F1: 0.0000, Prec: 0.6785, Rec: 0.3925 lr: 0.00070\n",
      "Epoch 22/Step 30, Loss: -0.20132, Accuracy: 0.99908, F1: 0.0537, Prec: 0.6652, Rec: 0.3938 lr: 0.00070\n",
      "Epoch 22/Step 40, Loss: -0.20587, Accuracy: 0.99907, F1: 0.0406, Prec: 0.6682, Rec: 0.3942 lr: 0.00070\n",
      "Epoch 22/Step 50, Loss: -0.24005, Accuracy: 0.99908, F1: 0.0326, Prec: 0.6777, Rec: 0.3912 lr: 0.00070\n",
      "Epoch 22/Step 60, Loss: -0.24917, Accuracy: 0.99909, F1: 0.0273, Prec: 0.6824, Rec: 0.3912 lr: 0.00070\n",
      "Epoch 22/Step 70, Loss: -0.23449, Accuracy: 0.99911, F1: 0.0234, Prec: 0.6779, Rec: 0.3941 lr: 0.00070\n",
      "Epoch 22/Step 80, Loss: -0.22676, Accuracy: 0.99911, F1: 0.0205, Prec: 0.6773, Rec: 0.3917 lr: 0.00070\n",
      "Epoch 22/Step 90, Loss: -0.21224, Accuracy: 0.99910, F1: 0.0270, Prec: 0.6768, Rec: 0.3906 lr: 0.00070\n",
      "Epoch 22/Step 100, Loss: -0.24522, Accuracy: 0.99911, F1: 0.0348, Prec: 0.6782, Rec: 0.3910 lr: 0.00070\n",
      "Epoch 22/Step 110, Loss: -0.24154, Accuracy: 0.99909, F1: 0.0394, Prec: 0.6751, Rec: 0.3910 lr: 0.00070\n",
      "Epoch 22/Step 120, Loss: -0.23167, Accuracy: 0.99909, F1: 0.0422, Prec: 0.6728, Rec: 0.3905 lr: 0.00070\n",
      "Epoch 22/Step 130, Loss: -0.19183, Accuracy: 0.99909, F1: 0.0536, Prec: 0.6717, Rec: 0.3906 lr: 0.00070\n",
      "Epoch 22/Step 140, Loss: -0.21281, Accuracy: 0.99908, F1: 0.0498, Prec: 0.6693, Rec: 0.3874 lr: 0.00070\n",
      "Epoch 22/Step 150, Loss: -0.22846, Accuracy: 0.99907, F1: 0.0465, Prec: 0.6671, Rec: 0.3859 lr: 0.00070\n",
      "Epoch 22/Step 160, Loss: -0.26404, Accuracy: 0.99907, F1: 0.0436, Prec: 0.6647, Rec: 0.3864 lr: 0.00070\n",
      "Epoch 22/Step 170, Loss: -0.24825, Accuracy: 0.99907, F1: 0.0411, Prec: 0.6628, Rec: 0.3861 lr: 0.00070\n",
      "Epoch 22/Step 180, Loss: -0.28534, Accuracy: 0.99907, F1: 0.0388, Prec: 0.6629, Rec: 0.3870 lr: 0.00070\n",
      "Epoch 22/Step 190, Loss: -0.21444, Accuracy: 0.99907, F1: 0.0368, Prec: 0.6604, Rec: 0.3865 lr: 0.00070\n",
      "Epoch 22/Step 200, Loss: -0.25757, Accuracy: 0.99906, F1: 0.0349, Prec: 0.6601, Rec: 0.3866 lr: 0.00070\n",
      "Epoch 22/Step 210, Loss: -0.21222, Accuracy: 0.99906, F1: 0.0333, Prec: 0.6599, Rec: 0.3865 lr: 0.00070\n",
      "Epoch 22/Step 220, Loss: -0.25298, Accuracy: 0.99906, F1: 0.0318, Prec: 0.6609, Rec: 0.3865 lr: 0.00070\n",
      "Epoch 22/Step 230, Loss: -0.22211, Accuracy: 0.99906, F1: 0.0304, Prec: 0.6599, Rec: 0.3862 lr: 0.00070\n",
      "Epoch 22/Step 240, Loss: -0.27702, Accuracy: 0.99905, F1: 0.0291, Prec: 0.6594, Rec: 0.3861 lr: 0.00070\n",
      "Epoch 22/Step 250, Loss: -0.25177, Accuracy: 0.99905, F1: 0.0280, Prec: 0.6602, Rec: 0.3852 lr: 0.00070\n",
      "Epoch 22/Step 260, Loss: -0.26859, Accuracy: 0.99905, F1: 0.0269, Prec: 0.6596, Rec: 0.3857 lr: 0.00070\n",
      "Epoch 22/Step 270, Loss: -0.26034, Accuracy: 0.99905, F1: 0.0259, Prec: 0.6578, Rec: 0.3854 lr: 0.00070\n",
      "Epoch 22/Step 280, Loss: -0.24121, Accuracy: 0.99904, F1: 0.0250, Prec: 0.6575, Rec: 0.3842 lr: 0.00070\n",
      "Epoch 22/Step 290, Loss: -0.23740, Accuracy: 0.99905, F1: 0.0241, Prec: 0.6576, Rec: 0.3841 lr: 0.00070\n",
      "Epoch 22/Step 300, Loss: -0.26298, Accuracy: 0.99905, F1: 0.0262, Prec: 0.6584, Rec: 0.3838 lr: 0.00070\n",
      "Epoch 22/Step 310, Loss: -0.24741, Accuracy: 0.99905, F1: 0.0291, Prec: 0.6580, Rec: 0.3839 lr: 0.00070\n",
      "Epoch 22/Step 320, Loss: -0.23945, Accuracy: 0.99905, F1: 0.0282, Prec: 0.6585, Rec: 0.3844 lr: 0.00070\n",
      "Epoch 22/Step 330, Loss: -0.25331, Accuracy: 0.99905, F1: 0.0273, Prec: 0.6590, Rec: 0.3843 lr: 0.00070\n",
      "Epoch 22/Step 340, Loss: -0.23520, Accuracy: 0.99905, F1: 0.0265, Prec: 0.6588, Rec: 0.3845 lr: 0.00070\n",
      "Epoch 22/Step 350, Loss: -0.21371, Accuracy: 0.99905, F1: 0.0258, Prec: 0.6598, Rec: 0.3851 lr: 0.00070\n",
      "Epoch 22/Step 360, Loss: -0.24650, Accuracy: 0.99905, F1: 0.0251, Prec: 0.6602, Rec: 0.3854 lr: 0.00070\n",
      "Epoch 22/Step 370, Loss: -0.24926, Accuracy: 0.99905, F1: 0.0244, Prec: 0.6600, Rec: 0.3856 lr: 0.00070\n",
      "Epoch 22/Step 380, Loss: -0.25518, Accuracy: 0.99905, F1: 0.0238, Prec: 0.6594, Rec: 0.3852 lr: 0.00070\n",
      "Epoch 22/Step 390, Loss: -0.21005, Accuracy: 0.99905, F1: 0.0232, Prec: 0.6594, Rec: 0.3849 lr: 0.00070\n",
      "Epoch 22/Step 400, Loss: -0.20432, Accuracy: 0.99905, F1: 0.0226, Prec: 0.6595, Rec: 0.3842 lr: 0.00070\n",
      "Epoch 22/Step 410, Loss: -0.20177, Accuracy: 0.99905, F1: 0.0220, Prec: 0.6595, Rec: 0.3841 lr: 0.00070\n",
      "Epoch 22/Step 420, Loss: -0.25514, Accuracy: 0.99906, F1: 0.0215, Prec: 0.6595, Rec: 0.3847 lr: 0.00070\n",
      "Epoch 22/Step 430, Loss: -0.23094, Accuracy: 0.99906, F1: 0.0210, Prec: 0.6591, Rec: 0.3849 lr: 0.00070\n",
      "Epoch 22/Step 440, Loss: -0.26426, Accuracy: 0.99905, F1: 0.0205, Prec: 0.6591, Rec: 0.3847 lr: 0.00070\n",
      "Epoch 22/Step 450, Loss: -0.26001, Accuracy: 0.99905, F1: 0.0201, Prec: 0.6591, Rec: 0.3848 lr: 0.00070\n",
      "Epoch 22/Step 460, Loss: -0.22057, Accuracy: 0.99905, F1: 0.0196, Prec: 0.6582, Rec: 0.3846 lr: 0.00070\n",
      "Epoch 22/Step 470, Loss: -0.22748, Accuracy: 0.99906, F1: 0.0192, Prec: 0.6579, Rec: 0.3844 lr: 0.00070\n",
      "Epoch 22/Step 480, Loss: -0.22965, Accuracy: 0.99905, F1: 0.0188, Prec: 0.6569, Rec: 0.3836 lr: 0.00070\n",
      "Epoch 22/Step 490, Loss: -0.21330, Accuracy: 0.99905, F1: 0.0184, Prec: 0.6571, Rec: 0.3831 lr: 0.00070\n",
      "Epoch 22/Step 500, Loss: -0.24363, Accuracy: 0.99905, F1: 0.0181, Prec: 0.6577, Rec: 0.3830 lr: 0.00070\n",
      "Epoch 22/Step 510, Loss: -0.28269, Accuracy: 0.99905, F1: 0.0177, Prec: 0.6569, Rec: 0.3832 lr: 0.00070\n",
      "Epoch 22/Step 520, Loss: -0.22729, Accuracy: 0.99905, F1: 0.0174, Prec: 0.6565, Rec: 0.3836 lr: 0.00070\n",
      "Epoch 22/Step 530, Loss: -0.23259, Accuracy: 0.99905, F1: 0.0170, Prec: 0.6557, Rec: 0.3830 lr: 0.00070\n",
      "Epoch 22/Step 540, Loss: -0.24098, Accuracy: 0.99905, F1: 0.0167, Prec: 0.6558, Rec: 0.3829 lr: 0.00070\n",
      "Epoch 22/Step 550, Loss: -0.27006, Accuracy: 0.99905, F1: 0.0179, Prec: 0.6555, Rec: 0.3831 lr: 0.00070\n",
      "Epoch 22/Step 560, Loss: -0.22787, Accuracy: 0.99905, F1: 0.0176, Prec: 0.6554, Rec: 0.3829 lr: 0.00070\n",
      "Epoch 22/Step 570, Loss: -0.25064, Accuracy: 0.99905, F1: 0.0172, Prec: 0.6552, Rec: 0.3827 lr: 0.00070\n",
      "Epoch 22/Step 580, Loss: -0.20304, Accuracy: 0.99905, F1: 0.0170, Prec: 0.6555, Rec: 0.3824 lr: 0.00070\n",
      "Epoch 22/Step 590, Loss: -0.18932, Accuracy: 0.99905, F1: 0.0167, Prec: 0.6552, Rec: 0.3821 lr: 0.00070\n",
      "Epoch 22/Step 600, Loss: -0.23367, Accuracy: 0.99905, F1: 0.0164, Prec: 0.6551, Rec: 0.3820 lr: 0.00070\n",
      "Epoch 22/Step 610, Loss: -0.28157, Accuracy: 0.99905, F1: 0.0161, Prec: 0.6547, Rec: 0.3821 lr: 0.00070\n",
      "Epoch 22/Step 620, Loss: -0.25091, Accuracy: 0.99905, F1: 0.0159, Prec: 0.6545, Rec: 0.3824 lr: 0.00070\n",
      "Epoch 22/Step 630, Loss: -0.21530, Accuracy: 0.99905, F1: 0.0156, Prec: 0.6539, Rec: 0.3823 lr: 0.00070\n",
      "Epoch 22/Step 640, Loss: -0.22382, Accuracy: 0.99905, F1: 0.0168, Prec: 0.6535, Rec: 0.3823 lr: 0.00070\n",
      "Epoch 22/Step 650, Loss: -0.21821, Accuracy: 0.99905, F1: 0.0165, Prec: 0.6536, Rec: 0.3823 lr: 0.00070\n",
      "Epoch 22/Step 660, Loss: -0.24406, Accuracy: 0.99905, F1: 0.0163, Prec: 0.6536, Rec: 0.3824 lr: 0.00070\n",
      "Epoch 22/Step 670, Loss: -0.22795, Accuracy: 0.99905, F1: 0.0160, Prec: 0.6539, Rec: 0.3824 lr: 0.00070\n",
      "Epoch 22/Step 680, Loss: -0.19627, Accuracy: 0.99905, F1: 0.0158, Prec: 0.6537, Rec: 0.3826 lr: 0.00070\n",
      "Epoch 22/Step 690, Loss: -0.25991, Accuracy: 0.99905, F1: 0.0156, Prec: 0.6536, Rec: 0.3826 lr: 0.00070\n",
      "Epoch 22/Step 700, Loss: -0.24498, Accuracy: 0.99905, F1: 0.0154, Prec: 0.6538, Rec: 0.3823 lr: 0.00070\n",
      "Epoch 22/Step 710, Loss: -0.24617, Accuracy: 0.99905, F1: 0.0151, Prec: 0.6543, Rec: 0.3827 lr: 0.00070\n",
      "Epoch 22/Step 720, Loss: -0.25730, Accuracy: 0.99905, F1: 0.0149, Prec: 0.6544, Rec: 0.3824 lr: 0.00070\n",
      "Epoch 22/Step 730, Loss: -0.21816, Accuracy: 0.99905, F1: 0.0147, Prec: 0.6542, Rec: 0.3822 lr: 0.00070\n",
      "Epoch 22/Step 740, Loss: -0.24138, Accuracy: 0.99905, F1: 0.0145, Prec: 0.6542, Rec: 0.3820 lr: 0.00070\n",
      "Epoch 22/Step 750, Loss: -0.25158, Accuracy: 0.99905, F1: 0.0143, Prec: 0.6537, Rec: 0.3821 lr: 0.00070\n",
      "Epoch 22/Step 760, Loss: -0.24270, Accuracy: 0.99905, F1: 0.0155, Prec: 0.6539, Rec: 0.3817 lr: 0.00070\n",
      "Epoch 22/Step 770, Loss: -0.26670, Accuracy: 0.99905, F1: 0.0153, Prec: 0.6539, Rec: 0.3817 lr: 0.00070\n",
      "Epoch 22/Step 780, Loss: -0.19421, Accuracy: 0.99905, F1: 0.0151, Prec: 0.6544, Rec: 0.3819 lr: 0.00070\n",
      "Epoch 22/Step 790, Loss: -0.25849, Accuracy: 0.99905, F1: 0.0149, Prec: 0.6543, Rec: 0.3816 lr: 0.00070\n",
      "Epoch 22/Step 800, Loss: -0.22383, Accuracy: 0.99905, F1: 0.0147, Prec: 0.6547, Rec: 0.3815 lr: 0.00070\n",
      "Epoch 22/Step 810, Loss: -0.16470, Accuracy: 0.99905, F1: 0.0145, Prec: 0.6549, Rec: 0.3814 lr: 0.00070\n",
      "Epoch 22/Step 820, Loss: -0.22917, Accuracy: 0.99905, F1: 0.0143, Prec: 0.6543, Rec: 0.3814 lr: 0.00070\n",
      "Epoch 22/Step 830, Loss: -0.26221, Accuracy: 0.99905, F1: 0.0142, Prec: 0.6546, Rec: 0.3815 lr: 0.00070\n",
      "Epoch 22/Step 840, Loss: -0.27405, Accuracy: 0.99905, F1: 0.0140, Prec: 0.6549, Rec: 0.3816 lr: 0.00070\n",
      "Epoch 22/Step 850, Loss: -0.23554, Accuracy: 0.99905, F1: 0.0138, Prec: 0.6547, Rec: 0.3815 lr: 0.00070\n",
      "Epoch 22/Step 860, Loss: -0.24465, Accuracy: 0.99905, F1: 0.0148, Prec: 0.6549, Rec: 0.3815 lr: 0.00070\n",
      "Epoch 22/Step 870, Loss: -0.23287, Accuracy: 0.99905, F1: 0.0146, Prec: 0.6542, Rec: 0.3812 lr: 0.00070\n",
      "Epoch 22/Step 880, Loss: -0.21473, Accuracy: 0.99905, F1: 0.0144, Prec: 0.6542, Rec: 0.3812 lr: 0.00070\n",
      "Epoch 22/Step 890, Loss: -0.23524, Accuracy: 0.99905, F1: 0.0143, Prec: 0.6540, Rec: 0.3811 lr: 0.00070\n",
      "Epoch 22/Step 900, Loss: -0.28470, Accuracy: 0.99905, F1: 0.0141, Prec: 0.6541, Rec: 0.3813 lr: 0.00070\n",
      "Epoch 22/Step 910, Loss: -0.19638, Accuracy: 0.99905, F1: 0.0140, Prec: 0.6540, Rec: 0.3811 lr: 0.00070\n",
      "Epoch 22/Step 920, Loss: -0.24537, Accuracy: 0.99905, F1: 0.0138, Prec: 0.6539, Rec: 0.3808 lr: 0.00070\n",
      "Epoch 22/Step 930, Loss: -0.22517, Accuracy: 0.99905, F1: 0.0137, Prec: 0.6540, Rec: 0.3809 lr: 0.00070\n",
      "Epoch 22/Step 940, Loss: -0.23955, Accuracy: 0.99906, F1: 0.0135, Prec: 0.6537, Rec: 0.3810 lr: 0.00070\n",
      "Epoch 22/Step 950, Loss: -0.25063, Accuracy: 0.99906, F1: 0.0134, Prec: 0.6535, Rec: 0.3811 lr: 0.00070\n",
      "Epoch 22/Step 960, Loss: -0.26604, Accuracy: 0.99906, F1: 0.0132, Prec: 0.6535, Rec: 0.3812 lr: 0.00070\n",
      "Epoch 22/Step 970, Loss: -0.21198, Accuracy: 0.99906, F1: 0.0131, Prec: 0.6533, Rec: 0.3808 lr: 0.00070\n",
      "Epoch 22/Step 980, Loss: -0.24575, Accuracy: 0.99906, F1: 0.0130, Prec: 0.6534, Rec: 0.3805 lr: 0.00070\n",
      "Epoch 22/Step 990, Loss: -0.23203, Accuracy: 0.99906, F1: 0.0128, Prec: 0.6528, Rec: 0.3804 lr: 0.00070\n",
      "Epoch 22/Step 1000, Loss: -0.24420, Accuracy: 0.99906, F1: 0.0127, Prec: 0.6528, Rec: 0.3807 lr: 0.00070\n",
      "Epoch 22/Step 1010, Loss: -0.25148, Accuracy: 0.99906, F1: 0.0126, Prec: 0.6531, Rec: 0.3808 lr: 0.00070\n",
      "Epoch 22/Step 1020, Loss: -0.19671, Accuracy: 0.99906, F1: 0.0125, Prec: 0.6530, Rec: 0.3807 lr: 0.00070\n",
      "Epoch 22/Step 1030, Loss: -0.24331, Accuracy: 0.99906, F1: 0.0123, Prec: 0.6531, Rec: 0.3806 lr: 0.00070\n",
      "Epoch 22/Step 1040, Loss: -0.23476, Accuracy: 0.99906, F1: 0.0122, Prec: 0.6530, Rec: 0.3806 lr: 0.00070\n",
      "Epoch 22/Step 1050, Loss: -0.26504, Accuracy: 0.99906, F1: 0.0121, Prec: 0.6531, Rec: 0.3807 lr: 0.00070\n",
      "Epoch 22/Step 1060, Loss: -0.26332, Accuracy: 0.99906, F1: 0.0120, Prec: 0.6534, Rec: 0.3809 lr: 0.00070\n",
      "Epoch 22/Step 1070, Loss: -0.23655, Accuracy: 0.99906, F1: 0.0119, Prec: 0.6534, Rec: 0.3809 lr: 0.00070\n",
      "Epoch 22/Step 1080, Loss: -0.22434, Accuracy: 0.99906, F1: 0.0118, Prec: 0.6533, Rec: 0.3810 lr: 0.00070\n",
      "Epoch 22/Step 1090, Loss: -0.23292, Accuracy: 0.99906, F1: 0.0117, Prec: 0.6532, Rec: 0.3808 lr: 0.00070\n",
      "Epoch 22/Step 1100, Loss: -0.24405, Accuracy: 0.99906, F1: 0.0116, Prec: 0.6531, Rec: 0.3809 lr: 0.00070\n",
      "Epoch 22/Step 1110, Loss: -0.20504, Accuracy: 0.99906, F1: 0.0115, Prec: 0.6531, Rec: 0.3809 lr: 0.00070\n",
      "Epoch 22/Step 1120, Loss: -0.21313, Accuracy: 0.99906, F1: 0.0121, Prec: 0.6532, Rec: 0.3808 lr: 0.00070\n",
      "Epoch 22/Step 1130, Loss: -0.22032, Accuracy: 0.99906, F1: 0.0120, Prec: 0.6533, Rec: 0.3810 lr: 0.00070\n",
      "Epoch 22/Step 1140, Loss: -0.23556, Accuracy: 0.99906, F1: 0.0119, Prec: 0.6532, Rec: 0.3812 lr: 0.00070\n",
      "Epoch 22/Step 1150, Loss: -0.26329, Accuracy: 0.99906, F1: 0.0118, Prec: 0.6535, Rec: 0.3812 lr: 0.00070\n",
      "Epoch 22/Step 1160, Loss: -0.20646, Accuracy: 0.99907, F1: 0.0117, Prec: 0.6539, Rec: 0.3814 lr: 0.00070\n",
      "Epoch 22/Step 1170, Loss: -0.21255, Accuracy: 0.99907, F1: 0.0116, Prec: 0.6540, Rec: 0.3814 lr: 0.00070\n",
      "Epoch 22/Step 1180, Loss: -0.19539, Accuracy: 0.99907, F1: 0.0115, Prec: 0.6540, Rec: 0.3813 lr: 0.00070\n",
      "Epoch 22/Step 1190, Loss: -0.27186, Accuracy: 0.99906, F1: 0.0114, Prec: 0.6538, Rec: 0.3812 lr: 0.00070\n",
      "Epoch 22/Step 1200, Loss: -0.22225, Accuracy: 0.99907, F1: 0.0113, Prec: 0.6542, Rec: 0.3814 lr: 0.00070\n",
      "Epoch 22/Step 1210, Loss: -0.25335, Accuracy: 0.99907, F1: 0.0112, Prec: 0.6544, Rec: 0.3816 lr: 0.00070\n",
      "Epoch 22/Step 1220, Loss: -0.26030, Accuracy: 0.99907, F1: 0.0111, Prec: 0.6543, Rec: 0.3817 lr: 0.00070\n",
      "Epoch 22/Step 1230, Loss: -0.24790, Accuracy: 0.99907, F1: 0.0110, Prec: 0.6541, Rec: 0.3818 lr: 0.00070\n",
      "Epoch 22/Step 1240, Loss: -0.28113, Accuracy: 0.99907, F1: 0.0109, Prec: 0.6540, Rec: 0.3818 lr: 0.00070\n",
      "Epoch 22/Step 1250, Loss: -0.17433, Accuracy: 0.99907, F1: 0.0108, Prec: 0.6540, Rec: 0.3818 lr: 0.00070\n",
      "Epoch 22/Step 1260, Loss: -0.25895, Accuracy: 0.99907, F1: 0.0107, Prec: 0.6542, Rec: 0.3819 lr: 0.00070\n",
      "Epoch 22/Step 1270, Loss: -0.23425, Accuracy: 0.99907, F1: 0.0107, Prec: 0.6541, Rec: 0.3820 lr: 0.00070\n",
      "Epoch 22/Step 1280, Loss: -0.30337, Accuracy: 0.99907, F1: 0.0106, Prec: 0.6540, Rec: 0.3821 lr: 0.00070\n",
      "Epoch 22/Step 1290, Loss: -0.24429, Accuracy: 0.99907, F1: 0.0105, Prec: 0.6544, Rec: 0.3820 lr: 0.00070\n",
      "Epoch 22/Step 1300, Loss: -0.21174, Accuracy: 0.99907, F1: 0.0104, Prec: 0.6541, Rec: 0.3820 lr: 0.00070\n",
      "Epoch 22/Step 1310, Loss: -0.24315, Accuracy: 0.99907, F1: 0.0103, Prec: 0.6539, Rec: 0.3821 lr: 0.00070\n",
      "Epoch 22/Step 1320, Loss: -0.27016, Accuracy: 0.99907, F1: 0.0103, Prec: 0.6541, Rec: 0.3822 lr: 0.00070\n",
      "Epoch 22/Step 1330, Loss: -0.25969, Accuracy: 0.99907, F1: 0.0102, Prec: 0.6543, Rec: 0.3820 lr: 0.00070\n",
      "Epoch 22/Step 1340, Loss: -0.23975, Accuracy: 0.99907, F1: 0.0101, Prec: 0.6543, Rec: 0.3822 lr: 0.00070\n",
      "Epoch 22/Step 1350, Loss: -0.19791, Accuracy: 0.99907, F1: 0.0100, Prec: 0.6545, Rec: 0.3822 lr: 0.00070\n",
      "Epoch 22/Step 1360, Loss: -0.22857, Accuracy: 0.99907, F1: 0.0100, Prec: 0.6546, Rec: 0.3822 lr: 0.00070\n",
      "Epoch 22/Step 1370, Loss: -0.23759, Accuracy: 0.99907, F1: 0.0105, Prec: 0.6545, Rec: 0.3824 lr: 0.00070\n",
      "Epoch 22/Step 1380, Loss: -0.24087, Accuracy: 0.99907, F1: 0.0104, Prec: 0.6546, Rec: 0.3825 lr: 0.00070\n",
      "Epoch 22/Step 1390, Loss: -0.24559, Accuracy: 0.99907, F1: 0.0103, Prec: 0.6544, Rec: 0.3824 lr: 0.00070\n",
      "Epoch 22/Step 1400, Loss: -0.25319, Accuracy: 0.99907, F1: 0.0102, Prec: 0.6546, Rec: 0.3826 lr: 0.00070\n",
      "Epoch 22/Step 1410, Loss: -0.21976, Accuracy: 0.99907, F1: 0.0102, Prec: 0.6547, Rec: 0.3825 lr: 0.00070\n",
      "Epoch 22/Step 1420, Loss: -0.22919, Accuracy: 0.99907, F1: 0.0101, Prec: 0.6548, Rec: 0.3823 lr: 0.00070\n",
      "Epoch 22/Step 1430, Loss: -0.22915, Accuracy: 0.99907, F1: 0.0100, Prec: 0.6548, Rec: 0.3822 lr: 0.00070\n",
      "Epoch 22/Step 1440, Loss: -0.23955, Accuracy: 0.99907, F1: 0.0107, Prec: 0.6550, Rec: 0.3823 lr: 0.00070\n",
      "Epoch 22/Step 1450, Loss: -0.24385, Accuracy: 0.99907, F1: 0.0111, Prec: 0.6552, Rec: 0.3824 lr: 0.00070\n",
      "Epoch 22/Step 1460, Loss: -0.22634, Accuracy: 0.99907, F1: 0.0110, Prec: 0.6552, Rec: 0.3823 lr: 0.00070\n",
      "Epoch 22/Step 1470, Loss: -0.22423, Accuracy: 0.99907, F1: 0.0109, Prec: 0.6552, Rec: 0.3823 lr: 0.00070\n",
      "Epoch 22/Step 1480, Loss: -0.23179, Accuracy: 0.99907, F1: 0.0113, Prec: 0.6549, Rec: 0.3823 lr: 0.00070\n",
      "Epoch 22/Step 1490, Loss: -0.22289, Accuracy: 0.99907, F1: 0.0113, Prec: 0.6549, Rec: 0.3821 lr: 0.00070\n",
      "Epoch 22/Step 1500, Loss: -0.25452, Accuracy: 0.99907, F1: 0.0112, Prec: 0.6550, Rec: 0.3822 lr: 0.00070\n",
      "Epoch 22/Step 1510, Loss: -0.22359, Accuracy: 0.99907, F1: 0.0111, Prec: 0.6550, Rec: 0.3823 lr: 0.00070\n",
      "Epoch 22/Step 1520, Loss: -0.27597, Accuracy: 0.99907, F1: 0.0115, Prec: 0.6552, Rec: 0.3824 lr: 0.00070\n",
      "Epoch 22/Step 1530, Loss: -0.22517, Accuracy: 0.99907, F1: 0.0121, Prec: 0.6555, Rec: 0.3825 lr: 0.00070\n",
      "Epoch 22/Step 1540, Loss: -0.20693, Accuracy: 0.99907, F1: 0.0120, Prec: 0.6554, Rec: 0.3822 lr: 0.00070\n",
      "Epoch 22/Step 1550, Loss: -0.23631, Accuracy: 0.99907, F1: 0.0125, Prec: 0.6556, Rec: 0.3822 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9987\n",
      "Validation f1: 0.0897\n",
      "Validation precision: 0.3940\n",
      "Validation recall: 0.2016\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_21_valF1Score0.090/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_21_valF1Score0.090/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 23\n",
      "Epoch 23/Step 0, Loss: -0.25529, Accuracy: 0.99917, F1: 0.0000, Prec: 0.7032, Rec: 0.4112 lr: 0.00070\n",
      "Epoch 23/Step 10, Loss: -0.28351, Accuracy: 0.99904, F1: 0.0000, Prec: 0.6920, Rec: 0.3992 lr: 0.00070\n",
      "Epoch 23/Step 20, Loss: -0.25452, Accuracy: 0.99907, F1: 0.0000, Prec: 0.6804, Rec: 0.3988 lr: 0.00070\n",
      "Epoch 23/Step 30, Loss: -0.21894, Accuracy: 0.99909, F1: 0.0549, Prec: 0.6728, Rec: 0.3975 lr: 0.00070\n",
      "Epoch 23/Step 40, Loss: -0.21445, Accuracy: 0.99909, F1: 0.0415, Prec: 0.6823, Rec: 0.3963 lr: 0.00070\n",
      "Epoch 23/Step 50, Loss: -0.24350, Accuracy: 0.99910, F1: 0.0334, Prec: 0.6925, Rec: 0.3936 lr: 0.00070\n",
      "Epoch 23/Step 60, Loss: -0.25644, Accuracy: 0.99911, F1: 0.0441, Prec: 0.6950, Rec: 0.3945 lr: 0.00070\n",
      "Epoch 23/Step 70, Loss: -0.23478, Accuracy: 0.99912, F1: 0.0379, Prec: 0.6906, Rec: 0.3970 lr: 0.00070\n",
      "Epoch 23/Step 80, Loss: -0.22369, Accuracy: 0.99912, F1: 0.0332, Prec: 0.6879, Rec: 0.3951 lr: 0.00070\n",
      "Epoch 23/Step 90, Loss: -0.21736, Accuracy: 0.99911, F1: 0.0296, Prec: 0.6875, Rec: 0.3939 lr: 0.00070\n",
      "Epoch 23/Step 100, Loss: -0.24688, Accuracy: 0.99912, F1: 0.0364, Prec: 0.6861, Rec: 0.3953 lr: 0.00070\n",
      "Epoch 23/Step 110, Loss: -0.23802, Accuracy: 0.99910, F1: 0.0409, Prec: 0.6779, Rec: 0.3959 lr: 0.00070\n",
      "Epoch 23/Step 120, Loss: -0.23204, Accuracy: 0.99909, F1: 0.0509, Prec: 0.6744, Rec: 0.3953 lr: 0.00070\n",
      "Epoch 23/Step 130, Loss: -0.20458, Accuracy: 0.99910, F1: 0.0616, Prec: 0.6746, Rec: 0.3952 lr: 0.00070\n",
      "Epoch 23/Step 140, Loss: -0.21276, Accuracy: 0.99908, F1: 0.0572, Prec: 0.6717, Rec: 0.3926 lr: 0.00070\n",
      "Epoch 23/Step 150, Loss: -0.22089, Accuracy: 0.99907, F1: 0.0534, Prec: 0.6705, Rec: 0.3906 lr: 0.00070\n",
      "Epoch 23/Step 160, Loss: -0.25612, Accuracy: 0.99907, F1: 0.0501, Prec: 0.6680, Rec: 0.3910 lr: 0.00070\n",
      "Epoch 23/Step 170, Loss: -0.24624, Accuracy: 0.99908, F1: 0.0560, Prec: 0.6661, Rec: 0.3907 lr: 0.00070\n",
      "Epoch 23/Step 180, Loss: -0.28578, Accuracy: 0.99908, F1: 0.0529, Prec: 0.6668, Rec: 0.3915 lr: 0.00070\n",
      "Epoch 23/Step 190, Loss: -0.21880, Accuracy: 0.99907, F1: 0.0501, Prec: 0.6651, Rec: 0.3907 lr: 0.00070\n",
      "Epoch 23/Step 200, Loss: -0.25386, Accuracy: 0.99907, F1: 0.0476, Prec: 0.6647, Rec: 0.3904 lr: 0.00070\n",
      "Epoch 23/Step 210, Loss: -0.21173, Accuracy: 0.99906, F1: 0.0454, Prec: 0.6630, Rec: 0.3904 lr: 0.00070\n",
      "Epoch 23/Step 220, Loss: -0.24975, Accuracy: 0.99906, F1: 0.0433, Prec: 0.6640, Rec: 0.3903 lr: 0.00070\n",
      "Epoch 23/Step 230, Loss: -0.21320, Accuracy: 0.99906, F1: 0.0414, Prec: 0.6627, Rec: 0.3900 lr: 0.00070\n",
      "Epoch 23/Step 240, Loss: -0.27568, Accuracy: 0.99906, F1: 0.0397, Prec: 0.6614, Rec: 0.3900 lr: 0.00070\n",
      "Epoch 23/Step 250, Loss: -0.25016, Accuracy: 0.99906, F1: 0.0381, Prec: 0.6621, Rec: 0.3892 lr: 0.00070\n",
      "Epoch 23/Step 260, Loss: -0.26844, Accuracy: 0.99906, F1: 0.0367, Prec: 0.6620, Rec: 0.3894 lr: 0.00070\n",
      "Epoch 23/Step 270, Loss: -0.26752, Accuracy: 0.99905, F1: 0.0353, Prec: 0.6611, Rec: 0.3890 lr: 0.00070\n",
      "Epoch 23/Step 280, Loss: -0.24188, Accuracy: 0.99905, F1: 0.0341, Prec: 0.6610, Rec: 0.3875 lr: 0.00070\n",
      "Epoch 23/Step 290, Loss: -0.23784, Accuracy: 0.99905, F1: 0.0329, Prec: 0.6613, Rec: 0.3876 lr: 0.00070\n",
      "Epoch 23/Step 300, Loss: -0.25539, Accuracy: 0.99905, F1: 0.0349, Prec: 0.6617, Rec: 0.3873 lr: 0.00070\n",
      "Epoch 23/Step 310, Loss: -0.25129, Accuracy: 0.99905, F1: 0.0372, Prec: 0.6619, Rec: 0.3872 lr: 0.00070\n",
      "Epoch 23/Step 320, Loss: -0.24335, Accuracy: 0.99906, F1: 0.0360, Prec: 0.6627, Rec: 0.3877 lr: 0.00070\n",
      "Epoch 23/Step 330, Loss: -0.25149, Accuracy: 0.99906, F1: 0.0349, Prec: 0.6633, Rec: 0.3877 lr: 0.00070\n",
      "Epoch 23/Step 340, Loss: -0.24666, Accuracy: 0.99906, F1: 0.0339, Prec: 0.6635, Rec: 0.3879 lr: 0.00070\n",
      "Epoch 23/Step 350, Loss: -0.21278, Accuracy: 0.99906, F1: 0.0329, Prec: 0.6642, Rec: 0.3884 lr: 0.00070\n",
      "Epoch 23/Step 360, Loss: -0.25461, Accuracy: 0.99906, F1: 0.0320, Prec: 0.6646, Rec: 0.3890 lr: 0.00070\n",
      "Epoch 23/Step 370, Loss: -0.24945, Accuracy: 0.99906, F1: 0.0312, Prec: 0.6641, Rec: 0.3892 lr: 0.00070\n",
      "Epoch 23/Step 380, Loss: -0.25742, Accuracy: 0.99906, F1: 0.0303, Prec: 0.6631, Rec: 0.3889 lr: 0.00070\n",
      "Epoch 23/Step 390, Loss: -0.20738, Accuracy: 0.99906, F1: 0.0296, Prec: 0.6635, Rec: 0.3883 lr: 0.00070\n",
      "Epoch 23/Step 400, Loss: -0.20490, Accuracy: 0.99906, F1: 0.0288, Prec: 0.6642, Rec: 0.3876 lr: 0.00070\n",
      "Epoch 23/Step 410, Loss: -0.20516, Accuracy: 0.99906, F1: 0.0281, Prec: 0.6636, Rec: 0.3876 lr: 0.00070\n",
      "Epoch 23/Step 420, Loss: -0.25572, Accuracy: 0.99906, F1: 0.0275, Prec: 0.6639, Rec: 0.3879 lr: 0.00070\n",
      "Epoch 23/Step 430, Loss: -0.23142, Accuracy: 0.99906, F1: 0.0268, Prec: 0.6634, Rec: 0.3881 lr: 0.00070\n",
      "Epoch 23/Step 440, Loss: -0.26467, Accuracy: 0.99906, F1: 0.0262, Prec: 0.6634, Rec: 0.3880 lr: 0.00070\n",
      "Epoch 23/Step 450, Loss: -0.25403, Accuracy: 0.99906, F1: 0.0256, Prec: 0.6635, Rec: 0.3880 lr: 0.00070\n",
      "Epoch 23/Step 460, Loss: -0.22988, Accuracy: 0.99906, F1: 0.0251, Prec: 0.6627, Rec: 0.3878 lr: 0.00070\n",
      "Epoch 23/Step 470, Loss: -0.23002, Accuracy: 0.99906, F1: 0.0245, Prec: 0.6625, Rec: 0.3875 lr: 0.00070\n",
      "Epoch 23/Step 480, Loss: -0.22175, Accuracy: 0.99906, F1: 0.0240, Prec: 0.6610, Rec: 0.3867 lr: 0.00070\n",
      "Epoch 23/Step 490, Loss: -0.21641, Accuracy: 0.99906, F1: 0.0235, Prec: 0.6605, Rec: 0.3866 lr: 0.00070\n",
      "Epoch 23/Step 500, Loss: -0.24570, Accuracy: 0.99906, F1: 0.0231, Prec: 0.6612, Rec: 0.3863 lr: 0.00070\n",
      "Epoch 23/Step 510, Loss: -0.28191, Accuracy: 0.99906, F1: 0.0226, Prec: 0.6612, Rec: 0.3864 lr: 0.00070\n",
      "Epoch 23/Step 520, Loss: -0.21633, Accuracy: 0.99906, F1: 0.0222, Prec: 0.6605, Rec: 0.3867 lr: 0.00070\n",
      "Epoch 23/Step 530, Loss: -0.23957, Accuracy: 0.99906, F1: 0.0218, Prec: 0.6589, Rec: 0.3864 lr: 0.00070\n",
      "Epoch 23/Step 540, Loss: -0.23659, Accuracy: 0.99906, F1: 0.0214, Prec: 0.6587, Rec: 0.3863 lr: 0.00070\n",
      "Epoch 23/Step 550, Loss: -0.26629, Accuracy: 0.99906, F1: 0.0210, Prec: 0.6587, Rec: 0.3864 lr: 0.00070\n",
      "Epoch 23/Step 560, Loss: -0.22221, Accuracy: 0.99906, F1: 0.0206, Prec: 0.6582, Rec: 0.3862 lr: 0.00070\n",
      "Epoch 23/Step 570, Loss: -0.24311, Accuracy: 0.99906, F1: 0.0202, Prec: 0.6577, Rec: 0.3862 lr: 0.00070\n",
      "Epoch 23/Step 580, Loss: -0.20613, Accuracy: 0.99905, F1: 0.0199, Prec: 0.6580, Rec: 0.3859 lr: 0.00070\n",
      "Epoch 23/Step 590, Loss: -0.19053, Accuracy: 0.99905, F1: 0.0196, Prec: 0.6577, Rec: 0.3857 lr: 0.00070\n",
      "Epoch 23/Step 600, Loss: -0.23734, Accuracy: 0.99905, F1: 0.0192, Prec: 0.6578, Rec: 0.3855 lr: 0.00070\n",
      "Epoch 23/Step 610, Loss: -0.29290, Accuracy: 0.99905, F1: 0.0189, Prec: 0.6577, Rec: 0.3856 lr: 0.00070\n",
      "Epoch 23/Step 620, Loss: -0.25766, Accuracy: 0.99905, F1: 0.0186, Prec: 0.6577, Rec: 0.3859 lr: 0.00070\n",
      "Epoch 23/Step 630, Loss: -0.21530, Accuracy: 0.99905, F1: 0.0183, Prec: 0.6575, Rec: 0.3858 lr: 0.00070\n",
      "Epoch 23/Step 640, Loss: -0.22266, Accuracy: 0.99905, F1: 0.0195, Prec: 0.6571, Rec: 0.3859 lr: 0.00070\n",
      "Epoch 23/Step 650, Loss: -0.21541, Accuracy: 0.99905, F1: 0.0192, Prec: 0.6571, Rec: 0.3859 lr: 0.00070\n",
      "Epoch 23/Step 660, Loss: -0.25064, Accuracy: 0.99905, F1: 0.0189, Prec: 0.6573, Rec: 0.3859 lr: 0.00070\n",
      "Epoch 23/Step 670, Loss: -0.24273, Accuracy: 0.99905, F1: 0.0186, Prec: 0.6578, Rec: 0.3858 lr: 0.00070\n",
      "Epoch 23/Step 680, Loss: -0.20631, Accuracy: 0.99905, F1: 0.0183, Prec: 0.6580, Rec: 0.3861 lr: 0.00070\n",
      "Epoch 23/Step 690, Loss: -0.26373, Accuracy: 0.99905, F1: 0.0181, Prec: 0.6581, Rec: 0.3859 lr: 0.00070\n",
      "Epoch 23/Step 700, Loss: -0.25207, Accuracy: 0.99905, F1: 0.0178, Prec: 0.6579, Rec: 0.3858 lr: 0.00070\n",
      "Epoch 23/Step 710, Loss: -0.24793, Accuracy: 0.99906, F1: 0.0175, Prec: 0.6583, Rec: 0.3862 lr: 0.00070\n",
      "Epoch 23/Step 720, Loss: -0.25693, Accuracy: 0.99906, F1: 0.0173, Prec: 0.6582, Rec: 0.3860 lr: 0.00070\n",
      "Epoch 23/Step 730, Loss: -0.22403, Accuracy: 0.99906, F1: 0.0171, Prec: 0.6581, Rec: 0.3857 lr: 0.00070\n",
      "Epoch 23/Step 740, Loss: -0.24016, Accuracy: 0.99906, F1: 0.0168, Prec: 0.6581, Rec: 0.3855 lr: 0.00070\n",
      "Epoch 23/Step 750, Loss: -0.25521, Accuracy: 0.99906, F1: 0.0166, Prec: 0.6581, Rec: 0.3854 lr: 0.00070\n",
      "Epoch 23/Step 760, Loss: -0.25187, Accuracy: 0.99906, F1: 0.0177, Prec: 0.6581, Rec: 0.3851 lr: 0.00070\n",
      "Epoch 23/Step 770, Loss: -0.26736, Accuracy: 0.99906, F1: 0.0175, Prec: 0.6577, Rec: 0.3852 lr: 0.00070\n",
      "Epoch 23/Step 780, Loss: -0.19961, Accuracy: 0.99906, F1: 0.0173, Prec: 0.6582, Rec: 0.3853 lr: 0.00070\n",
      "Epoch 23/Step 790, Loss: -0.25796, Accuracy: 0.99906, F1: 0.0170, Prec: 0.6580, Rec: 0.3850 lr: 0.00070\n",
      "Epoch 23/Step 800, Loss: -0.22473, Accuracy: 0.99906, F1: 0.0168, Prec: 0.6582, Rec: 0.3849 lr: 0.00070\n",
      "Epoch 23/Step 810, Loss: -0.17151, Accuracy: 0.99906, F1: 0.0166, Prec: 0.6583, Rec: 0.3849 lr: 0.00070\n",
      "Epoch 23/Step 820, Loss: -0.23333, Accuracy: 0.99906, F1: 0.0164, Prec: 0.6581, Rec: 0.3847 lr: 0.00070\n",
      "Epoch 23/Step 830, Loss: -0.26295, Accuracy: 0.99906, F1: 0.0162, Prec: 0.6581, Rec: 0.3848 lr: 0.00070\n",
      "Epoch 23/Step 840, Loss: -0.27777, Accuracy: 0.99906, F1: 0.0160, Prec: 0.6584, Rec: 0.3850 lr: 0.00070\n",
      "Epoch 23/Step 850, Loss: -0.24089, Accuracy: 0.99906, F1: 0.0158, Prec: 0.6584, Rec: 0.3848 lr: 0.00070\n",
      "Epoch 23/Step 860, Loss: -0.24050, Accuracy: 0.99906, F1: 0.0168, Prec: 0.6581, Rec: 0.3849 lr: 0.00070\n",
      "Epoch 23/Step 870, Loss: -0.23140, Accuracy: 0.99906, F1: 0.0166, Prec: 0.6576, Rec: 0.3847 lr: 0.00070\n",
      "Epoch 23/Step 880, Loss: -0.21218, Accuracy: 0.99906, F1: 0.0164, Prec: 0.6578, Rec: 0.3846 lr: 0.00070\n",
      "Epoch 23/Step 890, Loss: -0.23686, Accuracy: 0.99906, F1: 0.0162, Prec: 0.6574, Rec: 0.3845 lr: 0.00070\n",
      "Epoch 23/Step 900, Loss: -0.28915, Accuracy: 0.99906, F1: 0.0160, Prec: 0.6578, Rec: 0.3846 lr: 0.00070\n",
      "Epoch 23/Step 910, Loss: -0.19854, Accuracy: 0.99906, F1: 0.0158, Prec: 0.6575, Rec: 0.3844 lr: 0.00070\n",
      "Epoch 23/Step 920, Loss: -0.24603, Accuracy: 0.99906, F1: 0.0157, Prec: 0.6575, Rec: 0.3841 lr: 0.00070\n",
      "Epoch 23/Step 930, Loss: -0.22196, Accuracy: 0.99906, F1: 0.0155, Prec: 0.6576, Rec: 0.3842 lr: 0.00070\n",
      "Epoch 23/Step 940, Loss: -0.24063, Accuracy: 0.99906, F1: 0.0153, Prec: 0.6575, Rec: 0.3842 lr: 0.00070\n",
      "Epoch 23/Step 950, Loss: -0.24407, Accuracy: 0.99906, F1: 0.0152, Prec: 0.6577, Rec: 0.3843 lr: 0.00070\n",
      "Epoch 23/Step 960, Loss: -0.27072, Accuracy: 0.99906, F1: 0.0150, Prec: 0.6576, Rec: 0.3844 lr: 0.00070\n",
      "Epoch 23/Step 970, Loss: -0.21961, Accuracy: 0.99906, F1: 0.0149, Prec: 0.6575, Rec: 0.3840 lr: 0.00070\n",
      "Epoch 23/Step 980, Loss: -0.24871, Accuracy: 0.99906, F1: 0.0147, Prec: 0.6574, Rec: 0.3838 lr: 0.00070\n",
      "Epoch 23/Step 990, Loss: -0.23300, Accuracy: 0.99906, F1: 0.0146, Prec: 0.6568, Rec: 0.3838 lr: 0.00070\n",
      "Epoch 23/Step 1000, Loss: -0.24459, Accuracy: 0.99906, F1: 0.0144, Prec: 0.6568, Rec: 0.3840 lr: 0.00070\n",
      "Epoch 23/Step 1010, Loss: -0.25307, Accuracy: 0.99906, F1: 0.0143, Prec: 0.6573, Rec: 0.3841 lr: 0.00070\n",
      "Epoch 23/Step 1020, Loss: -0.20247, Accuracy: 0.99906, F1: 0.0141, Prec: 0.6572, Rec: 0.3840 lr: 0.00070\n",
      "Epoch 23/Step 1030, Loss: -0.25453, Accuracy: 0.99906, F1: 0.0140, Prec: 0.6574, Rec: 0.3839 lr: 0.00070\n",
      "Epoch 23/Step 1040, Loss: -0.24194, Accuracy: 0.99906, F1: 0.0139, Prec: 0.6576, Rec: 0.3839 lr: 0.00070\n",
      "Epoch 23/Step 1050, Loss: -0.27145, Accuracy: 0.99907, F1: 0.0137, Prec: 0.6576, Rec: 0.3840 lr: 0.00070\n",
      "Epoch 23/Step 1060, Loss: -0.26114, Accuracy: 0.99907, F1: 0.0136, Prec: 0.6577, Rec: 0.3843 lr: 0.00070\n",
      "Epoch 23/Step 1070, Loss: -0.23782, Accuracy: 0.99907, F1: 0.0135, Prec: 0.6579, Rec: 0.3843 lr: 0.00070\n",
      "Epoch 23/Step 1080, Loss: -0.22382, Accuracy: 0.99907, F1: 0.0133, Prec: 0.6579, Rec: 0.3844 lr: 0.00070\n",
      "Epoch 23/Step 1090, Loss: -0.23832, Accuracy: 0.99907, F1: 0.0132, Prec: 0.6579, Rec: 0.3842 lr: 0.00070\n",
      "Epoch 23/Step 1100, Loss: -0.25049, Accuracy: 0.99907, F1: 0.0131, Prec: 0.6581, Rec: 0.3842 lr: 0.00070\n",
      "Epoch 23/Step 1110, Loss: -0.21079, Accuracy: 0.99907, F1: 0.0130, Prec: 0.6581, Rec: 0.3842 lr: 0.00070\n",
      "Epoch 23/Step 1120, Loss: -0.22021, Accuracy: 0.99907, F1: 0.0129, Prec: 0.6581, Rec: 0.3842 lr: 0.00070\n",
      "Epoch 23/Step 1130, Loss: -0.22274, Accuracy: 0.99907, F1: 0.0128, Prec: 0.6584, Rec: 0.3844 lr: 0.00070\n",
      "Epoch 23/Step 1140, Loss: -0.24362, Accuracy: 0.99907, F1: 0.0126, Prec: 0.6582, Rec: 0.3846 lr: 0.00070\n",
      "Epoch 23/Step 1150, Loss: -0.26439, Accuracy: 0.99907, F1: 0.0125, Prec: 0.6584, Rec: 0.3846 lr: 0.00070\n",
      "Epoch 23/Step 1160, Loss: -0.20802, Accuracy: 0.99907, F1: 0.0124, Prec: 0.6589, Rec: 0.3848 lr: 0.00070\n",
      "Epoch 23/Step 1170, Loss: -0.21746, Accuracy: 0.99907, F1: 0.0123, Prec: 0.6591, Rec: 0.3847 lr: 0.00070\n",
      "Epoch 23/Step 1180, Loss: -0.19596, Accuracy: 0.99907, F1: 0.0122, Prec: 0.6589, Rec: 0.3847 lr: 0.00070\n",
      "Epoch 23/Step 1190, Loss: -0.26654, Accuracy: 0.99907, F1: 0.0121, Prec: 0.6587, Rec: 0.3846 lr: 0.00070\n",
      "Epoch 23/Step 1200, Loss: -0.23516, Accuracy: 0.99907, F1: 0.0120, Prec: 0.6591, Rec: 0.3848 lr: 0.00070\n",
      "Epoch 23/Step 1210, Loss: -0.25621, Accuracy: 0.99907, F1: 0.0119, Prec: 0.6593, Rec: 0.3850 lr: 0.00070\n",
      "Epoch 23/Step 1220, Loss: -0.26371, Accuracy: 0.99907, F1: 0.0118, Prec: 0.6593, Rec: 0.3851 lr: 0.00070\n",
      "Epoch 23/Step 1230, Loss: -0.25168, Accuracy: 0.99907, F1: 0.0117, Prec: 0.6592, Rec: 0.3851 lr: 0.00070\n",
      "Epoch 23/Step 1240, Loss: -0.27534, Accuracy: 0.99907, F1: 0.0116, Prec: 0.6592, Rec: 0.3850 lr: 0.00070\n",
      "Epoch 23/Step 1250, Loss: -0.18130, Accuracy: 0.99907, F1: 0.0115, Prec: 0.6590, Rec: 0.3852 lr: 0.00070\n",
      "Epoch 23/Step 1260, Loss: -0.26638, Accuracy: 0.99907, F1: 0.0114, Prec: 0.6593, Rec: 0.3852 lr: 0.00070\n",
      "Epoch 23/Step 1270, Loss: -0.23668, Accuracy: 0.99907, F1: 0.0114, Prec: 0.6593, Rec: 0.3853 lr: 0.00070\n",
      "Epoch 23/Step 1280, Loss: -0.30885, Accuracy: 0.99907, F1: 0.0113, Prec: 0.6592, Rec: 0.3853 lr: 0.00070\n",
      "Epoch 23/Step 1290, Loss: -0.24353, Accuracy: 0.99908, F1: 0.0121, Prec: 0.6596, Rec: 0.3853 lr: 0.00070\n",
      "Epoch 23/Step 1300, Loss: -0.21806, Accuracy: 0.99908, F1: 0.0120, Prec: 0.6595, Rec: 0.3852 lr: 0.00070\n",
      "Epoch 23/Step 1310, Loss: -0.24666, Accuracy: 0.99908, F1: 0.0119, Prec: 0.6595, Rec: 0.3854 lr: 0.00070\n",
      "Epoch 23/Step 1320, Loss: -0.27268, Accuracy: 0.99908, F1: 0.0118, Prec: 0.6597, Rec: 0.3855 lr: 0.00070\n",
      "Epoch 23/Step 1330, Loss: -0.26998, Accuracy: 0.99908, F1: 0.0117, Prec: 0.6598, Rec: 0.3853 lr: 0.00070\n",
      "Epoch 23/Step 1340, Loss: -0.24529, Accuracy: 0.99908, F1: 0.0116, Prec: 0.6598, Rec: 0.3855 lr: 0.00070\n",
      "Epoch 23/Step 1350, Loss: -0.19615, Accuracy: 0.99908, F1: 0.0115, Prec: 0.6599, Rec: 0.3855 lr: 0.00070\n",
      "Epoch 23/Step 1360, Loss: -0.22144, Accuracy: 0.99908, F1: 0.0115, Prec: 0.6602, Rec: 0.3854 lr: 0.00070\n",
      "Epoch 23/Step 1370, Loss: -0.23730, Accuracy: 0.99908, F1: 0.0114, Prec: 0.6600, Rec: 0.3857 lr: 0.00070\n",
      "Epoch 23/Step 1380, Loss: -0.24054, Accuracy: 0.99908, F1: 0.0113, Prec: 0.6601, Rec: 0.3857 lr: 0.00070\n",
      "Epoch 23/Step 1390, Loss: -0.24955, Accuracy: 0.99908, F1: 0.0112, Prec: 0.6601, Rec: 0.3856 lr: 0.00070\n",
      "Epoch 23/Step 1400, Loss: -0.26012, Accuracy: 0.99908, F1: 0.0111, Prec: 0.6601, Rec: 0.3857 lr: 0.00070\n",
      "Epoch 23/Step 1410, Loss: -0.22473, Accuracy: 0.99908, F1: 0.0111, Prec: 0.6602, Rec: 0.3857 lr: 0.00070\n",
      "Epoch 23/Step 1420, Loss: -0.23597, Accuracy: 0.99908, F1: 0.0110, Prec: 0.6603, Rec: 0.3855 lr: 0.00070\n",
      "Epoch 23/Step 1430, Loss: -0.23339, Accuracy: 0.99908, F1: 0.0109, Prec: 0.6606, Rec: 0.3854 lr: 0.00070\n",
      "Epoch 23/Step 1440, Loss: -0.24045, Accuracy: 0.99908, F1: 0.0115, Prec: 0.6606, Rec: 0.3855 lr: 0.00070\n",
      "Epoch 23/Step 1450, Loss: -0.24442, Accuracy: 0.99908, F1: 0.0114, Prec: 0.6609, Rec: 0.3855 lr: 0.00070\n",
      "Epoch 23/Step 1460, Loss: -0.22752, Accuracy: 0.99908, F1: 0.0113, Prec: 0.6608, Rec: 0.3855 lr: 0.00070\n",
      "Epoch 23/Step 1470, Loss: -0.23703, Accuracy: 0.99908, F1: 0.0113, Prec: 0.6610, Rec: 0.3854 lr: 0.00070\n",
      "Epoch 23/Step 1480, Loss: -0.23621, Accuracy: 0.99908, F1: 0.0112, Prec: 0.6609, Rec: 0.3855 lr: 0.00070\n",
      "Epoch 23/Step 1490, Loss: -0.22543, Accuracy: 0.99908, F1: 0.0111, Prec: 0.6609, Rec: 0.3853 lr: 0.00070\n",
      "Epoch 23/Step 1500, Loss: -0.25943, Accuracy: 0.99908, F1: 0.0116, Prec: 0.6611, Rec: 0.3854 lr: 0.00070\n",
      "Epoch 23/Step 1510, Loss: -0.22246, Accuracy: 0.99908, F1: 0.0115, Prec: 0.6611, Rec: 0.3854 lr: 0.00070\n",
      "Epoch 23/Step 1520, Loss: -0.27852, Accuracy: 0.99908, F1: 0.0119, Prec: 0.6612, Rec: 0.3855 lr: 0.00070\n",
      "Epoch 23/Step 1530, Loss: -0.21957, Accuracy: 0.99908, F1: 0.0125, Prec: 0.6614, Rec: 0.3856 lr: 0.00070\n",
      "Epoch 23/Step 1540, Loss: -0.20790, Accuracy: 0.99908, F1: 0.0124, Prec: 0.6614, Rec: 0.3853 lr: 0.00070\n",
      "Epoch 23/Step 1550, Loss: -0.23862, Accuracy: 0.99908, F1: 0.0128, Prec: 0.6613, Rec: 0.3854 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9987\n",
      "Validation f1: 0.1989\n",
      "Validation precision: 0.3893\n",
      "Validation recall: 0.2037\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_22_valF1Score0.199/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_22_valF1Score0.199/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 24\n",
      "Epoch 24/Step 0, Loss: -0.26614, Accuracy: 0.99921, F1: 0.0000, Prec: 0.7353, Rec: 0.4294 lr: 0.00070\n",
      "Epoch 24/Step 10, Loss: -0.29575, Accuracy: 0.99905, F1: 0.0000, Prec: 0.7052, Rec: 0.4037 lr: 0.00070\n",
      "Epoch 24/Step 20, Loss: -0.25717, Accuracy: 0.99909, F1: 0.0000, Prec: 0.6930, Rec: 0.4022 lr: 0.00070\n",
      "Epoch 24/Step 30, Loss: -0.22051, Accuracy: 0.99910, F1: 0.0273, Prec: 0.6807, Rec: 0.4022 lr: 0.00070\n",
      "Epoch 24/Step 40, Loss: -0.21827, Accuracy: 0.99910, F1: 0.0206, Prec: 0.6864, Rec: 0.4023 lr: 0.00070\n",
      "Epoch 24/Step 50, Loss: -0.23984, Accuracy: 0.99910, F1: 0.0166, Prec: 0.6931, Rec: 0.3991 lr: 0.00070\n",
      "Epoch 24/Step 60, Loss: -0.25764, Accuracy: 0.99911, F1: 0.0139, Prec: 0.6971, Rec: 0.3994 lr: 0.00070\n",
      "Epoch 24/Step 70, Loss: -0.23981, Accuracy: 0.99913, F1: 0.0119, Prec: 0.6939, Rec: 0.4017 lr: 0.00070\n",
      "Epoch 24/Step 80, Loss: -0.23021, Accuracy: 0.99913, F1: 0.0104, Prec: 0.6913, Rec: 0.4000 lr: 0.00070\n",
      "Epoch 24/Step 90, Loss: -0.21873, Accuracy: 0.99912, F1: 0.0093, Prec: 0.6923, Rec: 0.3986 lr: 0.00070\n",
      "Epoch 24/Step 100, Loss: -0.25229, Accuracy: 0.99912, F1: 0.0183, Prec: 0.6902, Rec: 0.4005 lr: 0.00070\n",
      "Epoch 24/Step 110, Loss: -0.24364, Accuracy: 0.99911, F1: 0.0246, Prec: 0.6898, Rec: 0.3990 lr: 0.00070\n",
      "Epoch 24/Step 120, Loss: -0.23004, Accuracy: 0.99911, F1: 0.0225, Prec: 0.6870, Rec: 0.3983 lr: 0.00070\n",
      "Epoch 24/Step 130, Loss: -0.20848, Accuracy: 0.99911, F1: 0.0285, Prec: 0.6843, Rec: 0.3993 lr: 0.00070\n",
      "Epoch 24/Step 140, Loss: -0.21937, Accuracy: 0.99910, F1: 0.0265, Prec: 0.6831, Rec: 0.3963 lr: 0.00070\n",
      "Epoch 24/Step 150, Loss: -0.23642, Accuracy: 0.99909, F1: 0.0247, Prec: 0.6808, Rec: 0.3946 lr: 0.00070\n",
      "Epoch 24/Step 160, Loss: -0.26142, Accuracy: 0.99909, F1: 0.0232, Prec: 0.6786, Rec: 0.3951 lr: 0.00070\n",
      "Epoch 24/Step 170, Loss: -0.24674, Accuracy: 0.99909, F1: 0.0218, Prec: 0.6773, Rec: 0.3944 lr: 0.00070\n",
      "Epoch 24/Step 180, Loss: -0.29334, Accuracy: 0.99909, F1: 0.0206, Prec: 0.6774, Rec: 0.3952 lr: 0.00070\n",
      "Epoch 24/Step 190, Loss: -0.22043, Accuracy: 0.99909, F1: 0.0195, Prec: 0.6745, Rec: 0.3948 lr: 0.00070\n",
      "Epoch 24/Step 200, Loss: -0.26345, Accuracy: 0.99908, F1: 0.0186, Prec: 0.6752, Rec: 0.3942 lr: 0.00070\n",
      "Epoch 24/Step 210, Loss: -0.21746, Accuracy: 0.99908, F1: 0.0177, Prec: 0.6748, Rec: 0.3941 lr: 0.00070\n",
      "Epoch 24/Step 220, Loss: -0.25934, Accuracy: 0.99908, F1: 0.0169, Prec: 0.6753, Rec: 0.3943 lr: 0.00070\n",
      "Epoch 24/Step 230, Loss: -0.21846, Accuracy: 0.99908, F1: 0.0162, Prec: 0.6746, Rec: 0.3939 lr: 0.00070\n",
      "Epoch 24/Step 240, Loss: -0.28066, Accuracy: 0.99907, F1: 0.0155, Prec: 0.6738, Rec: 0.3938 lr: 0.00070\n",
      "Epoch 24/Step 250, Loss: -0.25846, Accuracy: 0.99907, F1: 0.0149, Prec: 0.6739, Rec: 0.3930 lr: 0.00070\n",
      "Epoch 24/Step 260, Loss: -0.27119, Accuracy: 0.99907, F1: 0.0143, Prec: 0.6746, Rec: 0.3929 lr: 0.00070\n",
      "Epoch 24/Step 270, Loss: -0.26662, Accuracy: 0.99907, F1: 0.0138, Prec: 0.6728, Rec: 0.3925 lr: 0.00070\n",
      "Epoch 24/Step 280, Loss: -0.24092, Accuracy: 0.99906, F1: 0.0133, Prec: 0.6708, Rec: 0.3915 lr: 0.00070\n",
      "Epoch 24/Step 290, Loss: -0.24052, Accuracy: 0.99906, F1: 0.0128, Prec: 0.6706, Rec: 0.3917 lr: 0.00070\n",
      "Epoch 24/Step 300, Loss: -0.26620, Accuracy: 0.99906, F1: 0.0124, Prec: 0.6717, Rec: 0.3915 lr: 0.00070\n",
      "Epoch 24/Step 310, Loss: -0.25595, Accuracy: 0.99907, F1: 0.0155, Prec: 0.6720, Rec: 0.3912 lr: 0.00070\n",
      "Epoch 24/Step 320, Loss: -0.24212, Accuracy: 0.99907, F1: 0.0150, Prec: 0.6724, Rec: 0.3917 lr: 0.00070\n",
      "Epoch 24/Step 330, Loss: -0.24811, Accuracy: 0.99907, F1: 0.0145, Prec: 0.6727, Rec: 0.3916 lr: 0.00070\n",
      "Epoch 24/Step 340, Loss: -0.24588, Accuracy: 0.99907, F1: 0.0141, Prec: 0.6729, Rec: 0.3917 lr: 0.00070\n",
      "Epoch 24/Step 350, Loss: -0.21224, Accuracy: 0.99907, F1: 0.0137, Prec: 0.6740, Rec: 0.3920 lr: 0.00070\n",
      "Epoch 24/Step 360, Loss: -0.25542, Accuracy: 0.99907, F1: 0.0133, Prec: 0.6744, Rec: 0.3926 lr: 0.00070\n",
      "Epoch 24/Step 370, Loss: -0.25536, Accuracy: 0.99907, F1: 0.0130, Prec: 0.6747, Rec: 0.3924 lr: 0.00070\n",
      "Epoch 24/Step 380, Loss: -0.24484, Accuracy: 0.99907, F1: 0.0126, Prec: 0.6741, Rec: 0.3920 lr: 0.00070\n",
      "Epoch 24/Step 390, Loss: -0.20929, Accuracy: 0.99907, F1: 0.0144, Prec: 0.6742, Rec: 0.3913 lr: 0.00070\n",
      "Epoch 24/Step 400, Loss: -0.21741, Accuracy: 0.99907, F1: 0.0140, Prec: 0.6744, Rec: 0.3906 lr: 0.00070\n",
      "Epoch 24/Step 410, Loss: -0.19877, Accuracy: 0.99907, F1: 0.0137, Prec: 0.6746, Rec: 0.3903 lr: 0.00070\n",
      "Epoch 24/Step 420, Loss: -0.25389, Accuracy: 0.99907, F1: 0.0134, Prec: 0.6740, Rec: 0.3908 lr: 0.00070\n",
      "Epoch 24/Step 430, Loss: -0.22703, Accuracy: 0.99907, F1: 0.0131, Prec: 0.6733, Rec: 0.3911 lr: 0.00070\n",
      "Epoch 24/Step 440, Loss: -0.26360, Accuracy: 0.99907, F1: 0.0128, Prec: 0.6731, Rec: 0.3908 lr: 0.00070\n",
      "Epoch 24/Step 450, Loss: -0.24539, Accuracy: 0.99907, F1: 0.0125, Prec: 0.6730, Rec: 0.3907 lr: 0.00070\n",
      "Epoch 24/Step 460, Loss: -0.22745, Accuracy: 0.99907, F1: 0.0122, Prec: 0.6722, Rec: 0.3905 lr: 0.00070\n",
      "Epoch 24/Step 470, Loss: -0.23176, Accuracy: 0.99907, F1: 0.0120, Prec: 0.6721, Rec: 0.3902 lr: 0.00070\n",
      "Epoch 24/Step 480, Loss: -0.23431, Accuracy: 0.99907, F1: 0.0117, Prec: 0.6709, Rec: 0.3894 lr: 0.00070\n",
      "Epoch 24/Step 490, Loss: -0.21991, Accuracy: 0.99907, F1: 0.0115, Prec: 0.6701, Rec: 0.3892 lr: 0.00070\n",
      "Epoch 24/Step 500, Loss: -0.24265, Accuracy: 0.99907, F1: 0.0112, Prec: 0.6706, Rec: 0.3890 lr: 0.00070\n",
      "Epoch 24/Step 510, Loss: -0.28829, Accuracy: 0.99907, F1: 0.0110, Prec: 0.6704, Rec: 0.3890 lr: 0.00070\n",
      "Epoch 24/Step 520, Loss: -0.22493, Accuracy: 0.99907, F1: 0.0108, Prec: 0.6697, Rec: 0.3894 lr: 0.00070\n",
      "Epoch 24/Step 530, Loss: -0.24605, Accuracy: 0.99907, F1: 0.0106, Prec: 0.6688, Rec: 0.3889 lr: 0.00070\n",
      "Epoch 24/Step 540, Loss: -0.23648, Accuracy: 0.99907, F1: 0.0104, Prec: 0.6687, Rec: 0.3887 lr: 0.00070\n",
      "Epoch 24/Step 550, Loss: -0.27505, Accuracy: 0.99907, F1: 0.0116, Prec: 0.6685, Rec: 0.3889 lr: 0.00070\n",
      "Epoch 24/Step 560, Loss: -0.23078, Accuracy: 0.99907, F1: 0.0114, Prec: 0.6680, Rec: 0.3888 lr: 0.00070\n",
      "Epoch 24/Step 570, Loss: -0.25493, Accuracy: 0.99907, F1: 0.0112, Prec: 0.6676, Rec: 0.3887 lr: 0.00070\n",
      "Epoch 24/Step 580, Loss: -0.20735, Accuracy: 0.99907, F1: 0.0110, Prec: 0.6673, Rec: 0.3885 lr: 0.00070\n",
      "Epoch 24/Step 590, Loss: -0.18944, Accuracy: 0.99907, F1: 0.0109, Prec: 0.6667, Rec: 0.3883 lr: 0.00070\n",
      "Epoch 24/Step 600, Loss: -0.24558, Accuracy: 0.99906, F1: 0.0107, Prec: 0.6671, Rec: 0.3880 lr: 0.00070\n",
      "Epoch 24/Step 610, Loss: -0.29210, Accuracy: 0.99906, F1: 0.0121, Prec: 0.6672, Rec: 0.3879 lr: 0.00070\n",
      "Epoch 24/Step 620, Loss: -0.25532, Accuracy: 0.99906, F1: 0.0119, Prec: 0.6675, Rec: 0.3881 lr: 0.00070\n",
      "Epoch 24/Step 630, Loss: -0.22121, Accuracy: 0.99906, F1: 0.0117, Prec: 0.6675, Rec: 0.3879 lr: 0.00070\n",
      "Epoch 24/Step 640, Loss: -0.22264, Accuracy: 0.99906, F1: 0.0131, Prec: 0.6673, Rec: 0.3879 lr: 0.00070\n",
      "Epoch 24/Step 650, Loss: -0.22274, Accuracy: 0.99906, F1: 0.0129, Prec: 0.6674, Rec: 0.3879 lr: 0.00070\n",
      "Epoch 24/Step 660, Loss: -0.25572, Accuracy: 0.99906, F1: 0.0127, Prec: 0.6673, Rec: 0.3880 lr: 0.00070\n",
      "Epoch 24/Step 670, Loss: -0.24499, Accuracy: 0.99906, F1: 0.0125, Prec: 0.6679, Rec: 0.3878 lr: 0.00070\n",
      "Epoch 24/Step 680, Loss: -0.20456, Accuracy: 0.99906, F1: 0.0123, Prec: 0.6678, Rec: 0.3880 lr: 0.00070\n",
      "Epoch 24/Step 690, Loss: -0.27381, Accuracy: 0.99906, F1: 0.0121, Prec: 0.6673, Rec: 0.3880 lr: 0.00070\n",
      "Epoch 24/Step 700, Loss: -0.24813, Accuracy: 0.99907, F1: 0.0120, Prec: 0.6675, Rec: 0.3877 lr: 0.00070\n",
      "Epoch 24/Step 710, Loss: -0.25101, Accuracy: 0.99907, F1: 0.0118, Prec: 0.6680, Rec: 0.3881 lr: 0.00070\n",
      "Epoch 24/Step 720, Loss: -0.26152, Accuracy: 0.99907, F1: 0.0116, Prec: 0.6675, Rec: 0.3879 lr: 0.00070\n",
      "Epoch 24/Step 730, Loss: -0.22575, Accuracy: 0.99907, F1: 0.0115, Prec: 0.6673, Rec: 0.3877 lr: 0.00070\n",
      "Epoch 24/Step 740, Loss: -0.24456, Accuracy: 0.99907, F1: 0.0113, Prec: 0.6674, Rec: 0.3874 lr: 0.00070\n",
      "Epoch 24/Step 750, Loss: -0.25597, Accuracy: 0.99907, F1: 0.0112, Prec: 0.6670, Rec: 0.3874 lr: 0.00070\n",
      "Epoch 24/Step 760, Loss: -0.25345, Accuracy: 0.99907, F1: 0.0124, Prec: 0.6670, Rec: 0.3872 lr: 0.00070\n",
      "Epoch 24/Step 770, Loss: -0.26934, Accuracy: 0.99907, F1: 0.0122, Prec: 0.6669, Rec: 0.3871 lr: 0.00070\n",
      "Epoch 24/Step 780, Loss: -0.19939, Accuracy: 0.99907, F1: 0.0121, Prec: 0.6674, Rec: 0.3873 lr: 0.00070\n",
      "Epoch 24/Step 790, Loss: -0.26137, Accuracy: 0.99907, F1: 0.0119, Prec: 0.6671, Rec: 0.3871 lr: 0.00070\n",
      "Epoch 24/Step 800, Loss: -0.23575, Accuracy: 0.99907, F1: 0.0118, Prec: 0.6675, Rec: 0.3870 lr: 0.00070\n",
      "Epoch 24/Step 810, Loss: -0.17652, Accuracy: 0.99907, F1: 0.0116, Prec: 0.6676, Rec: 0.3870 lr: 0.00070\n",
      "Epoch 24/Step 820, Loss: -0.23519, Accuracy: 0.99907, F1: 0.0115, Prec: 0.6675, Rec: 0.3869 lr: 0.00070\n",
      "Epoch 24/Step 830, Loss: -0.26112, Accuracy: 0.99907, F1: 0.0113, Prec: 0.6677, Rec: 0.3870 lr: 0.00070\n",
      "Epoch 24/Step 840, Loss: -0.28744, Accuracy: 0.99907, F1: 0.0112, Prec: 0.6680, Rec: 0.3872 lr: 0.00070\n",
      "Epoch 24/Step 850, Loss: -0.24778, Accuracy: 0.99907, F1: 0.0111, Prec: 0.6680, Rec: 0.3869 lr: 0.00070\n",
      "Epoch 24/Step 860, Loss: -0.24442, Accuracy: 0.99907, F1: 0.0109, Prec: 0.6683, Rec: 0.3869 lr: 0.00070\n",
      "Epoch 24/Step 870, Loss: -0.23122, Accuracy: 0.99907, F1: 0.0108, Prec: 0.6676, Rec: 0.3867 lr: 0.00070\n",
      "Epoch 24/Step 880, Loss: -0.21561, Accuracy: 0.99907, F1: 0.0107, Prec: 0.6676, Rec: 0.3867 lr: 0.00070\n",
      "Epoch 24/Step 890, Loss: -0.23759, Accuracy: 0.99907, F1: 0.0106, Prec: 0.6674, Rec: 0.3865 lr: 0.00070\n",
      "Epoch 24/Step 900, Loss: -0.28802, Accuracy: 0.99907, F1: 0.0104, Prec: 0.6673, Rec: 0.3867 lr: 0.00070\n",
      "Epoch 24/Step 910, Loss: -0.20037, Accuracy: 0.99907, F1: 0.0103, Prec: 0.6670, Rec: 0.3865 lr: 0.00070\n",
      "Epoch 24/Step 920, Loss: -0.23923, Accuracy: 0.99907, F1: 0.0102, Prec: 0.6668, Rec: 0.3862 lr: 0.00070\n",
      "Epoch 24/Step 930, Loss: -0.22821, Accuracy: 0.99907, F1: 0.0101, Prec: 0.6669, Rec: 0.3862 lr: 0.00070\n",
      "Epoch 24/Step 940, Loss: -0.23956, Accuracy: 0.99907, F1: 0.0100, Prec: 0.6668, Rec: 0.3862 lr: 0.00070\n",
      "Epoch 24/Step 950, Loss: -0.25694, Accuracy: 0.99907, F1: 0.0099, Prec: 0.6669, Rec: 0.3863 lr: 0.00070\n",
      "Epoch 24/Step 960, Loss: -0.27588, Accuracy: 0.99907, F1: 0.0098, Prec: 0.6668, Rec: 0.3864 lr: 0.00070\n",
      "Epoch 24/Step 970, Loss: -0.21280, Accuracy: 0.99907, F1: 0.0097, Prec: 0.6667, Rec: 0.3860 lr: 0.00070\n",
      "Epoch 24/Step 980, Loss: -0.24482, Accuracy: 0.99907, F1: 0.0096, Prec: 0.6665, Rec: 0.3858 lr: 0.00070\n",
      "Epoch 24/Step 990, Loss: -0.22737, Accuracy: 0.99907, F1: 0.0095, Prec: 0.6655, Rec: 0.3858 lr: 0.00070\n",
      "Epoch 24/Step 1000, Loss: -0.24360, Accuracy: 0.99907, F1: 0.0094, Prec: 0.6655, Rec: 0.3861 lr: 0.00070\n",
      "Epoch 24/Step 1010, Loss: -0.25250, Accuracy: 0.99907, F1: 0.0093, Prec: 0.6659, Rec: 0.3862 lr: 0.00070\n",
      "Epoch 24/Step 1020, Loss: -0.20696, Accuracy: 0.99907, F1: 0.0092, Prec: 0.6657, Rec: 0.3862 lr: 0.00070\n",
      "Epoch 24/Step 1030, Loss: -0.25569, Accuracy: 0.99908, F1: 0.0091, Prec: 0.6658, Rec: 0.3861 lr: 0.00070\n",
      "Epoch 24/Step 1040, Loss: -0.24161, Accuracy: 0.99908, F1: 0.0090, Prec: 0.6658, Rec: 0.3861 lr: 0.00070\n",
      "Epoch 24/Step 1050, Loss: -0.26670, Accuracy: 0.99908, F1: 0.0090, Prec: 0.6656, Rec: 0.3863 lr: 0.00070\n",
      "Epoch 24/Step 1060, Loss: -0.25950, Accuracy: 0.99908, F1: 0.0089, Prec: 0.6658, Rec: 0.3865 lr: 0.00070\n",
      "Epoch 24/Step 1070, Loss: -0.24689, Accuracy: 0.99908, F1: 0.0088, Prec: 0.6661, Rec: 0.3864 lr: 0.00070\n",
      "Epoch 24/Step 1080, Loss: -0.23052, Accuracy: 0.99908, F1: 0.0087, Prec: 0.6660, Rec: 0.3866 lr: 0.00070\n",
      "Epoch 24/Step 1090, Loss: -0.23503, Accuracy: 0.99908, F1: 0.0086, Prec: 0.6657, Rec: 0.3865 lr: 0.00070\n",
      "Epoch 24/Step 1100, Loss: -0.25332, Accuracy: 0.99908, F1: 0.0086, Prec: 0.6658, Rec: 0.3865 lr: 0.00070\n",
      "Epoch 24/Step 1110, Loss: -0.20935, Accuracy: 0.99908, F1: 0.0085, Prec: 0.6658, Rec: 0.3864 lr: 0.00070\n",
      "Epoch 24/Step 1120, Loss: -0.21719, Accuracy: 0.99908, F1: 0.0092, Prec: 0.6658, Rec: 0.3864 lr: 0.00070\n",
      "Epoch 24/Step 1130, Loss: -0.22368, Accuracy: 0.99908, F1: 0.0091, Prec: 0.6660, Rec: 0.3865 lr: 0.00070\n",
      "Epoch 24/Step 1140, Loss: -0.24131, Accuracy: 0.99908, F1: 0.0090, Prec: 0.6660, Rec: 0.3866 lr: 0.00070\n",
      "Epoch 24/Step 1150, Loss: -0.26354, Accuracy: 0.99908, F1: 0.0089, Prec: 0.6661, Rec: 0.3867 lr: 0.00070\n",
      "Epoch 24/Step 1160, Loss: -0.20982, Accuracy: 0.99908, F1: 0.0089, Prec: 0.6664, Rec: 0.3869 lr: 0.00070\n",
      "Epoch 24/Step 1170, Loss: -0.21740, Accuracy: 0.99908, F1: 0.0088, Prec: 0.6667, Rec: 0.3868 lr: 0.00070\n",
      "Epoch 24/Step 1180, Loss: -0.20227, Accuracy: 0.99908, F1: 0.0087, Prec: 0.6666, Rec: 0.3868 lr: 0.00070\n",
      "Epoch 24/Step 1190, Loss: -0.26496, Accuracy: 0.99908, F1: 0.0086, Prec: 0.6662, Rec: 0.3867 lr: 0.00070\n",
      "Epoch 24/Step 1200, Loss: -0.23004, Accuracy: 0.99908, F1: 0.0086, Prec: 0.6665, Rec: 0.3869 lr: 0.00070\n",
      "Epoch 24/Step 1210, Loss: -0.25974, Accuracy: 0.99908, F1: 0.0085, Prec: 0.6668, Rec: 0.3871 lr: 0.00070\n",
      "Epoch 24/Step 1220, Loss: -0.26700, Accuracy: 0.99908, F1: 0.0084, Prec: 0.6665, Rec: 0.3872 lr: 0.00070\n",
      "Epoch 24/Step 1230, Loss: -0.25710, Accuracy: 0.99908, F1: 0.0084, Prec: 0.6663, Rec: 0.3873 lr: 0.00070\n",
      "Epoch 24/Step 1240, Loss: -0.28281, Accuracy: 0.99908, F1: 0.0083, Prec: 0.6664, Rec: 0.3871 lr: 0.00070\n",
      "Epoch 24/Step 1250, Loss: -0.18171, Accuracy: 0.99908, F1: 0.0082, Prec: 0.6665, Rec: 0.3872 lr: 0.00070\n",
      "Epoch 24/Step 1260, Loss: -0.26483, Accuracy: 0.99908, F1: 0.0082, Prec: 0.6667, Rec: 0.3873 lr: 0.00070\n",
      "Epoch 24/Step 1270, Loss: -0.23045, Accuracy: 0.99908, F1: 0.0081, Prec: 0.6667, Rec: 0.3874 lr: 0.00070\n",
      "Epoch 24/Step 1280, Loss: -0.30852, Accuracy: 0.99908, F1: 0.0080, Prec: 0.6666, Rec: 0.3874 lr: 0.00070\n",
      "Epoch 24/Step 1290, Loss: -0.25063, Accuracy: 0.99908, F1: 0.0080, Prec: 0.6668, Rec: 0.3875 lr: 0.00070\n",
      "Epoch 24/Step 1300, Loss: -0.22497, Accuracy: 0.99908, F1: 0.0079, Prec: 0.6669, Rec: 0.3874 lr: 0.00070\n",
      "Epoch 24/Step 1310, Loss: -0.24874, Accuracy: 0.99908, F1: 0.0078, Prec: 0.6670, Rec: 0.3874 lr: 0.00070\n",
      "Epoch 24/Step 1320, Loss: -0.27560, Accuracy: 0.99908, F1: 0.0078, Prec: 0.6669, Rec: 0.3875 lr: 0.00070\n",
      "Epoch 24/Step 1330, Loss: -0.26276, Accuracy: 0.99908, F1: 0.0077, Prec: 0.6669, Rec: 0.3875 lr: 0.00070\n",
      "Epoch 24/Step 1340, Loss: -0.24410, Accuracy: 0.99908, F1: 0.0077, Prec: 0.6670, Rec: 0.3876 lr: 0.00070\n",
      "Epoch 24/Step 1350, Loss: -0.20119, Accuracy: 0.99909, F1: 0.0076, Prec: 0.6671, Rec: 0.3876 lr: 0.00070\n",
      "Epoch 24/Step 1360, Loss: -0.22383, Accuracy: 0.99908, F1: 0.0076, Prec: 0.6672, Rec: 0.3876 lr: 0.00070\n",
      "Epoch 24/Step 1370, Loss: -0.24522, Accuracy: 0.99909, F1: 0.0075, Prec: 0.6672, Rec: 0.3878 lr: 0.00070\n",
      "Epoch 24/Step 1380, Loss: -0.24426, Accuracy: 0.99909, F1: 0.0074, Prec: 0.6671, Rec: 0.3879 lr: 0.00070\n",
      "Epoch 24/Step 1390, Loss: -0.24963, Accuracy: 0.99909, F1: 0.0074, Prec: 0.6670, Rec: 0.3878 lr: 0.00070\n",
      "Epoch 24/Step 1400, Loss: -0.25531, Accuracy: 0.99909, F1: 0.0073, Prec: 0.6672, Rec: 0.3878 lr: 0.00070\n",
      "Epoch 24/Step 1410, Loss: -0.22714, Accuracy: 0.99909, F1: 0.0073, Prec: 0.6673, Rec: 0.3878 lr: 0.00070\n",
      "Epoch 24/Step 1420, Loss: -0.23117, Accuracy: 0.99909, F1: 0.0072, Prec: 0.6673, Rec: 0.3876 lr: 0.00070\n",
      "Epoch 24/Step 1430, Loss: -0.23875, Accuracy: 0.99909, F1: 0.0072, Prec: 0.6675, Rec: 0.3875 lr: 0.00070\n",
      "Epoch 24/Step 1440, Loss: -0.23379, Accuracy: 0.99909, F1: 0.0071, Prec: 0.6676, Rec: 0.3876 lr: 0.00070\n",
      "Epoch 24/Step 1450, Loss: -0.24781, Accuracy: 0.99909, F1: 0.0071, Prec: 0.6678, Rec: 0.3877 lr: 0.00070\n",
      "Epoch 24/Step 1460, Loss: -0.23437, Accuracy: 0.99909, F1: 0.0070, Prec: 0.6677, Rec: 0.3876 lr: 0.00070\n",
      "Epoch 24/Step 1470, Loss: -0.23678, Accuracy: 0.99909, F1: 0.0070, Prec: 0.6677, Rec: 0.3876 lr: 0.00070\n",
      "Epoch 24/Step 1480, Loss: -0.23128, Accuracy: 0.99909, F1: 0.0069, Prec: 0.6677, Rec: 0.3876 lr: 0.00070\n",
      "Epoch 24/Step 1490, Loss: -0.22932, Accuracy: 0.99909, F1: 0.0069, Prec: 0.6676, Rec: 0.3875 lr: 0.00070\n",
      "Epoch 24/Step 1500, Loss: -0.25064, Accuracy: 0.99909, F1: 0.0074, Prec: 0.6676, Rec: 0.3876 lr: 0.00070\n",
      "Epoch 24/Step 1510, Loss: -0.22604, Accuracy: 0.99909, F1: 0.0073, Prec: 0.6678, Rec: 0.3876 lr: 0.00070\n",
      "Epoch 24/Step 1520, Loss: -0.28604, Accuracy: 0.99909, F1: 0.0073, Prec: 0.6678, Rec: 0.3878 lr: 0.00070\n",
      "Epoch 24/Step 1530, Loss: -0.22633, Accuracy: 0.99909, F1: 0.0079, Prec: 0.6679, Rec: 0.3878 lr: 0.00070\n",
      "Epoch 24/Step 1540, Loss: -0.20694, Accuracy: 0.99909, F1: 0.0079, Prec: 0.6680, Rec: 0.3875 lr: 0.00070\n",
      "Epoch 24/Step 1550, Loss: -0.23692, Accuracy: 0.99909, F1: 0.0078, Prec: 0.6680, Rec: 0.3876 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9987\n",
      "Validation f1: 0.0741\n",
      "Validation precision: 0.3826\n",
      "Validation recall: 0.2081\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_23_valF1Score0.074/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_23_valF1Score0.074/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 25\n",
      "Epoch 25/Step 0, Loss: -0.26384, Accuracy: 0.99919, F1: 0.0000, Prec: 0.7076, Rec: 0.4315 lr: 0.00070\n",
      "Epoch 25/Step 10, Loss: -0.29494, Accuracy: 0.99905, F1: 0.0000, Prec: 0.7027, Rec: 0.4053 lr: 0.00070\n",
      "Epoch 25/Step 20, Loss: -0.25353, Accuracy: 0.99909, F1: 0.0000, Prec: 0.7033, Rec: 0.3982 lr: 0.00070\n",
      "Epoch 25/Step 30, Loss: -0.21707, Accuracy: 0.99911, F1: 0.0533, Prec: 0.6854, Rec: 0.4002 lr: 0.00070\n",
      "Epoch 25/Step 40, Loss: -0.21695, Accuracy: 0.99910, F1: 0.0403, Prec: 0.6887, Rec: 0.4022 lr: 0.00070\n",
      "Epoch 25/Step 50, Loss: -0.25102, Accuracy: 0.99911, F1: 0.0324, Prec: 0.6976, Rec: 0.3995 lr: 0.00070\n",
      "Epoch 25/Step 60, Loss: -0.25675, Accuracy: 0.99911, F1: 0.0271, Prec: 0.6982, Rec: 0.4002 lr: 0.00070\n",
      "Epoch 25/Step 70, Loss: -0.23784, Accuracy: 0.99913, F1: 0.0233, Prec: 0.6963, Rec: 0.4025 lr: 0.00070\n",
      "Epoch 25/Step 80, Loss: -0.23456, Accuracy: 0.99913, F1: 0.0204, Prec: 0.6938, Rec: 0.4005 lr: 0.00070\n",
      "Epoch 25/Step 90, Loss: -0.21679, Accuracy: 0.99912, F1: 0.0284, Prec: 0.6936, Rec: 0.3997 lr: 0.00070\n",
      "Epoch 25/Step 100, Loss: -0.23945, Accuracy: 0.99913, F1: 0.0358, Prec: 0.6949, Rec: 0.4006 lr: 0.00070\n",
      "Epoch 25/Step 110, Loss: -0.24731, Accuracy: 0.99912, F1: 0.0401, Prec: 0.6928, Rec: 0.4000 lr: 0.00070\n",
      "Epoch 25/Step 120, Loss: -0.23930, Accuracy: 0.99911, F1: 0.0569, Prec: 0.6901, Rec: 0.3997 lr: 0.00070\n",
      "Epoch 25/Step 130, Loss: -0.20354, Accuracy: 0.99911, F1: 0.0673, Prec: 0.6884, Rec: 0.4001 lr: 0.00070\n",
      "Epoch 25/Step 140, Loss: -0.21484, Accuracy: 0.99910, F1: 0.0625, Prec: 0.6863, Rec: 0.3970 lr: 0.00070\n",
      "Epoch 25/Step 150, Loss: -0.23465, Accuracy: 0.99909, F1: 0.0584, Prec: 0.6851, Rec: 0.3950 lr: 0.00070\n",
      "Epoch 25/Step 160, Loss: -0.26296, Accuracy: 0.99909, F1: 0.0548, Prec: 0.6838, Rec: 0.3955 lr: 0.00070\n",
      "Epoch 25/Step 170, Loss: -0.25161, Accuracy: 0.99909, F1: 0.0515, Prec: 0.6823, Rec: 0.3947 lr: 0.00070\n",
      "Epoch 25/Step 180, Loss: -0.29391, Accuracy: 0.99909, F1: 0.0487, Prec: 0.6830, Rec: 0.3955 lr: 0.00070\n",
      "Epoch 25/Step 190, Loss: -0.22751, Accuracy: 0.99909, F1: 0.0462, Prec: 0.6825, Rec: 0.3946 lr: 0.00070\n",
      "Epoch 25/Step 200, Loss: -0.26235, Accuracy: 0.99908, F1: 0.0439, Prec: 0.6822, Rec: 0.3942 lr: 0.00070\n",
      "Epoch 25/Step 210, Loss: -0.21795, Accuracy: 0.99908, F1: 0.0418, Prec: 0.6816, Rec: 0.3941 lr: 0.00070\n",
      "Epoch 25/Step 220, Loss: -0.25432, Accuracy: 0.99908, F1: 0.0399, Prec: 0.6820, Rec: 0.3944 lr: 0.00070\n",
      "Epoch 25/Step 230, Loss: -0.22194, Accuracy: 0.99908, F1: 0.0382, Prec: 0.6810, Rec: 0.3941 lr: 0.00070\n",
      "Epoch 25/Step 240, Loss: -0.28829, Accuracy: 0.99908, F1: 0.0366, Prec: 0.6795, Rec: 0.3944 lr: 0.00070\n",
      "Epoch 25/Step 250, Loss: -0.25579, Accuracy: 0.99908, F1: 0.0351, Prec: 0.6801, Rec: 0.3937 lr: 0.00070\n",
      "Epoch 25/Step 260, Loss: -0.27155, Accuracy: 0.99908, F1: 0.0338, Prec: 0.6803, Rec: 0.3939 lr: 0.00070\n",
      "Epoch 25/Step 270, Loss: -0.27498, Accuracy: 0.99907, F1: 0.0325, Prec: 0.6795, Rec: 0.3934 lr: 0.00070\n",
      "Epoch 25/Step 280, Loss: -0.24019, Accuracy: 0.99907, F1: 0.0314, Prec: 0.6786, Rec: 0.3921 lr: 0.00070\n",
      "Epoch 25/Step 290, Loss: -0.23837, Accuracy: 0.99907, F1: 0.0303, Prec: 0.6785, Rec: 0.3921 lr: 0.00070\n",
      "Epoch 25/Step 300, Loss: -0.27054, Accuracy: 0.99907, F1: 0.0293, Prec: 0.6793, Rec: 0.3918 lr: 0.00070\n",
      "Epoch 25/Step 310, Loss: -0.24617, Accuracy: 0.99907, F1: 0.0317, Prec: 0.6788, Rec: 0.3918 lr: 0.00070\n",
      "Epoch 25/Step 320, Loss: -0.24019, Accuracy: 0.99908, F1: 0.0307, Prec: 0.6797, Rec: 0.3919 lr: 0.00070\n",
      "Epoch 25/Step 330, Loss: -0.25506, Accuracy: 0.99908, F1: 0.0298, Prec: 0.6799, Rec: 0.3917 lr: 0.00070\n",
      "Epoch 25/Step 340, Loss: -0.24541, Accuracy: 0.99907, F1: 0.0289, Prec: 0.6802, Rec: 0.3917 lr: 0.00070\n",
      "Epoch 25/Step 350, Loss: -0.22188, Accuracy: 0.99907, F1: 0.0281, Prec: 0.6805, Rec: 0.3925 lr: 0.00070\n",
      "Epoch 25/Step 360, Loss: -0.25188, Accuracy: 0.99907, F1: 0.0273, Prec: 0.6803, Rec: 0.3931 lr: 0.00070\n",
      "Epoch 25/Step 370, Loss: -0.25374, Accuracy: 0.99908, F1: 0.0266, Prec: 0.6794, Rec: 0.3932 lr: 0.00070\n",
      "Epoch 25/Step 380, Loss: -0.25281, Accuracy: 0.99908, F1: 0.0259, Prec: 0.6789, Rec: 0.3928 lr: 0.00070\n",
      "Epoch 25/Step 390, Loss: -0.21250, Accuracy: 0.99908, F1: 0.0252, Prec: 0.6786, Rec: 0.3924 lr: 0.00070\n",
      "Epoch 25/Step 400, Loss: -0.21524, Accuracy: 0.99908, F1: 0.0246, Prec: 0.6792, Rec: 0.3917 lr: 0.00070\n",
      "Epoch 25/Step 410, Loss: -0.20508, Accuracy: 0.99908, F1: 0.0240, Prec: 0.6798, Rec: 0.3912 lr: 0.00070\n",
      "Epoch 25/Step 420, Loss: -0.25230, Accuracy: 0.99908, F1: 0.0234, Prec: 0.6795, Rec: 0.3915 lr: 0.00070\n",
      "Epoch 25/Step 430, Loss: -0.23770, Accuracy: 0.99908, F1: 0.0229, Prec: 0.6783, Rec: 0.3920 lr: 0.00070\n",
      "Epoch 25/Step 440, Loss: -0.26975, Accuracy: 0.99908, F1: 0.0224, Prec: 0.6778, Rec: 0.3918 lr: 0.00070\n",
      "Epoch 25/Step 450, Loss: -0.25878, Accuracy: 0.99908, F1: 0.0219, Prec: 0.6783, Rec: 0.3917 lr: 0.00070\n",
      "Epoch 25/Step 460, Loss: -0.23241, Accuracy: 0.99908, F1: 0.0214, Prec: 0.6771, Rec: 0.3918 lr: 0.00070\n",
      "Epoch 25/Step 470, Loss: -0.22544, Accuracy: 0.99908, F1: 0.0209, Prec: 0.6770, Rec: 0.3914 lr: 0.00070\n",
      "Epoch 25/Step 480, Loss: -0.23370, Accuracy: 0.99908, F1: 0.0205, Prec: 0.6764, Rec: 0.3905 lr: 0.00070\n",
      "Epoch 25/Step 490, Loss: -0.21714, Accuracy: 0.99907, F1: 0.0201, Prec: 0.6759, Rec: 0.3902 lr: 0.00070\n",
      "Epoch 25/Step 500, Loss: -0.24552, Accuracy: 0.99908, F1: 0.0197, Prec: 0.6766, Rec: 0.3900 lr: 0.00070\n",
      "Epoch 25/Step 510, Loss: -0.29334, Accuracy: 0.99908, F1: 0.0193, Prec: 0.6764, Rec: 0.3901 lr: 0.00070\n",
      "Epoch 25/Step 520, Loss: -0.22131, Accuracy: 0.99908, F1: 0.0189, Prec: 0.6759, Rec: 0.3903 lr: 0.00070\n",
      "Epoch 25/Step 530, Loss: -0.24068, Accuracy: 0.99907, F1: 0.0186, Prec: 0.6745, Rec: 0.3900 lr: 0.00070\n",
      "Epoch 25/Step 540, Loss: -0.23896, Accuracy: 0.99907, F1: 0.0182, Prec: 0.6742, Rec: 0.3900 lr: 0.00070\n",
      "Epoch 25/Step 550, Loss: -0.27436, Accuracy: 0.99907, F1: 0.0194, Prec: 0.6742, Rec: 0.3900 lr: 0.00070\n",
      "Epoch 25/Step 560, Loss: -0.23655, Accuracy: 0.99907, F1: 0.0191, Prec: 0.6740, Rec: 0.3899 lr: 0.00070\n",
      "Epoch 25/Step 570, Loss: -0.25197, Accuracy: 0.99907, F1: 0.0187, Prec: 0.6734, Rec: 0.3899 lr: 0.00070\n",
      "Epoch 25/Step 580, Loss: -0.20593, Accuracy: 0.99907, F1: 0.0184, Prec: 0.6733, Rec: 0.3898 lr: 0.00070\n",
      "Epoch 25/Step 590, Loss: -0.18877, Accuracy: 0.99907, F1: 0.0181, Prec: 0.6728, Rec: 0.3895 lr: 0.00070\n",
      "Epoch 25/Step 600, Loss: -0.23425, Accuracy: 0.99907, F1: 0.0178, Prec: 0.6730, Rec: 0.3892 lr: 0.00070\n",
      "Epoch 25/Step 610, Loss: -0.28851, Accuracy: 0.99907, F1: 0.0175, Prec: 0.6728, Rec: 0.3892 lr: 0.00070\n",
      "Epoch 25/Step 620, Loss: -0.26125, Accuracy: 0.99907, F1: 0.0172, Prec: 0.6727, Rec: 0.3895 lr: 0.00070\n",
      "Epoch 25/Step 630, Loss: -0.22137, Accuracy: 0.99907, F1: 0.0169, Prec: 0.6728, Rec: 0.3894 lr: 0.00070\n",
      "Epoch 25/Step 640, Loss: -0.22925, Accuracy: 0.99907, F1: 0.0167, Prec: 0.6727, Rec: 0.3893 lr: 0.00070\n",
      "Epoch 25/Step 650, Loss: -0.22116, Accuracy: 0.99907, F1: 0.0164, Prec: 0.6726, Rec: 0.3894 lr: 0.00070\n",
      "Epoch 25/Step 660, Loss: -0.25554, Accuracy: 0.99907, F1: 0.0162, Prec: 0.6721, Rec: 0.3896 lr: 0.00070\n",
      "Epoch 25/Step 670, Loss: -0.25619, Accuracy: 0.99907, F1: 0.0159, Prec: 0.6725, Rec: 0.3896 lr: 0.00070\n",
      "Epoch 25/Step 680, Loss: -0.20464, Accuracy: 0.99907, F1: 0.0157, Prec: 0.6728, Rec: 0.3897 lr: 0.00070\n",
      "Epoch 25/Step 690, Loss: -0.27279, Accuracy: 0.99907, F1: 0.0155, Prec: 0.6724, Rec: 0.3898 lr: 0.00070\n",
      "Epoch 25/Step 700, Loss: -0.25004, Accuracy: 0.99907, F1: 0.0153, Prec: 0.6723, Rec: 0.3897 lr: 0.00070\n",
      "Epoch 25/Step 710, Loss: -0.24948, Accuracy: 0.99907, F1: 0.0150, Prec: 0.6728, Rec: 0.3900 lr: 0.00070\n",
      "Epoch 25/Step 720, Loss: -0.26011, Accuracy: 0.99907, F1: 0.0148, Prec: 0.6729, Rec: 0.3897 lr: 0.00070\n",
      "Epoch 25/Step 730, Loss: -0.22768, Accuracy: 0.99907, F1: 0.0146, Prec: 0.6727, Rec: 0.3895 lr: 0.00070\n",
      "Epoch 25/Step 740, Loss: -0.24321, Accuracy: 0.99907, F1: 0.0144, Prec: 0.6724, Rec: 0.3894 lr: 0.00070\n",
      "Epoch 25/Step 750, Loss: -0.26128, Accuracy: 0.99907, F1: 0.0142, Prec: 0.6723, Rec: 0.3892 lr: 0.00070\n",
      "Epoch 25/Step 760, Loss: -0.25721, Accuracy: 0.99907, F1: 0.0154, Prec: 0.6725, Rec: 0.3889 lr: 0.00070\n",
      "Epoch 25/Step 770, Loss: -0.27141, Accuracy: 0.99907, F1: 0.0152, Prec: 0.6722, Rec: 0.3889 lr: 0.00070\n",
      "Epoch 25/Step 780, Loss: -0.20207, Accuracy: 0.99907, F1: 0.0150, Prec: 0.6724, Rec: 0.3891 lr: 0.00070\n",
      "Epoch 25/Step 790, Loss: -0.26284, Accuracy: 0.99907, F1: 0.0149, Prec: 0.6724, Rec: 0.3888 lr: 0.00070\n",
      "Epoch 25/Step 800, Loss: -0.23763, Accuracy: 0.99907, F1: 0.0147, Prec: 0.6728, Rec: 0.3888 lr: 0.00070\n",
      "Epoch 25/Step 810, Loss: -0.17886, Accuracy: 0.99907, F1: 0.0145, Prec: 0.6731, Rec: 0.3889 lr: 0.00070\n",
      "Epoch 25/Step 820, Loss: -0.22664, Accuracy: 0.99908, F1: 0.0143, Prec: 0.6730, Rec: 0.3887 lr: 0.00070\n",
      "Epoch 25/Step 830, Loss: -0.26844, Accuracy: 0.99908, F1: 0.0141, Prec: 0.6733, Rec: 0.3888 lr: 0.00070\n",
      "Epoch 25/Step 840, Loss: -0.28736, Accuracy: 0.99908, F1: 0.0140, Prec: 0.6735, Rec: 0.3890 lr: 0.00070\n",
      "Epoch 25/Step 850, Loss: -0.24477, Accuracy: 0.99908, F1: 0.0138, Prec: 0.6733, Rec: 0.3888 lr: 0.00070\n",
      "Epoch 25/Step 860, Loss: -0.24994, Accuracy: 0.99908, F1: 0.0136, Prec: 0.6737, Rec: 0.3888 lr: 0.00070\n",
      "Epoch 25/Step 870, Loss: -0.24123, Accuracy: 0.99908, F1: 0.0135, Prec: 0.6731, Rec: 0.3887 lr: 0.00070\n",
      "Epoch 25/Step 880, Loss: -0.21660, Accuracy: 0.99908, F1: 0.0133, Prec: 0.6730, Rec: 0.3887 lr: 0.00070\n",
      "Epoch 25/Step 890, Loss: -0.21643, Accuracy: 0.99908, F1: 0.0132, Prec: 0.6728, Rec: 0.3885 lr: 0.00070\n",
      "Epoch 25/Step 900, Loss: -0.29460, Accuracy: 0.99908, F1: 0.0130, Prec: 0.6732, Rec: 0.3885 lr: 0.00070\n",
      "Epoch 25/Step 910, Loss: -0.20114, Accuracy: 0.99908, F1: 0.0129, Prec: 0.6727, Rec: 0.3883 lr: 0.00070\n",
      "Epoch 25/Step 920, Loss: -0.24671, Accuracy: 0.99908, F1: 0.0128, Prec: 0.6725, Rec: 0.3881 lr: 0.00070\n",
      "Epoch 25/Step 930, Loss: -0.22617, Accuracy: 0.99908, F1: 0.0126, Prec: 0.6725, Rec: 0.3881 lr: 0.00070\n",
      "Epoch 25/Step 940, Loss: -0.23860, Accuracy: 0.99908, F1: 0.0125, Prec: 0.6723, Rec: 0.3881 lr: 0.00070\n",
      "Epoch 25/Step 950, Loss: -0.25343, Accuracy: 0.99908, F1: 0.0124, Prec: 0.6725, Rec: 0.3882 lr: 0.00070\n",
      "Epoch 25/Step 960, Loss: -0.26930, Accuracy: 0.99908, F1: 0.0122, Prec: 0.6724, Rec: 0.3883 lr: 0.00070\n",
      "Epoch 25/Step 970, Loss: -0.21331, Accuracy: 0.99908, F1: 0.0121, Prec: 0.6722, Rec: 0.3879 lr: 0.00070\n",
      "Epoch 25/Step 980, Loss: -0.24438, Accuracy: 0.99908, F1: 0.0120, Prec: 0.6722, Rec: 0.3876 lr: 0.00070\n",
      "Epoch 25/Step 990, Loss: -0.22586, Accuracy: 0.99908, F1: 0.0119, Prec: 0.6714, Rec: 0.3876 lr: 0.00070\n",
      "Epoch 25/Step 1000, Loss: -0.24643, Accuracy: 0.99908, F1: 0.0117, Prec: 0.6714, Rec: 0.3878 lr: 0.00070\n",
      "Epoch 25/Step 1010, Loss: -0.25781, Accuracy: 0.99908, F1: 0.0116, Prec: 0.6717, Rec: 0.3879 lr: 0.00070\n",
      "Epoch 25/Step 1020, Loss: -0.21231, Accuracy: 0.99908, F1: 0.0115, Prec: 0.6716, Rec: 0.3879 lr: 0.00070\n",
      "Epoch 25/Step 1030, Loss: -0.25191, Accuracy: 0.99908, F1: 0.0114, Prec: 0.6717, Rec: 0.3878 lr: 0.00070\n",
      "Epoch 25/Step 1040, Loss: -0.24311, Accuracy: 0.99908, F1: 0.0113, Prec: 0.6719, Rec: 0.3878 lr: 0.00070\n",
      "Epoch 25/Step 1050, Loss: -0.27687, Accuracy: 0.99908, F1: 0.0112, Prec: 0.6720, Rec: 0.3879 lr: 0.00070\n",
      "Epoch 25/Step 1060, Loss: -0.26248, Accuracy: 0.99908, F1: 0.0111, Prec: 0.6721, Rec: 0.3881 lr: 0.00070\n",
      "Epoch 25/Step 1070, Loss: -0.23764, Accuracy: 0.99908, F1: 0.0110, Prec: 0.6722, Rec: 0.3881 lr: 0.00070\n",
      "Epoch 25/Step 1080, Loss: -0.22926, Accuracy: 0.99908, F1: 0.0109, Prec: 0.6724, Rec: 0.3882 lr: 0.00070\n",
      "Epoch 25/Step 1090, Loss: -0.24593, Accuracy: 0.99908, F1: 0.0108, Prec: 0.6722, Rec: 0.3881 lr: 0.00070\n",
      "Epoch 25/Step 1100, Loss: -0.25488, Accuracy: 0.99908, F1: 0.0107, Prec: 0.6723, Rec: 0.3882 lr: 0.00070\n",
      "Epoch 25/Step 1110, Loss: -0.21043, Accuracy: 0.99908, F1: 0.0106, Prec: 0.6722, Rec: 0.3881 lr: 0.00070\n",
      "Epoch 25/Step 1120, Loss: -0.22383, Accuracy: 0.99908, F1: 0.0112, Prec: 0.6721, Rec: 0.3882 lr: 0.00070\n",
      "Epoch 25/Step 1130, Loss: -0.22536, Accuracy: 0.99908, F1: 0.0111, Prec: 0.6722, Rec: 0.3884 lr: 0.00070\n",
      "Epoch 25/Step 1140, Loss: -0.24429, Accuracy: 0.99909, F1: 0.0110, Prec: 0.6721, Rec: 0.3885 lr: 0.00070\n",
      "Epoch 25/Step 1150, Loss: -0.26475, Accuracy: 0.99909, F1: 0.0109, Prec: 0.6722, Rec: 0.3886 lr: 0.00070\n",
      "Epoch 25/Step 1160, Loss: -0.21542, Accuracy: 0.99909, F1: 0.0108, Prec: 0.6725, Rec: 0.3889 lr: 0.00070\n",
      "Epoch 25/Step 1170, Loss: -0.21773, Accuracy: 0.99909, F1: 0.0107, Prec: 0.6728, Rec: 0.3888 lr: 0.00070\n",
      "Epoch 25/Step 1180, Loss: -0.20785, Accuracy: 0.99909, F1: 0.0106, Prec: 0.6728, Rec: 0.3887 lr: 0.00070\n",
      "Epoch 25/Step 1190, Loss: -0.27395, Accuracy: 0.99909, F1: 0.0105, Prec: 0.6726, Rec: 0.3886 lr: 0.00070\n",
      "Epoch 25/Step 1200, Loss: -0.23692, Accuracy: 0.99909, F1: 0.0104, Prec: 0.6730, Rec: 0.3888 lr: 0.00070\n",
      "Epoch 25/Step 1210, Loss: -0.25309, Accuracy: 0.99909, F1: 0.0103, Prec: 0.6732, Rec: 0.3890 lr: 0.00070\n",
      "Epoch 25/Step 1220, Loss: -0.26931, Accuracy: 0.99909, F1: 0.0103, Prec: 0.6731, Rec: 0.3891 lr: 0.00070\n",
      "Epoch 25/Step 1230, Loss: -0.26131, Accuracy: 0.99909, F1: 0.0102, Prec: 0.6729, Rec: 0.3891 lr: 0.00070\n",
      "Epoch 25/Step 1240, Loss: -0.29302, Accuracy: 0.99909, F1: 0.0101, Prec: 0.6728, Rec: 0.3891 lr: 0.00070\n",
      "Epoch 25/Step 1250, Loss: -0.18043, Accuracy: 0.99909, F1: 0.0100, Prec: 0.6729, Rec: 0.3891 lr: 0.00070\n",
      "Epoch 25/Step 1260, Loss: -0.27010, Accuracy: 0.99909, F1: 0.0099, Prec: 0.6729, Rec: 0.3893 lr: 0.00070\n",
      "Epoch 25/Step 1270, Loss: -0.23640, Accuracy: 0.99909, F1: 0.0099, Prec: 0.6730, Rec: 0.3894 lr: 0.00070\n",
      "Epoch 25/Step 1280, Loss: -0.30984, Accuracy: 0.99909, F1: 0.0098, Prec: 0.6730, Rec: 0.3894 lr: 0.00070\n",
      "Epoch 25/Step 1290, Loss: -0.25663, Accuracy: 0.99909, F1: 0.0097, Prec: 0.6731, Rec: 0.3895 lr: 0.00070\n",
      "Epoch 25/Step 1300, Loss: -0.22306, Accuracy: 0.99909, F1: 0.0096, Prec: 0.6733, Rec: 0.3895 lr: 0.00070\n",
      "Epoch 25/Step 1310, Loss: -0.24683, Accuracy: 0.99909, F1: 0.0096, Prec: 0.6733, Rec: 0.3895 lr: 0.00070\n",
      "Epoch 25/Step 1320, Loss: -0.27733, Accuracy: 0.99909, F1: 0.0095, Prec: 0.6732, Rec: 0.3897 lr: 0.00070\n",
      "Epoch 25/Step 1330, Loss: -0.27496, Accuracy: 0.99909, F1: 0.0094, Prec: 0.6733, Rec: 0.3896 lr: 0.00070\n",
      "Epoch 25/Step 1340, Loss: -0.25063, Accuracy: 0.99909, F1: 0.0093, Prec: 0.6736, Rec: 0.3897 lr: 0.00070\n",
      "Epoch 25/Step 1350, Loss: -0.20567, Accuracy: 0.99909, F1: 0.0093, Prec: 0.6736, Rec: 0.3897 lr: 0.00070\n",
      "Epoch 25/Step 1360, Loss: -0.22454, Accuracy: 0.99909, F1: 0.0092, Prec: 0.6738, Rec: 0.3897 lr: 0.00070\n",
      "Epoch 25/Step 1370, Loss: -0.24406, Accuracy: 0.99909, F1: 0.0091, Prec: 0.6739, Rec: 0.3898 lr: 0.00070\n",
      "Epoch 25/Step 1380, Loss: -0.24200, Accuracy: 0.99909, F1: 0.0091, Prec: 0.6738, Rec: 0.3899 lr: 0.00070\n",
      "Epoch 25/Step 1390, Loss: -0.24526, Accuracy: 0.99909, F1: 0.0090, Prec: 0.6736, Rec: 0.3899 lr: 0.00070\n",
      "Epoch 25/Step 1400, Loss: -0.26176, Accuracy: 0.99909, F1: 0.0089, Prec: 0.6738, Rec: 0.3900 lr: 0.00070\n",
      "Epoch 25/Step 1410, Loss: -0.22882, Accuracy: 0.99909, F1: 0.0089, Prec: 0.6738, Rec: 0.3900 lr: 0.00070\n",
      "Epoch 25/Step 1420, Loss: -0.23338, Accuracy: 0.99909, F1: 0.0088, Prec: 0.6739, Rec: 0.3898 lr: 0.00070\n",
      "Epoch 25/Step 1430, Loss: -0.24086, Accuracy: 0.99909, F1: 0.0088, Prec: 0.6740, Rec: 0.3896 lr: 0.00070\n",
      "Epoch 25/Step 1440, Loss: -0.23926, Accuracy: 0.99909, F1: 0.0087, Prec: 0.6742, Rec: 0.3897 lr: 0.00070\n",
      "Epoch 25/Step 1450, Loss: -0.25809, Accuracy: 0.99909, F1: 0.0086, Prec: 0.6744, Rec: 0.3898 lr: 0.00070\n",
      "Epoch 25/Step 1460, Loss: -0.23524, Accuracy: 0.99909, F1: 0.0086, Prec: 0.6744, Rec: 0.3898 lr: 0.00070\n",
      "Epoch 25/Step 1470, Loss: -0.24095, Accuracy: 0.99909, F1: 0.0085, Prec: 0.6746, Rec: 0.3897 lr: 0.00070\n",
      "Epoch 25/Step 1480, Loss: -0.24005, Accuracy: 0.99909, F1: 0.0085, Prec: 0.6744, Rec: 0.3898 lr: 0.00070\n",
      "Epoch 25/Step 1490, Loss: -0.23376, Accuracy: 0.99909, F1: 0.0084, Prec: 0.6742, Rec: 0.3897 lr: 0.00070\n",
      "Epoch 25/Step 1500, Loss: -0.25973, Accuracy: 0.99909, F1: 0.0083, Prec: 0.6743, Rec: 0.3898 lr: 0.00070\n",
      "Epoch 25/Step 1510, Loss: -0.22632, Accuracy: 0.99910, F1: 0.0083, Prec: 0.6745, Rec: 0.3898 lr: 0.00070\n",
      "Epoch 25/Step 1520, Loss: -0.29246, Accuracy: 0.99910, F1: 0.0082, Prec: 0.6746, Rec: 0.3899 lr: 0.00070\n",
      "Epoch 25/Step 1530, Loss: -0.23148, Accuracy: 0.99910, F1: 0.0082, Prec: 0.6746, Rec: 0.3900 lr: 0.00070\n",
      "Epoch 25/Step 1540, Loss: -0.20929, Accuracy: 0.99910, F1: 0.0081, Prec: 0.6746, Rec: 0.3898 lr: 0.00070\n",
      "Epoch 25/Step 1550, Loss: -0.23805, Accuracy: 0.99910, F1: 0.0081, Prec: 0.6748, Rec: 0.3898 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9987\n",
      "Validation f1: 0.0633\n",
      "Validation precision: 0.3822\n",
      "Validation recall: 0.2140\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_24_valF1Score0.063/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_24_valF1Score0.063/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 26\n",
      "Epoch 26/Step 0, Loss: -0.26719, Accuracy: 0.99921, F1: 0.0000, Prec: 0.7260, Rec: 0.4348 lr: 0.00070\n",
      "Epoch 26/Step 10, Loss: -0.29682, Accuracy: 0.99907, F1: 0.0000, Prec: 0.7141, Rec: 0.4116 lr: 0.00070\n",
      "Epoch 26/Step 20, Loss: -0.26237, Accuracy: 0.99911, F1: 0.0000, Prec: 0.7125, Rec: 0.4056 lr: 0.00070\n",
      "Epoch 26/Step 30, Loss: -0.22162, Accuracy: 0.99912, F1: 0.0555, Prec: 0.7001, Rec: 0.4051 lr: 0.00070\n",
      "Epoch 26/Step 40, Loss: -0.21898, Accuracy: 0.99911, F1: 0.0419, Prec: 0.6952, Rec: 0.4073 lr: 0.00070\n",
      "Epoch 26/Step 50, Loss: -0.25424, Accuracy: 0.99911, F1: 0.0337, Prec: 0.7004, Rec: 0.4056 lr: 0.00070\n",
      "Epoch 26/Step 60, Loss: -0.26147, Accuracy: 0.99912, F1: 0.0282, Prec: 0.7058, Rec: 0.4042 lr: 0.00070\n",
      "Epoch 26/Step 70, Loss: -0.24972, Accuracy: 0.99914, F1: 0.0242, Prec: 0.7039, Rec: 0.4064 lr: 0.00070\n",
      "Epoch 26/Step 80, Loss: -0.23875, Accuracy: 0.99914, F1: 0.0212, Prec: 0.6988, Rec: 0.4049 lr: 0.00070\n",
      "Epoch 26/Step 90, Loss: -0.22243, Accuracy: 0.99913, F1: 0.0189, Prec: 0.7002, Rec: 0.4033 lr: 0.00070\n",
      "Epoch 26/Step 100, Loss: -0.25114, Accuracy: 0.99914, F1: 0.0276, Prec: 0.7014, Rec: 0.4047 lr: 0.00070\n",
      "Epoch 26/Step 110, Loss: -0.25225, Accuracy: 0.99912, F1: 0.0328, Prec: 0.6984, Rec: 0.4044 lr: 0.00070\n",
      "Epoch 26/Step 120, Loss: -0.24032, Accuracy: 0.99912, F1: 0.0438, Prec: 0.6977, Rec: 0.4027 lr: 0.00070\n",
      "Epoch 26/Step 130, Loss: -0.21316, Accuracy: 0.99912, F1: 0.0549, Prec: 0.6965, Rec: 0.4029 lr: 0.00070\n",
      "Epoch 26/Step 140, Loss: -0.22015, Accuracy: 0.99911, F1: 0.0510, Prec: 0.6933, Rec: 0.4003 lr: 0.00070\n",
      "Epoch 26/Step 150, Loss: -0.23618, Accuracy: 0.99910, F1: 0.0476, Prec: 0.6908, Rec: 0.3987 lr: 0.00070\n",
      "Epoch 26/Step 160, Loss: -0.26955, Accuracy: 0.99910, F1: 0.0447, Prec: 0.6903, Rec: 0.3983 lr: 0.00070\n",
      "Epoch 26/Step 170, Loss: -0.25546, Accuracy: 0.99910, F1: 0.0421, Prec: 0.6894, Rec: 0.3974 lr: 0.00070\n",
      "Epoch 26/Step 180, Loss: -0.29984, Accuracy: 0.99910, F1: 0.0398, Prec: 0.6883, Rec: 0.3989 lr: 0.00070\n",
      "Epoch 26/Step 190, Loss: -0.23275, Accuracy: 0.99910, F1: 0.0377, Prec: 0.6870, Rec: 0.3980 lr: 0.00070\n",
      "Epoch 26/Step 200, Loss: -0.25942, Accuracy: 0.99909, F1: 0.0358, Prec: 0.6860, Rec: 0.3976 lr: 0.00070\n",
      "Epoch 26/Step 210, Loss: -0.22067, Accuracy: 0.99909, F1: 0.0341, Prec: 0.6847, Rec: 0.3976 lr: 0.00070\n",
      "Epoch 26/Step 220, Loss: -0.26365, Accuracy: 0.99909, F1: 0.0326, Prec: 0.6859, Rec: 0.3975 lr: 0.00070\n",
      "Epoch 26/Step 230, Loss: -0.21606, Accuracy: 0.99909, F1: 0.0311, Prec: 0.6854, Rec: 0.3968 lr: 0.00070\n",
      "Epoch 26/Step 240, Loss: -0.28606, Accuracy: 0.99908, F1: 0.0299, Prec: 0.6842, Rec: 0.3970 lr: 0.00070\n",
      "Epoch 26/Step 250, Loss: -0.26129, Accuracy: 0.99908, F1: 0.0287, Prec: 0.6833, Rec: 0.3967 lr: 0.00070\n",
      "Epoch 26/Step 260, Loss: -0.27302, Accuracy: 0.99908, F1: 0.0276, Prec: 0.6841, Rec: 0.3967 lr: 0.00070\n",
      "Epoch 26/Step 270, Loss: -0.27552, Accuracy: 0.99908, F1: 0.0266, Prec: 0.6836, Rec: 0.3962 lr: 0.00070\n",
      "Epoch 26/Step 280, Loss: -0.23771, Accuracy: 0.99908, F1: 0.0256, Prec: 0.6822, Rec: 0.3950 lr: 0.00070\n",
      "Epoch 26/Step 290, Loss: -0.24610, Accuracy: 0.99908, F1: 0.0247, Prec: 0.6812, Rec: 0.3955 lr: 0.00070\n",
      "Epoch 26/Step 300, Loss: -0.27274, Accuracy: 0.99908, F1: 0.0239, Prec: 0.6821, Rec: 0.3954 lr: 0.00070\n",
      "Epoch 26/Step 310, Loss: -0.25369, Accuracy: 0.99908, F1: 0.0264, Prec: 0.6815, Rec: 0.3953 lr: 0.00070\n",
      "Epoch 26/Step 320, Loss: -0.23809, Accuracy: 0.99908, F1: 0.0256, Prec: 0.6814, Rec: 0.3958 lr: 0.00070\n",
      "Epoch 26/Step 330, Loss: -0.25748, Accuracy: 0.99908, F1: 0.0248, Prec: 0.6821, Rec: 0.3955 lr: 0.00070\n",
      "Epoch 26/Step 340, Loss: -0.24810, Accuracy: 0.99908, F1: 0.0241, Prec: 0.6826, Rec: 0.3954 lr: 0.00070\n",
      "Epoch 26/Step 350, Loss: -0.22230, Accuracy: 0.99908, F1: 0.0234, Prec: 0.6836, Rec: 0.3959 lr: 0.00070\n",
      "Epoch 26/Step 360, Loss: -0.25318, Accuracy: 0.99908, F1: 0.0228, Prec: 0.6835, Rec: 0.3966 lr: 0.00070\n",
      "Epoch 26/Step 370, Loss: -0.25886, Accuracy: 0.99908, F1: 0.0222, Prec: 0.6832, Rec: 0.3967 lr: 0.00070\n",
      "Epoch 26/Step 380, Loss: -0.25749, Accuracy: 0.99908, F1: 0.0216, Prec: 0.6825, Rec: 0.3964 lr: 0.00070\n",
      "Epoch 26/Step 390, Loss: -0.21893, Accuracy: 0.99908, F1: 0.0210, Prec: 0.6827, Rec: 0.3960 lr: 0.00070\n",
      "Epoch 26/Step 400, Loss: -0.22873, Accuracy: 0.99908, F1: 0.0205, Prec: 0.6832, Rec: 0.3953 lr: 0.00070\n",
      "Epoch 26/Step 410, Loss: -0.20343, Accuracy: 0.99909, F1: 0.0200, Prec: 0.6833, Rec: 0.3950 lr: 0.00070\n",
      "Epoch 26/Step 420, Loss: -0.26428, Accuracy: 0.99909, F1: 0.0195, Prec: 0.6837, Rec: 0.3953 lr: 0.00070\n",
      "Epoch 26/Step 430, Loss: -0.24198, Accuracy: 0.99909, F1: 0.0191, Prec: 0.6829, Rec: 0.3957 lr: 0.00070\n",
      "Epoch 26/Step 440, Loss: -0.27138, Accuracy: 0.99908, F1: 0.0186, Prec: 0.6828, Rec: 0.3954 lr: 0.00070\n",
      "Epoch 26/Step 450, Loss: -0.25848, Accuracy: 0.99908, F1: 0.0182, Prec: 0.6833, Rec: 0.3951 lr: 0.00070\n",
      "Epoch 26/Step 460, Loss: -0.23076, Accuracy: 0.99909, F1: 0.0178, Prec: 0.6821, Rec: 0.3952 lr: 0.00070\n",
      "Epoch 26/Step 470, Loss: -0.22254, Accuracy: 0.99909, F1: 0.0174, Prec: 0.6812, Rec: 0.3950 lr: 0.00070\n",
      "Epoch 26/Step 480, Loss: -0.24315, Accuracy: 0.99908, F1: 0.0171, Prec: 0.6804, Rec: 0.3941 lr: 0.00070\n",
      "Epoch 26/Step 490, Loss: -0.22030, Accuracy: 0.99908, F1: 0.0167, Prec: 0.6804, Rec: 0.3937 lr: 0.00070\n",
      "Epoch 26/Step 500, Loss: -0.24649, Accuracy: 0.99908, F1: 0.0164, Prec: 0.6806, Rec: 0.3936 lr: 0.00070\n",
      "Epoch 26/Step 510, Loss: -0.29424, Accuracy: 0.99908, F1: 0.0161, Prec: 0.6808, Rec: 0.3935 lr: 0.00070\n",
      "Epoch 26/Step 520, Loss: -0.23294, Accuracy: 0.99908, F1: 0.0158, Prec: 0.6809, Rec: 0.3935 lr: 0.00070\n",
      "Epoch 26/Step 530, Loss: -0.25172, Accuracy: 0.99908, F1: 0.0155, Prec: 0.6795, Rec: 0.3932 lr: 0.00070\n",
      "Epoch 26/Step 540, Loss: -0.23994, Accuracy: 0.99908, F1: 0.0152, Prec: 0.6796, Rec: 0.3931 lr: 0.00070\n",
      "Epoch 26/Step 550, Loss: -0.28039, Accuracy: 0.99908, F1: 0.0149, Prec: 0.6797, Rec: 0.3931 lr: 0.00070\n",
      "Epoch 26/Step 560, Loss: -0.23785, Accuracy: 0.99908, F1: 0.0147, Prec: 0.6792, Rec: 0.3930 lr: 0.00070\n",
      "Epoch 26/Step 570, Loss: -0.25507, Accuracy: 0.99908, F1: 0.0144, Prec: 0.6789, Rec: 0.3929 lr: 0.00070\n",
      "Epoch 26/Step 580, Loss: -0.20901, Accuracy: 0.99908, F1: 0.0141, Prec: 0.6787, Rec: 0.3928 lr: 0.00070\n",
      "Epoch 26/Step 590, Loss: -0.19626, Accuracy: 0.99908, F1: 0.0139, Prec: 0.6782, Rec: 0.3925 lr: 0.00070\n",
      "Epoch 26/Step 600, Loss: -0.23975, Accuracy: 0.99908, F1: 0.0137, Prec: 0.6781, Rec: 0.3923 lr: 0.00070\n",
      "Epoch 26/Step 610, Loss: -0.28933, Accuracy: 0.99908, F1: 0.0135, Prec: 0.6778, Rec: 0.3925 lr: 0.00070\n",
      "Epoch 26/Step 620, Loss: -0.26606, Accuracy: 0.99908, F1: 0.0132, Prec: 0.6777, Rec: 0.3928 lr: 0.00070\n",
      "Epoch 26/Step 630, Loss: -0.22190, Accuracy: 0.99908, F1: 0.0130, Prec: 0.6773, Rec: 0.3928 lr: 0.00070\n",
      "Epoch 26/Step 640, Loss: -0.23049, Accuracy: 0.99908, F1: 0.0128, Prec: 0.6770, Rec: 0.3927 lr: 0.00070\n",
      "Epoch 26/Step 650, Loss: -0.21438, Accuracy: 0.99908, F1: 0.0126, Prec: 0.6768, Rec: 0.3927 lr: 0.00070\n",
      "Epoch 26/Step 660, Loss: -0.26644, Accuracy: 0.99908, F1: 0.0124, Prec: 0.6766, Rec: 0.3929 lr: 0.00070\n",
      "Epoch 26/Step 670, Loss: -0.25204, Accuracy: 0.99908, F1: 0.0122, Prec: 0.6771, Rec: 0.3928 lr: 0.00070\n",
      "Epoch 26/Step 680, Loss: -0.21020, Accuracy: 0.99908, F1: 0.0121, Prec: 0.6777, Rec: 0.3929 lr: 0.00070\n",
      "Epoch 26/Step 690, Loss: -0.27070, Accuracy: 0.99908, F1: 0.0119, Prec: 0.6774, Rec: 0.3929 lr: 0.00070\n",
      "Epoch 26/Step 700, Loss: -0.25558, Accuracy: 0.99908, F1: 0.0117, Prec: 0.6773, Rec: 0.3928 lr: 0.00070\n",
      "Epoch 26/Step 710, Loss: -0.25052, Accuracy: 0.99908, F1: 0.0116, Prec: 0.6781, Rec: 0.3930 lr: 0.00070\n",
      "Epoch 26/Step 720, Loss: -0.26497, Accuracy: 0.99908, F1: 0.0114, Prec: 0.6781, Rec: 0.3928 lr: 0.00070\n",
      "Epoch 26/Step 730, Loss: -0.23012, Accuracy: 0.99908, F1: 0.0112, Prec: 0.6776, Rec: 0.3927 lr: 0.00070\n",
      "Epoch 26/Step 740, Loss: -0.25037, Accuracy: 0.99908, F1: 0.0111, Prec: 0.6775, Rec: 0.3925 lr: 0.00070\n",
      "Epoch 26/Step 750, Loss: -0.26079, Accuracy: 0.99908, F1: 0.0109, Prec: 0.6772, Rec: 0.3926 lr: 0.00070\n",
      "Epoch 26/Step 760, Loss: -0.25187, Accuracy: 0.99908, F1: 0.0122, Prec: 0.6769, Rec: 0.3923 lr: 0.00070\n",
      "Epoch 26/Step 770, Loss: -0.27623, Accuracy: 0.99908, F1: 0.0120, Prec: 0.6769, Rec: 0.3923 lr: 0.00070\n",
      "Epoch 26/Step 780, Loss: -0.20183, Accuracy: 0.99908, F1: 0.0119, Prec: 0.6772, Rec: 0.3924 lr: 0.00070\n",
      "Epoch 26/Step 790, Loss: -0.26516, Accuracy: 0.99908, F1: 0.0117, Prec: 0.6770, Rec: 0.3922 lr: 0.00070\n",
      "Epoch 26/Step 800, Loss: -0.23449, Accuracy: 0.99908, F1: 0.0116, Prec: 0.6773, Rec: 0.3921 lr: 0.00070\n",
      "Epoch 26/Step 810, Loss: -0.17973, Accuracy: 0.99908, F1: 0.0114, Prec: 0.6773, Rec: 0.3921 lr: 0.00070\n",
      "Epoch 26/Step 820, Loss: -0.23542, Accuracy: 0.99908, F1: 0.0113, Prec: 0.6770, Rec: 0.3920 lr: 0.00070\n",
      "Epoch 26/Step 830, Loss: -0.27151, Accuracy: 0.99908, F1: 0.0112, Prec: 0.6772, Rec: 0.3920 lr: 0.00070\n",
      "Epoch 26/Step 840, Loss: -0.28801, Accuracy: 0.99908, F1: 0.0110, Prec: 0.6775, Rec: 0.3923 lr: 0.00070\n",
      "Epoch 26/Step 850, Loss: -0.25327, Accuracy: 0.99908, F1: 0.0109, Prec: 0.6774, Rec: 0.3921 lr: 0.00070\n",
      "Epoch 26/Step 860, Loss: -0.24638, Accuracy: 0.99908, F1: 0.0108, Prec: 0.6777, Rec: 0.3920 lr: 0.00070\n",
      "Epoch 26/Step 870, Loss: -0.24195, Accuracy: 0.99908, F1: 0.0106, Prec: 0.6774, Rec: 0.3918 lr: 0.00070\n",
      "Epoch 26/Step 880, Loss: -0.21834, Accuracy: 0.99908, F1: 0.0105, Prec: 0.6772, Rec: 0.3918 lr: 0.00070\n",
      "Epoch 26/Step 890, Loss: -0.23209, Accuracy: 0.99908, F1: 0.0104, Prec: 0.6768, Rec: 0.3917 lr: 0.00070\n",
      "Epoch 26/Step 900, Loss: -0.29996, Accuracy: 0.99908, F1: 0.0103, Prec: 0.6768, Rec: 0.3919 lr: 0.00070\n",
      "Epoch 26/Step 910, Loss: -0.20473, Accuracy: 0.99908, F1: 0.0102, Prec: 0.6765, Rec: 0.3917 lr: 0.00070\n",
      "Epoch 26/Step 920, Loss: -0.24798, Accuracy: 0.99908, F1: 0.0101, Prec: 0.6760, Rec: 0.3915 lr: 0.00070\n",
      "Epoch 26/Step 930, Loss: -0.23451, Accuracy: 0.99908, F1: 0.0100, Prec: 0.6759, Rec: 0.3916 lr: 0.00070\n",
      "Epoch 26/Step 940, Loss: -0.23987, Accuracy: 0.99908, F1: 0.0099, Prec: 0.6758, Rec: 0.3915 lr: 0.00070\n",
      "Epoch 26/Step 950, Loss: -0.24542, Accuracy: 0.99909, F1: 0.0098, Prec: 0.6759, Rec: 0.3916 lr: 0.00070\n",
      "Epoch 26/Step 960, Loss: -0.28346, Accuracy: 0.99909, F1: 0.0097, Prec: 0.6760, Rec: 0.3916 lr: 0.00070\n",
      "Epoch 26/Step 970, Loss: -0.21554, Accuracy: 0.99909, F1: 0.0096, Prec: 0.6757, Rec: 0.3911 lr: 0.00070\n",
      "Epoch 26/Step 980, Loss: -0.25241, Accuracy: 0.99909, F1: 0.0095, Prec: 0.6757, Rec: 0.3909 lr: 0.00070\n",
      "Epoch 26/Step 990, Loss: -0.22921, Accuracy: 0.99908, F1: 0.0094, Prec: 0.6747, Rec: 0.3909 lr: 0.00070\n",
      "Epoch 26/Step 1000, Loss: -0.24527, Accuracy: 0.99909, F1: 0.0093, Prec: 0.6746, Rec: 0.3912 lr: 0.00070\n",
      "Epoch 26/Step 1010, Loss: -0.26408, Accuracy: 0.99909, F1: 0.0092, Prec: 0.6749, Rec: 0.3914 lr: 0.00070\n",
      "Epoch 26/Step 1020, Loss: -0.20116, Accuracy: 0.99909, F1: 0.0091, Prec: 0.6749, Rec: 0.3913 lr: 0.00070\n",
      "Epoch 26/Step 1030, Loss: -0.25573, Accuracy: 0.99909, F1: 0.0090, Prec: 0.6750, Rec: 0.3912 lr: 0.00070\n",
      "Epoch 26/Step 1040, Loss: -0.24369, Accuracy: 0.99909, F1: 0.0089, Prec: 0.6751, Rec: 0.3912 lr: 0.00070\n",
      "Epoch 26/Step 1050, Loss: -0.27030, Accuracy: 0.99909, F1: 0.0088, Prec: 0.6752, Rec: 0.3914 lr: 0.00070\n",
      "Epoch 26/Step 1060, Loss: -0.26979, Accuracy: 0.99909, F1: 0.0087, Prec: 0.6754, Rec: 0.3916 lr: 0.00070\n",
      "Epoch 26/Step 1070, Loss: -0.24899, Accuracy: 0.99909, F1: 0.0087, Prec: 0.6755, Rec: 0.3916 lr: 0.00070\n",
      "Epoch 26/Step 1080, Loss: -0.22681, Accuracy: 0.99909, F1: 0.0086, Prec: 0.6754, Rec: 0.3917 lr: 0.00070\n",
      "Epoch 26/Step 1090, Loss: -0.24128, Accuracy: 0.99909, F1: 0.0085, Prec: 0.6753, Rec: 0.3916 lr: 0.00070\n",
      "Epoch 26/Step 1100, Loss: -0.25544, Accuracy: 0.99909, F1: 0.0084, Prec: 0.6754, Rec: 0.3916 lr: 0.00070\n",
      "Epoch 26/Step 1110, Loss: -0.20943, Accuracy: 0.99909, F1: 0.0083, Prec: 0.6754, Rec: 0.3916 lr: 0.00070\n",
      "Epoch 26/Step 1120, Loss: -0.22087, Accuracy: 0.99909, F1: 0.0083, Prec: 0.6753, Rec: 0.3916 lr: 0.00070\n",
      "Epoch 26/Step 1130, Loss: -0.22063, Accuracy: 0.99909, F1: 0.0082, Prec: 0.6754, Rec: 0.3917 lr: 0.00070\n",
      "Epoch 26/Step 1140, Loss: -0.23959, Accuracy: 0.99909, F1: 0.0081, Prec: 0.6756, Rec: 0.3917 lr: 0.00070\n",
      "Epoch 26/Step 1150, Loss: -0.26656, Accuracy: 0.99909, F1: 0.0081, Prec: 0.6757, Rec: 0.3917 lr: 0.00070\n",
      "Epoch 26/Step 1160, Loss: -0.21623, Accuracy: 0.99909, F1: 0.0080, Prec: 0.6758, Rec: 0.3921 lr: 0.00070\n",
      "Epoch 26/Step 1170, Loss: -0.22043, Accuracy: 0.99909, F1: 0.0079, Prec: 0.6761, Rec: 0.3919 lr: 0.00070\n",
      "Epoch 26/Step 1180, Loss: -0.20897, Accuracy: 0.99909, F1: 0.0079, Prec: 0.6762, Rec: 0.3917 lr: 0.00070\n",
      "Epoch 26/Step 1190, Loss: -0.26937, Accuracy: 0.99909, F1: 0.0078, Prec: 0.6756, Rec: 0.3917 lr: 0.00070\n",
      "Epoch 26/Step 1200, Loss: -0.23563, Accuracy: 0.99909, F1: 0.0077, Prec: 0.6759, Rec: 0.3920 lr: 0.00070\n",
      "Epoch 26/Step 1210, Loss: -0.25925, Accuracy: 0.99909, F1: 0.0077, Prec: 0.6761, Rec: 0.3921 lr: 0.00070\n",
      "Epoch 26/Step 1220, Loss: -0.27622, Accuracy: 0.99909, F1: 0.0076, Prec: 0.6761, Rec: 0.3921 lr: 0.00070\n",
      "Epoch 26/Step 1230, Loss: -0.25719, Accuracy: 0.99910, F1: 0.0075, Prec: 0.6759, Rec: 0.3922 lr: 0.00070\n",
      "Epoch 26/Step 1240, Loss: -0.28227, Accuracy: 0.99909, F1: 0.0075, Prec: 0.6758, Rec: 0.3922 lr: 0.00070\n",
      "Epoch 26/Step 1250, Loss: -0.18854, Accuracy: 0.99910, F1: 0.0074, Prec: 0.6761, Rec: 0.3921 lr: 0.00070\n",
      "Epoch 26/Step 1260, Loss: -0.26711, Accuracy: 0.99910, F1: 0.0074, Prec: 0.6759, Rec: 0.3923 lr: 0.00070\n",
      "Epoch 26/Step 1270, Loss: -0.24010, Accuracy: 0.99910, F1: 0.0073, Prec: 0.6758, Rec: 0.3925 lr: 0.00070\n",
      "Epoch 26/Step 1280, Loss: -0.30353, Accuracy: 0.99910, F1: 0.0072, Prec: 0.6759, Rec: 0.3924 lr: 0.00070\n",
      "Epoch 26/Step 1290, Loss: -0.25843, Accuracy: 0.99910, F1: 0.0072, Prec: 0.6761, Rec: 0.3925 lr: 0.00070\n",
      "Epoch 26/Step 1300, Loss: -0.22793, Accuracy: 0.99910, F1: 0.0071, Prec: 0.6761, Rec: 0.3925 lr: 0.00070\n",
      "Epoch 26/Step 1310, Loss: -0.25537, Accuracy: 0.99910, F1: 0.0071, Prec: 0.6764, Rec: 0.3925 lr: 0.00070\n",
      "Epoch 26/Step 1320, Loss: -0.27887, Accuracy: 0.99910, F1: 0.0070, Prec: 0.6765, Rec: 0.3926 lr: 0.00070\n",
      "Epoch 26/Step 1330, Loss: -0.27670, Accuracy: 0.99910, F1: 0.0070, Prec: 0.6765, Rec: 0.3925 lr: 0.00070\n",
      "Epoch 26/Step 1340, Loss: -0.25369, Accuracy: 0.99910, F1: 0.0069, Prec: 0.6768, Rec: 0.3927 lr: 0.00070\n",
      "Epoch 26/Step 1350, Loss: -0.19722, Accuracy: 0.99910, F1: 0.0069, Prec: 0.6769, Rec: 0.3926 lr: 0.00070\n",
      "Epoch 26/Step 1360, Loss: -0.22621, Accuracy: 0.99910, F1: 0.0068, Prec: 0.6770, Rec: 0.3927 lr: 0.00070\n",
      "Epoch 26/Step 1370, Loss: -0.24472, Accuracy: 0.99910, F1: 0.0068, Prec: 0.6772, Rec: 0.3928 lr: 0.00070\n",
      "Epoch 26/Step 1380, Loss: -0.25070, Accuracy: 0.99910, F1: 0.0067, Prec: 0.6769, Rec: 0.3930 lr: 0.00070\n",
      "Epoch 26/Step 1390, Loss: -0.24694, Accuracy: 0.99910, F1: 0.0067, Prec: 0.6769, Rec: 0.3929 lr: 0.00070\n",
      "Epoch 26/Step 1400, Loss: -0.26008, Accuracy: 0.99910, F1: 0.0066, Prec: 0.6771, Rec: 0.3930 lr: 0.00070\n",
      "Epoch 26/Step 1410, Loss: -0.22923, Accuracy: 0.99910, F1: 0.0066, Prec: 0.6770, Rec: 0.3930 lr: 0.00070\n",
      "Epoch 26/Step 1420, Loss: -0.23177, Accuracy: 0.99910, F1: 0.0065, Prec: 0.6769, Rec: 0.3929 lr: 0.00070\n",
      "Epoch 26/Step 1430, Loss: -0.24139, Accuracy: 0.99910, F1: 0.0065, Prec: 0.6772, Rec: 0.3927 lr: 0.00070\n",
      "Epoch 26/Step 1440, Loss: -0.23970, Accuracy: 0.99910, F1: 0.0064, Prec: 0.6774, Rec: 0.3928 lr: 0.00070\n",
      "Epoch 26/Step 1450, Loss: -0.25880, Accuracy: 0.99910, F1: 0.0064, Prec: 0.6773, Rec: 0.3929 lr: 0.00070\n",
      "Epoch 26/Step 1460, Loss: -0.23460, Accuracy: 0.99910, F1: 0.0063, Prec: 0.6774, Rec: 0.3928 lr: 0.00070\n",
      "Epoch 26/Step 1470, Loss: -0.24910, Accuracy: 0.99910, F1: 0.0063, Prec: 0.6775, Rec: 0.3928 lr: 0.00070\n",
      "Epoch 26/Step 1480, Loss: -0.23815, Accuracy: 0.99910, F1: 0.0063, Prec: 0.6773, Rec: 0.3929 lr: 0.00070\n",
      "Epoch 26/Step 1490, Loss: -0.23865, Accuracy: 0.99910, F1: 0.0062, Prec: 0.6773, Rec: 0.3927 lr: 0.00070\n",
      "Epoch 26/Step 1500, Loss: -0.25811, Accuracy: 0.99910, F1: 0.0062, Prec: 0.6775, Rec: 0.3928 lr: 0.00070\n",
      "Epoch 26/Step 1510, Loss: -0.22140, Accuracy: 0.99910, F1: 0.0061, Prec: 0.6777, Rec: 0.3927 lr: 0.00070\n",
      "Epoch 26/Step 1520, Loss: -0.28640, Accuracy: 0.99910, F1: 0.0061, Prec: 0.6778, Rec: 0.3928 lr: 0.00070\n",
      "Epoch 26/Step 1530, Loss: -0.22530, Accuracy: 0.99910, F1: 0.0061, Prec: 0.6780, Rec: 0.3929 lr: 0.00070\n",
      "Epoch 26/Step 1540, Loss: -0.20235, Accuracy: 0.99910, F1: 0.0060, Prec: 0.6780, Rec: 0.3926 lr: 0.00070\n",
      "Epoch 26/Step 1550, Loss: -0.23963, Accuracy: 0.99910, F1: 0.0060, Prec: 0.6780, Rec: 0.3927 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9987\n",
      "Validation f1: 0.0239\n",
      "Validation precision: 0.3836\n",
      "Validation recall: 0.2100\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_25_valF1Score0.024/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_25_valF1Score0.024/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 27\n",
      "Epoch 27/Step 0, Loss: -0.27208, Accuracy: 0.99923, F1: 0.0000, Prec: 0.7454, Rec: 0.4389 lr: 0.00070\n",
      "Epoch 27/Step 10, Loss: -0.29658, Accuracy: 0.99907, F1: 0.0000, Prec: 0.7080, Rec: 0.4166 lr: 0.00070\n",
      "Epoch 27/Step 20, Loss: -0.26712, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6986, Rec: 0.4126 lr: 0.00070\n",
      "Epoch 27/Step 30, Loss: -0.22686, Accuracy: 0.99913, F1: 0.0565, Prec: 0.7013, Rec: 0.4097 lr: 0.00070\n",
      "Epoch 27/Step 40, Loss: -0.21724, Accuracy: 0.99911, F1: 0.0427, Prec: 0.6993, Rec: 0.4111 lr: 0.00070\n",
      "Epoch 27/Step 50, Loss: -0.25453, Accuracy: 0.99912, F1: 0.0343, Prec: 0.6995, Rec: 0.4098 lr: 0.00070\n",
      "Epoch 27/Step 60, Loss: -0.25939, Accuracy: 0.99912, F1: 0.0287, Prec: 0.7028, Rec: 0.4086 lr: 0.00070\n",
      "Epoch 27/Step 70, Loss: -0.24742, Accuracy: 0.99914, F1: 0.0247, Prec: 0.7005, Rec: 0.4098 lr: 0.00070\n",
      "Epoch 27/Step 80, Loss: -0.24005, Accuracy: 0.99914, F1: 0.0216, Prec: 0.6960, Rec: 0.4083 lr: 0.00070\n",
      "Epoch 27/Step 90, Loss: -0.22724, Accuracy: 0.99913, F1: 0.0192, Prec: 0.6955, Rec: 0.4072 lr: 0.00070\n",
      "Epoch 27/Step 100, Loss: -0.25020, Accuracy: 0.99914, F1: 0.0173, Prec: 0.6986, Rec: 0.4079 lr: 0.00070\n",
      "Epoch 27/Step 110, Loss: -0.24476, Accuracy: 0.99913, F1: 0.0158, Prec: 0.6986, Rec: 0.4065 lr: 0.00070\n",
      "Epoch 27/Step 120, Loss: -0.24345, Accuracy: 0.99912, F1: 0.0145, Prec: 0.6947, Rec: 0.4061 lr: 0.00070\n",
      "Epoch 27/Step 130, Loss: -0.21355, Accuracy: 0.99912, F1: 0.0134, Prec: 0.6921, Rec: 0.4066 lr: 0.00070\n",
      "Epoch 27/Step 140, Loss: -0.22411, Accuracy: 0.99911, F1: 0.0124, Prec: 0.6915, Rec: 0.4031 lr: 0.00070\n",
      "Epoch 27/Step 150, Loss: -0.23895, Accuracy: 0.99910, F1: 0.0116, Prec: 0.6891, Rec: 0.4015 lr: 0.00070\n",
      "Epoch 27/Step 160, Loss: -0.26886, Accuracy: 0.99910, F1: 0.0109, Prec: 0.6875, Rec: 0.4016 lr: 0.00070\n",
      "Epoch 27/Step 170, Loss: -0.25167, Accuracy: 0.99910, F1: 0.0102, Prec: 0.6876, Rec: 0.4011 lr: 0.00070\n",
      "Epoch 27/Step 180, Loss: -0.29640, Accuracy: 0.99910, F1: 0.0097, Prec: 0.6883, Rec: 0.4020 lr: 0.00070\n",
      "Epoch 27/Step 190, Loss: -0.23726, Accuracy: 0.99910, F1: 0.0092, Prec: 0.6871, Rec: 0.4010 lr: 0.00070\n",
      "Epoch 27/Step 200, Loss: -0.26369, Accuracy: 0.99909, F1: 0.0087, Prec: 0.6873, Rec: 0.4005 lr: 0.00070\n",
      "Epoch 27/Step 210, Loss: -0.22322, Accuracy: 0.99909, F1: 0.0083, Prec: 0.6875, Rec: 0.4001 lr: 0.00070\n",
      "Epoch 27/Step 220, Loss: -0.26403, Accuracy: 0.99909, F1: 0.0079, Prec: 0.6881, Rec: 0.4005 lr: 0.00070\n",
      "Epoch 27/Step 230, Loss: -0.21883, Accuracy: 0.99909, F1: 0.0076, Prec: 0.6875, Rec: 0.4000 lr: 0.00070\n",
      "Epoch 27/Step 240, Loss: -0.28560, Accuracy: 0.99909, F1: 0.0073, Prec: 0.6867, Rec: 0.4001 lr: 0.00070\n",
      "Epoch 27/Step 250, Loss: -0.26121, Accuracy: 0.99909, F1: 0.0070, Prec: 0.6867, Rec: 0.3994 lr: 0.00070\n",
      "Epoch 27/Step 260, Loss: -0.27889, Accuracy: 0.99909, F1: 0.0067, Prec: 0.6872, Rec: 0.3995 lr: 0.00070\n",
      "Epoch 27/Step 270, Loss: -0.27415, Accuracy: 0.99908, F1: 0.0065, Prec: 0.6868, Rec: 0.3989 lr: 0.00070\n",
      "Epoch 27/Step 280, Loss: -0.24572, Accuracy: 0.99908, F1: 0.0062, Prec: 0.6863, Rec: 0.3977 lr: 0.00070\n",
      "Epoch 27/Step 290, Loss: -0.24943, Accuracy: 0.99908, F1: 0.0060, Prec: 0.6848, Rec: 0.3981 lr: 0.00070\n",
      "Epoch 27/Step 300, Loss: -0.27979, Accuracy: 0.99908, F1: 0.0058, Prec: 0.6861, Rec: 0.3978 lr: 0.00070\n",
      "Epoch 27/Step 310, Loss: -0.25546, Accuracy: 0.99909, F1: 0.0056, Prec: 0.6860, Rec: 0.3978 lr: 0.00070\n",
      "Epoch 27/Step 320, Loss: -0.23892, Accuracy: 0.99909, F1: 0.0055, Prec: 0.6867, Rec: 0.3980 lr: 0.00070\n",
      "Epoch 27/Step 330, Loss: -0.26175, Accuracy: 0.99909, F1: 0.0053, Prec: 0.6864, Rec: 0.3981 lr: 0.00070\n",
      "Epoch 27/Step 340, Loss: -0.25557, Accuracy: 0.99908, F1: 0.0051, Prec: 0.6863, Rec: 0.3980 lr: 0.00070\n",
      "Epoch 27/Step 350, Loss: -0.21994, Accuracy: 0.99909, F1: 0.0050, Prec: 0.6876, Rec: 0.3982 lr: 0.00070\n",
      "Epoch 27/Step 360, Loss: -0.25314, Accuracy: 0.99909, F1: 0.0048, Prec: 0.6876, Rec: 0.3989 lr: 0.00070\n",
      "Epoch 27/Step 370, Loss: -0.25918, Accuracy: 0.99909, F1: 0.0047, Prec: 0.6869, Rec: 0.3992 lr: 0.00070\n",
      "Epoch 27/Step 380, Loss: -0.25889, Accuracy: 0.99909, F1: 0.0046, Prec: 0.6865, Rec: 0.3986 lr: 0.00070\n",
      "Epoch 27/Step 390, Loss: -0.21758, Accuracy: 0.99909, F1: 0.0045, Prec: 0.6869, Rec: 0.3982 lr: 0.00070\n",
      "Epoch 27/Step 400, Loss: -0.22895, Accuracy: 0.99909, F1: 0.0044, Prec: 0.6870, Rec: 0.3976 lr: 0.00070\n",
      "Epoch 27/Step 410, Loss: -0.20853, Accuracy: 0.99909, F1: 0.0043, Prec: 0.6870, Rec: 0.3974 lr: 0.00070\n",
      "Epoch 27/Step 420, Loss: -0.26515, Accuracy: 0.99909, F1: 0.0042, Prec: 0.6876, Rec: 0.3975 lr: 0.00070\n",
      "Epoch 27/Step 430, Loss: -0.23749, Accuracy: 0.99909, F1: 0.0041, Prec: 0.6861, Rec: 0.3979 lr: 0.00070\n",
      "Epoch 27/Step 440, Loss: -0.26970, Accuracy: 0.99909, F1: 0.0040, Prec: 0.6862, Rec: 0.3977 lr: 0.00070\n",
      "Epoch 27/Step 450, Loss: -0.26211, Accuracy: 0.99909, F1: 0.0039, Prec: 0.6867, Rec: 0.3974 lr: 0.00070\n",
      "Epoch 27/Step 460, Loss: -0.23472, Accuracy: 0.99909, F1: 0.0038, Prec: 0.6854, Rec: 0.3974 lr: 0.00070\n",
      "Epoch 27/Step 470, Loss: -0.22656, Accuracy: 0.99909, F1: 0.0037, Prec: 0.6848, Rec: 0.3971 lr: 0.00070\n",
      "Epoch 27/Step 480, Loss: -0.24260, Accuracy: 0.99909, F1: 0.0036, Prec: 0.6840, Rec: 0.3962 lr: 0.00070\n",
      "Epoch 27/Step 490, Loss: -0.21083, Accuracy: 0.99909, F1: 0.0036, Prec: 0.6834, Rec: 0.3960 lr: 0.00070\n",
      "Epoch 27/Step 500, Loss: -0.24707, Accuracy: 0.99909, F1: 0.0035, Prec: 0.6841, Rec: 0.3958 lr: 0.00070\n",
      "Epoch 27/Step 510, Loss: -0.28488, Accuracy: 0.99909, F1: 0.0034, Prec: 0.6837, Rec: 0.3959 lr: 0.00070\n",
      "Epoch 27/Step 520, Loss: -0.23448, Accuracy: 0.99909, F1: 0.0034, Prec: 0.6838, Rec: 0.3960 lr: 0.00070\n",
      "Epoch 27/Step 530, Loss: -0.24714, Accuracy: 0.99909, F1: 0.0033, Prec: 0.6827, Rec: 0.3955 lr: 0.00070\n",
      "Epoch 27/Step 540, Loss: -0.24417, Accuracy: 0.99909, F1: 0.0032, Prec: 0.6823, Rec: 0.3955 lr: 0.00070\n",
      "Epoch 27/Step 550, Loss: -0.28200, Accuracy: 0.99908, F1: 0.0032, Prec: 0.6825, Rec: 0.3955 lr: 0.00070\n",
      "Epoch 27/Step 560, Loss: -0.23902, Accuracy: 0.99908, F1: 0.0031, Prec: 0.6820, Rec: 0.3954 lr: 0.00070\n",
      "Epoch 27/Step 570, Loss: -0.25815, Accuracy: 0.99908, F1: 0.0031, Prec: 0.6810, Rec: 0.3954 lr: 0.00070\n",
      "Epoch 27/Step 580, Loss: -0.21106, Accuracy: 0.99908, F1: 0.0030, Prec: 0.6812, Rec: 0.3952 lr: 0.00070\n",
      "Epoch 27/Step 590, Loss: -0.19919, Accuracy: 0.99908, F1: 0.0030, Prec: 0.6811, Rec: 0.3948 lr: 0.00070\n",
      "Epoch 27/Step 600, Loss: -0.24402, Accuracy: 0.99908, F1: 0.0029, Prec: 0.6811, Rec: 0.3946 lr: 0.00070\n",
      "Epoch 27/Step 610, Loss: -0.29902, Accuracy: 0.99908, F1: 0.0029, Prec: 0.6810, Rec: 0.3948 lr: 0.00070\n",
      "Epoch 27/Step 620, Loss: -0.25719, Accuracy: 0.99908, F1: 0.0028, Prec: 0.6809, Rec: 0.3950 lr: 0.00070\n",
      "Epoch 27/Step 630, Loss: -0.22255, Accuracy: 0.99908, F1: 0.0028, Prec: 0.6809, Rec: 0.3948 lr: 0.00070\n",
      "Epoch 27/Step 640, Loss: -0.22951, Accuracy: 0.99908, F1: 0.0027, Prec: 0.6806, Rec: 0.3948 lr: 0.00070\n",
      "Epoch 27/Step 650, Loss: -0.21509, Accuracy: 0.99908, F1: 0.0027, Prec: 0.6802, Rec: 0.3948 lr: 0.00070\n",
      "Epoch 27/Step 660, Loss: -0.26121, Accuracy: 0.99908, F1: 0.0026, Prec: 0.6801, Rec: 0.3948 lr: 0.00070\n",
      "Epoch 27/Step 670, Loss: -0.26677, Accuracy: 0.99908, F1: 0.0026, Prec: 0.6803, Rec: 0.3948 lr: 0.00070\n",
      "Epoch 27/Step 680, Loss: -0.21135, Accuracy: 0.99908, F1: 0.0026, Prec: 0.6805, Rec: 0.3950 lr: 0.00070\n",
      "Epoch 27/Step 690, Loss: -0.27594, Accuracy: 0.99908, F1: 0.0025, Prec: 0.6805, Rec: 0.3950 lr: 0.00070\n",
      "Epoch 27/Step 700, Loss: -0.25442, Accuracy: 0.99908, F1: 0.0025, Prec: 0.6806, Rec: 0.3948 lr: 0.00070\n",
      "Epoch 27/Step 710, Loss: -0.26014, Accuracy: 0.99908, F1: 0.0025, Prec: 0.6810, Rec: 0.3952 lr: 0.00070\n",
      "Epoch 27/Step 720, Loss: -0.26334, Accuracy: 0.99908, F1: 0.0024, Prec: 0.6810, Rec: 0.3949 lr: 0.00070\n",
      "Epoch 27/Step 730, Loss: -0.23732, Accuracy: 0.99908, F1: 0.0024, Prec: 0.6808, Rec: 0.3948 lr: 0.00070\n",
      "Epoch 27/Step 740, Loss: -0.25159, Accuracy: 0.99908, F1: 0.0024, Prec: 0.6806, Rec: 0.3947 lr: 0.00070\n",
      "Epoch 27/Step 750, Loss: -0.26491, Accuracy: 0.99908, F1: 0.0023, Prec: 0.6803, Rec: 0.3947 lr: 0.00070\n",
      "Epoch 27/Step 760, Loss: -0.26075, Accuracy: 0.99908, F1: 0.0037, Prec: 0.6805, Rec: 0.3944 lr: 0.00070\n",
      "Epoch 27/Step 770, Loss: -0.26497, Accuracy: 0.99909, F1: 0.0036, Prec: 0.6803, Rec: 0.3944 lr: 0.00070\n",
      "Epoch 27/Step 780, Loss: -0.20852, Accuracy: 0.99909, F1: 0.0036, Prec: 0.6809, Rec: 0.3944 lr: 0.00070\n",
      "Epoch 27/Step 790, Loss: -0.26232, Accuracy: 0.99908, F1: 0.0035, Prec: 0.6808, Rec: 0.3941 lr: 0.00070\n",
      "Epoch 27/Step 800, Loss: -0.24109, Accuracy: 0.99909, F1: 0.0035, Prec: 0.6810, Rec: 0.3940 lr: 0.00070\n",
      "Epoch 27/Step 810, Loss: -0.18006, Accuracy: 0.99909, F1: 0.0035, Prec: 0.6809, Rec: 0.3941 lr: 0.00070\n",
      "Epoch 27/Step 820, Loss: -0.23308, Accuracy: 0.99909, F1: 0.0034, Prec: 0.6807, Rec: 0.3939 lr: 0.00070\n",
      "Epoch 27/Step 830, Loss: -0.27466, Accuracy: 0.99909, F1: 0.0034, Prec: 0.6808, Rec: 0.3940 lr: 0.00070\n",
      "Epoch 27/Step 840, Loss: -0.29044, Accuracy: 0.99909, F1: 0.0033, Prec: 0.6808, Rec: 0.3942 lr: 0.00070\n",
      "Epoch 27/Step 850, Loss: -0.25449, Accuracy: 0.99909, F1: 0.0033, Prec: 0.6804, Rec: 0.3940 lr: 0.00070\n",
      "Epoch 27/Step 860, Loss: -0.24906, Accuracy: 0.99909, F1: 0.0033, Prec: 0.6806, Rec: 0.3940 lr: 0.00070\n",
      "Epoch 27/Step 870, Loss: -0.23925, Accuracy: 0.99909, F1: 0.0032, Prec: 0.6806, Rec: 0.3937 lr: 0.00070\n",
      "Epoch 27/Step 880, Loss: -0.21489, Accuracy: 0.99909, F1: 0.0032, Prec: 0.6804, Rec: 0.3938 lr: 0.00070\n",
      "Epoch 27/Step 890, Loss: -0.23468, Accuracy: 0.99909, F1: 0.0031, Prec: 0.6800, Rec: 0.3936 lr: 0.00070\n",
      "Epoch 27/Step 900, Loss: -0.30029, Accuracy: 0.99909, F1: 0.0031, Prec: 0.6800, Rec: 0.3938 lr: 0.00070\n",
      "Epoch 27/Step 910, Loss: -0.20612, Accuracy: 0.99909, F1: 0.0031, Prec: 0.6799, Rec: 0.3935 lr: 0.00070\n",
      "Epoch 27/Step 920, Loss: -0.24207, Accuracy: 0.99909, F1: 0.0030, Prec: 0.6797, Rec: 0.3933 lr: 0.00070\n",
      "Epoch 27/Step 930, Loss: -0.23481, Accuracy: 0.99909, F1: 0.0030, Prec: 0.6797, Rec: 0.3933 lr: 0.00070\n",
      "Epoch 27/Step 940, Loss: -0.24524, Accuracy: 0.99909, F1: 0.0030, Prec: 0.6794, Rec: 0.3933 lr: 0.00070\n",
      "Epoch 27/Step 950, Loss: -0.24939, Accuracy: 0.99909, F1: 0.0029, Prec: 0.6793, Rec: 0.3934 lr: 0.00070\n",
      "Epoch 27/Step 960, Loss: -0.27717, Accuracy: 0.99909, F1: 0.0029, Prec: 0.6793, Rec: 0.3934 lr: 0.00070\n",
      "Epoch 27/Step 970, Loss: -0.22287, Accuracy: 0.99909, F1: 0.0029, Prec: 0.6791, Rec: 0.3930 lr: 0.00070\n",
      "Epoch 27/Step 980, Loss: -0.24661, Accuracy: 0.99909, F1: 0.0029, Prec: 0.6792, Rec: 0.3928 lr: 0.00070\n",
      "Epoch 27/Step 990, Loss: -0.23267, Accuracy: 0.99909, F1: 0.0028, Prec: 0.6784, Rec: 0.3927 lr: 0.00070\n",
      "Epoch 27/Step 1000, Loss: -0.24656, Accuracy: 0.99909, F1: 0.0028, Prec: 0.6782, Rec: 0.3929 lr: 0.00070\n",
      "Epoch 27/Step 1010, Loss: -0.25372, Accuracy: 0.99909, F1: 0.0028, Prec: 0.6785, Rec: 0.3930 lr: 0.00070\n",
      "Epoch 27/Step 1020, Loss: -0.20786, Accuracy: 0.99909, F1: 0.0027, Prec: 0.6784, Rec: 0.3930 lr: 0.00070\n",
      "Epoch 27/Step 1030, Loss: -0.24891, Accuracy: 0.99909, F1: 0.0027, Prec: 0.6785, Rec: 0.3929 lr: 0.00070\n",
      "Epoch 27/Step 1040, Loss: -0.24485, Accuracy: 0.99909, F1: 0.0027, Prec: 0.6785, Rec: 0.3929 lr: 0.00070\n",
      "Epoch 27/Step 1050, Loss: -0.27437, Accuracy: 0.99909, F1: 0.0027, Prec: 0.6785, Rec: 0.3930 lr: 0.00070\n",
      "Epoch 27/Step 1060, Loss: -0.27133, Accuracy: 0.99909, F1: 0.0026, Prec: 0.6785, Rec: 0.3932 lr: 0.00070\n",
      "Epoch 27/Step 1070, Loss: -0.24652, Accuracy: 0.99909, F1: 0.0026, Prec: 0.6786, Rec: 0.3932 lr: 0.00070\n",
      "Epoch 27/Step 1080, Loss: -0.23538, Accuracy: 0.99909, F1: 0.0026, Prec: 0.6788, Rec: 0.3932 lr: 0.00070\n",
      "Epoch 27/Step 1090, Loss: -0.24254, Accuracy: 0.99909, F1: 0.0026, Prec: 0.6787, Rec: 0.3931 lr: 0.00070\n",
      "Epoch 27/Step 1100, Loss: -0.25077, Accuracy: 0.99909, F1: 0.0025, Prec: 0.6787, Rec: 0.3932 lr: 0.00070\n",
      "Epoch 27/Step 1110, Loss: -0.20955, Accuracy: 0.99909, F1: 0.0025, Prec: 0.6787, Rec: 0.3932 lr: 0.00070\n",
      "Epoch 27/Step 1120, Loss: -0.22998, Accuracy: 0.99909, F1: 0.0032, Prec: 0.6787, Rec: 0.3931 lr: 0.00070\n",
      "Epoch 27/Step 1130, Loss: -0.22337, Accuracy: 0.99910, F1: 0.0032, Prec: 0.6786, Rec: 0.3933 lr: 0.00070\n",
      "Epoch 27/Step 1140, Loss: -0.24127, Accuracy: 0.99910, F1: 0.0032, Prec: 0.6787, Rec: 0.3934 lr: 0.00070\n",
      "Epoch 27/Step 1150, Loss: -0.26914, Accuracy: 0.99910, F1: 0.0031, Prec: 0.6788, Rec: 0.3934 lr: 0.00070\n",
      "Epoch 27/Step 1160, Loss: -0.21525, Accuracy: 0.99910, F1: 0.0031, Prec: 0.6791, Rec: 0.3938 lr: 0.00070\n",
      "Epoch 27/Step 1170, Loss: -0.21566, Accuracy: 0.99910, F1: 0.0031, Prec: 0.6793, Rec: 0.3936 lr: 0.00070\n",
      "Epoch 27/Step 1180, Loss: -0.20689, Accuracy: 0.99910, F1: 0.0031, Prec: 0.6794, Rec: 0.3935 lr: 0.00070\n",
      "Epoch 27/Step 1190, Loss: -0.27258, Accuracy: 0.99910, F1: 0.0030, Prec: 0.6790, Rec: 0.3934 lr: 0.00070\n",
      "Epoch 27/Step 1200, Loss: -0.23970, Accuracy: 0.99910, F1: 0.0030, Prec: 0.6792, Rec: 0.3938 lr: 0.00070\n",
      "Epoch 27/Step 1210, Loss: -0.25845, Accuracy: 0.99910, F1: 0.0030, Prec: 0.6796, Rec: 0.3939 lr: 0.00070\n",
      "Epoch 27/Step 1220, Loss: -0.27692, Accuracy: 0.99910, F1: 0.0030, Prec: 0.6796, Rec: 0.3938 lr: 0.00070\n",
      "Epoch 27/Step 1230, Loss: -0.25888, Accuracy: 0.99910, F1: 0.0029, Prec: 0.6795, Rec: 0.3938 lr: 0.00070\n",
      "Epoch 27/Step 1240, Loss: -0.28849, Accuracy: 0.99910, F1: 0.0029, Prec: 0.6793, Rec: 0.3938 lr: 0.00070\n",
      "Epoch 27/Step 1250, Loss: -0.19193, Accuracy: 0.99910, F1: 0.0029, Prec: 0.6795, Rec: 0.3939 lr: 0.00070\n",
      "Epoch 27/Step 1260, Loss: -0.27271, Accuracy: 0.99910, F1: 0.0029, Prec: 0.6796, Rec: 0.3940 lr: 0.00070\n",
      "Epoch 27/Step 1270, Loss: -0.23543, Accuracy: 0.99910, F1: 0.0028, Prec: 0.6795, Rec: 0.3942 lr: 0.00070\n",
      "Epoch 27/Step 1280, Loss: -0.31479, Accuracy: 0.99910, F1: 0.0028, Prec: 0.6795, Rec: 0.3941 lr: 0.00070\n",
      "Epoch 27/Step 1290, Loss: -0.25452, Accuracy: 0.99910, F1: 0.0028, Prec: 0.6798, Rec: 0.3942 lr: 0.00070\n",
      "Epoch 27/Step 1300, Loss: -0.23025, Accuracy: 0.99910, F1: 0.0028, Prec: 0.6798, Rec: 0.3942 lr: 0.00070\n",
      "Epoch 27/Step 1310, Loss: -0.26170, Accuracy: 0.99910, F1: 0.0028, Prec: 0.6800, Rec: 0.3942 lr: 0.00070\n",
      "Epoch 27/Step 1320, Loss: -0.27902, Accuracy: 0.99910, F1: 0.0027, Prec: 0.6800, Rec: 0.3944 lr: 0.00070\n",
      "Epoch 27/Step 1330, Loss: -0.27642, Accuracy: 0.99910, F1: 0.0027, Prec: 0.6800, Rec: 0.3944 lr: 0.00070\n",
      "Epoch 27/Step 1340, Loss: -0.25213, Accuracy: 0.99910, F1: 0.0027, Prec: 0.6801, Rec: 0.3945 lr: 0.00070\n",
      "Epoch 27/Step 1350, Loss: -0.20917, Accuracy: 0.99910, F1: 0.0027, Prec: 0.6802, Rec: 0.3945 lr: 0.00070\n",
      "Epoch 27/Step 1360, Loss: -0.22298, Accuracy: 0.99910, F1: 0.0026, Prec: 0.6804, Rec: 0.3945 lr: 0.00070\n",
      "Epoch 27/Step 1370, Loss: -0.24594, Accuracy: 0.99910, F1: 0.0026, Prec: 0.6805, Rec: 0.3947 lr: 0.00070\n",
      "Epoch 27/Step 1380, Loss: -0.25351, Accuracy: 0.99910, F1: 0.0026, Prec: 0.6805, Rec: 0.3948 lr: 0.00070\n",
      "Epoch 27/Step 1390, Loss: -0.24367, Accuracy: 0.99910, F1: 0.0026, Prec: 0.6802, Rec: 0.3948 lr: 0.00070\n",
      "Epoch 27/Step 1400, Loss: -0.26094, Accuracy: 0.99910, F1: 0.0026, Prec: 0.6803, Rec: 0.3949 lr: 0.00070\n",
      "Epoch 27/Step 1410, Loss: -0.23125, Accuracy: 0.99910, F1: 0.0026, Prec: 0.6804, Rec: 0.3949 lr: 0.00070\n",
      "Epoch 27/Step 1420, Loss: -0.23462, Accuracy: 0.99910, F1: 0.0025, Prec: 0.6803, Rec: 0.3947 lr: 0.00070\n",
      "Epoch 27/Step 1430, Loss: -0.24343, Accuracy: 0.99910, F1: 0.0025, Prec: 0.6806, Rec: 0.3946 lr: 0.00070\n",
      "Epoch 27/Step 1440, Loss: -0.24028, Accuracy: 0.99911, F1: 0.0025, Prec: 0.6807, Rec: 0.3946 lr: 0.00070\n",
      "Epoch 27/Step 1450, Loss: -0.25817, Accuracy: 0.99910, F1: 0.0025, Prec: 0.6809, Rec: 0.3948 lr: 0.00070\n",
      "Epoch 27/Step 1460, Loss: -0.23684, Accuracy: 0.99910, F1: 0.0025, Prec: 0.6809, Rec: 0.3947 lr: 0.00070\n",
      "Epoch 27/Step 1470, Loss: -0.24351, Accuracy: 0.99911, F1: 0.0025, Prec: 0.6811, Rec: 0.3947 lr: 0.00070\n",
      "Epoch 27/Step 1480, Loss: -0.23691, Accuracy: 0.99911, F1: 0.0024, Prec: 0.6810, Rec: 0.3947 lr: 0.00070\n",
      "Epoch 27/Step 1490, Loss: -0.23607, Accuracy: 0.99910, F1: 0.0024, Prec: 0.6809, Rec: 0.3946 lr: 0.00070\n",
      "Epoch 27/Step 1500, Loss: -0.26677, Accuracy: 0.99911, F1: 0.0035, Prec: 0.6811, Rec: 0.3947 lr: 0.00070\n",
      "Epoch 27/Step 1510, Loss: -0.22718, Accuracy: 0.99911, F1: 0.0035, Prec: 0.6811, Rec: 0.3947 lr: 0.00070\n",
      "Epoch 27/Step 1520, Loss: -0.28688, Accuracy: 0.99911, F1: 0.0040, Prec: 0.6812, Rec: 0.3948 lr: 0.00070\n",
      "Epoch 27/Step 1530, Loss: -0.23143, Accuracy: 0.99911, F1: 0.0040, Prec: 0.6813, Rec: 0.3949 lr: 0.00070\n",
      "Epoch 27/Step 1540, Loss: -0.21126, Accuracy: 0.99911, F1: 0.0040, Prec: 0.6815, Rec: 0.3946 lr: 0.00070\n",
      "Epoch 27/Step 1550, Loss: -0.24367, Accuracy: 0.99911, F1: 0.0040, Prec: 0.6817, Rec: 0.3946 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9987\n",
      "Validation f1: 0.0102\n",
      "Validation precision: 0.3811\n",
      "Validation recall: 0.2149\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_26_valF1Score0.010/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_26_valF1Score0.010/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 28\n",
      "Epoch 28/Step 0, Loss: -0.27939, Accuracy: 0.99925, F1: 0.0000, Prec: 0.7652, Rec: 0.4510 lr: 0.00070\n",
      "Epoch 28/Step 10, Loss: -0.30049, Accuracy: 0.99907, F1: 0.0000, Prec: 0.7159, Rec: 0.4177 lr: 0.00070\n",
      "Epoch 28/Step 20, Loss: -0.26901, Accuracy: 0.99911, F1: 0.0000, Prec: 0.7105, Rec: 0.4140 lr: 0.00070\n",
      "Epoch 28/Step 30, Loss: -0.23027, Accuracy: 0.99913, F1: 0.0529, Prec: 0.7031, Rec: 0.4127 lr: 0.00070\n",
      "Epoch 28/Step 40, Loss: -0.22047, Accuracy: 0.99912, F1: 0.0400, Prec: 0.7076, Rec: 0.4128 lr: 0.00070\n",
      "Epoch 28/Step 50, Loss: -0.25746, Accuracy: 0.99912, F1: 0.0322, Prec: 0.7058, Rec: 0.4124 lr: 0.00070\n",
      "Epoch 28/Step 60, Loss: -0.26367, Accuracy: 0.99913, F1: 0.0269, Prec: 0.7120, Rec: 0.4112 lr: 0.00070\n",
      "Epoch 28/Step 70, Loss: -0.24560, Accuracy: 0.99915, F1: 0.0231, Prec: 0.7129, Rec: 0.4118 lr: 0.00070\n",
      "Epoch 28/Step 80, Loss: -0.24077, Accuracy: 0.99915, F1: 0.0203, Prec: 0.7070, Rec: 0.4104 lr: 0.00070\n",
      "Epoch 28/Step 90, Loss: -0.22744, Accuracy: 0.99914, F1: 0.0180, Prec: 0.7063, Rec: 0.4091 lr: 0.00070\n",
      "Epoch 28/Step 100, Loss: -0.25959, Accuracy: 0.99915, F1: 0.0267, Prec: 0.7086, Rec: 0.4099 lr: 0.00070\n",
      "Epoch 28/Step 110, Loss: -0.24898, Accuracy: 0.99914, F1: 0.0327, Prec: 0.7088, Rec: 0.4083 lr: 0.00070\n",
      "Epoch 28/Step 120, Loss: -0.23503, Accuracy: 0.99913, F1: 0.0300, Prec: 0.7072, Rec: 0.4068 lr: 0.00070\n",
      "Epoch 28/Step 130, Loss: -0.21004, Accuracy: 0.99913, F1: 0.0277, Prec: 0.7041, Rec: 0.4077 lr: 0.00070\n",
      "Epoch 28/Step 140, Loss: -0.22113, Accuracy: 0.99912, F1: 0.0257, Prec: 0.7021, Rec: 0.4050 lr: 0.00070\n",
      "Epoch 28/Step 150, Loss: -0.23895, Accuracy: 0.99911, F1: 0.0240, Prec: 0.7013, Rec: 0.4027 lr: 0.00070\n",
      "Epoch 28/Step 160, Loss: -0.26177, Accuracy: 0.99911, F1: 0.0225, Prec: 0.6989, Rec: 0.4028 lr: 0.00070\n",
      "Epoch 28/Step 170, Loss: -0.25788, Accuracy: 0.99911, F1: 0.0212, Prec: 0.6988, Rec: 0.4020 lr: 0.00070\n",
      "Epoch 28/Step 180, Loss: -0.29331, Accuracy: 0.99911, F1: 0.0201, Prec: 0.6978, Rec: 0.4030 lr: 0.00070\n",
      "Epoch 28/Step 190, Loss: -0.23175, Accuracy: 0.99911, F1: 0.0190, Prec: 0.6955, Rec: 0.4022 lr: 0.00070\n",
      "Epoch 28/Step 200, Loss: -0.25976, Accuracy: 0.99910, F1: 0.0181, Prec: 0.6964, Rec: 0.4014 lr: 0.00070\n",
      "Epoch 28/Step 210, Loss: -0.22891, Accuracy: 0.99910, F1: 0.0172, Prec: 0.6958, Rec: 0.4011 lr: 0.00070\n",
      "Epoch 28/Step 220, Loss: -0.26654, Accuracy: 0.99910, F1: 0.0164, Prec: 0.6969, Rec: 0.4014 lr: 0.00070\n",
      "Epoch 28/Step 230, Loss: -0.22591, Accuracy: 0.99910, F1: 0.0157, Prec: 0.6961, Rec: 0.4010 lr: 0.00070\n",
      "Epoch 28/Step 240, Loss: -0.29011, Accuracy: 0.99910, F1: 0.0151, Prec: 0.6957, Rec: 0.4008 lr: 0.00070\n",
      "Epoch 28/Step 250, Loss: -0.25700, Accuracy: 0.99910, F1: 0.0145, Prec: 0.6953, Rec: 0.4002 lr: 0.00070\n",
      "Epoch 28/Step 260, Loss: -0.27935, Accuracy: 0.99910, F1: 0.0139, Prec: 0.6955, Rec: 0.4004 lr: 0.00070\n",
      "Epoch 28/Step 270, Loss: -0.27548, Accuracy: 0.99909, F1: 0.0134, Prec: 0.6947, Rec: 0.3998 lr: 0.00070\n",
      "Epoch 28/Step 280, Loss: -0.24268, Accuracy: 0.99909, F1: 0.0129, Prec: 0.6938, Rec: 0.3986 lr: 0.00070\n",
      "Epoch 28/Step 290, Loss: -0.25259, Accuracy: 0.99909, F1: 0.0125, Prec: 0.6928, Rec: 0.3991 lr: 0.00070\n",
      "Epoch 28/Step 300, Loss: -0.28753, Accuracy: 0.99909, F1: 0.0121, Prec: 0.6937, Rec: 0.3989 lr: 0.00070\n",
      "Epoch 28/Step 310, Loss: -0.25571, Accuracy: 0.99909, F1: 0.0117, Prec: 0.6935, Rec: 0.3988 lr: 0.00070\n",
      "Epoch 28/Step 320, Loss: -0.24265, Accuracy: 0.99909, F1: 0.0113, Prec: 0.6940, Rec: 0.3992 lr: 0.00070\n",
      "Epoch 28/Step 330, Loss: -0.25741, Accuracy: 0.99909, F1: 0.0110, Prec: 0.6939, Rec: 0.3992 lr: 0.00070\n",
      "Epoch 28/Step 340, Loss: -0.26178, Accuracy: 0.99909, F1: 0.0106, Prec: 0.6939, Rec: 0.3992 lr: 0.00070\n",
      "Epoch 28/Step 350, Loss: -0.22372, Accuracy: 0.99909, F1: 0.0103, Prec: 0.6950, Rec: 0.3996 lr: 0.00070\n",
      "Epoch 28/Step 360, Loss: -0.25845, Accuracy: 0.99909, F1: 0.0101, Prec: 0.6955, Rec: 0.4002 lr: 0.00070\n",
      "Epoch 28/Step 370, Loss: -0.26085, Accuracy: 0.99910, F1: 0.0098, Prec: 0.6949, Rec: 0.4005 lr: 0.00070\n",
      "Epoch 28/Step 380, Loss: -0.26399, Accuracy: 0.99910, F1: 0.0095, Prec: 0.6944, Rec: 0.4002 lr: 0.00070\n",
      "Epoch 28/Step 390, Loss: -0.22077, Accuracy: 0.99910, F1: 0.0093, Prec: 0.6950, Rec: 0.3995 lr: 0.00070\n",
      "Epoch 28/Step 400, Loss: -0.23061, Accuracy: 0.99910, F1: 0.0091, Prec: 0.6951, Rec: 0.3989 lr: 0.00070\n",
      "Epoch 28/Step 410, Loss: -0.21149, Accuracy: 0.99910, F1: 0.0088, Prec: 0.6950, Rec: 0.3987 lr: 0.00070\n",
      "Epoch 28/Step 420, Loss: -0.26335, Accuracy: 0.99910, F1: 0.0086, Prec: 0.6955, Rec: 0.3989 lr: 0.00070\n",
      "Epoch 28/Step 430, Loss: -0.24619, Accuracy: 0.99910, F1: 0.0084, Prec: 0.6948, Rec: 0.3993 lr: 0.00070\n",
      "Epoch 28/Step 440, Loss: -0.27233, Accuracy: 0.99910, F1: 0.0082, Prec: 0.6945, Rec: 0.3992 lr: 0.00070\n",
      "Epoch 28/Step 450, Loss: -0.26020, Accuracy: 0.99910, F1: 0.0080, Prec: 0.6952, Rec: 0.3989 lr: 0.00070\n",
      "Epoch 28/Step 460, Loss: -0.24448, Accuracy: 0.99910, F1: 0.0079, Prec: 0.6948, Rec: 0.3986 lr: 0.00070\n",
      "Epoch 28/Step 470, Loss: -0.23044, Accuracy: 0.99910, F1: 0.0077, Prec: 0.6949, Rec: 0.3981 lr: 0.00070\n",
      "Epoch 28/Step 480, Loss: -0.23884, Accuracy: 0.99910, F1: 0.0075, Prec: 0.6936, Rec: 0.3973 lr: 0.00070\n",
      "Epoch 28/Step 490, Loss: -0.22801, Accuracy: 0.99910, F1: 0.0074, Prec: 0.6931, Rec: 0.3971 lr: 0.00070\n",
      "Epoch 28/Step 500, Loss: -0.24669, Accuracy: 0.99910, F1: 0.0072, Prec: 0.6933, Rec: 0.3970 lr: 0.00070\n",
      "Epoch 28/Step 510, Loss: -0.29837, Accuracy: 0.99910, F1: 0.0071, Prec: 0.6931, Rec: 0.3971 lr: 0.00070\n",
      "Epoch 28/Step 520, Loss: -0.22778, Accuracy: 0.99910, F1: 0.0070, Prec: 0.6934, Rec: 0.3971 lr: 0.00070\n",
      "Epoch 28/Step 530, Loss: -0.24016, Accuracy: 0.99910, F1: 0.0068, Prec: 0.6921, Rec: 0.3966 lr: 0.00070\n",
      "Epoch 28/Step 540, Loss: -0.24837, Accuracy: 0.99909, F1: 0.0067, Prec: 0.6912, Rec: 0.3967 lr: 0.00070\n",
      "Epoch 28/Step 550, Loss: -0.28216, Accuracy: 0.99909, F1: 0.0066, Prec: 0.6908, Rec: 0.3967 lr: 0.00070\n",
      "Epoch 28/Step 560, Loss: -0.23240, Accuracy: 0.99909, F1: 0.0065, Prec: 0.6907, Rec: 0.3965 lr: 0.00070\n",
      "Epoch 28/Step 570, Loss: -0.25718, Accuracy: 0.99909, F1: 0.0064, Prec: 0.6903, Rec: 0.3963 lr: 0.00070\n",
      "Epoch 28/Step 580, Loss: -0.21153, Accuracy: 0.99909, F1: 0.0062, Prec: 0.6900, Rec: 0.3962 lr: 0.00070\n",
      "Epoch 28/Step 590, Loss: -0.19539, Accuracy: 0.99909, F1: 0.0061, Prec: 0.6898, Rec: 0.3958 lr: 0.00070\n",
      "Epoch 28/Step 600, Loss: -0.24259, Accuracy: 0.99909, F1: 0.0060, Prec: 0.6900, Rec: 0.3956 lr: 0.00070\n",
      "Epoch 28/Step 610, Loss: -0.30466, Accuracy: 0.99909, F1: 0.0059, Prec: 0.6900, Rec: 0.3958 lr: 0.00070\n",
      "Epoch 28/Step 620, Loss: -0.26086, Accuracy: 0.99909, F1: 0.0058, Prec: 0.6902, Rec: 0.3960 lr: 0.00070\n",
      "Epoch 28/Step 630, Loss: -0.22218, Accuracy: 0.99909, F1: 0.0058, Prec: 0.6898, Rec: 0.3958 lr: 0.00070\n",
      "Epoch 28/Step 640, Loss: -0.23236, Accuracy: 0.99909, F1: 0.0057, Prec: 0.6894, Rec: 0.3959 lr: 0.00070\n",
      "Epoch 28/Step 650, Loss: -0.21521, Accuracy: 0.99909, F1: 0.0056, Prec: 0.6892, Rec: 0.3959 lr: 0.00070\n",
      "Epoch 28/Step 660, Loss: -0.26092, Accuracy: 0.99909, F1: 0.0055, Prec: 0.6892, Rec: 0.3959 lr: 0.00070\n",
      "Epoch 28/Step 670, Loss: -0.26812, Accuracy: 0.99909, F1: 0.0054, Prec: 0.6894, Rec: 0.3959 lr: 0.00070\n",
      "Epoch 28/Step 680, Loss: -0.21293, Accuracy: 0.99909, F1: 0.0053, Prec: 0.6897, Rec: 0.3960 lr: 0.00070\n",
      "Epoch 28/Step 690, Loss: -0.27188, Accuracy: 0.99909, F1: 0.0053, Prec: 0.6895, Rec: 0.3961 lr: 0.00070\n",
      "Epoch 28/Step 700, Loss: -0.26114, Accuracy: 0.99909, F1: 0.0052, Prec: 0.6895, Rec: 0.3960 lr: 0.00070\n",
      "Epoch 28/Step 710, Loss: -0.25636, Accuracy: 0.99909, F1: 0.0051, Prec: 0.6900, Rec: 0.3964 lr: 0.00070\n",
      "Epoch 28/Step 720, Loss: -0.26576, Accuracy: 0.99909, F1: 0.0050, Prec: 0.6900, Rec: 0.3961 lr: 0.00070\n",
      "Epoch 28/Step 730, Loss: -0.23020, Accuracy: 0.99909, F1: 0.0050, Prec: 0.6898, Rec: 0.3960 lr: 0.00070\n",
      "Epoch 28/Step 740, Loss: -0.25058, Accuracy: 0.99909, F1: 0.0049, Prec: 0.6898, Rec: 0.3959 lr: 0.00070\n",
      "Epoch 28/Step 750, Loss: -0.27075, Accuracy: 0.99909, F1: 0.0048, Prec: 0.6898, Rec: 0.3958 lr: 0.00070\n",
      "Epoch 28/Step 760, Loss: -0.26036, Accuracy: 0.99909, F1: 0.0048, Prec: 0.6901, Rec: 0.3955 lr: 0.00070\n",
      "Epoch 28/Step 770, Loss: -0.26876, Accuracy: 0.99910, F1: 0.0047, Prec: 0.6900, Rec: 0.3955 lr: 0.00070\n",
      "Epoch 28/Step 780, Loss: -0.20144, Accuracy: 0.99910, F1: 0.0046, Prec: 0.6904, Rec: 0.3955 lr: 0.00070\n",
      "Epoch 28/Step 790, Loss: -0.27343, Accuracy: 0.99909, F1: 0.0046, Prec: 0.6906, Rec: 0.3951 lr: 0.00070\n",
      "Epoch 28/Step 800, Loss: -0.24288, Accuracy: 0.99909, F1: 0.0045, Prec: 0.6906, Rec: 0.3951 lr: 0.00070\n",
      "Epoch 28/Step 810, Loss: -0.17177, Accuracy: 0.99910, F1: 0.0045, Prec: 0.6906, Rec: 0.3952 lr: 0.00070\n",
      "Epoch 28/Step 820, Loss: -0.23728, Accuracy: 0.99910, F1: 0.0044, Prec: 0.6905, Rec: 0.3950 lr: 0.00070\n",
      "Epoch 28/Step 830, Loss: -0.26714, Accuracy: 0.99910, F1: 0.0044, Prec: 0.6907, Rec: 0.3951 lr: 0.00070\n",
      "Epoch 28/Step 840, Loss: -0.28680, Accuracy: 0.99910, F1: 0.0043, Prec: 0.6908, Rec: 0.3953 lr: 0.00070\n",
      "Epoch 28/Step 850, Loss: -0.25197, Accuracy: 0.99910, F1: 0.0043, Prec: 0.6902, Rec: 0.3952 lr: 0.00070\n",
      "Epoch 28/Step 860, Loss: -0.24852, Accuracy: 0.99910, F1: 0.0042, Prec: 0.6905, Rec: 0.3951 lr: 0.00070\n",
      "Epoch 28/Step 870, Loss: -0.24428, Accuracy: 0.99910, F1: 0.0042, Prec: 0.6902, Rec: 0.3949 lr: 0.00070\n",
      "Epoch 28/Step 880, Loss: -0.21593, Accuracy: 0.99910, F1: 0.0041, Prec: 0.6899, Rec: 0.3950 lr: 0.00070\n",
      "Epoch 28/Step 890, Loss: -0.23270, Accuracy: 0.99910, F1: 0.0041, Prec: 0.6899, Rec: 0.3948 lr: 0.00070\n",
      "Epoch 28/Step 900, Loss: -0.30027, Accuracy: 0.99910, F1: 0.0040, Prec: 0.6902, Rec: 0.3947 lr: 0.00070\n",
      "Epoch 28/Step 910, Loss: -0.20644, Accuracy: 0.99910, F1: 0.0040, Prec: 0.6900, Rec: 0.3944 lr: 0.00070\n",
      "Epoch 28/Step 920, Loss: -0.24877, Accuracy: 0.99910, F1: 0.0039, Prec: 0.6898, Rec: 0.3942 lr: 0.00070\n",
      "Epoch 28/Step 930, Loss: -0.23102, Accuracy: 0.99910, F1: 0.0039, Prec: 0.6899, Rec: 0.3943 lr: 0.00070\n",
      "Epoch 28/Step 940, Loss: -0.23740, Accuracy: 0.99910, F1: 0.0039, Prec: 0.6899, Rec: 0.3943 lr: 0.00070\n",
      "Epoch 28/Step 950, Loss: -0.24918, Accuracy: 0.99910, F1: 0.0038, Prec: 0.6898, Rec: 0.3944 lr: 0.00070\n",
      "Epoch 28/Step 960, Loss: -0.27330, Accuracy: 0.99910, F1: 0.0038, Prec: 0.6895, Rec: 0.3944 lr: 0.00070\n",
      "Epoch 28/Step 970, Loss: -0.22168, Accuracy: 0.99910, F1: 0.0037, Prec: 0.6893, Rec: 0.3940 lr: 0.00070\n",
      "Epoch 28/Step 980, Loss: -0.25326, Accuracy: 0.99910, F1: 0.0037, Prec: 0.6894, Rec: 0.3938 lr: 0.00070\n",
      "Epoch 28/Step 990, Loss: -0.23305, Accuracy: 0.99910, F1: 0.0037, Prec: 0.6888, Rec: 0.3937 lr: 0.00070\n",
      "Epoch 28/Step 1000, Loss: -0.24123, Accuracy: 0.99910, F1: 0.0036, Prec: 0.6887, Rec: 0.3940 lr: 0.00070\n",
      "Epoch 28/Step 1010, Loss: -0.25984, Accuracy: 0.99910, F1: 0.0036, Prec: 0.6889, Rec: 0.3942 lr: 0.00070\n",
      "Epoch 28/Step 1020, Loss: -0.20659, Accuracy: 0.99910, F1: 0.0036, Prec: 0.6888, Rec: 0.3942 lr: 0.00070\n",
      "Epoch 28/Step 1030, Loss: -0.25431, Accuracy: 0.99910, F1: 0.0035, Prec: 0.6887, Rec: 0.3941 lr: 0.00070\n",
      "Epoch 28/Step 1040, Loss: -0.24548, Accuracy: 0.99910, F1: 0.0035, Prec: 0.6885, Rec: 0.3942 lr: 0.00070\n",
      "Epoch 28/Step 1050, Loss: -0.27819, Accuracy: 0.99910, F1: 0.0035, Prec: 0.6886, Rec: 0.3942 lr: 0.00070\n",
      "Epoch 28/Step 1060, Loss: -0.27124, Accuracy: 0.99910, F1: 0.0034, Prec: 0.6887, Rec: 0.3945 lr: 0.00070\n",
      "Epoch 28/Step 1070, Loss: -0.25145, Accuracy: 0.99910, F1: 0.0034, Prec: 0.6886, Rec: 0.3945 lr: 0.00070\n",
      "Epoch 28/Step 1080, Loss: -0.23365, Accuracy: 0.99910, F1: 0.0034, Prec: 0.6887, Rec: 0.3945 lr: 0.00070\n",
      "Epoch 28/Step 1090, Loss: -0.25089, Accuracy: 0.99910, F1: 0.0033, Prec: 0.6887, Rec: 0.3944 lr: 0.00070\n",
      "Epoch 28/Step 1100, Loss: -0.26161, Accuracy: 0.99910, F1: 0.0033, Prec: 0.6890, Rec: 0.3944 lr: 0.00070\n",
      "Epoch 28/Step 1110, Loss: -0.21052, Accuracy: 0.99910, F1: 0.0033, Prec: 0.6886, Rec: 0.3945 lr: 0.00070\n",
      "Epoch 28/Step 1120, Loss: -0.23373, Accuracy: 0.99910, F1: 0.0032, Prec: 0.6883, Rec: 0.3945 lr: 0.00070\n",
      "Epoch 28/Step 1130, Loss: -0.22125, Accuracy: 0.99910, F1: 0.0032, Prec: 0.6884, Rec: 0.3946 lr: 0.00070\n",
      "Epoch 28/Step 1140, Loss: -0.25407, Accuracy: 0.99911, F1: 0.0032, Prec: 0.6884, Rec: 0.3947 lr: 0.00070\n",
      "Epoch 28/Step 1150, Loss: -0.27450, Accuracy: 0.99911, F1: 0.0032, Prec: 0.6886, Rec: 0.3947 lr: 0.00070\n",
      "Epoch 28/Step 1160, Loss: -0.21672, Accuracy: 0.99911, F1: 0.0031, Prec: 0.6889, Rec: 0.3950 lr: 0.00070\n",
      "Epoch 28/Step 1170, Loss: -0.21874, Accuracy: 0.99911, F1: 0.0031, Prec: 0.6890, Rec: 0.3949 lr: 0.00070\n",
      "Epoch 28/Step 1180, Loss: -0.20420, Accuracy: 0.99911, F1: 0.0031, Prec: 0.6892, Rec: 0.3947 lr: 0.00070\n",
      "Epoch 28/Step 1190, Loss: -0.26478, Accuracy: 0.99911, F1: 0.0030, Prec: 0.6889, Rec: 0.3946 lr: 0.00070\n",
      "Epoch 28/Step 1200, Loss: -0.22901, Accuracy: 0.99911, F1: 0.0030, Prec: 0.6891, Rec: 0.3949 lr: 0.00070\n",
      "Epoch 28/Step 1210, Loss: -0.26536, Accuracy: 0.99911, F1: 0.0030, Prec: 0.6895, Rec: 0.3950 lr: 0.00070\n",
      "Epoch 28/Step 1220, Loss: -0.27490, Accuracy: 0.99911, F1: 0.0030, Prec: 0.6895, Rec: 0.3950 lr: 0.00070\n",
      "Epoch 28/Step 1230, Loss: -0.25654, Accuracy: 0.99911, F1: 0.0029, Prec: 0.6894, Rec: 0.3950 lr: 0.00070\n",
      "Epoch 28/Step 1240, Loss: -0.28723, Accuracy: 0.99911, F1: 0.0029, Prec: 0.6893, Rec: 0.3950 lr: 0.00070\n",
      "Epoch 28/Step 1250, Loss: -0.19093, Accuracy: 0.99911, F1: 0.0029, Prec: 0.6892, Rec: 0.3951 lr: 0.00070\n",
      "Epoch 28/Step 1260, Loss: -0.27201, Accuracy: 0.99911, F1: 0.0029, Prec: 0.6892, Rec: 0.3952 lr: 0.00070\n",
      "Epoch 28/Step 1270, Loss: -0.23848, Accuracy: 0.99911, F1: 0.0029, Prec: 0.6892, Rec: 0.3954 lr: 0.00070\n",
      "Epoch 28/Step 1280, Loss: -0.31261, Accuracy: 0.99911, F1: 0.0028, Prec: 0.6892, Rec: 0.3954 lr: 0.00070\n",
      "Epoch 28/Step 1290, Loss: -0.25997, Accuracy: 0.99911, F1: 0.0028, Prec: 0.6896, Rec: 0.3954 lr: 0.00070\n",
      "Epoch 28/Step 1300, Loss: -0.23176, Accuracy: 0.99911, F1: 0.0028, Prec: 0.6895, Rec: 0.3954 lr: 0.00070\n",
      "Epoch 28/Step 1310, Loss: -0.25254, Accuracy: 0.99911, F1: 0.0028, Prec: 0.6896, Rec: 0.3955 lr: 0.00070\n",
      "Epoch 28/Step 1320, Loss: -0.28381, Accuracy: 0.99911, F1: 0.0027, Prec: 0.6898, Rec: 0.3956 lr: 0.00070\n",
      "Epoch 28/Step 1330, Loss: -0.28416, Accuracy: 0.99911, F1: 0.0027, Prec: 0.6898, Rec: 0.3955 lr: 0.00070\n",
      "Epoch 28/Step 1340, Loss: -0.25044, Accuracy: 0.99911, F1: 0.0027, Prec: 0.6899, Rec: 0.3958 lr: 0.00070\n",
      "Epoch 28/Step 1350, Loss: -0.21002, Accuracy: 0.99911, F1: 0.0027, Prec: 0.6899, Rec: 0.3958 lr: 0.00070\n",
      "Epoch 28/Step 1360, Loss: -0.22845, Accuracy: 0.99911, F1: 0.0027, Prec: 0.6901, Rec: 0.3958 lr: 0.00070\n",
      "Epoch 28/Step 1370, Loss: -0.24711, Accuracy: 0.99911, F1: 0.0026, Prec: 0.6902, Rec: 0.3960 lr: 0.00070\n",
      "Epoch 28/Step 1380, Loss: -0.25827, Accuracy: 0.99911, F1: 0.0026, Prec: 0.6901, Rec: 0.3961 lr: 0.00070\n",
      "Epoch 28/Step 1390, Loss: -0.25255, Accuracy: 0.99911, F1: 0.0026, Prec: 0.6899, Rec: 0.3961 lr: 0.00070\n",
      "Epoch 28/Step 1400, Loss: -0.26387, Accuracy: 0.99911, F1: 0.0026, Prec: 0.6900, Rec: 0.3962 lr: 0.00070\n",
      "Epoch 28/Step 1410, Loss: -0.23386, Accuracy: 0.99911, F1: 0.0026, Prec: 0.6901, Rec: 0.3961 lr: 0.00070\n",
      "Epoch 28/Step 1420, Loss: -0.23781, Accuracy: 0.99911, F1: 0.0026, Prec: 0.6901, Rec: 0.3960 lr: 0.00070\n",
      "Epoch 28/Step 1430, Loss: -0.24953, Accuracy: 0.99911, F1: 0.0025, Prec: 0.6902, Rec: 0.3959 lr: 0.00070\n",
      "Epoch 28/Step 1440, Loss: -0.24963, Accuracy: 0.99911, F1: 0.0025, Prec: 0.6904, Rec: 0.3960 lr: 0.00070\n",
      "Epoch 28/Step 1450, Loss: -0.26001, Accuracy: 0.99911, F1: 0.0025, Prec: 0.6904, Rec: 0.3961 lr: 0.00070\n",
      "Epoch 28/Step 1460, Loss: -0.22937, Accuracy: 0.99911, F1: 0.0025, Prec: 0.6904, Rec: 0.3961 lr: 0.00070\n",
      "Epoch 28/Step 1470, Loss: -0.24782, Accuracy: 0.99912, F1: 0.0025, Prec: 0.6905, Rec: 0.3960 lr: 0.00070\n",
      "Epoch 28/Step 1480, Loss: -0.24440, Accuracy: 0.99911, F1: 0.0025, Prec: 0.6905, Rec: 0.3961 lr: 0.00070\n",
      "Epoch 28/Step 1490, Loss: -0.23967, Accuracy: 0.99911, F1: 0.0024, Prec: 0.6902, Rec: 0.3960 lr: 0.00070\n",
      "Epoch 28/Step 1500, Loss: -0.26801, Accuracy: 0.99912, F1: 0.0024, Prec: 0.6904, Rec: 0.3961 lr: 0.00070\n",
      "Epoch 28/Step 1510, Loss: -0.23081, Accuracy: 0.99912, F1: 0.0024, Prec: 0.6906, Rec: 0.3961 lr: 0.00070\n",
      "Epoch 28/Step 1520, Loss: -0.29437, Accuracy: 0.99912, F1: 0.0024, Prec: 0.6907, Rec: 0.3962 lr: 0.00070\n",
      "Epoch 28/Step 1530, Loss: -0.23143, Accuracy: 0.99912, F1: 0.0024, Prec: 0.6907, Rec: 0.3963 lr: 0.00070\n",
      "Epoch 28/Step 1540, Loss: -0.21354, Accuracy: 0.99912, F1: 0.0024, Prec: 0.6908, Rec: 0.3960 lr: 0.00070\n",
      "Epoch 28/Step 1550, Loss: -0.24682, Accuracy: 0.99912, F1: 0.0023, Prec: 0.6910, Rec: 0.3960 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9987\n",
      "Validation f1: 0.0000\n",
      "Validation precision: 0.3804\n",
      "Validation recall: 0.2120\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_27_valF1Score0.000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_27_valF1Score0.000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 29\n",
      "Epoch 29/Step 0, Loss: -0.28044, Accuracy: 0.99924, F1: 0.0000, Prec: 0.7467, Rec: 0.4578 lr: 0.00070\n",
      "Epoch 29/Step 10, Loss: -0.30278, Accuracy: 0.99905, F1: 0.0000, Prec: 0.6941, Rec: 0.4218 lr: 0.00070\n",
      "Epoch 29/Step 20, Loss: -0.27008, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6959, Rec: 0.4142 lr: 0.00070\n",
      "Epoch 29/Step 30, Loss: -0.22696, Accuracy: 0.99913, F1: 0.0308, Prec: 0.7048, Rec: 0.4104 lr: 0.00070\n",
      "Epoch 29/Step 40, Loss: -0.22757, Accuracy: 0.99913, F1: 0.0233, Prec: 0.7122, Rec: 0.4106 lr: 0.00070\n",
      "Epoch 29/Step 50, Loss: -0.25491, Accuracy: 0.99913, F1: 0.0188, Prec: 0.7077, Rec: 0.4112 lr: 0.00070\n",
      "Epoch 29/Step 60, Loss: -0.27031, Accuracy: 0.99913, F1: 0.0157, Prec: 0.7123, Rec: 0.4118 lr: 0.00070\n",
      "Epoch 29/Step 70, Loss: -0.25322, Accuracy: 0.99915, F1: 0.0135, Prec: 0.7152, Rec: 0.4128 lr: 0.00070\n",
      "Epoch 29/Step 80, Loss: -0.24521, Accuracy: 0.99915, F1: 0.0118, Prec: 0.7133, Rec: 0.4108 lr: 0.00070\n",
      "Epoch 29/Step 90, Loss: -0.23022, Accuracy: 0.99915, F1: 0.0105, Prec: 0.7103, Rec: 0.4107 lr: 0.00070\n",
      "Epoch 29/Step 100, Loss: -0.26161, Accuracy: 0.99915, F1: 0.0095, Prec: 0.7113, Rec: 0.4121 lr: 0.00070\n",
      "Epoch 29/Step 110, Loss: -0.25802, Accuracy: 0.99914, F1: 0.0086, Prec: 0.7121, Rec: 0.4105 lr: 0.00070\n",
      "Epoch 29/Step 120, Loss: -0.23834, Accuracy: 0.99914, F1: 0.0079, Prec: 0.7092, Rec: 0.4095 lr: 0.00070\n",
      "Epoch 29/Step 130, Loss: -0.21353, Accuracy: 0.99914, F1: 0.0073, Prec: 0.7070, Rec: 0.4101 lr: 0.00070\n",
      "Epoch 29/Step 140, Loss: -0.21601, Accuracy: 0.99913, F1: 0.0068, Prec: 0.7053, Rec: 0.4066 lr: 0.00070\n",
      "Epoch 29/Step 150, Loss: -0.23695, Accuracy: 0.99912, F1: 0.0063, Prec: 0.7047, Rec: 0.4040 lr: 0.00070\n",
      "Epoch 29/Step 160, Loss: -0.26588, Accuracy: 0.99912, F1: 0.0059, Prec: 0.7031, Rec: 0.4042 lr: 0.00070\n",
      "Epoch 29/Step 170, Loss: -0.26739, Accuracy: 0.99912, F1: 0.0056, Prec: 0.7016, Rec: 0.4038 lr: 0.00070\n",
      "Epoch 29/Step 180, Loss: -0.29864, Accuracy: 0.99912, F1: 0.0053, Prec: 0.7016, Rec: 0.4048 lr: 0.00070\n",
      "Epoch 29/Step 190, Loss: -0.24358, Accuracy: 0.99912, F1: 0.0050, Prec: 0.7007, Rec: 0.4038 lr: 0.00070\n",
      "Epoch 29/Step 200, Loss: -0.26392, Accuracy: 0.99911, F1: 0.0048, Prec: 0.7003, Rec: 0.4036 lr: 0.00070\n",
      "Epoch 29/Step 210, Loss: -0.22338, Accuracy: 0.99911, F1: 0.0045, Prec: 0.7010, Rec: 0.4032 lr: 0.00070\n",
      "Epoch 29/Step 220, Loss: -0.26077, Accuracy: 0.99911, F1: 0.0043, Prec: 0.7018, Rec: 0.4036 lr: 0.00070\n",
      "Epoch 29/Step 230, Loss: -0.22303, Accuracy: 0.99911, F1: 0.0041, Prec: 0.7008, Rec: 0.4034 lr: 0.00070\n",
      "Epoch 29/Step 240, Loss: -0.29055, Accuracy: 0.99910, F1: 0.0040, Prec: 0.6996, Rec: 0.4038 lr: 0.00070\n",
      "Epoch 29/Step 250, Loss: -0.26048, Accuracy: 0.99910, F1: 0.0038, Prec: 0.6993, Rec: 0.4031 lr: 0.00070\n",
      "Epoch 29/Step 260, Loss: -0.27909, Accuracy: 0.99910, F1: 0.0037, Prec: 0.6997, Rec: 0.4032 lr: 0.00070\n",
      "Epoch 29/Step 270, Loss: -0.27476, Accuracy: 0.99910, F1: 0.0035, Prec: 0.6996, Rec: 0.4025 lr: 0.00070\n",
      "Epoch 29/Step 280, Loss: -0.25271, Accuracy: 0.99910, F1: 0.0034, Prec: 0.6993, Rec: 0.4013 lr: 0.00070\n",
      "Epoch 29/Step 290, Loss: -0.25049, Accuracy: 0.99910, F1: 0.0033, Prec: 0.6988, Rec: 0.4014 lr: 0.00070\n",
      "Epoch 29/Step 300, Loss: -0.28342, Accuracy: 0.99910, F1: 0.0032, Prec: 0.6996, Rec: 0.4014 lr: 0.00070\n",
      "Epoch 29/Step 310, Loss: -0.25953, Accuracy: 0.99910, F1: 0.0031, Prec: 0.6997, Rec: 0.4012 lr: 0.00070\n",
      "Epoch 29/Step 320, Loss: -0.24244, Accuracy: 0.99910, F1: 0.0030, Prec: 0.7000, Rec: 0.4015 lr: 0.00070\n",
      "Epoch 29/Step 330, Loss: -0.26247, Accuracy: 0.99910, F1: 0.0029, Prec: 0.6996, Rec: 0.4016 lr: 0.00070\n",
      "Epoch 29/Step 340, Loss: -0.25779, Accuracy: 0.99910, F1: 0.0028, Prec: 0.7000, Rec: 0.4014 lr: 0.00070\n",
      "Epoch 29/Step 350, Loss: -0.22553, Accuracy: 0.99910, F1: 0.0027, Prec: 0.7016, Rec: 0.4016 lr: 0.00070\n",
      "Epoch 29/Step 360, Loss: -0.25569, Accuracy: 0.99910, F1: 0.0026, Prec: 0.7018, Rec: 0.4022 lr: 0.00070\n",
      "Epoch 29/Step 370, Loss: -0.26912, Accuracy: 0.99910, F1: 0.0026, Prec: 0.7017, Rec: 0.4023 lr: 0.00070\n",
      "Epoch 29/Step 380, Loss: -0.26254, Accuracy: 0.99910, F1: 0.0025, Prec: 0.7007, Rec: 0.4022 lr: 0.00070\n",
      "Epoch 29/Step 390, Loss: -0.22250, Accuracy: 0.99911, F1: 0.0024, Prec: 0.7008, Rec: 0.4018 lr: 0.00070\n",
      "Epoch 29/Step 400, Loss: -0.23080, Accuracy: 0.99911, F1: 0.0024, Prec: 0.7009, Rec: 0.4010 lr: 0.00070\n",
      "Epoch 29/Step 410, Loss: -0.21558, Accuracy: 0.99911, F1: 0.0023, Prec: 0.7006, Rec: 0.4009 lr: 0.00070\n",
      "Epoch 29/Step 420, Loss: -0.26530, Accuracy: 0.99911, F1: 0.0023, Prec: 0.7001, Rec: 0.4013 lr: 0.00070\n",
      "Epoch 29/Step 430, Loss: -0.24976, Accuracy: 0.99911, F1: 0.0022, Prec: 0.6994, Rec: 0.4016 lr: 0.00070\n",
      "Epoch 29/Step 440, Loss: -0.27067, Accuracy: 0.99910, F1: 0.0022, Prec: 0.6990, Rec: 0.4014 lr: 0.00070\n",
      "Epoch 29/Step 450, Loss: -0.26011, Accuracy: 0.99910, F1: 0.0021, Prec: 0.6990, Rec: 0.4013 lr: 0.00070\n",
      "Epoch 29/Step 460, Loss: -0.24125, Accuracy: 0.99910, F1: 0.0021, Prec: 0.6987, Rec: 0.4011 lr: 0.00070\n",
      "Epoch 29/Step 470, Loss: -0.23561, Accuracy: 0.99911, F1: 0.0020, Prec: 0.6985, Rec: 0.4008 lr: 0.00070\n",
      "Epoch 29/Step 480, Loss: -0.24327, Accuracy: 0.99910, F1: 0.0020, Prec: 0.6971, Rec: 0.3999 lr: 0.00070\n",
      "Epoch 29/Step 490, Loss: -0.22228, Accuracy: 0.99910, F1: 0.0019, Prec: 0.6963, Rec: 0.3996 lr: 0.00070\n",
      "Epoch 29/Step 500, Loss: -0.25053, Accuracy: 0.99910, F1: 0.0019, Prec: 0.6966, Rec: 0.3995 lr: 0.00070\n",
      "Epoch 29/Step 510, Loss: -0.29989, Accuracy: 0.99910, F1: 0.0019, Prec: 0.6965, Rec: 0.3996 lr: 0.00070\n",
      "Epoch 29/Step 520, Loss: -0.23415, Accuracy: 0.99910, F1: 0.0018, Prec: 0.6966, Rec: 0.3996 lr: 0.00070\n",
      "Epoch 29/Step 530, Loss: -0.25092, Accuracy: 0.99910, F1: 0.0018, Prec: 0.6953, Rec: 0.3992 lr: 0.00070\n",
      "Epoch 29/Step 540, Loss: -0.24182, Accuracy: 0.99910, F1: 0.0018, Prec: 0.6948, Rec: 0.3991 lr: 0.00070\n",
      "Epoch 29/Step 550, Loss: -0.28169, Accuracy: 0.99910, F1: 0.0017, Prec: 0.6948, Rec: 0.3990 lr: 0.00070\n",
      "Epoch 29/Step 560, Loss: -0.23594, Accuracy: 0.99910, F1: 0.0017, Prec: 0.6945, Rec: 0.3987 lr: 0.00070\n",
      "Epoch 29/Step 570, Loss: -0.25969, Accuracy: 0.99910, F1: 0.0017, Prec: 0.6941, Rec: 0.3986 lr: 0.00070\n",
      "Epoch 29/Step 580, Loss: -0.21151, Accuracy: 0.99910, F1: 0.0016, Prec: 0.6937, Rec: 0.3984 lr: 0.00070\n",
      "Epoch 29/Step 590, Loss: -0.18752, Accuracy: 0.99910, F1: 0.0016, Prec: 0.6932, Rec: 0.3981 lr: 0.00070\n",
      "Epoch 29/Step 600, Loss: -0.24042, Accuracy: 0.99910, F1: 0.0016, Prec: 0.6935, Rec: 0.3978 lr: 0.00070\n",
      "Epoch 29/Step 610, Loss: -0.29422, Accuracy: 0.99909, F1: 0.0016, Prec: 0.6934, Rec: 0.3979 lr: 0.00070\n",
      "Epoch 29/Step 620, Loss: -0.26732, Accuracy: 0.99909, F1: 0.0015, Prec: 0.6927, Rec: 0.3985 lr: 0.00070\n",
      "Epoch 29/Step 630, Loss: -0.22159, Accuracy: 0.99909, F1: 0.0015, Prec: 0.6924, Rec: 0.3982 lr: 0.00070\n",
      "Epoch 29/Step 640, Loss: -0.23699, Accuracy: 0.99909, F1: 0.0015, Prec: 0.6924, Rec: 0.3982 lr: 0.00070\n",
      "Epoch 29/Step 650, Loss: -0.22153, Accuracy: 0.99909, F1: 0.0015, Prec: 0.6923, Rec: 0.3982 lr: 0.00070\n",
      "Epoch 29/Step 660, Loss: -0.26605, Accuracy: 0.99909, F1: 0.0014, Prec: 0.6918, Rec: 0.3984 lr: 0.00070\n",
      "Epoch 29/Step 670, Loss: -0.27282, Accuracy: 0.99909, F1: 0.0014, Prec: 0.6923, Rec: 0.3983 lr: 0.00070\n",
      "Epoch 29/Step 680, Loss: -0.21574, Accuracy: 0.99910, F1: 0.0014, Prec: 0.6928, Rec: 0.3983 lr: 0.00070\n",
      "Epoch 29/Step 690, Loss: -0.27273, Accuracy: 0.99909, F1: 0.0014, Prec: 0.6922, Rec: 0.3983 lr: 0.00070\n",
      "Epoch 29/Step 700, Loss: -0.25780, Accuracy: 0.99910, F1: 0.0014, Prec: 0.6921, Rec: 0.3981 lr: 0.00070\n",
      "Epoch 29/Step 710, Loss: -0.25471, Accuracy: 0.99910, F1: 0.0013, Prec: 0.6929, Rec: 0.3984 lr: 0.00070\n",
      "Epoch 29/Step 720, Loss: -0.26091, Accuracy: 0.99910, F1: 0.0013, Prec: 0.6928, Rec: 0.3981 lr: 0.00070\n",
      "Epoch 29/Step 730, Loss: -0.23722, Accuracy: 0.99910, F1: 0.0013, Prec: 0.6923, Rec: 0.3980 lr: 0.00070\n",
      "Epoch 29/Step 740, Loss: -0.25346, Accuracy: 0.99910, F1: 0.0013, Prec: 0.6922, Rec: 0.3979 lr: 0.00070\n",
      "Epoch 29/Step 750, Loss: -0.25454, Accuracy: 0.99910, F1: 0.0013, Prec: 0.6921, Rec: 0.3979 lr: 0.00070\n",
      "Epoch 29/Step 760, Loss: -0.25899, Accuracy: 0.99910, F1: 0.0013, Prec: 0.6922, Rec: 0.3975 lr: 0.00070\n",
      "Epoch 29/Step 770, Loss: -0.27023, Accuracy: 0.99910, F1: 0.0012, Prec: 0.6921, Rec: 0.3975 lr: 0.00070\n",
      "Epoch 29/Step 780, Loss: -0.20145, Accuracy: 0.99910, F1: 0.0012, Prec: 0.6921, Rec: 0.3976 lr: 0.00070\n",
      "Epoch 29/Step 790, Loss: -0.26661, Accuracy: 0.99910, F1: 0.0012, Prec: 0.6920, Rec: 0.3973 lr: 0.00070\n",
      "Epoch 29/Step 800, Loss: -0.23925, Accuracy: 0.99910, F1: 0.0012, Prec: 0.6926, Rec: 0.3971 lr: 0.00070\n",
      "Epoch 29/Step 810, Loss: -0.18341, Accuracy: 0.99910, F1: 0.0012, Prec: 0.6924, Rec: 0.3972 lr: 0.00070\n",
      "Epoch 29/Step 820, Loss: -0.23402, Accuracy: 0.99910, F1: 0.0012, Prec: 0.6923, Rec: 0.3970 lr: 0.00070\n",
      "Epoch 29/Step 830, Loss: -0.27376, Accuracy: 0.99910, F1: 0.0012, Prec: 0.6927, Rec: 0.3971 lr: 0.00070\n",
      "Epoch 29/Step 840, Loss: -0.29154, Accuracy: 0.99910, F1: 0.0011, Prec: 0.6928, Rec: 0.3973 lr: 0.00070\n",
      "Epoch 29/Step 850, Loss: -0.25292, Accuracy: 0.99910, F1: 0.0011, Prec: 0.6921, Rec: 0.3972 lr: 0.00070\n",
      "Epoch 29/Step 860, Loss: -0.25090, Accuracy: 0.99910, F1: 0.0011, Prec: 0.6922, Rec: 0.3972 lr: 0.00070\n",
      "Epoch 29/Step 870, Loss: -0.24323, Accuracy: 0.99910, F1: 0.0011, Prec: 0.6922, Rec: 0.3968 lr: 0.00070\n",
      "Epoch 29/Step 880, Loss: -0.21478, Accuracy: 0.99910, F1: 0.0011, Prec: 0.6922, Rec: 0.3968 lr: 0.00070\n",
      "Epoch 29/Step 890, Loss: -0.23039, Accuracy: 0.99910, F1: 0.0011, Prec: 0.6916, Rec: 0.3967 lr: 0.00070\n",
      "Epoch 29/Step 900, Loss: -0.30162, Accuracy: 0.99910, F1: 0.0011, Prec: 0.6916, Rec: 0.3968 lr: 0.00070\n",
      "Epoch 29/Step 910, Loss: -0.20201, Accuracy: 0.99910, F1: 0.0010, Prec: 0.6912, Rec: 0.3965 lr: 0.00070\n",
      "Epoch 29/Step 920, Loss: -0.25021, Accuracy: 0.99910, F1: 0.0010, Prec: 0.6909, Rec: 0.3963 lr: 0.00070\n",
      "Epoch 29/Step 930, Loss: -0.22179, Accuracy: 0.99910, F1: 0.0010, Prec: 0.6908, Rec: 0.3964 lr: 0.00070\n",
      "Epoch 29/Step 940, Loss: -0.24849, Accuracy: 0.99910, F1: 0.0010, Prec: 0.6906, Rec: 0.3964 lr: 0.00070\n",
      "Epoch 29/Step 950, Loss: -0.25385, Accuracy: 0.99910, F1: 0.0010, Prec: 0.6906, Rec: 0.3965 lr: 0.00070\n",
      "Epoch 29/Step 960, Loss: -0.28167, Accuracy: 0.99910, F1: 0.0010, Prec: 0.6903, Rec: 0.3965 lr: 0.00070\n",
      "Epoch 29/Step 970, Loss: -0.22130, Accuracy: 0.99910, F1: 0.0010, Prec: 0.6902, Rec: 0.3961 lr: 0.00070\n",
      "Epoch 29/Step 980, Loss: -0.25824, Accuracy: 0.99910, F1: 0.0010, Prec: 0.6904, Rec: 0.3959 lr: 0.00070\n",
      "Epoch 29/Step 990, Loss: -0.24259, Accuracy: 0.99910, F1: 0.0010, Prec: 0.6900, Rec: 0.3958 lr: 0.00070\n",
      "Epoch 29/Step 1000, Loss: -0.24798, Accuracy: 0.99910, F1: 0.0010, Prec: 0.6900, Rec: 0.3960 lr: 0.00070\n",
      "Epoch 29/Step 1010, Loss: -0.25322, Accuracy: 0.99910, F1: 0.0009, Prec: 0.6902, Rec: 0.3962 lr: 0.00070\n",
      "Epoch 29/Step 1020, Loss: -0.21104, Accuracy: 0.99910, F1: 0.0009, Prec: 0.6900, Rec: 0.3962 lr: 0.00070\n",
      "Epoch 29/Step 1030, Loss: -0.25885, Accuracy: 0.99910, F1: 0.0009, Prec: 0.6900, Rec: 0.3961 lr: 0.00070\n",
      "Epoch 29/Step 1040, Loss: -0.24644, Accuracy: 0.99910, F1: 0.0009, Prec: 0.6900, Rec: 0.3961 lr: 0.00070\n",
      "Epoch 29/Step 1050, Loss: -0.27373, Accuracy: 0.99910, F1: 0.0009, Prec: 0.6899, Rec: 0.3963 lr: 0.00070\n",
      "Epoch 29/Step 1060, Loss: -0.28077, Accuracy: 0.99911, F1: 0.0009, Prec: 0.6899, Rec: 0.3966 lr: 0.00070\n",
      "Epoch 29/Step 1070, Loss: -0.25326, Accuracy: 0.99911, F1: 0.0009, Prec: 0.6899, Rec: 0.3965 lr: 0.00070\n",
      "Epoch 29/Step 1080, Loss: -0.23367, Accuracy: 0.99911, F1: 0.0009, Prec: 0.6900, Rec: 0.3966 lr: 0.00070\n",
      "Epoch 29/Step 1090, Loss: -0.25098, Accuracy: 0.99911, F1: 0.0009, Prec: 0.6897, Rec: 0.3965 lr: 0.00070\n",
      "Epoch 29/Step 1100, Loss: -0.26242, Accuracy: 0.99911, F1: 0.0009, Prec: 0.6898, Rec: 0.3966 lr: 0.00070\n",
      "Epoch 29/Step 1110, Loss: -0.21038, Accuracy: 0.99911, F1: 0.0009, Prec: 0.6899, Rec: 0.3965 lr: 0.00070\n",
      "Epoch 29/Step 1120, Loss: -0.22891, Accuracy: 0.99911, F1: 0.0009, Prec: 0.6897, Rec: 0.3965 lr: 0.00070\n",
      "Epoch 29/Step 1130, Loss: -0.21722, Accuracy: 0.99911, F1: 0.0008, Prec: 0.6896, Rec: 0.3966 lr: 0.00070\n",
      "Epoch 29/Step 1140, Loss: -0.24264, Accuracy: 0.99911, F1: 0.0008, Prec: 0.6896, Rec: 0.3967 lr: 0.00070\n",
      "Epoch 29/Step 1150, Loss: -0.26474, Accuracy: 0.99911, F1: 0.0008, Prec: 0.6898, Rec: 0.3967 lr: 0.00070\n",
      "Epoch 29/Step 1160, Loss: -0.21661, Accuracy: 0.99911, F1: 0.0008, Prec: 0.6899, Rec: 0.3970 lr: 0.00070\n",
      "Epoch 29/Step 1170, Loss: -0.22395, Accuracy: 0.99911, F1: 0.0008, Prec: 0.6898, Rec: 0.3970 lr: 0.00070\n",
      "Epoch 29/Step 1180, Loss: -0.20557, Accuracy: 0.99911, F1: 0.0008, Prec: 0.6900, Rec: 0.3968 lr: 0.00070\n",
      "Epoch 29/Step 1190, Loss: -0.27449, Accuracy: 0.99911, F1: 0.0008, Prec: 0.6900, Rec: 0.3966 lr: 0.00070\n",
      "Epoch 29/Step 1200, Loss: -0.23543, Accuracy: 0.99911, F1: 0.0008, Prec: 0.6900, Rec: 0.3970 lr: 0.00070\n",
      "Epoch 29/Step 1210, Loss: -0.26176, Accuracy: 0.99911, F1: 0.0008, Prec: 0.6902, Rec: 0.3971 lr: 0.00070\n",
      "Epoch 29/Step 1220, Loss: -0.27843, Accuracy: 0.99911, F1: 0.0008, Prec: 0.6903, Rec: 0.3971 lr: 0.00070\n",
      "Epoch 29/Step 1230, Loss: -0.26753, Accuracy: 0.99911, F1: 0.0008, Prec: 0.6904, Rec: 0.3971 lr: 0.00070\n",
      "Epoch 29/Step 1240, Loss: -0.28977, Accuracy: 0.99911, F1: 0.0008, Prec: 0.6903, Rec: 0.3971 lr: 0.00070\n",
      "Epoch 29/Step 1250, Loss: -0.19394, Accuracy: 0.99911, F1: 0.0008, Prec: 0.6905, Rec: 0.3971 lr: 0.00070\n",
      "Epoch 29/Step 1260, Loss: -0.26861, Accuracy: 0.99911, F1: 0.0008, Prec: 0.6907, Rec: 0.3972 lr: 0.00070\n",
      "Epoch 29/Step 1270, Loss: -0.22994, Accuracy: 0.99911, F1: 0.0008, Prec: 0.6908, Rec: 0.3973 lr: 0.00070\n",
      "Epoch 29/Step 1280, Loss: -0.31474, Accuracy: 0.99911, F1: 0.0007, Prec: 0.6907, Rec: 0.3973 lr: 0.00070\n",
      "Epoch 29/Step 1290, Loss: -0.25902, Accuracy: 0.99911, F1: 0.0007, Prec: 0.6909, Rec: 0.3974 lr: 0.00070\n",
      "Epoch 29/Step 1300, Loss: -0.23465, Accuracy: 0.99911, F1: 0.0007, Prec: 0.6911, Rec: 0.3973 lr: 0.00070\n",
      "Epoch 29/Step 1310, Loss: -0.25419, Accuracy: 0.99911, F1: 0.0007, Prec: 0.6910, Rec: 0.3975 lr: 0.00070\n",
      "Epoch 29/Step 1320, Loss: -0.27929, Accuracy: 0.99911, F1: 0.0007, Prec: 0.6910, Rec: 0.3976 lr: 0.00070\n",
      "Epoch 29/Step 1330, Loss: -0.28526, Accuracy: 0.99911, F1: 0.0007, Prec: 0.6912, Rec: 0.3975 lr: 0.00070\n",
      "Epoch 29/Step 1340, Loss: -0.25637, Accuracy: 0.99911, F1: 0.0007, Prec: 0.6914, Rec: 0.3977 lr: 0.00070\n",
      "Epoch 29/Step 1350, Loss: -0.20825, Accuracy: 0.99911, F1: 0.0007, Prec: 0.6915, Rec: 0.3977 lr: 0.00070\n",
      "Epoch 29/Step 1360, Loss: -0.22337, Accuracy: 0.99911, F1: 0.0007, Prec: 0.6915, Rec: 0.3977 lr: 0.00070\n",
      "Epoch 29/Step 1370, Loss: -0.24742, Accuracy: 0.99911, F1: 0.0007, Prec: 0.6915, Rec: 0.3980 lr: 0.00070\n",
      "Epoch 29/Step 1380, Loss: -0.25849, Accuracy: 0.99912, F1: 0.0007, Prec: 0.6914, Rec: 0.3981 lr: 0.00070\n",
      "Epoch 29/Step 1390, Loss: -0.25039, Accuracy: 0.99912, F1: 0.0007, Prec: 0.6913, Rec: 0.3980 lr: 0.00070\n",
      "Epoch 29/Step 1400, Loss: -0.26982, Accuracy: 0.99912, F1: 0.0007, Prec: 0.6913, Rec: 0.3982 lr: 0.00070\n",
      "Epoch 29/Step 1410, Loss: -0.23749, Accuracy: 0.99912, F1: 0.0007, Prec: 0.6914, Rec: 0.3981 lr: 0.00070\n",
      "Epoch 29/Step 1420, Loss: -0.23857, Accuracy: 0.99912, F1: 0.0007, Prec: 0.6915, Rec: 0.3980 lr: 0.00070\n",
      "Epoch 29/Step 1430, Loss: -0.25395, Accuracy: 0.99912, F1: 0.0007, Prec: 0.6916, Rec: 0.3979 lr: 0.00070\n",
      "Epoch 29/Step 1440, Loss: -0.24634, Accuracy: 0.99912, F1: 0.0007, Prec: 0.6917, Rec: 0.3980 lr: 0.00070\n",
      "Epoch 29/Step 1450, Loss: -0.25739, Accuracy: 0.99912, F1: 0.0007, Prec: 0.6918, Rec: 0.3981 lr: 0.00070\n",
      "Epoch 29/Step 1460, Loss: -0.23038, Accuracy: 0.99912, F1: 0.0007, Prec: 0.6918, Rec: 0.3981 lr: 0.00070\n",
      "Epoch 29/Step 1470, Loss: -0.24610, Accuracy: 0.99912, F1: 0.0007, Prec: 0.6920, Rec: 0.3980 lr: 0.00070\n",
      "Epoch 29/Step 1480, Loss: -0.24514, Accuracy: 0.99912, F1: 0.0006, Prec: 0.6920, Rec: 0.3980 lr: 0.00070\n",
      "Epoch 29/Step 1490, Loss: -0.23819, Accuracy: 0.99912, F1: 0.0006, Prec: 0.6917, Rec: 0.3979 lr: 0.00070\n",
      "Epoch 29/Step 1500, Loss: -0.27283, Accuracy: 0.99912, F1: 0.0006, Prec: 0.6918, Rec: 0.3980 lr: 0.00070\n",
      "Epoch 29/Step 1510, Loss: -0.23622, Accuracy: 0.99912, F1: 0.0006, Prec: 0.6920, Rec: 0.3980 lr: 0.00070\n",
      "Epoch 29/Step 1520, Loss: -0.29334, Accuracy: 0.99912, F1: 0.0006, Prec: 0.6921, Rec: 0.3981 lr: 0.00070\n",
      "Epoch 29/Step 1530, Loss: -0.23654, Accuracy: 0.99912, F1: 0.0006, Prec: 0.6922, Rec: 0.3983 lr: 0.00070\n",
      "Epoch 29/Step 1540, Loss: -0.21289, Accuracy: 0.99912, F1: 0.0006, Prec: 0.6922, Rec: 0.3980 lr: 0.00070\n",
      "Epoch 29/Step 1550, Loss: -0.24750, Accuracy: 0.99912, F1: 0.0006, Prec: 0.6923, Rec: 0.3981 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9987\n",
      "Validation f1: 0.0000\n",
      "Validation precision: 0.3711\n",
      "Validation recall: 0.2185\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_28_valF1Score0.000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_28_valF1Score0.000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 30\n",
      "Epoch 30/Step 0, Loss: -0.27271, Accuracy: 0.99919, F1: 0.0000, Prec: 0.6945, Rec: 0.4605 lr: 0.00070\n",
      "Epoch 30/Step 10, Loss: -0.30682, Accuracy: 0.99907, F1: 0.0000, Prec: 0.7058, Rec: 0.4268 lr: 0.00070\n",
      "Epoch 30/Step 20, Loss: -0.27654, Accuracy: 0.99911, F1: 0.0000, Prec: 0.7080, Rec: 0.4212 lr: 0.00070\n",
      "Epoch 30/Step 30, Loss: -0.23723, Accuracy: 0.99914, F1: 0.0000, Prec: 0.7141, Rec: 0.4166 lr: 0.00070\n",
      "Epoch 30/Step 40, Loss: -0.22873, Accuracy: 0.99914, F1: 0.0000, Prec: 0.7195, Rec: 0.4169 lr: 0.00070\n",
      "Epoch 30/Step 50, Loss: -0.25698, Accuracy: 0.99914, F1: 0.0000, Prec: 0.7171, Rec: 0.4145 lr: 0.00070\n",
      "Epoch 30/Step 60, Loss: -0.26694, Accuracy: 0.99914, F1: 0.0000, Prec: 0.7188, Rec: 0.4146 lr: 0.00070\n",
      "Epoch 30/Step 70, Loss: -0.24035, Accuracy: 0.99916, F1: 0.0000, Prec: 0.7199, Rec: 0.4148 lr: 0.00070\n",
      "Epoch 30/Step 80, Loss: -0.24988, Accuracy: 0.99916, F1: 0.0000, Prec: 0.7194, Rec: 0.4126 lr: 0.00070\n",
      "Epoch 30/Step 90, Loss: -0.23438, Accuracy: 0.99915, F1: 0.0000, Prec: 0.7186, Rec: 0.4121 lr: 0.00070\n",
      "Epoch 30/Step 100, Loss: -0.26018, Accuracy: 0.99916, F1: 0.0000, Prec: 0.7184, Rec: 0.4137 lr: 0.00070\n",
      "Epoch 30/Step 110, Loss: -0.25082, Accuracy: 0.99915, F1: 0.0000, Prec: 0.7186, Rec: 0.4121 lr: 0.00070\n",
      "Epoch 30/Step 120, Loss: -0.23938, Accuracy: 0.99914, F1: 0.0000, Prec: 0.7164, Rec: 0.4113 lr: 0.00070\n",
      "Epoch 30/Step 130, Loss: -0.21841, Accuracy: 0.99914, F1: 0.0000, Prec: 0.7138, Rec: 0.4116 lr: 0.00070\n",
      "Epoch 30/Step 140, Loss: -0.22474, Accuracy: 0.99913, F1: 0.0000, Prec: 0.7103, Rec: 0.4089 lr: 0.00070\n",
      "Epoch 30/Step 150, Loss: -0.23286, Accuracy: 0.99912, F1: 0.0000, Prec: 0.7090, Rec: 0.4068 lr: 0.00070\n",
      "Epoch 30/Step 160, Loss: -0.27249, Accuracy: 0.99912, F1: 0.0000, Prec: 0.7086, Rec: 0.4066 lr: 0.00070\n",
      "Epoch 30/Step 170, Loss: -0.26213, Accuracy: 0.99912, F1: 0.0000, Prec: 0.7063, Rec: 0.4064 lr: 0.00070\n",
      "Epoch 30/Step 180, Loss: -0.30101, Accuracy: 0.99912, F1: 0.0000, Prec: 0.7052, Rec: 0.4078 lr: 0.00070\n",
      "Epoch 30/Step 190, Loss: -0.23715, Accuracy: 0.99912, F1: 0.0000, Prec: 0.7053, Rec: 0.4062 lr: 0.00070\n",
      "Epoch 30/Step 200, Loss: -0.27107, Accuracy: 0.99912, F1: 0.0000, Prec: 0.7062, Rec: 0.4051 lr: 0.00070\n",
      "Epoch 30/Step 210, Loss: -0.22572, Accuracy: 0.99911, F1: 0.0000, Prec: 0.7054, Rec: 0.4050 lr: 0.00070\n",
      "Epoch 30/Step 220, Loss: -0.26255, Accuracy: 0.99911, F1: 0.0000, Prec: 0.7054, Rec: 0.4053 lr: 0.00070\n",
      "Epoch 30/Step 230, Loss: -0.22162, Accuracy: 0.99911, F1: 0.0000, Prec: 0.7046, Rec: 0.4047 lr: 0.00070\n",
      "Epoch 30/Step 240, Loss: -0.28665, Accuracy: 0.99911, F1: 0.0000, Prec: 0.7030, Rec: 0.4048 lr: 0.00070\n",
      "Epoch 30/Step 250, Loss: -0.26381, Accuracy: 0.99911, F1: 0.0000, Prec: 0.7026, Rec: 0.4042 lr: 0.00070\n",
      "Epoch 30/Step 260, Loss: -0.27870, Accuracy: 0.99911, F1: 0.0000, Prec: 0.7027, Rec: 0.4044 lr: 0.00070\n",
      "Epoch 30/Step 270, Loss: -0.27055, Accuracy: 0.99910, F1: 0.0000, Prec: 0.7019, Rec: 0.4039 lr: 0.00070\n",
      "Epoch 30/Step 280, Loss: -0.25205, Accuracy: 0.99910, F1: 0.0000, Prec: 0.7015, Rec: 0.4026 lr: 0.00070\n",
      "Epoch 30/Step 290, Loss: -0.25309, Accuracy: 0.99910, F1: 0.0000, Prec: 0.7005, Rec: 0.4029 lr: 0.00070\n",
      "Epoch 30/Step 300, Loss: -0.29087, Accuracy: 0.99910, F1: 0.0000, Prec: 0.7010, Rec: 0.4031 lr: 0.00070\n",
      "Epoch 30/Step 310, Loss: -0.25075, Accuracy: 0.99910, F1: 0.0000, Prec: 0.7017, Rec: 0.4025 lr: 0.00070\n",
      "Epoch 30/Step 320, Loss: -0.25587, Accuracy: 0.99911, F1: 0.0000, Prec: 0.7024, Rec: 0.4026 lr: 0.00070\n",
      "Epoch 30/Step 330, Loss: -0.26507, Accuracy: 0.99910, F1: 0.0000, Prec: 0.7023, Rec: 0.4026 lr: 0.00070\n",
      "Epoch 30/Step 340, Loss: -0.25686, Accuracy: 0.99910, F1: 0.0000, Prec: 0.7020, Rec: 0.4027 lr: 0.00070\n",
      "Epoch 30/Step 350, Loss: -0.23004, Accuracy: 0.99910, F1: 0.0000, Prec: 0.7034, Rec: 0.4030 lr: 0.00070\n",
      "Epoch 30/Step 360, Loss: -0.25710, Accuracy: 0.99910, F1: 0.0000, Prec: 0.7034, Rec: 0.4036 lr: 0.00070\n",
      "Epoch 30/Step 370, Loss: -0.26705, Accuracy: 0.99911, F1: 0.0000, Prec: 0.7031, Rec: 0.4037 lr: 0.00070\n",
      "Epoch 30/Step 380, Loss: -0.26226, Accuracy: 0.99911, F1: 0.0000, Prec: 0.7026, Rec: 0.4035 lr: 0.00070\n",
      "Epoch 30/Step 390, Loss: -0.22383, Accuracy: 0.99911, F1: 0.0000, Prec: 0.7028, Rec: 0.4031 lr: 0.00070\n",
      "Epoch 30/Step 400, Loss: -0.23254, Accuracy: 0.99911, F1: 0.0000, Prec: 0.7028, Rec: 0.4024 lr: 0.00070\n",
      "Epoch 30/Step 410, Loss: -0.21608, Accuracy: 0.99911, F1: 0.0000, Prec: 0.7026, Rec: 0.4023 lr: 0.00070\n",
      "Epoch 30/Step 420, Loss: -0.27278, Accuracy: 0.99911, F1: 0.0000, Prec: 0.7023, Rec: 0.4028 lr: 0.00070\n",
      "Epoch 30/Step 430, Loss: -0.24943, Accuracy: 0.99911, F1: 0.0000, Prec: 0.7019, Rec: 0.4030 lr: 0.00070\n",
      "Epoch 30/Step 440, Loss: -0.26666, Accuracy: 0.99911, F1: 0.0000, Prec: 0.7017, Rec: 0.4028 lr: 0.00070\n",
      "Epoch 30/Step 450, Loss: -0.26312, Accuracy: 0.99911, F1: 0.0000, Prec: 0.7018, Rec: 0.4027 lr: 0.00070\n",
      "Epoch 30/Step 460, Loss: -0.24737, Accuracy: 0.99911, F1: 0.0000, Prec: 0.7013, Rec: 0.4026 lr: 0.00070\n",
      "Epoch 30/Step 470, Loss: -0.22801, Accuracy: 0.99911, F1: 0.0000, Prec: 0.7010, Rec: 0.4023 lr: 0.00070\n",
      "Epoch 30/Step 480, Loss: -0.23821, Accuracy: 0.99911, F1: 0.0000, Prec: 0.7001, Rec: 0.4014 lr: 0.00070\n",
      "Epoch 30/Step 490, Loss: -0.22373, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6995, Rec: 0.4011 lr: 0.00070\n",
      "Epoch 30/Step 500, Loss: -0.24834, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6997, Rec: 0.4011 lr: 0.00070\n",
      "Epoch 30/Step 510, Loss: -0.29411, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6996, Rec: 0.4011 lr: 0.00070\n",
      "Epoch 30/Step 520, Loss: -0.23787, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6999, Rec: 0.4010 lr: 0.00070\n",
      "Epoch 30/Step 530, Loss: -0.24812, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6989, Rec: 0.4006 lr: 0.00070\n",
      "Epoch 30/Step 540, Loss: -0.24895, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6985, Rec: 0.4006 lr: 0.00070\n",
      "Epoch 30/Step 550, Loss: -0.28107, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6984, Rec: 0.4006 lr: 0.00070\n",
      "Epoch 30/Step 560, Loss: -0.23851, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6983, Rec: 0.4004 lr: 0.00070\n",
      "Epoch 30/Step 570, Loss: -0.25580, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6983, Rec: 0.4001 lr: 0.00070\n",
      "Epoch 30/Step 580, Loss: -0.20784, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6979, Rec: 0.3999 lr: 0.00070\n",
      "Epoch 30/Step 590, Loss: -0.19661, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6971, Rec: 0.3997 lr: 0.00070\n",
      "Epoch 30/Step 600, Loss: -0.24866, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6974, Rec: 0.3994 lr: 0.00070\n",
      "Epoch 30/Step 610, Loss: -0.30356, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6974, Rec: 0.3995 lr: 0.00070\n",
      "Epoch 30/Step 620, Loss: -0.26631, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6969, Rec: 0.4001 lr: 0.00070\n",
      "Epoch 30/Step 630, Loss: -0.22181, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6966, Rec: 0.3998 lr: 0.00070\n",
      "Epoch 30/Step 640, Loss: -0.23879, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6962, Rec: 0.4000 lr: 0.00070\n",
      "Epoch 30/Step 650, Loss: -0.22511, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6962, Rec: 0.3999 lr: 0.00070\n",
      "Epoch 30/Step 660, Loss: -0.26639, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6961, Rec: 0.3999 lr: 0.00070\n",
      "Epoch 30/Step 670, Loss: -0.28494, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6967, Rec: 0.4000 lr: 0.00070\n",
      "Epoch 30/Step 680, Loss: -0.21413, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6971, Rec: 0.4000 lr: 0.00070\n",
      "Epoch 30/Step 690, Loss: -0.27274, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6967, Rec: 0.4000 lr: 0.00070\n",
      "Epoch 30/Step 700, Loss: -0.25733, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6961, Rec: 0.3999 lr: 0.00070\n",
      "Epoch 30/Step 710, Loss: -0.26360, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6966, Rec: 0.4003 lr: 0.00070\n",
      "Epoch 30/Step 720, Loss: -0.26314, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6967, Rec: 0.4000 lr: 0.00070\n",
      "Epoch 30/Step 730, Loss: -0.23239, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6964, Rec: 0.3998 lr: 0.00070\n",
      "Epoch 30/Step 740, Loss: -0.25394, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6962, Rec: 0.3997 lr: 0.00070\n",
      "Epoch 30/Step 750, Loss: -0.26018, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6962, Rec: 0.3996 lr: 0.00070\n",
      "Epoch 30/Step 760, Loss: -0.25719, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6962, Rec: 0.3992 lr: 0.00070\n",
      "Epoch 30/Step 770, Loss: -0.27357, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6958, Rec: 0.3993 lr: 0.00070\n",
      "Epoch 30/Step 780, Loss: -0.19994, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6960, Rec: 0.3993 lr: 0.00070\n",
      "Epoch 30/Step 790, Loss: -0.26779, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6958, Rec: 0.3990 lr: 0.00070\n",
      "Epoch 30/Step 800, Loss: -0.24123, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6961, Rec: 0.3989 lr: 0.00070\n",
      "Epoch 30/Step 810, Loss: -0.18570, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6961, Rec: 0.3989 lr: 0.00070\n",
      "Epoch 30/Step 820, Loss: -0.23612, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6957, Rec: 0.3987 lr: 0.00070\n",
      "Epoch 30/Step 830, Loss: -0.27528, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6959, Rec: 0.3988 lr: 0.00070\n",
      "Epoch 30/Step 840, Loss: -0.29308, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6962, Rec: 0.3988 lr: 0.00070\n",
      "Epoch 30/Step 850, Loss: -0.26899, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6955, Rec: 0.3987 lr: 0.00070\n",
      "Epoch 30/Step 860, Loss: -0.24832, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6954, Rec: 0.3987 lr: 0.00070\n",
      "Epoch 30/Step 870, Loss: -0.24155, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6952, Rec: 0.3984 lr: 0.00070\n",
      "Epoch 30/Step 880, Loss: -0.22528, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6951, Rec: 0.3984 lr: 0.00070\n",
      "Epoch 30/Step 890, Loss: -0.24010, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6947, Rec: 0.3983 lr: 0.00070\n",
      "Epoch 30/Step 900, Loss: -0.29445, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6947, Rec: 0.3984 lr: 0.00070\n",
      "Epoch 30/Step 910, Loss: -0.20114, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6947, Rec: 0.3981 lr: 0.00070\n",
      "Epoch 30/Step 920, Loss: -0.24668, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6942, Rec: 0.3979 lr: 0.00070\n",
      "Epoch 30/Step 930, Loss: -0.22923, Accuracy: 0.99910, F1: 0.0000, Prec: 0.6939, Rec: 0.3980 lr: 0.00070\n",
      "Epoch 30/Step 940, Loss: -0.24434, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6936, Rec: 0.3981 lr: 0.00070\n",
      "Epoch 30/Step 950, Loss: -0.25727, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6936, Rec: 0.3981 lr: 0.00070\n",
      "Epoch 30/Step 960, Loss: -0.28127, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6935, Rec: 0.3981 lr: 0.00070\n",
      "Epoch 30/Step 970, Loss: -0.22841, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6932, Rec: 0.3978 lr: 0.00070\n",
      "Epoch 30/Step 980, Loss: -0.25251, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6935, Rec: 0.3974 lr: 0.00070\n",
      "Epoch 30/Step 990, Loss: -0.23419, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6932, Rec: 0.3972 lr: 0.00070\n",
      "Epoch 30/Step 1000, Loss: -0.25021, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6929, Rec: 0.3975 lr: 0.00070\n",
      "Epoch 30/Step 1010, Loss: -0.26740, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6930, Rec: 0.3977 lr: 0.00070\n",
      "Epoch 30/Step 1020, Loss: -0.20952, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6930, Rec: 0.3977 lr: 0.00070\n",
      "Epoch 30/Step 1030, Loss: -0.26443, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6931, Rec: 0.3976 lr: 0.00070\n",
      "Epoch 30/Step 1040, Loss: -0.24931, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6932, Rec: 0.3977 lr: 0.00070\n",
      "Epoch 30/Step 1050, Loss: -0.27860, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6930, Rec: 0.3979 lr: 0.00070\n",
      "Epoch 30/Step 1060, Loss: -0.27545, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6932, Rec: 0.3981 lr: 0.00070\n",
      "Epoch 30/Step 1070, Loss: -0.25167, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6932, Rec: 0.3980 lr: 0.00070\n",
      "Epoch 30/Step 1080, Loss: -0.23753, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6932, Rec: 0.3981 lr: 0.00070\n",
      "Epoch 30/Step 1090, Loss: -0.24373, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6927, Rec: 0.3981 lr: 0.00070\n",
      "Epoch 30/Step 1100, Loss: -0.26145, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6926, Rec: 0.3981 lr: 0.00070\n",
      "Epoch 30/Step 1110, Loss: -0.21105, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6926, Rec: 0.3981 lr: 0.00070\n",
      "Epoch 30/Step 1120, Loss: -0.23374, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6925, Rec: 0.3981 lr: 0.00070\n",
      "Epoch 30/Step 1130, Loss: -0.21555, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6925, Rec: 0.3982 lr: 0.00070\n",
      "Epoch 30/Step 1140, Loss: -0.24824, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6923, Rec: 0.3983 lr: 0.00070\n",
      "Epoch 30/Step 1150, Loss: -0.27775, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6925, Rec: 0.3984 lr: 0.00070\n",
      "Epoch 30/Step 1160, Loss: -0.21712, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6927, Rec: 0.3987 lr: 0.00070\n",
      "Epoch 30/Step 1170, Loss: -0.22531, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6930, Rec: 0.3985 lr: 0.00070\n",
      "Epoch 30/Step 1180, Loss: -0.21419, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6931, Rec: 0.3984 lr: 0.00070\n",
      "Epoch 30/Step 1190, Loss: -0.27412, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6929, Rec: 0.3983 lr: 0.00070\n",
      "Epoch 30/Step 1200, Loss: -0.23617, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6929, Rec: 0.3986 lr: 0.00070\n",
      "Epoch 30/Step 1210, Loss: -0.26582, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6931, Rec: 0.3988 lr: 0.00070\n",
      "Epoch 30/Step 1220, Loss: -0.27865, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6932, Rec: 0.3988 lr: 0.00070\n",
      "Epoch 30/Step 1230, Loss: -0.25867, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6933, Rec: 0.3986 lr: 0.00070\n",
      "Epoch 30/Step 1240, Loss: -0.29148, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6928, Rec: 0.3987 lr: 0.00070\n",
      "Epoch 30/Step 1250, Loss: -0.19011, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6928, Rec: 0.3988 lr: 0.00070\n",
      "Epoch 30/Step 1260, Loss: -0.27536, Accuracy: 0.99911, F1: 0.0000, Prec: 0.6930, Rec: 0.3990 lr: 0.00070\n",
      "Epoch 30/Step 1270, Loss: -0.23523, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6927, Rec: 0.3991 lr: 0.00070\n",
      "Epoch 30/Step 1280, Loss: -0.30793, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6926, Rec: 0.3991 lr: 0.00070\n",
      "Epoch 30/Step 1290, Loss: -0.25621, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6929, Rec: 0.3991 lr: 0.00070\n",
      "Epoch 30/Step 1300, Loss: -0.23347, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6930, Rec: 0.3990 lr: 0.00070\n",
      "Epoch 30/Step 1310, Loss: -0.25167, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6934, Rec: 0.3990 lr: 0.00070\n",
      "Epoch 30/Step 1320, Loss: -0.28341, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6933, Rec: 0.3991 lr: 0.00070\n",
      "Epoch 30/Step 1330, Loss: -0.28269, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6933, Rec: 0.3991 lr: 0.00070\n",
      "Epoch 30/Step 1340, Loss: -0.26038, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6936, Rec: 0.3993 lr: 0.00070\n",
      "Epoch 30/Step 1350, Loss: -0.21095, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6937, Rec: 0.3992 lr: 0.00070\n",
      "Epoch 30/Step 1360, Loss: -0.22519, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6938, Rec: 0.3993 lr: 0.00070\n",
      "Epoch 30/Step 1370, Loss: -0.24689, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6939, Rec: 0.3994 lr: 0.00070\n",
      "Epoch 30/Step 1380, Loss: -0.26506, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6938, Rec: 0.3995 lr: 0.00070\n",
      "Epoch 30/Step 1390, Loss: -0.24356, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6936, Rec: 0.3995 lr: 0.00070\n",
      "Epoch 30/Step 1400, Loss: -0.26794, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6939, Rec: 0.3996 lr: 0.00070\n",
      "Epoch 30/Step 1410, Loss: -0.23982, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6938, Rec: 0.3996 lr: 0.00070\n",
      "Epoch 30/Step 1420, Loss: -0.23803, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6939, Rec: 0.3994 lr: 0.00070\n",
      "Epoch 30/Step 1430, Loss: -0.25562, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6942, Rec: 0.3992 lr: 0.00070\n",
      "Epoch 30/Step 1440, Loss: -0.24283, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6943, Rec: 0.3993 lr: 0.00070\n",
      "Epoch 30/Step 1450, Loss: -0.25356, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6944, Rec: 0.3994 lr: 0.00070\n",
      "Epoch 30/Step 1460, Loss: -0.23793, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6943, Rec: 0.3994 lr: 0.00070\n",
      "Epoch 30/Step 1470, Loss: -0.25439, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6944, Rec: 0.3993 lr: 0.00070\n",
      "Epoch 30/Step 1480, Loss: -0.24545, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6944, Rec: 0.3993 lr: 0.00070\n",
      "Epoch 30/Step 1490, Loss: -0.23668, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6942, Rec: 0.3991 lr: 0.00070\n",
      "Epoch 30/Step 1500, Loss: -0.27583, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6942, Rec: 0.3993 lr: 0.00070\n",
      "Epoch 30/Step 1510, Loss: -0.23590, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6944, Rec: 0.3993 lr: 0.00070\n",
      "Epoch 30/Step 1520, Loss: -0.29864, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6945, Rec: 0.3994 lr: 0.00070\n",
      "Epoch 30/Step 1530, Loss: -0.23418, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6946, Rec: 0.3995 lr: 0.00070\n",
      "Epoch 30/Step 1540, Loss: -0.21946, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6946, Rec: 0.3993 lr: 0.00070\n",
      "Epoch 30/Step 1550, Loss: -0.24631, Accuracy: 0.99912, F1: 0.0000, Prec: 0.6948, Rec: 0.3993 lr: 0.00070\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9987\n",
      "Validation f1: 0.0000\n",
      "Validation precision: 0.3780\n",
      "Validation recall: 0.2132\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_29_valF1Score0.000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_29_valF1Score0.000/assets\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow_addons as tfa\n",
    "\n",
    "BATCH_SIZE=64\n",
    "LOG_INTERVAL=10\n",
    "epochs = 30\n",
    "saveModel=True\n",
    "\n",
    "\n",
    "log_dir = \"./logs/\"+model.name+\"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+\"_\"+SO\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,\n",
    "                                                      write_graph=True, update_freq=5)\n",
    "\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "# Instantiate an optimizer .\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=7e-4)\n",
    "\n",
    "# Instantiate a loss function.\n",
    "# loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "# loss_fn = WeightedBinaryCE(np.ones(len(mlb.classes_)))\n",
    "# loss_fn = WeightedBinaryCE(labelWeights)\n",
    "loss_fn = WeightedComboLoss(labelWeights)\n",
    "\n",
    "train_acc_metric = tf.keras.metrics.BinaryAccuracy()\n",
    "train_f1_metric = WeightedF1(classWeights=labelWeights, threshold=0.5)\n",
    "train_prec = tf.keras.metrics.Precision()\n",
    "train_rec = tf.keras.metrics.Recall()\n",
    "# train_f1_metric = tfa.metrics.F1Score(num_classes=len(mlb.classes_), threshold=0.5, average=\"macro\")\n",
    "\n",
    "val_acc_metric = tf.keras.metrics.BinaryAccuracy()\n",
    "val_f1_metric = WeightedF1(classWeights=labelWeights, threshold=0.5)\n",
    "# val_f1_metric = tfa.metrics.F1Score(num_classes=len(mlb.classes_), threshold=0.5, average=\"macro\")\n",
    "val_prec = tf.keras.metrics.Precision()\n",
    "val_rec = tf.keras.metrics.Recall()\n",
    "\n",
    "batchedDataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "batchedDatasetVal = datasetVal.batch(BATCH_SIZE, drop_remainder=False)\n",
    "\n",
    "# batchedDataset = batchedDataset.cache(os.path.join(DATA_PATH, \"datasetCache\"+SO))\n",
    "# batchedDatasetVal = batchedDatasetVal.cache(os.path.join(DATA_PATH, \"datasetCacheVal\"+SO))\n",
    "\n",
    "@tf.function()\n",
    "def trainStep(x_batch_train, y_batch_train):\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        probs = model(x_batch_train, training=True) \n",
    "        loss_value = loss_fn(y_batch_train, probs)\n",
    "\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    #Gradient clipping\n",
    "    # grads = [tf.clip_by_norm(g, 2.0) for g in grads]\n",
    "\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights)) \n",
    "    return loss_value, probs\n",
    "\n",
    "@tf.function()\n",
    "def valStep(x_batch_val, y_batch_val):\n",
    "    valProbs = model(x_batch_val, training=False)\n",
    "    # Update val metrics\n",
    "    val_acc_metric.update_state(y_batch_val, valProbs)\n",
    "    val_f1_metric.update_state(y_batch_val, valProbs)\n",
    "    val_prec.update_state(y_batch_val, valProbs)\n",
    "    val_rec.update_state(y_batch_val, valProbs)\n",
    "\n",
    "maxStep=0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch+1,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(batchedDataset):\n",
    "\n",
    "        loss_value, probs=trainStep(x_batch_train,y_batch_train)\n",
    "\n",
    "        train_acc_metric.update_state(y_batch_train, probs)\n",
    "        train_f1_metric.update_state(y_batch_train, probs)\n",
    "        train_prec.update_state(y_batch_train, probs)\n",
    "        train_rec.update_state(y_batch_train, probs)\n",
    "\n",
    "        # Log \n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            template = 'Epoch {}/Step {}, Loss: {:.5f}, Accuracy: {:.5f}, F1: {:.4f}, Prec: {:.4f}, Rec: {:.4f} lr: {:.5f}'\n",
    "            print (template.format(epoch+1, step,loss_value, \n",
    "                                    train_acc_metric.result(),train_f1_metric.result(),\n",
    "                                    train_prec.result(), train_rec.result(), optimizer.learning_rate.numpy()))\n",
    "            \n",
    "            with summary_writer.as_default():\n",
    "                tf.summary.scalar('loss', loss_value, step=maxStep*epoch+step)\n",
    "                tf.summary.scalar('accuracy', train_acc_metric.result(), step=maxStep*epoch+step)\n",
    "                tf.summary.scalar('f1', train_f1_metric.result(), step=maxStep*epoch+step)\n",
    "                tf.summary.scalar('prec', train_prec.result(), step=maxStep*epoch+step)\n",
    "                tf.summary.scalar('rec', train_rec.result(), step=maxStep*epoch+step)\n",
    "                tf.summary.scalar('learning rate', optimizer.learning_rate.numpy(), step=maxStep*epoch+step)\n",
    "                summary_writer.flush()\n",
    "\n",
    "    \n",
    "    train_acc_metric.reset_states()\n",
    "    train_f1_metric.reset_states()\n",
    "    train_prec.reset_states()\n",
    "    train_rec.reset_states()\n",
    "\n",
    "    maxStep=step\n",
    "\n",
    "    print(\"Epoch finished. Start validation\")\n",
    "    for x_batch_val, y_batch_val in batchedDatasetVal:\n",
    "        valStep(x_batch_val, y_batch_val)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    val_f1 = val_f1_metric.result()\n",
    "    val_f1_metric.reset_states()\n",
    "    val_precision = val_prec.result()\n",
    "    val_prec.reset_states()\n",
    "    val_recall = val_rec.result()\n",
    "    val_rec.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    print(\"Validation f1: %.4f\" % (float(val_f1),))\n",
    "    print(\"Validation precision: %.4f\" % (float(val_precision),))\n",
    "    print(\"Validation recall: %.4f\" % (float(val_recall),))\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('valAcc', float(val_acc), step=epoch)\n",
    "        tf.summary.scalar('valF1', float(val_f1), step=epoch)\n",
    "        tf.summary.scalar('valPrecision', float(val_precision), step=epoch)\n",
    "        tf.summary.scalar('valRecall', float(val_recall), step=epoch)\n",
    "        summary_writer.flush()\n",
    "    if saveModel:\n",
    "      model.save(os.path.join(DATA_PATH, \"model_\"+SO+\"_epoch_{}_valF1Score{:.3f}\".format(epoch, float(val_f1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "374f7234",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model.save(os.path.join(DATA_PATH, \"model_\"+SO+\"_epoch_{}_valf1Score{:.3f}\".format(epoch, float(val_f1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cefc1f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 11:08:59.004876: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 246ms/step\n",
      "[('GO:0006139', 'GO:0006725', 'GO:0007049', 'GO:0008150', 'GO:0008152', 'GO:0009987', 'GO:0016043', 'GO:0034641', 'GO:0044237', 'GO:0046483', 'GO:0071840', 'GO:0090304', 'GO:1901360')]\n",
      "[1.        1.        0.9999999 1.        1.        1.        1.\n",
      " 1.        1.        1.        1.        1.        1.       ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "probs= model.predict(tf.expand_dims(list(datasetVal.take(32))[10][0], 0))\n",
    "prediction= [1 if p > 0.5 else 0 for p in probs[0]]\n",
    "probabilities= probs[probs>0.5]\n",
    "# classes = np.argwhere(prediction)\n",
    "print(mlb.inverse_transform(np.array([prediction])))\n",
    "print(probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
