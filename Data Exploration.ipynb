{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d77e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "DATA_PATH = os.getenv('DATA_PATH')\n",
    "print(DATA_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3544f8a",
   "metadata": {},
   "source": [
    "## Reading fasta, obo and tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b515f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "sequences = [rec.seq for rec in SeqIO.parse(os.path.join(DATA_PATH, \"Train/train_sequences.fasta\"),\"fasta\")]\n",
    "ids = [rec.id for rec in SeqIO.parse(os.path.join(DATA_PATH, \"Train/train_sequences.fasta\"),\"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e492f673",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {} sequences in the dataset.\".format(len(sequences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2898414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "import obonet\n",
    "\n",
    "# Read the taxrank ontology\n",
    "url = os.path.join(DATA_PATH, \"Train/go-basic.obo\")\n",
    "graph = obonet.read_obo(url)\n",
    "\n",
    "# Number of nodes\n",
    "print(len(graph))\n",
    "\n",
    "# Number of edges\n",
    "print(graph.number_of_edges())\n",
    "\n",
    "# Check if the ontology is a DAG\n",
    "print(networkx.is_directed_acyclic_graph(graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4bf949",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, \"Train/train_terms.tsv\"), sep='\\t')\n",
    "uniqueTerms = df[\"term\"].unique()\n",
    "termsArr = list(df[\"term\"].to_numpy())\n",
    "\n",
    "uniqueTermsDict={}\n",
    "for i,el in enumerate(uniqueTerms):\n",
    "    uniqueTermsDict[el] = i\n",
    "    \n",
    "termToken = [uniqueTermsDict[el] for el in termsArr]\n",
    "df[\"termToken\"] = termToken\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356b5e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29043526",
   "metadata": {},
   "source": [
    "Test for the first entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb38aa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['EntryID'] == \"A0A009IHW8\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5338b7f8",
   "metadata": {},
   "source": [
    "## GO analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1058ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_counts = df[\"term\"].value_counts()\n",
    "print(item_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_name = {id_: data.get('name') for id_, data in graph.nodes(data=True)}\n",
    "name_to_id = {data['name']: id_ for id_, data in graph.nodes(data=True) if 'name' in data}\n",
    "print(id_to_name['GO:0005575'] )\n",
    "print(id_to_name['GO:0008150'] )\n",
    "print(id_to_name['GO:0110165'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b2429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(id_to_name['GO:0042324'] )\n",
    "print(networkx.ancestors(graph, 'GO:0042324'))\n",
    "print(networkx.descendants(graph, 'GO:0042324'))\n",
    "\n",
    "paths = networkx.all_simple_paths(\n",
    "    graph,\n",
    "    source='GO:0042324',\n",
    "    target=name_to_id['molecular_function']\n",
    ")\n",
    "\n",
    "for path in paths:\n",
    "    print('•', ' ⟶ '.join(id_to_name[node] for node in path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e676b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "allGOs= df.loc[df['EntryID'] == \"A0A009IHW8\"][\"term\"].to_numpy()\n",
    "print([[id_to_name[el],el] for el in allGOs])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45a724ce",
   "metadata": {},
   "source": [
    "### Find GOs without ancestors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaf1812",
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedGOs = list(networkx.topological_sort(graph))\n",
    "rootGOs = []\n",
    "for g in sortedGOs:\n",
    "    if len(networkx.ancestors(graph,g)) ==0:\n",
    "        rootGOs.append(g)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "print(rootGOs)\n",
    "print(len(rootGOs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f37ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(networkx.ancestors(graph, sortedGOs[1000]))\n",
    "print(id_to_name[sortedGOs[1000]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77edf357",
   "metadata": {},
   "source": [
    "### How many of them are used in our dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75ff06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRootGOs = np.intersect1d(uniqueTerms,rootGOs)\n",
    "print(len(dataRootGOs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c099fc2",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cae9a3b0",
   "metadata": {},
   "source": [
    "The task is a multilabel classification: The output has several possible targets (Gene Ontologies) but each can only be 1 (existing) or 0 (non existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48073ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "dftest=df.loc[df['EntryID'] == \"A0A009IHW8\"]\n",
    "indices = dftest[\"termToken\"].to_numpy()\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([termToken])\n",
    "print(indices)\n",
    "print(mlb.transform([indices]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92019f8c",
   "metadata": {},
   "source": [
    "## Amino acids coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b747477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aminos_list = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'X']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96203a63",
   "metadata": {},
   "source": [
    "- A: Alanine\n",
    "- C: Cysteine\n",
    "- D: Aspartic acid\n",
    "- E: Glutamic acid\n",
    "- F: Phenylalanine\n",
    "- G: Glycine\n",
    "- H: Histidine\n",
    "- I: Isoleucine\n",
    "- K: Lysine\n",
    "- L: Leucine\n",
    "- M: Methionine\n",
    "- N: Asparagine\n",
    "- O: Pyrrolysine\n",
    "- P: Proline\n",
    "- Q: Glutamine\n",
    "- R: Arginine\n",
    "- S: Serine\n",
    "- T: Threonine\n",
    "- U: Selenocystein\n",
    "- V: Valine\n",
    "- W: Tryptophan\n",
    "- Y: Tyrosine\n",
    "- X: unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e42462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_dict = {'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'O': 21, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'U': 22, 'V': 18, 'W': 19, 'Y': 20, 'X':23}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfd823ba",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431f9df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqLengths = [len(seq) for seq in sequences]\n",
    "maxLen = max(seqLengths)\n",
    "print(\"The max. length of the sequences is {}\".format(maxLen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f722e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use numpy vectorize to speed up the mapping (hopefully)\n",
    "mapping = lambda x: aa_dict[x]\n",
    "vectMapping = np.vectorize(mapping)\n",
    "\n",
    "\n",
    "def generator():\n",
    "    for i,seq in enumerate(sequences):\n",
    "        entryId = ids[i]\n",
    "        labelData = df.loc[df['EntryID'] == entryId]\n",
    "        \n",
    "        indices = labelData[\"termToken\"].to_numpy()\n",
    "\n",
    "        y = mlb.transform([indices])\n",
    "        \n",
    "        arr = np.array(seq)\n",
    "        mappedArr = vectMapping(arr)\n",
    "        padWidth = maxLen - arr.size\n",
    "        paddedArr = np.pad(mappedArr, (0, padWidth))\n",
    "        yield paddedArr,y[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd15e8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = generator()\n",
    "test = next(g)\n",
    "print(\"The first (padded) sample sequence: {}\".format(test[0]))\n",
    "print(\"The first sample has {} classes\".format(np.count_nonzero(test[1])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c2d5f18",
   "metadata": {},
   "source": [
    "## Basic classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26769fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "for i,el in enumerate(g):\n",
    "    X.append(el[0])\n",
    "    y.append(el[1])\n",
    "    if i ==10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eabba57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= np.array(X)\n",
    "y= np.array(y)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2624936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(clf.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6337c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.decision_path([X[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0317f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([X[0]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10c4a51a",
   "metadata": {},
   "source": [
    "## Tensorflow Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f0d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(generator, output_signature=(\n",
    "         tf.TensorSpec(shape=(maxLen,), dtype=tf.int32),\n",
    "         tf.TensorSpec(shape=(uniqueTerms.size,), dtype=tf.int32)))\n",
    "list(dataset.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98752d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input( shape=(maxLen,1)))\n",
    "model.add(tf.keras.layers.Conv1D(3, 5, activation=tf.keras.activations.relu))\n",
    "model.add(tf.keras.layers.Conv1D(5, 5, strides=2, activation=tf.keras.activations.relu ))\n",
    "model.add(tf.keras.layers.Conv1D(7, 5, strides=2, activation=tf.keras.activations.relu ))\n",
    "model.add(tf.keras.layers.Conv1D(7, 5, strides=2, activation=tf.keras.activations.relu ))\n",
    "model.add(tf.keras.layers.Conv1D(7, 5, strides=2, activation=tf.keras.activations.relu ))\n",
    "model.add(tf.keras.layers.Conv1D(7, 5, strides=2, activation=tf.keras.activations.relu ))\n",
    "model.add(tf.keras.layers.Conv1D(7, 5, strides=2, activation=tf.keras.activations.relu ))\n",
    "model.add(tf.keras.layers.Conv1D(7, 5, strides=2, activation=tf.keras.activations.relu ))\n",
    "model.add(tf.keras.layers.Conv1D(7, 5, strides=2, activation=tf.keras.activations.relu ))\n",
    "model.add(tf.keras.layers.Conv1D(7, 5, strides=2, activation=tf.keras.activations.relu ))\n",
    "model.add(tf.keras.layers.Conv1D(7, 5, strides=2, activation=tf.keras.activations.relu ))\n",
    "model.add(tf.keras.layers.Conv1D(7, 5, strides=2, activation=tf.keras.activations.relu ))\n",
    "model.add(tf.keras.layers.Conv1D(7, 5, strides=2, activation=tf.keras.activations.relu ))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(uniqueTerms.size))\n",
    "model.add(tf.keras.layers.Softmax())\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9113c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "batchedDataset = dataset.batch(32)\n",
    "# print(batchedDataset.take(1))\n",
    "model.fit(batchedDataset, epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
