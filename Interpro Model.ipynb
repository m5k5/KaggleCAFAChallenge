{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c1d77e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 23:44:11.632311: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-28 23:44:12.082024: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "/mnt/e/ML/cafa-5-protein-function-prediction\n",
      "/mnt/e/ML/output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 23:44:12.772830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-28 23:44:12.789911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-28 23:44:12.790239: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "# try:\n",
    "#   tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "# except:\n",
    "#   # Invalid device or cannot modify virtual devices once initialized.\n",
    "#   pass\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "DATA_PATH = os.getenv('DATA_PATH')\n",
    "DATA_PATH_INTERPRO = os.getenv('DATA_PATH_INTERPRO')\n",
    "print(DATA_PATH)\n",
    "print(DATA_PATH_INTERPRO)\n",
    "\n",
    "# Choose subontology (CCO, MFO or BPO)\n",
    "SO = 'BPO'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3544f8a",
   "metadata": {},
   "source": [
    "## Reading fasta, obo and tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b515f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "sequences = [rec.seq for rec in SeqIO.parse(os.path.join(DATA_PATH, \"Train/train_sequences.fasta\"),\"fasta\")]\n",
    "ids = [rec.id for rec in SeqIO.parse(os.path.join(DATA_PATH, \"Train/train_sequences.fasta\"),\"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2898414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "import obonet\n",
    "\n",
    "# Read the taxrank ontology\n",
    "url = os.path.join(DATA_PATH, \"Train/go-basic.obo\")\n",
    "graph = obonet.read_obo(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f4bf949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3497732, 3)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, \"Train/train_terms.tsv\"), sep='\\t')\n",
    "\n",
    "dfSO = df.loc[df[\"aspect\"]==SO]\n",
    "uniqueTerms = dfSO[\"term\"].unique()\n",
    "termsArr = list(dfSO[\"term\"].to_numpy())\n",
    "\n",
    "uniqueTermsDict={}\n",
    "for i,el in enumerate(uniqueTerms):\n",
    "    uniqueTermsDict[el] = i\n",
    "    \n",
    "print(dfSO.shape)\n",
    "df=dfSO\n",
    "\n",
    "df.set_index(\"EntryID\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4dec705",
   "metadata": {},
   "outputs": [],
   "source": [
    "testID = df.index.to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b181e117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>aspect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EntryID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0008152</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0034655</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0072523</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0044270</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0006753</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:1901292</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0044237</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:1901360</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0008150</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:1901564</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:1901565</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0009117</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0006139</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0044281</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0046496</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0019362</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0046483</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0055086</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0044248</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0019439</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0019637</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0006807</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0019677</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:1901361</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0006163</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0046700</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0009987</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0006725</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0006796</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0034641</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0072521</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0071704</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0019364</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:1901575</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0072526</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0046434</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0009166</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0072524</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0006195</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0009056</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0044238</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0006793</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0019674</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  term aspect\n",
       "EntryID                      \n",
       "A0A009IHW8  GO:0008152    BPO\n",
       "A0A009IHW8  GO:0034655    BPO\n",
       "A0A009IHW8  GO:0072523    BPO\n",
       "A0A009IHW8  GO:0044270    BPO\n",
       "A0A009IHW8  GO:0006753    BPO\n",
       "A0A009IHW8  GO:1901292    BPO\n",
       "A0A009IHW8  GO:0044237    BPO\n",
       "A0A009IHW8  GO:1901360    BPO\n",
       "A0A009IHW8  GO:0008150    BPO\n",
       "A0A009IHW8  GO:1901564    BPO\n",
       "A0A009IHW8  GO:1901565    BPO\n",
       "A0A009IHW8  GO:0009117    BPO\n",
       "A0A009IHW8  GO:0006139    BPO\n",
       "A0A009IHW8  GO:0044281    BPO\n",
       "A0A009IHW8  GO:0046496    BPO\n",
       "A0A009IHW8  GO:0019362    BPO\n",
       "A0A009IHW8  GO:0046483    BPO\n",
       "A0A009IHW8  GO:0055086    BPO\n",
       "A0A009IHW8  GO:0044248    BPO\n",
       "A0A009IHW8  GO:0019439    BPO\n",
       "A0A009IHW8  GO:0019637    BPO\n",
       "A0A009IHW8  GO:0006807    BPO\n",
       "A0A009IHW8  GO:0019677    BPO\n",
       "A0A009IHW8  GO:1901361    BPO\n",
       "A0A009IHW8  GO:0006163    BPO\n",
       "A0A009IHW8  GO:0046700    BPO\n",
       "A0A009IHW8  GO:0009987    BPO\n",
       "A0A009IHW8  GO:0006725    BPO\n",
       "A0A009IHW8  GO:0006796    BPO\n",
       "A0A009IHW8  GO:0034641    BPO\n",
       "A0A009IHW8  GO:0072521    BPO\n",
       "A0A009IHW8  GO:0071704    BPO\n",
       "A0A009IHW8  GO:0019364    BPO\n",
       "A0A009IHW8  GO:1901575    BPO\n",
       "A0A009IHW8  GO:0072526    BPO\n",
       "A0A009IHW8  GO:0046434    BPO\n",
       "A0A009IHW8  GO:0009166    BPO\n",
       "A0A009IHW8  GO:0072524    BPO\n",
       "A0A009IHW8  GO:0006195    BPO\n",
       "A0A009IHW8  GO:0009056    BPO\n",
       "A0A009IHW8  GO:0044238    BPO\n",
       "A0A009IHW8  GO:0006793    BPO\n",
       "A0A009IHW8  GO:0019674    BPO"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[testID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fff067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGo = pd.read_csv(os.path.join(DATA_PATH, \"Train/train_terms.tsv\"), sep='\\t')\n",
    "\n",
    "dfGo = dfGo.loc[dfGo[\"aspect\"]==SO]\n",
    "\n",
    "dfGo.set_index(\"term\", inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5338b7f8",
   "metadata": {},
   "source": [
    "## GO analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1058ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_counts = df[\"term\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb35584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_name = {id_: data.get('name') for id_, data in graph.nodes(data=True)}\n",
    "name_to_id = {data['name']: id_ for id_, data in graph.nodes(data=True) if 'name' in data}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c099fc2",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cae9a3b0",
   "metadata": {},
   "source": [
    "The task is a multilabel classification: The output has several possible targets (Gene Ontologies) but each can only be 1 (existing) or 0 (non existing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8e63ed9",
   "metadata": {},
   "source": [
    "Extract label weights from IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7e3c316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found GOs: 0 (set to 0)\n"
     ]
    }
   ],
   "source": [
    "dfIa = pd.read_csv(os.path.join(DATA_PATH, \"IA.txt\"), sep='\\t', header=None)\n",
    "\n",
    "dfIa.set_index(0, inplace=True)\n",
    "\n",
    "labelWeights=[]\n",
    "allIndices = dfIa.index.tolist()\n",
    "\n",
    "\n",
    "\n",
    "notFound=0\n",
    "for go in item_counts.index.to_list():\n",
    "    if go in allIndices:\n",
    "        labelWeights.append(dfIa.loc[go].to_numpy()[0])\n",
    "    else:\n",
    "        notFound += 1\n",
    "        labelWeights.append(0)\n",
    "\n",
    "print(\"Not found GOs: {} (set to 0)\".format(notFound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caeee590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading presaved data\n"
     ]
    }
   ],
   "source": [
    "topGOs=item_counts.index.to_list()\n",
    "\n",
    "threshold=0\n",
    "labelWeights=np.array(labelWeights)\n",
    "selection = labelWeights>threshold\n",
    "topGOs=np.array(topGOs)[selection]\n",
    "\n",
    "if os.path.exists(os.path.join(DATA_PATH, \"GODataSizes_\"+SO+\".npy\")):\n",
    "    print(\"Loading presaved data\")\n",
    "    GODataSizes = np.load(os.path.join(DATA_PATH, \"GODataSizes_\"+SO+\".npy\"))\n",
    "else:\n",
    "    GODataSizes= [dfGo.loc[g].size for g in topGOs]\n",
    "    np.save(os.path.join(DATA_PATH, \"GODataSizes_\"+SO), GODataSizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e87f301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11807\n"
     ]
    }
   ],
   "source": [
    "#At least 10 samples\n",
    "print(np.count_nonzero(np.array(GODataSizes)>5))\n",
    "GODataSizes= np.array(GODataSizes)\n",
    "GOsWithSufficientData = topGOs[GODataSizes>5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99f6a6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14109\n",
      "['GO:0008152' 'GO:0034655' 'GO:0072523' 'GO:0044270' 'GO:0006753'\n",
      " 'GO:1901292' 'GO:0044237' 'GO:1901360' 'GO:0008150' 'GO:1901564'\n",
      " 'GO:1901565' 'GO:0009117' 'GO:0006139' 'GO:0044281' 'GO:0046496'\n",
      " 'GO:0019362' 'GO:0046483' 'GO:0055086' 'GO:0044248' 'GO:0019439'\n",
      " 'GO:0019637' 'GO:0006807' 'GO:0019677' 'GO:1901361' 'GO:0006163'\n",
      " 'GO:0046700' 'GO:0009987' 'GO:0006725' 'GO:0006796' 'GO:0034641'\n",
      " 'GO:0072521' 'GO:0071704' 'GO:0019364' 'GO:1901575' 'GO:0072526'\n",
      " 'GO:0046434' 'GO:0009166' 'GO:0072524' 'GO:0006195' 'GO:0009056'\n",
      " 'GO:0044238' 'GO:0006793' 'GO:0019674']\n",
      "[[0 0 0 ... 0 0 0]]\n",
      "11807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manuel/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['GO:0006195', 'GO:0008150', 'GO:0019364', 'GO:1901292'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pickle\n",
    "\n",
    "print(len(topGOs))\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([GOsWithSufficientData])\n",
    "\n",
    "dftest=df.loc[testID]\n",
    "indices = dftest[\"term\"].to_numpy()\n",
    "print(indices)\n",
    "print(mlb.transform([indices]))\n",
    "print(len(mlb.classes_))\n",
    "\n",
    "with open(os.path.join(DATA_PATH,'MLB_'+SO+'.pkl'), 'wb') as f:\n",
    "    pickle.dump(mlb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb189ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found GOs: 0 (set to 0)\n"
     ]
    }
   ],
   "source": [
    "labelWeightsCorr=[]\n",
    "occurenceScores=[]\n",
    "termHist= df[\"term\"].value_counts()\n",
    "maxGoCount = termHist.max()\n",
    "\n",
    "notFound=0\n",
    "for go in mlb.classes_:\n",
    "    if go in allIndices:\n",
    "        occurenceScore = (maxGoCount-termHist[go])/maxGoCount\n",
    "        occurenceScores.append(occurenceScore)\n",
    "        labelWeightsCorr.append(dfIa.loc[go].to_numpy()[0])\n",
    "    else:\n",
    "        notFound += 1\n",
    "        labelWeightsCorr.append(0)\n",
    "\n",
    "print(\"Not found GOs: {} (set to 0)\".format(notFound))\n",
    "labelWeightsCorr=np.array(labelWeightsCorr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92019f8c",
   "metadata": {},
   "source": [
    "## Amino acids encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e42462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_dict = {'A': 1, 'B':24, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'O': 21, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'U': 22, 'V': 18, 'W': 19, 'Y': 20, 'X':30, 'Z':23}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d206203f",
   "metadata": {},
   "source": [
    "## Interpro Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43765061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "root = ET.parse(os.path.join(DATA_PATH, \"interpro.xml\")).getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e280b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "possibleDomains=[]\n",
    "for child in root:\n",
    "    if \"type\" in child.attrib:\n",
    "        if(child.attrib[\"type\"]==\"Domain\"):\n",
    "            # print(child.tag, child.attrib)\n",
    "            possibleDomains.append(child.attrib[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23b46e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ... 0 0 0]]\n",
      "12811\n"
     ]
    }
   ],
   "source": [
    "len(possibleDomains)\n",
    "\n",
    "mlbInterPro = MultiLabelBinarizer()\n",
    "mlbInterPro.fit([possibleDomains])\n",
    "\n",
    "\n",
    "print(mlbInterPro.transform([[\"IPR000001\"]]))\n",
    "print(len(mlbInterPro.classes_))\n",
    "\n",
    "with open(os.path.join(DATA_PATH,'MLB_InterPro_'+SO+'.pkl'), 'wb') as f:\n",
    "    pickle.dump(mlbInterPro, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cd8d58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(os.path.join(DATA_PATH_INTERPRO, \"train_sequences1.fasta.json\")) as f:\n",
    "    iprData1 = json.load(f)\n",
    "\n",
    "with open(os.path.join(DATA_PATH_INTERPRO, \"train_sequences2.fasta.json\")) as f:\n",
    "    iprData2 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e1c7d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe80cc798d4489dbadfb22581e75707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "iprIds = {}\n",
    "\n",
    "\n",
    "for entry in tqdm([*iprData1[\"results\"], *iprData2[\"results\"]]):\n",
    "    entryId = entry[\"xref\"][0][\"id\"]\n",
    "    matches=[]\n",
    "    for match in entry[\"matches\"]:\n",
    "        sigEntry = match[\"signature\"][\"entry\"]\n",
    "        if(sigEntry):\n",
    "            type = sigEntry[\"type\"]\n",
    "            if type==\"DOMAIN\":\n",
    "                iprId = match[\"signature\"][\"entry\"][\"accession\"]\n",
    "                matches.append(iprId)\n",
    "    iprIds[entryId] = matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c824d142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140645"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iprIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d2cd32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testInput = mlbInterPro.transform([iprIds[\"Q8NDA2\"]])\n",
    "np.count_nonzero(testInput)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfd823ba",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ff7484e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A0A009IHW8' 'A0A021WW32' 'A0A023FFD0' ... 'X5L1L5' 'X5L565' 'X5M5N0']\n"
     ]
    }
   ],
   "source": [
    "dfAll=pd.read_csv(os.path.join(DATA_PATH, \"Train/train_terms.tsv\"), sep='\\t')\n",
    "\n",
    "soEntries = dfAll.loc[dfAll[\"aspect\"]==SO]\n",
    "soEntryIds = soEntries[\"EntryID\"].unique()\n",
    "\n",
    "print(soEntryIds)\n",
    "\n",
    "dfAll.set_index(\"EntryID\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44f722e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99572\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "TRAIN_VAL_SPLIT = 0.7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Shuffle the data\n",
    "import random\n",
    "random.seed(516213)\n",
    "c = list(zip(sequences, ids))\n",
    "random.shuffle(c)\n",
    "sequencesShuffle, idsShuffle = zip(*c)\n",
    "\n",
    "\n",
    "#Train Validation Split\n",
    "split = int(np.floor(len(sequencesShuffle)*TRAIN_VAL_SPLIT))\n",
    "print(split)\n",
    "trainSeq = sequencesShuffle[0:split]\n",
    "valSeq = sequencesShuffle[split+1:]\n",
    "trainIds = idsShuffle[0:split]\n",
    "valIds = idsShuffle[split+1:]\n",
    "\n",
    "\n",
    "def generator():\n",
    "  for i,seq in enumerate(trainSeq):\n",
    "      entryId = trainIds[i]\n",
    "      if entryId in soEntryIds:\n",
    "        labelData = df.loc[entryId]\n",
    "        # indices = labelData[\"termToken\"].to_numpy()\n",
    "        indices = labelData[\"term\"].to_numpy()\n",
    "      else: \n",
    "        indices=[]\n",
    "\n",
    "      with warnings.catch_warnings():\n",
    "        #supress the warnings for unknown classes\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        y = mlb.transform([indices])\n",
    "\n",
    "      with warnings.catch_warnings():\n",
    "        #supress the warnings for unknown classes\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        if entryId in iprIds:\n",
    "          x  = mlbInterPro.transform([iprIds[entryId]])\n",
    "        else:\n",
    "          x  = mlbInterPro.transform([[]])\n",
    "     \n",
    "      yield (x[0],y[0])\n",
    "\n",
    "\n",
    "def generatorVal():\n",
    "  for i,seq in enumerate(valSeq):\n",
    "      entryId = valIds[i]\n",
    "      if entryId in soEntryIds:\n",
    "        labelData = df.loc[entryId]\n",
    "        # indices = labelData[\"termToken\"].to_numpy()\n",
    "        indices = labelData[\"term\"].to_numpy()\n",
    "      else: \n",
    "        indices=[]\n",
    "\n",
    "      with warnings.catch_warnings():\n",
    "        #supress the warnings for unknown classes\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        y = mlb.transform([indices])\n",
    "\n",
    "      with warnings.catch_warnings():\n",
    "        #supress the warnings for unknown classes\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        if entryId in iprIds:\n",
    "          x  = mlbInterPro.transform([iprIds[entryId]])\n",
    "        else:\n",
    "          x  = mlbInterPro.transform([[]])\n",
    "     \n",
    "      yield (x[0],y[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2727338a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first sample: \n",
      "(12811,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "The first sample has 2 input classes\n",
      "The first sample has 0 output classes\n"
     ]
    }
   ],
   "source": [
    "g = generator()\n",
    "test = next(g)\n",
    "print(\"The first sample: \\n{}\\n{}\".format(test[0].shape, test[0][0:100]))\n",
    "print(\"The first sample has {} input classes\".format(np.count_nonzero(test[0])))\n",
    "print(\"The first sample has {} output classes\".format(np.count_nonzero(test[1])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10c4a51a",
   "metadata": {},
   "source": [
    "## Tensorflow Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63f0d2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 23:44:55.479167: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-28 23:44:55.479615: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-28 23:44:55.479975: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-28 23:44:55.943418: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-28 23:44:55.943809: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-28 23:44:55.943821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-07-28 23:44:55.944115: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-28 23:44:55.944150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6569 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:2b:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(<tf.Tensor: shape=(12811,), dtype=int32, numpy=array([0, 0, 0, ..., 0, 0, 0], dtype=int32)>, <tf.Tensor: shape=(11807,), dtype=int32, numpy=array([0, 0, 0, ..., 0, 0, 0], dtype=int32)>)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 23:44:56.290704: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(generator, output_signature=(\n",
    "         tf.TensorSpec(shape=(len(mlbInterPro.classes_),), dtype=tf.int32),\n",
    "         tf.TensorSpec(shape=(len(mlb.classes_),), dtype=tf.int32)))\n",
    "print(list(dataset.take(1)))\n",
    "\n",
    "datasetVal = tf.data.Dataset.from_generator(generatorVal, output_signature=(\n",
    "         tf.TensorSpec(shape=(len(mlbInterPro.classes_),), dtype=tf.int32),\n",
    "         tf.TensorSpec(shape=(len(mlb.classes_),), dtype=tf.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0a554f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98752d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DenseModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 12811)]           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               6559744   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 11807)             6056991   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,148,191\n",
      "Trainable params: 13,145,119\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "VOCAB_SIZE=len(aa_dict)\n",
    "EMBED_DIM=10\n",
    "\n",
    "def createModel():\n",
    "    inputs = tf.keras.Input(shape=(len(mlbInterPro.classes_),))\n",
    "    # x=layers.Embedding(VOCAB_SIZE, EMBED_DIM, name=\"embedding\")(inputs)\n",
    "  \n",
    "    x = layers.Dense(512)(inputs)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "\n",
    "    x = layers.Dense(512)(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "\n",
    "    x = layers.Dense(512)(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "\n",
    "    outputs=layers.Dense(len(mlb.classes_), activation=tf.keras.activations.sigmoid)(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name=\"DenseModel\")\n",
    "\n",
    "model = createModel()\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a3ddc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Learning rate schedule\n",
    "initial_learning_rate = 0.001\n",
    "decaySteps=5000\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(initial_learning_rate, first_decay_steps=decaySteps,\n",
    "                                                                t_mul=2.0, m_mul=0.7)\n",
    "# lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "#     initial_learning_rate, decay_steps=decaySteps, alpha=0.01)\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate,decay_steps=decaySteps,decay_rate=0.9,staircase=False)\n",
    "step = np.linspace(0,decaySteps*3)\n",
    "lr = lr_schedule(step)\n",
    "# plt.figure(figsize = (8,6))\n",
    "# # plt.yscale(\"log\")\n",
    "# plt.plot(step, lr)\n",
    "# plt.ylim([0,max(plt.ylim())])\n",
    "# plt.xlabel('step')\n",
    "# _ = plt.ylabel('Learning Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2f43e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9113c4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 23:44:56.896325: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-28 23:44:58.816599: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fa4e4214910 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-28 23:44:58.816632: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce GTX 1070, Compute Capability 6.1\n",
      "2023-07-28 23:44:58.820439: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-28 23:44:58.944732: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-07-28 23:44:59.041101: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/Step 0, Loss: -0.00085, Accuracy: 0.50149, F1: 0.0017, Prec: 0.3647, Rec: 0.0009, lr: 0.00080\n",
      "Epoch 1/Step 20, Loss: -0.00078, Accuracy: 0.50398, F1: 0.0020, Prec: 0.3325, Rec: 0.0010, lr: 0.00080\n",
      "Epoch 1/Step 40, Loss: -0.00132, Accuracy: 0.50791, F1: 0.0020, Prec: 0.3438, Rec: 0.0010, lr: 0.00080\n",
      "Epoch 1/Step 60, Loss: -0.00158, Accuracy: 0.51073, F1: 0.0021, Prec: 0.3565, Rec: 0.0010, lr: 0.00080\n",
      "Epoch 1/Step 80, Loss: -0.00158, Accuracy: 0.51147, F1: 0.0021, Prec: 0.3627, Rec: 0.0011, lr: 0.00080\n",
      "Epoch 1/Step 100, Loss: -0.00134, Accuracy: 0.51048, F1: 0.0022, Prec: 0.3710, Rec: 0.0011, lr: 0.00080\n",
      "Epoch 1/Step 120, Loss: -0.00121, Accuracy: 0.51380, F1: 0.0024, Prec: 0.3797, Rec: 0.0012, lr: 0.00080\n",
      "Epoch 1/Step 140, Loss: -0.00314, Accuracy: 0.52995, F1: 0.0026, Prec: 0.3858, Rec: 0.0013, lr: 0.00080\n",
      "Epoch 1/Step 160, Loss: -0.00165, Accuracy: 0.55529, F1: 0.0031, Prec: 0.3947, Rec: 0.0016, lr: 0.00080\n",
      "Epoch 1/Step 180, Loss: -0.00315, Accuracy: 0.58086, F1: 0.0041, Prec: 0.4024, Rec: 0.0021, lr: 0.00080\n",
      "Epoch 1/Step 200, Loss: -0.00187, Accuracy: 0.60642, F1: 0.0054, Prec: 0.4095, Rec: 0.0027, lr: 0.00080\n",
      "Epoch 1/Step 220, Loss: -0.00393, Accuracy: 0.63297, F1: 0.0067, Prec: 0.4158, Rec: 0.0034, lr: 0.00080\n",
      "Epoch 1/Step 240, Loss: -0.00548, Accuracy: 0.65820, F1: 0.0084, Prec: 0.4227, Rec: 0.0043, lr: 0.00080\n",
      "Epoch 1/Step 260, Loss: -0.00779, Accuracy: 0.68100, F1: 0.0102, Prec: 0.4270, Rec: 0.0052, lr: 0.00080\n",
      "Epoch 1/Step 280, Loss: -0.01293, Accuracy: 0.70137, F1: 0.0124, Prec: 0.4305, Rec: 0.0064, lr: 0.00080\n",
      "Epoch 1/Step 300, Loss: -0.03080, Accuracy: 0.71979, F1: 0.0151, Prec: 0.4304, Rec: 0.0078, lr: 0.00080\n",
      "Epoch 1/Step 320, Loss: -0.05591, Accuracy: 0.73661, F1: 0.0192, Prec: 0.4256, Rec: 0.0102, lr: 0.00080\n",
      "Epoch 1/Step 340, Loss: -0.08706, Accuracy: 0.75179, F1: 0.0253, Prec: 0.4166, Rec: 0.0144, lr: 0.00080\n",
      "Epoch 1/Step 360, Loss: -0.10355, Accuracy: 0.76538, F1: 0.0318, Prec: 0.4050, Rec: 0.0197, lr: 0.00080\n",
      "Epoch 1/Step 380, Loss: -0.12470, Accuracy: 0.77759, F1: 0.0377, Prec: 0.3932, Rec: 0.0250, lr: 0.00080\n",
      "Epoch 1/Step 400, Loss: -0.09127, Accuracy: 0.78860, F1: 0.0430, Prec: 0.3810, Rec: 0.0308, lr: 0.00080\n",
      "Epoch 1/Step 420, Loss: -0.11347, Accuracy: 0.79856, F1: 0.0480, Prec: 0.3699, Rec: 0.0366, lr: 0.00080\n",
      "Epoch 1/Step 440, Loss: -0.09473, Accuracy: 0.80763, F1: 0.0531, Prec: 0.3600, Rec: 0.0427, lr: 0.00080\n",
      "Epoch 1/Step 460, Loss: -0.10119, Accuracy: 0.81591, F1: 0.0574, Prec: 0.3506, Rec: 0.0480, lr: 0.00080\n",
      "Epoch 1/Step 480, Loss: -0.10729, Accuracy: 0.82350, F1: 0.0617, Prec: 0.3419, Rec: 0.0538, lr: 0.00080\n",
      "Epoch 1/Step 500, Loss: -0.12197, Accuracy: 0.83049, F1: 0.0654, Prec: 0.3337, Rec: 0.0590, lr: 0.00080\n",
      "Epoch 1/Step 520, Loss: -0.09914, Accuracy: 0.83694, F1: 0.0690, Prec: 0.3261, Rec: 0.0641, lr: 0.00080\n",
      "Epoch 1/Step 540, Loss: -0.08763, Accuracy: 0.84292, F1: 0.0720, Prec: 0.3187, Rec: 0.0687, lr: 0.00080\n",
      "Epoch 1/Step 560, Loss: -0.13777, Accuracy: 0.84847, F1: 0.0753, Prec: 0.3125, Rec: 0.0730, lr: 0.00080\n",
      "Epoch 1/Step 580, Loss: -0.13154, Accuracy: 0.85364, F1: 0.0781, Prec: 0.3064, Rec: 0.0772, lr: 0.00080\n",
      "Epoch 1/Step 600, Loss: -0.09956, Accuracy: 0.85846, F1: 0.0807, Prec: 0.3005, Rec: 0.0811, lr: 0.00080\n",
      "Epoch 1/Step 620, Loss: -0.14095, Accuracy: 0.86297, F1: 0.0833, Prec: 0.2951, Rec: 0.0851, lr: 0.00080\n",
      "Epoch 1/Step 640, Loss: -0.11419, Accuracy: 0.86720, F1: 0.0860, Prec: 0.2905, Rec: 0.0888, lr: 0.00080\n",
      "Epoch 1/Step 660, Loss: -0.11071, Accuracy: 0.87118, F1: 0.0884, Prec: 0.2859, Rec: 0.0923, lr: 0.00080\n",
      "Epoch 1/Step 680, Loss: -0.10491, Accuracy: 0.87493, F1: 0.0905, Prec: 0.2815, Rec: 0.0954, lr: 0.00080\n",
      "Epoch 1/Step 700, Loss: -0.10606, Accuracy: 0.87846, F1: 0.0923, Prec: 0.2772, Rec: 0.0982, lr: 0.00080\n",
      "Epoch 1/Step 720, Loss: -0.11946, Accuracy: 0.88179, F1: 0.0942, Prec: 0.2733, Rec: 0.1011, lr: 0.00080\n",
      "Epoch 1/Step 740, Loss: -0.11619, Accuracy: 0.88495, F1: 0.0961, Prec: 0.2697, Rec: 0.1039, lr: 0.00080\n",
      "Epoch 1/Step 760, Loss: -0.12658, Accuracy: 0.88793, F1: 0.0980, Prec: 0.2663, Rec: 0.1066, lr: 0.00080\n",
      "Epoch 1/Step 780, Loss: -0.12691, Accuracy: 0.89077, F1: 0.0998, Prec: 0.2631, Rec: 0.1093, lr: 0.00080\n",
      "Epoch 1/Step 800, Loss: -0.10214, Accuracy: 0.89346, F1: 0.1013, Prec: 0.2598, Rec: 0.1118, lr: 0.00080\n",
      "Epoch 1/Step 820, Loss: -0.12034, Accuracy: 0.89603, F1: 0.1027, Prec: 0.2567, Rec: 0.1140, lr: 0.00080\n",
      "Epoch 1/Step 840, Loss: -0.13771, Accuracy: 0.89847, F1: 0.1043, Prec: 0.2538, Rec: 0.1166, lr: 0.00080\n",
      "Epoch 1/Step 860, Loss: -0.11511, Accuracy: 0.90080, F1: 0.1056, Prec: 0.2509, Rec: 0.1189, lr: 0.00080\n",
      "Epoch 1/Step 880, Loss: -0.10997, Accuracy: 0.90302, F1: 0.1070, Prec: 0.2484, Rec: 0.1212, lr: 0.00080\n",
      "Epoch 1/Step 900, Loss: -0.14548, Accuracy: 0.90514, F1: 0.1083, Prec: 0.2459, Rec: 0.1232, lr: 0.00080\n",
      "Epoch 1/Step 920, Loss: -0.11601, Accuracy: 0.90717, F1: 0.1096, Prec: 0.2435, Rec: 0.1253, lr: 0.00080\n",
      "Epoch 1/Step 940, Loss: -0.12334, Accuracy: 0.90912, F1: 0.1107, Prec: 0.2412, Rec: 0.1270, lr: 0.00080\n",
      "Epoch 1/Step 960, Loss: -0.13838, Accuracy: 0.91098, F1: 0.1119, Prec: 0.2390, Rec: 0.1289, lr: 0.00080\n",
      "Epoch 1/Step 980, Loss: -0.12477, Accuracy: 0.91277, F1: 0.1131, Prec: 0.2370, Rec: 0.1308, lr: 0.00080\n",
      "Epoch 1/Step 1000, Loss: -0.14831, Accuracy: 0.91449, F1: 0.1141, Prec: 0.2349, Rec: 0.1324, lr: 0.00080\n",
      "Epoch 1/Step 1020, Loss: -0.11814, Accuracy: 0.91614, F1: 0.1152, Prec: 0.2330, Rec: 0.1341, lr: 0.00080\n",
      "Epoch 1/Step 1040, Loss: -0.12248, Accuracy: 0.91772, F1: 0.1161, Prec: 0.2312, Rec: 0.1357, lr: 0.00080\n",
      "Epoch 1/Step 1060, Loss: -0.11969, Accuracy: 0.91925, F1: 0.1169, Prec: 0.2292, Rec: 0.1370, lr: 0.00080\n",
      "Epoch 1/Step 1080, Loss: -0.13113, Accuracy: 0.92072, F1: 0.1179, Prec: 0.2275, Rec: 0.1386, lr: 0.00080\n",
      "Epoch 1/Step 1100, Loss: -0.11996, Accuracy: 0.92214, F1: 0.1188, Prec: 0.2259, Rec: 0.1401, lr: 0.00080\n",
      "Epoch 1/Step 1120, Loss: -0.09859, Accuracy: 0.92350, F1: 0.1195, Prec: 0.2240, Rec: 0.1415, lr: 0.00080\n",
      "Epoch 1/Step 1140, Loss: -0.10722, Accuracy: 0.92482, F1: 0.1203, Prec: 0.2226, Rec: 0.1427, lr: 0.00080\n",
      "Epoch 1/Step 1160, Loss: -0.14127, Accuracy: 0.92609, F1: 0.1213, Prec: 0.2212, Rec: 0.1442, lr: 0.00080\n",
      "Epoch 1/Step 1180, Loss: -0.10830, Accuracy: 0.92732, F1: 0.1221, Prec: 0.2199, Rec: 0.1456, lr: 0.00080\n",
      "Epoch 1/Step 1200, Loss: -0.11298, Accuracy: 0.92851, F1: 0.1229, Prec: 0.2184, Rec: 0.1469, lr: 0.00080\n",
      "Epoch 1/Step 1220, Loss: -0.12040, Accuracy: 0.92966, F1: 0.1235, Prec: 0.2170, Rec: 0.1480, lr: 0.00080\n",
      "Epoch 1/Step 1240, Loss: -0.17941, Accuracy: 0.93078, F1: 0.1242, Prec: 0.2156, Rec: 0.1494, lr: 0.00080\n",
      "Epoch 1/Step 1260, Loss: -0.10864, Accuracy: 0.93185, F1: 0.1249, Prec: 0.2144, Rec: 0.1505, lr: 0.00080\n",
      "Epoch 1/Step 1280, Loss: -0.16491, Accuracy: 0.93290, F1: 0.1255, Prec: 0.2131, Rec: 0.1516, lr: 0.00080\n",
      "Epoch 1/Step 1300, Loss: -0.11002, Accuracy: 0.93391, F1: 0.1262, Prec: 0.2119, Rec: 0.1526, lr: 0.00080\n",
      "Epoch 1/Step 1320, Loss: -0.12462, Accuracy: 0.93489, F1: 0.1268, Prec: 0.2107, Rec: 0.1539, lr: 0.00080\n",
      "Epoch 1/Step 1340, Loss: -0.12815, Accuracy: 0.93584, F1: 0.1275, Prec: 0.2096, Rec: 0.1550, lr: 0.00080\n",
      "Epoch 1/Step 1360, Loss: -0.11891, Accuracy: 0.93677, F1: 0.1282, Prec: 0.2086, Rec: 0.1562, lr: 0.00080\n",
      "Epoch 1/Step 1380, Loss: -0.14101, Accuracy: 0.93766, F1: 0.1288, Prec: 0.2076, Rec: 0.1573, lr: 0.00080\n",
      "Epoch 1/Step 1400, Loss: -0.12682, Accuracy: 0.93854, F1: 0.1292, Prec: 0.2064, Rec: 0.1581, lr: 0.00080\n",
      "Epoch 1/Step 1420, Loss: -0.11613, Accuracy: 0.93938, F1: 0.1298, Prec: 0.2054, Rec: 0.1591, lr: 0.00080\n",
      "Epoch 1/Step 1440, Loss: -0.11378, Accuracy: 0.94021, F1: 0.1303, Prec: 0.2045, Rec: 0.1601, lr: 0.00080\n",
      "Epoch 1/Step 1460, Loss: -0.09936, Accuracy: 0.94101, F1: 0.1308, Prec: 0.2034, Rec: 0.1609, lr: 0.00080\n",
      "Epoch 1/Step 1480, Loss: -0.13851, Accuracy: 0.94179, F1: 0.1312, Prec: 0.2024, Rec: 0.1617, lr: 0.00080\n",
      "Epoch 1/Step 1500, Loss: -0.11521, Accuracy: 0.94254, F1: 0.1316, Prec: 0.2014, Rec: 0.1625, lr: 0.00080\n",
      "Epoch 1/Step 1520, Loss: -0.13514, Accuracy: 0.94328, F1: 0.1321, Prec: 0.2006, Rec: 0.1633, lr: 0.00080\n",
      "Epoch 1/Step 1540, Loss: -0.09877, Accuracy: 0.94400, F1: 0.1325, Prec: 0.1997, Rec: 0.1641, lr: 0.00080\n",
      "Epoch finished. Start validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 23:47:23.320391: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.9987\n",
      "Validation f1: 0.1683\n",
      "Validation precision: 0.1354\n",
      "Validation recall: 0.2259\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 23:48:17.659666: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-28 23:48:17.670400: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-28 23:48:17.681057: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-28 23:48:17.898306: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-28 23:48:17.946835: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-28 23:48:17.992751: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_0_valF1Score0.1683/assets\n",
      "\n",
      "Start of epoch 2\n",
      "Epoch 2/Step 0, Loss: -0.11588, Accuracy: 0.99877, F1: 0.1854, Prec: 0.1529, Rec: 0.2356, lr: 0.00080\n",
      "Epoch 2/Step 20, Loss: -0.12627, Accuracy: 0.99872, F1: 0.1707, Prec: 0.1366, Rec: 0.2292, lr: 0.00080\n",
      "Epoch 2/Step 40, Loss: -0.13540, Accuracy: 0.99874, F1: 0.1723, Prec: 0.1382, Rec: 0.2308, lr: 0.00080\n",
      "Epoch 2/Step 60, Loss: -0.14871, Accuracy: 0.99876, F1: 0.1729, Prec: 0.1390, Rec: 0.2313, lr: 0.00080\n",
      "Epoch 2/Step 80, Loss: -0.12752, Accuracy: 0.99877, F1: 0.1694, Prec: 0.1353, Rec: 0.2291, lr: 0.00080\n",
      "Epoch 2/Step 100, Loss: -0.14747, Accuracy: 0.99877, F1: 0.1696, Prec: 0.1351, Rec: 0.2306, lr: 0.00080\n",
      "Epoch 2/Step 120, Loss: -0.11717, Accuracy: 0.99876, F1: 0.1706, Prec: 0.1356, Rec: 0.2330, lr: 0.00080\n",
      "Epoch 2/Step 140, Loss: -0.12954, Accuracy: 0.99876, F1: 0.1701, Prec: 0.1353, Rec: 0.2324, lr: 0.00080\n",
      "Epoch 2/Step 160, Loss: -0.13317, Accuracy: 0.99875, F1: 0.1698, Prec: 0.1349, Rec: 0.2323, lr: 0.00080\n",
      "Epoch 2/Step 180, Loss: -0.11848, Accuracy: 0.99875, F1: 0.1690, Prec: 0.1340, Rec: 0.2321, lr: 0.00080\n",
      "Epoch 2/Step 200, Loss: -0.13328, Accuracy: 0.99874, F1: 0.1684, Prec: 0.1333, Rec: 0.2320, lr: 0.00080\n",
      "Epoch 2/Step 220, Loss: -0.14090, Accuracy: 0.99874, F1: 0.1685, Prec: 0.1334, Rec: 0.2318, lr: 0.00080\n",
      "Epoch 2/Step 240, Loss: -0.16587, Accuracy: 0.99874, F1: 0.1693, Prec: 0.1343, Rec: 0.2326, lr: 0.00080\n",
      "Epoch 2/Step 260, Loss: -0.14182, Accuracy: 0.99874, F1: 0.1694, Prec: 0.1343, Rec: 0.2329, lr: 0.00080\n",
      "Epoch 2/Step 280, Loss: -0.12740, Accuracy: 0.99873, F1: 0.1700, Prec: 0.1347, Rec: 0.2338, lr: 0.00080\n",
      "Epoch 2/Step 300, Loss: -0.15614, Accuracy: 0.99873, F1: 0.1697, Prec: 0.1346, Rec: 0.2332, lr: 0.00080\n",
      "Epoch 2/Step 320, Loss: -0.15936, Accuracy: 0.99874, F1: 0.1695, Prec: 0.1345, Rec: 0.2326, lr: 0.00080\n",
      "Epoch 2/Step 340, Loss: -0.14364, Accuracy: 0.99874, F1: 0.1697, Prec: 0.1346, Rec: 0.2328, lr: 0.00080\n",
      "Epoch 2/Step 360, Loss: -0.15979, Accuracy: 0.99874, F1: 0.1698, Prec: 0.1346, Rec: 0.2331, lr: 0.00080\n",
      "Epoch 2/Step 380, Loss: -0.16937, Accuracy: 0.99874, F1: 0.1697, Prec: 0.1348, Rec: 0.2324, lr: 0.00080\n",
      "Epoch 2/Step 400, Loss: -0.10235, Accuracy: 0.99874, F1: 0.1692, Prec: 0.1344, Rec: 0.2319, lr: 0.00080\n",
      "Epoch 2/Step 420, Loss: -0.14642, Accuracy: 0.99875, F1: 0.1691, Prec: 0.1342, Rec: 0.2317, lr: 0.00080\n",
      "Epoch 2/Step 440, Loss: -0.11394, Accuracy: 0.99875, F1: 0.1694, Prec: 0.1345, Rec: 0.2321, lr: 0.00080\n",
      "Epoch 2/Step 460, Loss: -0.11775, Accuracy: 0.99875, F1: 0.1693, Prec: 0.1344, Rec: 0.2321, lr: 0.00080\n",
      "Epoch 2/Step 480, Loss: -0.12570, Accuracy: 0.99875, F1: 0.1696, Prec: 0.1346, Rec: 0.2324, lr: 0.00080\n",
      "Epoch 2/Step 500, Loss: -0.14592, Accuracy: 0.99875, F1: 0.1697, Prec: 0.1347, Rec: 0.2325, lr: 0.00080\n",
      "Epoch 2/Step 520, Loss: -0.11653, Accuracy: 0.99875, F1: 0.1698, Prec: 0.1348, Rec: 0.2329, lr: 0.00080\n",
      "Epoch 2/Step 540, Loss: -0.11047, Accuracy: 0.99875, F1: 0.1696, Prec: 0.1345, Rec: 0.2328, lr: 0.00080\n",
      "Epoch 2/Step 560, Loss: -0.15573, Accuracy: 0.99875, F1: 0.1699, Prec: 0.1348, Rec: 0.2329, lr: 0.00080\n",
      "Epoch 2/Step 580, Loss: -0.15168, Accuracy: 0.99875, F1: 0.1700, Prec: 0.1348, Rec: 0.2331, lr: 0.00080\n",
      "Epoch 2/Step 600, Loss: -0.10560, Accuracy: 0.99875, F1: 0.1697, Prec: 0.1345, Rec: 0.2333, lr: 0.00080\n",
      "Epoch 2/Step 620, Loss: -0.16017, Accuracy: 0.99875, F1: 0.1699, Prec: 0.1345, Rec: 0.2341, lr: 0.00080\n",
      "Epoch 2/Step 640, Loss: -0.12755, Accuracy: 0.99875, F1: 0.1704, Prec: 0.1349, Rec: 0.2346, lr: 0.00080\n",
      "Epoch 2/Step 660, Loss: -0.12944, Accuracy: 0.99875, F1: 0.1707, Prec: 0.1351, Rec: 0.2351, lr: 0.00080\n",
      "Epoch 2/Step 680, Loss: -0.10954, Accuracy: 0.99875, F1: 0.1707, Prec: 0.1351, Rec: 0.2351, lr: 0.00080\n",
      "Epoch 2/Step 700, Loss: -0.12539, Accuracy: 0.99876, F1: 0.1706, Prec: 0.1350, Rec: 0.2349, lr: 0.00080\n",
      "Epoch 2/Step 720, Loss: -0.13891, Accuracy: 0.99876, F1: 0.1706, Prec: 0.1350, Rec: 0.2350, lr: 0.00080\n",
      "Epoch 2/Step 740, Loss: -0.12792, Accuracy: 0.99876, F1: 0.1707, Prec: 0.1351, Rec: 0.2352, lr: 0.00080\n",
      "Epoch 2/Step 760, Loss: -0.13478, Accuracy: 0.99876, F1: 0.1708, Prec: 0.1352, Rec: 0.2354, lr: 0.00080\n",
      "Epoch 2/Step 780, Loss: -0.13720, Accuracy: 0.99876, F1: 0.1711, Prec: 0.1354, Rec: 0.2358, lr: 0.00080\n",
      "Epoch 2/Step 800, Loss: -0.11042, Accuracy: 0.99876, F1: 0.1711, Prec: 0.1353, Rec: 0.2360, lr: 0.00080\n",
      "Epoch 2/Step 820, Loss: -0.12572, Accuracy: 0.99876, F1: 0.1710, Prec: 0.1352, Rec: 0.2359, lr: 0.00080\n",
      "Epoch 2/Step 840, Loss: -0.15494, Accuracy: 0.99876, F1: 0.1711, Prec: 0.1352, Rec: 0.2362, lr: 0.00080\n",
      "Epoch 2/Step 860, Loss: -0.13287, Accuracy: 0.99876, F1: 0.1711, Prec: 0.1352, Rec: 0.2364, lr: 0.00080\n",
      "Epoch 2/Step 880, Loss: -0.12212, Accuracy: 0.99876, F1: 0.1712, Prec: 0.1352, Rec: 0.2366, lr: 0.00080\n",
      "Epoch 2/Step 900, Loss: -0.15608, Accuracy: 0.99876, F1: 0.1713, Prec: 0.1353, Rec: 0.2368, lr: 0.00080\n",
      "Epoch 2/Step 920, Loss: -0.11980, Accuracy: 0.99876, F1: 0.1715, Prec: 0.1354, Rec: 0.2371, lr: 0.00080\n",
      "Epoch 2/Step 940, Loss: -0.12674, Accuracy: 0.99876, F1: 0.1714, Prec: 0.1354, Rec: 0.2369, lr: 0.00080\n",
      "Epoch 2/Step 960, Loss: -0.13960, Accuracy: 0.99876, F1: 0.1716, Prec: 0.1355, Rec: 0.2371, lr: 0.00080\n",
      "Epoch 2/Step 980, Loss: -0.12967, Accuracy: 0.99876, F1: 0.1717, Prec: 0.1356, Rec: 0.2373, lr: 0.00080\n",
      "Epoch 2/Step 1000, Loss: -0.15801, Accuracy: 0.99876, F1: 0.1717, Prec: 0.1356, Rec: 0.2374, lr: 0.00080\n",
      "Epoch 2/Step 1020, Loss: -0.13334, Accuracy: 0.99876, F1: 0.1719, Prec: 0.1358, Rec: 0.2375, lr: 0.00080\n",
      "Epoch 2/Step 1040, Loss: -0.12993, Accuracy: 0.99876, F1: 0.1719, Prec: 0.1358, Rec: 0.2376, lr: 0.00080\n",
      "Epoch 2/Step 1060, Loss: -0.12940, Accuracy: 0.99876, F1: 0.1718, Prec: 0.1357, Rec: 0.2375, lr: 0.00080\n",
      "Epoch 2/Step 1080, Loss: -0.14357, Accuracy: 0.99876, F1: 0.1720, Prec: 0.1358, Rec: 0.2377, lr: 0.00080\n",
      "Epoch 2/Step 1100, Loss: -0.13678, Accuracy: 0.99876, F1: 0.1721, Prec: 0.1359, Rec: 0.2378, lr: 0.00080\n",
      "Epoch 2/Step 1120, Loss: -0.10572, Accuracy: 0.99876, F1: 0.1720, Prec: 0.1358, Rec: 0.2379, lr: 0.00080\n",
      "Epoch 2/Step 1140, Loss: -0.11523, Accuracy: 0.99876, F1: 0.1721, Prec: 0.1359, Rec: 0.2379, lr: 0.00080\n",
      "Epoch 2/Step 1160, Loss: -0.14841, Accuracy: 0.99876, F1: 0.1722, Prec: 0.1361, Rec: 0.2380, lr: 0.00080\n",
      "Epoch 2/Step 1180, Loss: -0.11801, Accuracy: 0.99876, F1: 0.1724, Prec: 0.1362, Rec: 0.2382, lr: 0.00080\n",
      "Epoch 2/Step 1200, Loss: -0.12400, Accuracy: 0.99876, F1: 0.1724, Prec: 0.1362, Rec: 0.2383, lr: 0.00080\n",
      "Epoch 2/Step 1220, Loss: -0.13201, Accuracy: 0.99876, F1: 0.1724, Prec: 0.1363, Rec: 0.2382, lr: 0.00080\n",
      "Epoch 2/Step 1240, Loss: -0.19161, Accuracy: 0.99876, F1: 0.1725, Prec: 0.1363, Rec: 0.2384, lr: 0.00080\n",
      "Epoch 2/Step 1260, Loss: -0.12451, Accuracy: 0.99876, F1: 0.1726, Prec: 0.1363, Rec: 0.2384, lr: 0.00080\n",
      "Epoch 2/Step 1280, Loss: -0.18050, Accuracy: 0.99876, F1: 0.1726, Prec: 0.1363, Rec: 0.2384, lr: 0.00080\n",
      "Epoch 2/Step 1300, Loss: -0.11249, Accuracy: 0.99876, F1: 0.1726, Prec: 0.1364, Rec: 0.2385, lr: 0.00080\n",
      "Epoch 2/Step 1320, Loss: -0.13354, Accuracy: 0.99875, F1: 0.1727, Prec: 0.1364, Rec: 0.2387, lr: 0.00080\n",
      "Epoch 2/Step 1340, Loss: -0.13208, Accuracy: 0.99875, F1: 0.1728, Prec: 0.1365, Rec: 0.2389, lr: 0.00080\n",
      "Epoch 2/Step 1360, Loss: -0.12751, Accuracy: 0.99876, F1: 0.1729, Prec: 0.1365, Rec: 0.2391, lr: 0.00080\n",
      "Epoch 2/Step 1380, Loss: -0.15293, Accuracy: 0.99876, F1: 0.1729, Prec: 0.1366, Rec: 0.2392, lr: 0.00080\n",
      "Epoch 2/Step 1400, Loss: -0.13814, Accuracy: 0.99876, F1: 0.1729, Prec: 0.1365, Rec: 0.2391, lr: 0.00080\n",
      "Epoch 2/Step 1420, Loss: -0.12086, Accuracy: 0.99876, F1: 0.1729, Prec: 0.1365, Rec: 0.2392, lr: 0.00080\n",
      "Epoch 2/Step 1440, Loss: -0.12235, Accuracy: 0.99876, F1: 0.1730, Prec: 0.1365, Rec: 0.2394, lr: 0.00080\n",
      "Epoch 2/Step 1460, Loss: -0.10349, Accuracy: 0.99876, F1: 0.1729, Prec: 0.1364, Rec: 0.2395, lr: 0.00080\n",
      "Epoch 2/Step 1480, Loss: -0.14085, Accuracy: 0.99876, F1: 0.1728, Prec: 0.1364, Rec: 0.2395, lr: 0.00080\n",
      "Epoch 2/Step 1500, Loss: -0.12201, Accuracy: 0.99876, F1: 0.1728, Prec: 0.1363, Rec: 0.2395, lr: 0.00080\n",
      "Epoch 2/Step 1520, Loss: -0.14815, Accuracy: 0.99876, F1: 0.1729, Prec: 0.1364, Rec: 0.2396, lr: 0.00080\n",
      "Epoch 2/Step 1540, Loss: -0.10130, Accuracy: 0.99876, F1: 0.1729, Prec: 0.1363, Rec: 0.2397, lr: 0.00080\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9988\n",
      "Validation f1: 0.1710\n",
      "Validation precision: 0.1334\n",
      "Validation recall: 0.2422\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 23:51:18.598330: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-28 23:51:18.609430: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-28 23:51:18.619562: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-28 23:51:18.805745: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-28 23:51:18.852889: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-28 23:51:18.897177: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_1_valF1Score0.1710/assets\n",
      "\n",
      "Start of epoch 3\n",
      "Epoch 3/Step 0, Loss: -0.13135, Accuracy: 0.99884, F1: 0.1917, Prec: 0.1532, Rec: 0.2561, lr: 0.00080\n",
      "Epoch 3/Step 20, Loss: -0.13526, Accuracy: 0.99878, F1: 0.1798, Prec: 0.1405, Rec: 0.2519, lr: 0.00080\n",
      "Epoch 3/Step 40, Loss: -0.13635, Accuracy: 0.99879, F1: 0.1799, Prec: 0.1405, Rec: 0.2522, lr: 0.00080\n",
      "Epoch 3/Step 60, Loss: -0.15822, Accuracy: 0.99881, F1: 0.1808, Prec: 0.1416, Rec: 0.2526, lr: 0.00080\n",
      "Epoch 3/Step 80, Loss: -0.13389, Accuracy: 0.99882, F1: 0.1766, Prec: 0.1378, Rec: 0.2484, lr: 0.00080\n",
      "Epoch 3/Step 100, Loss: -0.15814, Accuracy: 0.99882, F1: 0.1766, Prec: 0.1375, Rec: 0.2493, lr: 0.00080\n",
      "Epoch 3/Step 120, Loss: -0.12739, Accuracy: 0.99881, F1: 0.1771, Prec: 0.1377, Rec: 0.2510, lr: 0.00080\n",
      "Epoch 3/Step 140, Loss: -0.14482, Accuracy: 0.99880, F1: 0.1768, Prec: 0.1376, Rec: 0.2506, lr: 0.00080\n",
      "Epoch 3/Step 160, Loss: -0.14049, Accuracy: 0.99880, F1: 0.1764, Prec: 0.1371, Rec: 0.2505, lr: 0.00080\n",
      "Epoch 3/Step 180, Loss: -0.13253, Accuracy: 0.99880, F1: 0.1756, Prec: 0.1363, Rec: 0.2501, lr: 0.00080\n",
      "Epoch 3/Step 200, Loss: -0.14367, Accuracy: 0.99879, F1: 0.1749, Prec: 0.1354, Rec: 0.2502, lr: 0.00080\n",
      "Epoch 3/Step 220, Loss: -0.14811, Accuracy: 0.99879, F1: 0.1752, Prec: 0.1355, Rec: 0.2508, lr: 0.00080\n",
      "Epoch 3/Step 240, Loss: -0.16866, Accuracy: 0.99879, F1: 0.1760, Prec: 0.1363, Rec: 0.2518, lr: 0.00080\n",
      "Epoch 3/Step 260, Loss: -0.15151, Accuracy: 0.99879, F1: 0.1761, Prec: 0.1363, Rec: 0.2519, lr: 0.00080\n",
      "Epoch 3/Step 280, Loss: -0.13020, Accuracy: 0.99878, F1: 0.1764, Prec: 0.1365, Rec: 0.2528, lr: 0.00080\n",
      "Epoch 3/Step 300, Loss: -0.16879, Accuracy: 0.99878, F1: 0.1761, Prec: 0.1362, Rec: 0.2524, lr: 0.00080\n",
      "Epoch 3/Step 320, Loss: -0.17375, Accuracy: 0.99879, F1: 0.1759, Prec: 0.1362, Rec: 0.2517, lr: 0.00080\n",
      "Epoch 3/Step 340, Loss: -0.14809, Accuracy: 0.99879, F1: 0.1760, Prec: 0.1362, Rec: 0.2521, lr: 0.00080\n",
      "Epoch 3/Step 360, Loss: -0.16404, Accuracy: 0.99879, F1: 0.1761, Prec: 0.1363, Rec: 0.2522, lr: 0.00080\n",
      "Epoch 3/Step 380, Loss: -0.17777, Accuracy: 0.99879, F1: 0.1758, Prec: 0.1363, Rec: 0.2510, lr: 0.00080\n",
      "Epoch 3/Step 400, Loss: -0.10710, Accuracy: 0.99879, F1: 0.1752, Prec: 0.1358, Rec: 0.2505, lr: 0.00080\n",
      "Epoch 3/Step 420, Loss: -0.14934, Accuracy: 0.99879, F1: 0.1750, Prec: 0.1356, Rec: 0.2502, lr: 0.00080\n",
      "Epoch 3/Step 440, Loss: -0.12888, Accuracy: 0.99879, F1: 0.1752, Prec: 0.1357, Rec: 0.2504, lr: 0.00080\n",
      "Epoch 3/Step 460, Loss: -0.12580, Accuracy: 0.99879, F1: 0.1750, Prec: 0.1356, Rec: 0.2503, lr: 0.00080\n",
      "Epoch 3/Step 480, Loss: -0.12868, Accuracy: 0.99879, F1: 0.1753, Prec: 0.1358, Rec: 0.2506, lr: 0.00080\n",
      "Epoch 3/Step 500, Loss: -0.15080, Accuracy: 0.99879, F1: 0.1753, Prec: 0.1359, Rec: 0.2505, lr: 0.00080\n",
      "Epoch 3/Step 520, Loss: -0.11663, Accuracy: 0.99879, F1: 0.1754, Prec: 0.1359, Rec: 0.2506, lr: 0.00080\n",
      "Epoch 3/Step 540, Loss: -0.11488, Accuracy: 0.99879, F1: 0.1752, Prec: 0.1358, Rec: 0.2504, lr: 0.00080\n",
      "Epoch 3/Step 560, Loss: -0.15339, Accuracy: 0.99879, F1: 0.1754, Prec: 0.1360, Rec: 0.2504, lr: 0.00080\n",
      "Epoch 3/Step 580, Loss: -0.15815, Accuracy: 0.99879, F1: 0.1755, Prec: 0.1361, Rec: 0.2506, lr: 0.00080\n",
      "Epoch 3/Step 600, Loss: -0.11265, Accuracy: 0.99879, F1: 0.1753, Prec: 0.1358, Rec: 0.2506, lr: 0.00080\n",
      "Epoch 3/Step 620, Loss: -0.17296, Accuracy: 0.99879, F1: 0.1754, Prec: 0.1358, Rec: 0.2513, lr: 0.00080\n",
      "Epoch 3/Step 640, Loss: -0.13292, Accuracy: 0.99879, F1: 0.1759, Prec: 0.1362, Rec: 0.2518, lr: 0.00080\n",
      "Epoch 3/Step 660, Loss: -0.13607, Accuracy: 0.99879, F1: 0.1762, Prec: 0.1365, Rec: 0.2522, lr: 0.00080\n",
      "Epoch 3/Step 680, Loss: -0.11254, Accuracy: 0.99879, F1: 0.1763, Prec: 0.1365, Rec: 0.2522, lr: 0.00080\n",
      "Epoch 3/Step 700, Loss: -0.12298, Accuracy: 0.99880, F1: 0.1760, Prec: 0.1364, Rec: 0.2519, lr: 0.00080\n",
      "Epoch 3/Step 720, Loss: -0.14421, Accuracy: 0.99880, F1: 0.1761, Prec: 0.1364, Rec: 0.2519, lr: 0.00080\n",
      "Epoch 3/Step 740, Loss: -0.13816, Accuracy: 0.99880, F1: 0.1762, Prec: 0.1365, Rec: 0.2520, lr: 0.00080\n",
      "Epoch 3/Step 760, Loss: -0.14579, Accuracy: 0.99880, F1: 0.1763, Prec: 0.1366, Rec: 0.2523, lr: 0.00080\n",
      "Epoch 3/Step 780, Loss: -0.13952, Accuracy: 0.99880, F1: 0.1766, Prec: 0.1368, Rec: 0.2526, lr: 0.00080\n",
      "Epoch 3/Step 800, Loss: -0.11098, Accuracy: 0.99880, F1: 0.1766, Prec: 0.1368, Rec: 0.2528, lr: 0.00080\n",
      "Epoch 3/Step 820, Loss: -0.13794, Accuracy: 0.99880, F1: 0.1766, Prec: 0.1368, Rec: 0.2527, lr: 0.00080\n",
      "Epoch 3/Step 840, Loss: -0.16301, Accuracy: 0.99880, F1: 0.1767, Prec: 0.1368, Rec: 0.2531, lr: 0.00080\n",
      "Epoch 3/Step 860, Loss: -0.13486, Accuracy: 0.99880, F1: 0.1767, Prec: 0.1367, Rec: 0.2532, lr: 0.00080\n",
      "Epoch 3/Step 880, Loss: -0.12893, Accuracy: 0.99880, F1: 0.1768, Prec: 0.1369, Rec: 0.2534, lr: 0.00080\n",
      "Epoch 3/Step 900, Loss: -0.16347, Accuracy: 0.99880, F1: 0.1769, Prec: 0.1370, Rec: 0.2535, lr: 0.00080\n",
      "Epoch 3/Step 920, Loss: -0.12786, Accuracy: 0.99879, F1: 0.1771, Prec: 0.1371, Rec: 0.2539, lr: 0.00080\n",
      "Epoch 3/Step 940, Loss: -0.13554, Accuracy: 0.99880, F1: 0.1770, Prec: 0.1371, Rec: 0.2536, lr: 0.00080\n",
      "Epoch 3/Step 960, Loss: -0.15692, Accuracy: 0.99880, F1: 0.1772, Prec: 0.1372, Rec: 0.2538, lr: 0.00080\n",
      "Epoch 3/Step 980, Loss: -0.13416, Accuracy: 0.99880, F1: 0.1773, Prec: 0.1373, Rec: 0.2540, lr: 0.00080\n",
      "Epoch 3/Step 1000, Loss: -0.15962, Accuracy: 0.99880, F1: 0.1774, Prec: 0.1373, Rec: 0.2542, lr: 0.00080\n",
      "Epoch 3/Step 1020, Loss: -0.14268, Accuracy: 0.99880, F1: 0.1775, Prec: 0.1374, Rec: 0.2543, lr: 0.00080\n",
      "Epoch 3/Step 1040, Loss: -0.13252, Accuracy: 0.99880, F1: 0.1775, Prec: 0.1374, Rec: 0.2543, lr: 0.00080\n",
      "Epoch 3/Step 1060, Loss: -0.13060, Accuracy: 0.99880, F1: 0.1774, Prec: 0.1373, Rec: 0.2542, lr: 0.00080\n",
      "Epoch 3/Step 1080, Loss: -0.15229, Accuracy: 0.99880, F1: 0.1775, Prec: 0.1373, Rec: 0.2544, lr: 0.00080\n",
      "Epoch 3/Step 1100, Loss: -0.14350, Accuracy: 0.99880, F1: 0.1775, Prec: 0.1373, Rec: 0.2545, lr: 0.00080\n",
      "Epoch 3/Step 1120, Loss: -0.10974, Accuracy: 0.99880, F1: 0.1774, Prec: 0.1372, Rec: 0.2546, lr: 0.00080\n",
      "Epoch 3/Step 1140, Loss: -0.11873, Accuracy: 0.99880, F1: 0.1775, Prec: 0.1373, Rec: 0.2546, lr: 0.00080\n",
      "Epoch 3/Step 1160, Loss: -0.16403, Accuracy: 0.99880, F1: 0.1776, Prec: 0.1374, Rec: 0.2546, lr: 0.00080\n",
      "Epoch 3/Step 1180, Loss: -0.12592, Accuracy: 0.99880, F1: 0.1777, Prec: 0.1375, Rec: 0.2548, lr: 0.00080\n",
      "Epoch 3/Step 1200, Loss: -0.12829, Accuracy: 0.99880, F1: 0.1777, Prec: 0.1375, Rec: 0.2547, lr: 0.00080\n",
      "Epoch 3/Step 1220, Loss: -0.13494, Accuracy: 0.99880, F1: 0.1778, Prec: 0.1376, Rec: 0.2546, lr: 0.00080\n",
      "Epoch 3/Step 1240, Loss: -0.20487, Accuracy: 0.99880, F1: 0.1779, Prec: 0.1377, Rec: 0.2548, lr: 0.00080\n",
      "Epoch 3/Step 1260, Loss: -0.13167, Accuracy: 0.99880, F1: 0.1779, Prec: 0.1378, Rec: 0.2548, lr: 0.00080\n",
      "Epoch 3/Step 1280, Loss: -0.18805, Accuracy: 0.99880, F1: 0.1779, Prec: 0.1378, Rec: 0.2548, lr: 0.00080\n",
      "Epoch 3/Step 1300, Loss: -0.11311, Accuracy: 0.99880, F1: 0.1780, Prec: 0.1378, Rec: 0.2549, lr: 0.00080\n",
      "Epoch 3/Step 1320, Loss: -0.13599, Accuracy: 0.99880, F1: 0.1780, Prec: 0.1379, Rec: 0.2550, lr: 0.00080\n",
      "Epoch 3/Step 1340, Loss: -0.14742, Accuracy: 0.99880, F1: 0.1782, Prec: 0.1379, Rec: 0.2552, lr: 0.00080\n",
      "Epoch 3/Step 1360, Loss: -0.13740, Accuracy: 0.99880, F1: 0.1783, Prec: 0.1380, Rec: 0.2554, lr: 0.00080\n",
      "Epoch 3/Step 1380, Loss: -0.15652, Accuracy: 0.99880, F1: 0.1783, Prec: 0.1381, Rec: 0.2555, lr: 0.00080\n",
      "Epoch 3/Step 1400, Loss: -0.14543, Accuracy: 0.99880, F1: 0.1783, Prec: 0.1381, Rec: 0.2553, lr: 0.00080\n",
      "Epoch 3/Step 1420, Loss: -0.12613, Accuracy: 0.99880, F1: 0.1783, Prec: 0.1381, Rec: 0.2554, lr: 0.00080\n",
      "Epoch 3/Step 1440, Loss: -0.12491, Accuracy: 0.99880, F1: 0.1784, Prec: 0.1381, Rec: 0.2555, lr: 0.00080\n",
      "Epoch 3/Step 1460, Loss: -0.10725, Accuracy: 0.99880, F1: 0.1783, Prec: 0.1380, Rec: 0.2555, lr: 0.00080\n",
      "Epoch 3/Step 1480, Loss: -0.14344, Accuracy: 0.99880, F1: 0.1782, Prec: 0.1379, Rec: 0.2555, lr: 0.00080\n",
      "Epoch 3/Step 1500, Loss: -0.13390, Accuracy: 0.99880, F1: 0.1782, Prec: 0.1379, Rec: 0.2556, lr: 0.00080\n",
      "Epoch 3/Step 1520, Loss: -0.16255, Accuracy: 0.99880, F1: 0.1783, Prec: 0.1380, Rec: 0.2555, lr: 0.00080\n",
      "Epoch 3/Step 1540, Loss: -0.10654, Accuracy: 0.99880, F1: 0.1783, Prec: 0.1380, Rec: 0.2556, lr: 0.00080\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9988\n",
      "Validation f1: 0.1734\n",
      "Validation precision: 0.1334\n",
      "Validation recall: 0.2521\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 23:54:17.289743: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-28 23:54:17.299852: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-28 23:54:17.310822: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-28 23:54:17.497174: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-28 23:54:17.543986: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-28 23:54:17.588383: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_2_valF1Score0.1734/assets\n",
      "\n",
      "Start of epoch 4\n",
      "Epoch 4/Step 0, Loss: -0.12433, Accuracy: 0.99883, F1: 0.1977, Prec: 0.1566, Rec: 0.2680, lr: 0.00080\n",
      "Epoch 4/Step 20, Loss: -0.13731, Accuracy: 0.99880, F1: 0.1821, Prec: 0.1413, Rec: 0.2589, lr: 0.00080\n",
      "Epoch 4/Step 40, Loss: -0.14679, Accuracy: 0.99881, F1: 0.1838, Prec: 0.1428, Rec: 0.2603, lr: 0.00080\n",
      "Epoch 4/Step 60, Loss: -0.16204, Accuracy: 0.99883, F1: 0.1849, Prec: 0.1439, Rec: 0.2615, lr: 0.00080\n",
      "Epoch 4/Step 80, Loss: -0.13512, Accuracy: 0.99884, F1: 0.1805, Prec: 0.1397, Rec: 0.2578, lr: 0.00080\n",
      "Epoch 4/Step 100, Loss: -0.16153, Accuracy: 0.99884, F1: 0.1806, Prec: 0.1393, Rec: 0.2596, lr: 0.00080\n",
      "Epoch 4/Step 120, Loss: -0.12858, Accuracy: 0.99883, F1: 0.1814, Prec: 0.1398, Rec: 0.2619, lr: 0.00080\n",
      "Epoch 4/Step 140, Loss: -0.14941, Accuracy: 0.99882, F1: 0.1814, Prec: 0.1398, Rec: 0.2618, lr: 0.00080\n",
      "Epoch 4/Step 160, Loss: -0.14506, Accuracy: 0.99882, F1: 0.1810, Prec: 0.1392, Rec: 0.2619, lr: 0.00080\n",
      "Epoch 4/Step 180, Loss: -0.13601, Accuracy: 0.99882, F1: 0.1802, Prec: 0.1385, Rec: 0.2613, lr: 0.00080\n",
      "Epoch 4/Step 200, Loss: -0.15168, Accuracy: 0.99881, F1: 0.1795, Prec: 0.1376, Rec: 0.2619, lr: 0.00080\n",
      "Epoch 4/Step 220, Loss: -0.15379, Accuracy: 0.99881, F1: 0.1797, Prec: 0.1376, Rec: 0.2625, lr: 0.00080\n",
      "Epoch 4/Step 240, Loss: -0.17639, Accuracy: 0.99881, F1: 0.1803, Prec: 0.1381, Rec: 0.2634, lr: 0.00080\n",
      "Epoch 4/Step 260, Loss: -0.15367, Accuracy: 0.99881, F1: 0.1803, Prec: 0.1380, Rec: 0.2635, lr: 0.00080\n",
      "Epoch 4/Step 280, Loss: -0.13897, Accuracy: 0.99881, F1: 0.1808, Prec: 0.1384, Rec: 0.2642, lr: 0.00080\n",
      "Epoch 4/Step 300, Loss: -0.17484, Accuracy: 0.99881, F1: 0.1804, Prec: 0.1381, Rec: 0.2637, lr: 0.00080\n",
      "Epoch 4/Step 320, Loss: -0.17562, Accuracy: 0.99881, F1: 0.1802, Prec: 0.1381, Rec: 0.2630, lr: 0.00080\n",
      "Epoch 4/Step 340, Loss: -0.15367, Accuracy: 0.99881, F1: 0.1804, Prec: 0.1381, Rec: 0.2634, lr: 0.00080\n",
      "Epoch 4/Step 360, Loss: -0.16603, Accuracy: 0.99881, F1: 0.1806, Prec: 0.1384, Rec: 0.2635, lr: 0.00080\n",
      "Epoch 4/Step 380, Loss: -0.17998, Accuracy: 0.99881, F1: 0.1803, Prec: 0.1383, Rec: 0.2623, lr: 0.00080\n",
      "Epoch 4/Step 400, Loss: -0.11047, Accuracy: 0.99881, F1: 0.1797, Prec: 0.1379, Rec: 0.2616, lr: 0.00080\n",
      "Epoch 4/Step 420, Loss: -0.15324, Accuracy: 0.99881, F1: 0.1794, Prec: 0.1377, Rec: 0.2611, lr: 0.00080\n",
      "Epoch 4/Step 440, Loss: -0.13976, Accuracy: 0.99881, F1: 0.1797, Prec: 0.1380, Rec: 0.2613, lr: 0.00080\n",
      "Epoch 4/Step 460, Loss: -0.12873, Accuracy: 0.99881, F1: 0.1796, Prec: 0.1380, Rec: 0.2611, lr: 0.00080\n",
      "Epoch 4/Step 480, Loss: -0.13325, Accuracy: 0.99881, F1: 0.1797, Prec: 0.1380, Rec: 0.2613, lr: 0.00080\n",
      "Epoch 4/Step 500, Loss: -0.15587, Accuracy: 0.99881, F1: 0.1798, Prec: 0.1381, Rec: 0.2614, lr: 0.00080\n",
      "Epoch 4/Step 520, Loss: -0.12236, Accuracy: 0.99882, F1: 0.1799, Prec: 0.1382, Rec: 0.2615, lr: 0.00080\n",
      "Epoch 4/Step 540, Loss: -0.12087, Accuracy: 0.99881, F1: 0.1797, Prec: 0.1380, Rec: 0.2613, lr: 0.00080\n",
      "Epoch 4/Step 560, Loss: -0.16437, Accuracy: 0.99881, F1: 0.1799, Prec: 0.1382, Rec: 0.2612, lr: 0.00080\n",
      "Epoch 4/Step 580, Loss: -0.16260, Accuracy: 0.99881, F1: 0.1800, Prec: 0.1383, Rec: 0.2613, lr: 0.00080\n",
      "Epoch 4/Step 600, Loss: -0.10988, Accuracy: 0.99881, F1: 0.1797, Prec: 0.1379, Rec: 0.2614, lr: 0.00080\n",
      "Epoch 4/Step 620, Loss: -0.17460, Accuracy: 0.99881, F1: 0.1799, Prec: 0.1380, Rec: 0.2622, lr: 0.00080\n",
      "Epoch 4/Step 640, Loss: -0.13808, Accuracy: 0.99881, F1: 0.1804, Prec: 0.1384, Rec: 0.2626, lr: 0.00080\n",
      "Epoch 4/Step 660, Loss: -0.14955, Accuracy: 0.99881, F1: 0.1807, Prec: 0.1386, Rec: 0.2630, lr: 0.00080\n",
      "Epoch 4/Step 680, Loss: -0.11958, Accuracy: 0.99882, F1: 0.1808, Prec: 0.1388, Rec: 0.2629, lr: 0.00080\n",
      "Epoch 4/Step 700, Loss: -0.12356, Accuracy: 0.99882, F1: 0.1806, Prec: 0.1387, Rec: 0.2625, lr: 0.00080\n",
      "Epoch 4/Step 720, Loss: -0.15139, Accuracy: 0.99882, F1: 0.1807, Prec: 0.1388, Rec: 0.2624, lr: 0.00080\n",
      "Epoch 4/Step 740, Loss: -0.14315, Accuracy: 0.99882, F1: 0.1808, Prec: 0.1389, Rec: 0.2626, lr: 0.00080\n",
      "Epoch 4/Step 760, Loss: -0.15013, Accuracy: 0.99882, F1: 0.1809, Prec: 0.1389, Rec: 0.2628, lr: 0.00080\n",
      "Epoch 4/Step 780, Loss: -0.14107, Accuracy: 0.99882, F1: 0.1811, Prec: 0.1391, Rec: 0.2631, lr: 0.00080\n",
      "Epoch 4/Step 800, Loss: -0.11355, Accuracy: 0.99882, F1: 0.1811, Prec: 0.1390, Rec: 0.2633, lr: 0.00080\n",
      "Epoch 4/Step 820, Loss: -0.13893, Accuracy: 0.99882, F1: 0.1810, Prec: 0.1390, Rec: 0.2630, lr: 0.00080\n",
      "Epoch 4/Step 840, Loss: -0.16681, Accuracy: 0.99882, F1: 0.1811, Prec: 0.1390, Rec: 0.2633, lr: 0.00080\n",
      "Epoch 4/Step 860, Loss: -0.14277, Accuracy: 0.99882, F1: 0.1810, Prec: 0.1389, Rec: 0.2633, lr: 0.00080\n",
      "Epoch 4/Step 880, Loss: -0.13043, Accuracy: 0.99882, F1: 0.1811, Prec: 0.1390, Rec: 0.2635, lr: 0.00080\n",
      "Epoch 4/Step 900, Loss: -0.17715, Accuracy: 0.99882, F1: 0.1812, Prec: 0.1392, Rec: 0.2636, lr: 0.00080\n",
      "Epoch 4/Step 920, Loss: -0.13070, Accuracy: 0.99882, F1: 0.1814, Prec: 0.1392, Rec: 0.2638, lr: 0.00080\n",
      "Epoch 4/Step 940, Loss: -0.14955, Accuracy: 0.99882, F1: 0.1813, Prec: 0.1392, Rec: 0.2634, lr: 0.00080\n",
      "Epoch 4/Step 960, Loss: -0.16537, Accuracy: 0.99882, F1: 0.1814, Prec: 0.1393, Rec: 0.2636, lr: 0.00080\n",
      "Epoch 4/Step 980, Loss: -0.13776, Accuracy: 0.99882, F1: 0.1815, Prec: 0.1394, Rec: 0.2638, lr: 0.00080\n",
      "Epoch 4/Step 1000, Loss: -0.16907, Accuracy: 0.99882, F1: 0.1815, Prec: 0.1394, Rec: 0.2638, lr: 0.00080\n",
      "Epoch 4/Step 1020, Loss: -0.14073, Accuracy: 0.99882, F1: 0.1817, Prec: 0.1396, Rec: 0.2639, lr: 0.00080\n",
      "Epoch 4/Step 1040, Loss: -0.14004, Accuracy: 0.99882, F1: 0.1817, Prec: 0.1396, Rec: 0.2639, lr: 0.00080\n",
      "Epoch 4/Step 1060, Loss: -0.14291, Accuracy: 0.99882, F1: 0.1816, Prec: 0.1395, Rec: 0.2638, lr: 0.00080\n",
      "Epoch 4/Step 1080, Loss: -0.15389, Accuracy: 0.99882, F1: 0.1817, Prec: 0.1395, Rec: 0.2640, lr: 0.00080\n",
      "Epoch 4/Step 1100, Loss: -0.15784, Accuracy: 0.99882, F1: 0.1817, Prec: 0.1396, Rec: 0.2641, lr: 0.00080\n",
      "Epoch 4/Step 1120, Loss: -0.11473, Accuracy: 0.99882, F1: 0.1816, Prec: 0.1394, Rec: 0.2642, lr: 0.00080\n",
      "Epoch 4/Step 1140, Loss: -0.11898, Accuracy: 0.99882, F1: 0.1817, Prec: 0.1395, Rec: 0.2641, lr: 0.00080\n",
      "Epoch 4/Step 1160, Loss: -0.16745, Accuracy: 0.99882, F1: 0.1818, Prec: 0.1396, Rec: 0.2642, lr: 0.00080\n",
      "Epoch 4/Step 1180, Loss: -0.13303, Accuracy: 0.99882, F1: 0.1819, Prec: 0.1398, Rec: 0.2643, lr: 0.00080\n",
      "Epoch 4/Step 1200, Loss: -0.13057, Accuracy: 0.99882, F1: 0.1819, Prec: 0.1397, Rec: 0.2643, lr: 0.00080\n",
      "Epoch 4/Step 1220, Loss: -0.14188, Accuracy: 0.99882, F1: 0.1820, Prec: 0.1398, Rec: 0.2641, lr: 0.00080\n",
      "Epoch 4/Step 1240, Loss: -0.21089, Accuracy: 0.99882, F1: 0.1821, Prec: 0.1399, Rec: 0.2644, lr: 0.00080\n",
      "Epoch 4/Step 1260, Loss: -0.14135, Accuracy: 0.99882, F1: 0.1821, Prec: 0.1400, Rec: 0.2643, lr: 0.00080\n",
      "Epoch 4/Step 1280, Loss: -0.19893, Accuracy: 0.99882, F1: 0.1821, Prec: 0.1400, Rec: 0.2643, lr: 0.00080\n",
      "Epoch 4/Step 1300, Loss: -0.12067, Accuracy: 0.99882, F1: 0.1821, Prec: 0.1400, Rec: 0.2642, lr: 0.00080\n",
      "Epoch 4/Step 1320, Loss: -0.14295, Accuracy: 0.99882, F1: 0.1822, Prec: 0.1401, Rec: 0.2644, lr: 0.00080\n",
      "Epoch 4/Step 1340, Loss: -0.15339, Accuracy: 0.99882, F1: 0.1824, Prec: 0.1402, Rec: 0.2646, lr: 0.00080\n",
      "Epoch 4/Step 1360, Loss: -0.13597, Accuracy: 0.99882, F1: 0.1825, Prec: 0.1403, Rec: 0.2648, lr: 0.00080\n",
      "Epoch 4/Step 1380, Loss: -0.15754, Accuracy: 0.99882, F1: 0.1825, Prec: 0.1403, Rec: 0.2648, lr: 0.00080\n",
      "Epoch 4/Step 1400, Loss: -0.14910, Accuracy: 0.99882, F1: 0.1825, Prec: 0.1403, Rec: 0.2646, lr: 0.00080\n",
      "Epoch 4/Step 1420, Loss: -0.12322, Accuracy: 0.99882, F1: 0.1825, Prec: 0.1404, Rec: 0.2647, lr: 0.00080\n",
      "Epoch 4/Step 1440, Loss: -0.12729, Accuracy: 0.99882, F1: 0.1825, Prec: 0.1403, Rec: 0.2648, lr: 0.00080\n",
      "Epoch 4/Step 1460, Loss: -0.11392, Accuracy: 0.99882, F1: 0.1824, Prec: 0.1402, Rec: 0.2647, lr: 0.00080\n",
      "Epoch 4/Step 1480, Loss: -0.15038, Accuracy: 0.99882, F1: 0.1824, Prec: 0.1402, Rec: 0.2648, lr: 0.00080\n",
      "Epoch 4/Step 1500, Loss: -0.13700, Accuracy: 0.99882, F1: 0.1823, Prec: 0.1401, Rec: 0.2647, lr: 0.00080\n",
      "Epoch 4/Step 1520, Loss: -0.17407, Accuracy: 0.99882, F1: 0.1824, Prec: 0.1403, Rec: 0.2647, lr: 0.00080\n",
      "Epoch 4/Step 1540, Loss: -0.10454, Accuracy: 0.99882, F1: 0.1824, Prec: 0.1402, Rec: 0.2648, lr: 0.00080\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9988\n",
      "Validation f1: 0.1756\n",
      "Validation precision: 0.1343\n",
      "Validation recall: 0.2582\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 23:57:15.920501: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-28 23:57:15.930805: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-28 23:57:15.942069: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-28 23:57:16.132390: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-28 23:57:16.181239: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-28 23:57:16.226035: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/cafa-5-protein-function-prediction/model_BPO_epoch_3_valF1Score0.1756/assets\n",
      "\n",
      "Start of epoch 5\n",
      "Epoch 5/Step 0, Loss: -0.12872, Accuracy: 0.99884, F1: 0.1997, Prec: 0.1575, Rec: 0.2728, lr: 0.00080\n",
      "Epoch 5/Step 20, Loss: -0.13814, Accuracy: 0.99881, F1: 0.1850, Prec: 0.1422, Rec: 0.2672, lr: 0.00080\n",
      "Epoch 5/Step 40, Loss: -0.14764, Accuracy: 0.99883, F1: 0.1868, Prec: 0.1440, Rec: 0.2680, lr: 0.00080\n",
      "Epoch 5/Step 60, Loss: -0.16705, Accuracy: 0.99885, F1: 0.1883, Prec: 0.1455, Rec: 0.2699, lr: 0.00080\n",
      "Epoch 5/Step 80, Loss: -0.14882, Accuracy: 0.99886, F1: 0.1842, Prec: 0.1418, Rec: 0.2660, lr: 0.00080\n",
      "Epoch 5/Step 100, Loss: -0.16484, Accuracy: 0.99886, F1: 0.1845, Prec: 0.1416, Rec: 0.2676, lr: 0.00080\n",
      "Epoch 5/Step 120, Loss: -0.13192, Accuracy: 0.99885, F1: 0.1853, Prec: 0.1421, Rec: 0.2698, lr: 0.00080\n",
      "Epoch 5/Step 140, Loss: -0.15636, Accuracy: 0.99884, F1: 0.1852, Prec: 0.1420, Rec: 0.2697, lr: 0.00080\n",
      "Epoch 5/Step 160, Loss: -0.14940, Accuracy: 0.99883, F1: 0.1845, Prec: 0.1412, Rec: 0.2696, lr: 0.00080\n",
      "Epoch 5/Step 180, Loss: -0.14316, Accuracy: 0.99884, F1: 0.1840, Prec: 0.1407, Rec: 0.2693, lr: 0.00080\n",
      "Epoch 5/Step 200, Loss: -0.14989, Accuracy: 0.99883, F1: 0.1833, Prec: 0.1399, Rec: 0.2697, lr: 0.00080\n",
      "Epoch 5/Step 220, Loss: -0.16184, Accuracy: 0.99883, F1: 0.1835, Prec: 0.1401, Rec: 0.2697, lr: 0.00080\n",
      "Epoch 5/Step 240, Loss: -0.18185, Accuracy: 0.99882, F1: 0.1843, Prec: 0.1409, Rec: 0.2703, lr: 0.00080\n",
      "Epoch 5/Step 260, Loss: -0.15285, Accuracy: 0.99882, F1: 0.1842, Prec: 0.1407, Rec: 0.2702, lr: 0.00080\n",
      "Epoch 5/Step 280, Loss: -0.14944, Accuracy: 0.99882, F1: 0.1847, Prec: 0.1410, Rec: 0.2713, lr: 0.00080\n",
      "Epoch 5/Step 300, Loss: -0.18087, Accuracy: 0.99882, F1: 0.1843, Prec: 0.1408, Rec: 0.2707, lr: 0.00080\n",
      "Epoch 5/Step 320, Loss: -0.17667, Accuracy: 0.99882, F1: 0.1839, Prec: 0.1405, Rec: 0.2699, lr: 0.00080\n",
      "Epoch 5/Step 340, Loss: -0.15952, Accuracy: 0.99882, F1: 0.1842, Prec: 0.1407, Rec: 0.2705, lr: 0.00080\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 76\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mStart of epoch \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,))\n\u001b[1;32m     75\u001b[0m \u001b[39m# Iterate over the batches of the dataset.\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m \u001b[39mfor\u001b[39;00m step, (x_batch_train, y_batch_train) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(batchedDataset):\n\u001b[1;32m     78\u001b[0m     loss_value \u001b[39m=\u001b[39mtrainStep(x_batch_train,y_batch_train)\n\u001b[1;32m     80\u001b[0m     \u001b[39m# Log \u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:797\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    796\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 797\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[1;32m    798\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    799\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:780\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    779\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[0;32m--> 780\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[1;32m    781\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[1;32m    782\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[1;32m    783\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[1;32m    785\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    786\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3011\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3009\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   3010\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3011\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   3012\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mIteratorGetNext\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, iterator, \u001b[39m\"\u001b[39;49m\u001b[39moutput_types\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_types,\n\u001b[1;32m   3013\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39moutput_shapes\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_shapes)\n\u001b[1;32m   3014\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3015\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "BATCH_SIZE=64\n",
    "LOG_INTERVAL=20\n",
    "epochs = 15\n",
    "saveModel=True\n",
    "\n",
    "\n",
    "log_dir = \"./logs/\"+model.name+\"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+\"_\"+SO\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,\n",
    "                                                      write_graph=True, update_freq=5)\n",
    "\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "# Instantiate an optimizer .\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=8e-4)\n",
    "\n",
    "# Instantiate a loss function.\n",
    "# loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "# loss_fn = WeightedBinaryCE(np.ones(len(mlb.classes_)))\n",
    "# loss_fn = WeightedBinaryCE(labelWeightsCorr)\n",
    "# loss_fn = WeightedComboLoss(labelWeightsCorr, alpha=0.5, beta=0.5, labelSmoothing=0.05)\n",
    "loss_fn = WeightedComboLoss(labelWeightsCorr, alpha=0.5, beta=0.5)\n",
    "\n",
    "train_acc_metric = WeightedAccuracy(classWeights=labelWeightsCorr)\n",
    "train_f1_metric = WeightedF1(classWeights=labelWeightsCorr, threshold=0.5)\n",
    "train_prec = WeightedPrecision(classWeights=labelWeightsCorr)\n",
    "train_rec = WeightedRecall(classWeights=labelWeightsCorr)\n",
    "\n",
    "val_acc_metric = WeightedAccuracy(classWeights=labelWeightsCorr)\n",
    "val_f1_metric = WeightedF1(classWeights=labelWeightsCorr, threshold=0.5)\n",
    "val_prec = WeightedPrecision(classWeights=labelWeightsCorr)\n",
    "val_rec = WeightedRecall(classWeights=labelWeightsCorr)\n",
    "\n",
    "batchedDataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "batchedDatasetVal = datasetVal.batch(BATCH_SIZE, drop_remainder=False)\n",
    "\n",
    "# batchedDataset = batchedDataset.cache(os.path.join(DATA_PATH, \"datasetCache\"+SO))\n",
    "# batchedDatasetVal = batchedDatasetVal.cache(os.path.join(DATA_PATH, \"datasetCacheVal\"+SO))\n",
    "\n",
    "@tf.function()\n",
    "def trainStep(x_batch_train, y_batch_train):\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        probs = model(x_batch_train, training=True) \n",
    "        loss_value = loss_fn(y_batch_train, probs)\n",
    "\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    #Gradient clipping\n",
    "    # grads = [tf.clip_by_norm(g, 2.0) for g in grads]\n",
    "\n",
    "    train_acc_metric.update_state(y_batch_train, probs)\n",
    "    train_f1_metric.update_state(y_batch_train, probs)\n",
    "    train_prec.update_state(y_batch_train, probs)\n",
    "    train_rec.update_state(y_batch_train, probs)\n",
    "\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights)) \n",
    "    return loss_value\n",
    "\n",
    "@tf.function()\n",
    "def valStep(x_batch_val, y_batch_val):\n",
    "    valProbs = model(x_batch_val, training=False)\n",
    "    # Update val metrics\n",
    "    val_acc_metric.update_state(y_batch_val, valProbs)\n",
    "    val_f1_metric.update_state(y_batch_val, valProbs)\n",
    "    val_prec.update_state(y_batch_val, valProbs)\n",
    "    val_rec.update_state(y_batch_val, valProbs)\n",
    "\n",
    "maxStep=0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch+1,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(batchedDataset):\n",
    "\n",
    "        loss_value =trainStep(x_batch_train,y_batch_train)\n",
    "\n",
    "        # Log \n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            template = 'Epoch {}/Step {}, Loss: {:.5f}, Accuracy: {:.5f}, F1: {:.4f}, Prec: {:.4f}, Rec: {:.4f}, lr: {:.5f}'\n",
    "            print(template.format(epoch+1, step,loss_value.numpy(), \n",
    "                                    train_acc_metric.result(),train_f1_metric.result(),\n",
    "                                    train_prec.result(), train_rec.result(), optimizer.learning_rate.numpy()))\n",
    "            \n",
    "            with summary_writer.as_default():\n",
    "                tf.summary.scalar('loss', loss_value, step=maxStep*epoch+step)\n",
    "                tf.summary.scalar('accuracy', train_acc_metric.result(), step=maxStep*epoch+step)\n",
    "                tf.summary.scalar('f1', train_f1_metric.result(), step=maxStep*epoch+step)\n",
    "                tf.summary.scalar('prec', train_prec.result(), step=maxStep*epoch+step)\n",
    "                tf.summary.scalar('rec', train_rec.result(), step=maxStep*epoch+step)\n",
    "                tf.summary.scalar('learning rate', optimizer.learning_rate.numpy(), step=maxStep*epoch+step)\n",
    "                summary_writer.flush()\n",
    "\n",
    "    \n",
    "    train_acc_metric.reset_states()\n",
    "    train_f1_metric.reset_states()\n",
    "    train_prec.reset_states()\n",
    "    train_rec.reset_states()\n",
    "\n",
    "    maxStep=step\n",
    "\n",
    "    print(\"Epoch finished. Start validation\")\n",
    "    for x_batch_val, y_batch_val in batchedDatasetVal:\n",
    "        valStep(x_batch_val, y_batch_val)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    val_f1 = val_f1_metric.result()\n",
    "    val_f1_metric.reset_states()\n",
    "    val_precision = val_prec.result()\n",
    "    val_prec.reset_states()\n",
    "    val_recall = val_rec.result()\n",
    "    val_rec.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    print(\"Validation f1: %.4f\" % (float(val_f1),))\n",
    "    print(\"Validation precision: %.4f\" % (float(val_precision),))\n",
    "    print(\"Validation recall: %.4f\" % (float(val_recall),))\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('valAcc', float(val_acc), step=epoch)\n",
    "        tf.summary.scalar('valF1', float(val_f1), step=epoch)\n",
    "        tf.summary.scalar('valPrecision', float(val_precision), step=epoch)\n",
    "        tf.summary.scalar('valRecall', float(val_recall), step=epoch)\n",
    "        summary_writer.flush()\n",
    "    if saveModel:\n",
    "      model.save(os.path.join(DATA_PATH, \"model_\"+SO+\"_epoch_{}_valF1Score{:.4f}\".format(epoch, float(val_f1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f7234",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model.save(os.path.join(DATA_PATH, \"model_\"+SO+\"_epoch_{}_valf1Score{:.3f}\".format(epoch, float(val_f1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc1f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "probs= model.predict(tf.expand_dims(list(datasetVal.take(32))[10][0], 0))\n",
    "prediction= [1 if p > 0.5 else 0 for p in probs[0]]\n",
    "probabilities= probs[probs>0.5]\n",
    "# classes = np.argwhere(prediction)\n",
    "print(mlb.inverse_transform(np.array([prediction])))\n",
    "print(probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
