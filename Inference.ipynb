{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c1d77e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 16:45:32.674989: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-24 16:45:33.256239: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/e/ML/cafa-5-protein-function-prediction\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "DATA_PATH = os.getenv('DATA_PATH')\n",
    "print(DATA_PATH)\n",
    "\n",
    "# subontology (CCO, BPO or BPO)\n",
    "SOs = ['CCO', 'MFO', 'BPO']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3544f8a",
   "metadata": {},
   "source": [
    "## Reading fasta, obo and tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b515f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "sequences = [rec.seq for rec in SeqIO.parse(os.path.join(DATA_PATH, \"Test (Targets)/testsuperset.fasta\"),\"fasta\")]\n",
    "ids = [rec.id for rec in SeqIO.parse(os.path.join(DATA_PATH, \"Test (Targets)/testsuperset.fasta\"),\"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e492f673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 141865 sequences in the dataset.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} sequences in the dataset.\".format(len(sequences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2898414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "import obonet\n",
    "\n",
    "# Read the taxrank ontology\n",
    "url = os.path.join(DATA_PATH, \"Train/go-basic.obo\")\n",
    "graph = obonet.read_obo(url)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c099fc2",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f6a6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2433\n",
      "2099\n",
      "13376\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pickle \n",
    "\n",
    "\n",
    "with open(os.path.join(DATA_PATH,'MLB_CCO.pkl'), 'rb') as f:\n",
    "    mlbCco = pickle.load(f)\n",
    "with open(os.path.join(DATA_PATH,'MLB_MFO.pkl'), 'rb') as f:\n",
    "    mlbMfo = pickle.load(f)\n",
    "with open(os.path.join(DATA_PATH,'MLB_BPO.pkl'), 'rb') as f:\n",
    "    mlbBpo = pickle.load(f)\n",
    "\n",
    "print(len(mlbCco.classes_))\n",
    "print(len(mlbMfo.classes_))\n",
    "print(len(mlbBpo.classes_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92019f8c",
   "metadata": {},
   "source": [
    "## Amino acids encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b747477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aminos_list = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e42462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_dict = {'A': 1, 'B':24, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'O': 21, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'U': 22, 'V': 18, 'W': 19, 'Y': 20, 'X':30, 'Z':23}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfd823ba",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "431f9df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = 35375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44f722e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from itertools import product\n",
    "\n",
    "k = 3\n",
    "\n",
    "allAA = list(aa_dict.keys())\n",
    "allAA.sort()\n",
    "allCombinations= list(product(*(allAA for i in range(k))))\n",
    "allCombinations=np.array([''.join(el) for el in allCombinations])\n",
    "\n",
    "positionDict = dict(zip(allCombinations, np.arange(0,allCombinations.size).T))\n",
    "\n",
    "mapping = lambda x: aa_dict[x]\n",
    "vectMapping = np.vectorize(mapping)\n",
    "\n",
    "\n",
    "def generator():\n",
    "    for i,seq in enumerate(sequences):\n",
    "        kmers = [seq[j:j+k] if j < len(seq)-(k-1) else 0 for j,el in enumerate(seq)]\n",
    "        kmers = kmers[0:-(k-1)]\n",
    "        kmers = [str(el) for el in kmers]\n",
    "        values, counts = np.unique(kmers, return_counts=True)\n",
    "        freqVector=np.zeros(allCombinations.shape)\n",
    "        for j,v in enumerate(values):\n",
    "            freqVector[positionDict[v]] = counts[j]\n",
    "        yield ids[i], freqVector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd15e8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first sample sequence: ('Q9CQV8', array([1., 0., 0., ..., 0., 0., 0.]))\n"
     ]
    }
   ],
   "source": [
    "g = generator()\n",
    "test = next(g)\n",
    "print(\"The first sample sequence: {}\".format(test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10c4a51a",
   "metadata": {},
   "source": [
    "## Tensorflow Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f0d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(generator, output_signature=(tf.TensorSpec(shape=(),dtype=tf.dtypes.string),\n",
    "         tf.TensorSpec(shape=(allCombinations.size,), dtype=tf.int32)))\n",
    "print(list(dataset.take(1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9113c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CCOmodel = tf.keras.saving.load_model(os.path.join(DATA_PATH, \"model_CCO_epoch_20_valF1Score0.738\"))\n",
    "MFOmodel = tf.keras.saving.load_model(os.path.join(DATA_PATH, \"model_MFO_epoch_16_valF1Score0.853\"))\n",
    "# BPOmodel = tf.keras.saving.load_model(os.path.join(DATA_PATH, \"model_BPO_epoch_9_valF1Score0.568\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc1f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# probs= CCOmodel.predict(tf.expand_dims(list(dataset.take(64))[0][1], 0))\n",
    "# prediction= [1 if p > 0.5 else 0 for p in probs[0]]\n",
    "# probabilities= probs[probs>0.5]\n",
    "# # classes = np.argwhere(prediction)\n",
    "# print(mlb.inverse_transform(np.array([prediction])))\n",
    "# print(probabilities)\n",
    "\n",
    "\n",
    "batchedDataset = dataset.batch(512)\n",
    "tableData=[]\n",
    "\n",
    "for entries, data in tqdm(batchedDataset):\n",
    "\n",
    "    probsCCO= CCOmodel.predict_on_batch(data)\n",
    "    probsMFO= MFOmodel.predict_on_batch(data)\n",
    "    # probsBPO= BPOmodel.predict_on_batch(data)\n",
    "\n",
    "    for i,prob in enumerate(probsCCO):\n",
    "        prediction = np.where(probsCCO[i] > 0.5, 1, 0)\n",
    "        # prediction= [1 if p > 0.5 else 0 for p in prob]\n",
    "        probabilities= prob[prob>0.5]\n",
    "        entry = entries[i]\n",
    "        GOs = mlbCco.inverse_transform(np.array([prediction]))\n",
    "        for j,g in enumerate(GOs[0]):\n",
    "            tableData.append([entry.numpy().decode(\"utf-8\") , g, probabilities[j]])\n",
    "\n",
    "    for i,prob in enumerate(probsMFO):\n",
    "        prediction = np.where(probsMFO[i] > 0.5, 1, 0)\n",
    "        # prediction= [1 if p > 0.5 else 0 for p in prob]\n",
    "        probabilities= prob[prob>0.5]\n",
    "        entry = entries[i]\n",
    "        GOs = mlbMfo.inverse_transform(np.array([prediction]))\n",
    "        for j,g in enumerate(GOs[0]):\n",
    "            tableData.append([entry.numpy().decode(\"utf-8\") , g, probabilities[j]])\n",
    "\n",
    "    # for i,prob in enumerate(probsBPO):\n",
    "    #     prediction = np.where(probsBPO[i] > 0.5, 1, 0)\n",
    "    #     # prediction= [1 if p > 0.5 else 0 for p in prob]\n",
    "    #     probabilities= prob[prob>0.5]\n",
    "    #     entry = entries[i]\n",
    "    #     GOs = mlbBpo.inverse_transform(np.array([prediction]))\n",
    "    #     for j,g in enumerate(GOs[0]):\n",
    "    #         tableData.append([entry.numpy().decode(\"utf-8\") , g, probabilities[j]])\n",
    "\n",
    "        \n",
    "# results = pd.DataFrame(tableData, columns=['Entry ID', 'GO', 'Probability'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15bedbbd",
   "metadata": {},
   "source": [
    "## 1vR Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a007cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(os.path.join(DATA_PATH,\"ClassifierArray_\"+\"MFO\"+\".bin\"), \"rb\") as f: \n",
    "    classifiersMFO = pickle.load(f)\n",
    "with open(os.path.join(DATA_PATH,\"ClassifierArray_\"+\"BPO\"+\".bin\"), \"rb\") as f: \n",
    "    classifiersBPO = pickle.load(f)\n",
    "with open(os.path.join(DATA_PATH,\"ClassifierArray_\"+\"CCO\"+\".bin\"), \"rb\") as f: \n",
    "    classifiersCCO = pickle.load(f)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5102b75",
   "metadata": {},
   "source": [
    "Split classifiers for multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282b6124",
   "metadata": {},
   "outputs": [],
   "source": [
    "NoClassifiersMFO = len(classifiersMFO)\n",
    "classifiersMFO1 = [c if m>=0 and m<NoClassifiersMFO//3 else None for m,c in enumerate(classifiersMFO)]\n",
    "classifiersMFO2 = [c if m>=NoClassifiersMFO//3 and m<2*NoClassifiersMFO//3 else None for m,c in enumerate(classifiersMFO)]\n",
    "classifiersMFO3 = [c if m>=2*NoClassifiersMFO//3 and m<NoClassifiersMFO else None for m,c in enumerate(classifiersMFO)]\n",
    "\n",
    "NoClassifiersBPO = len(classifiersBPO)\n",
    "classifiersBPO1 = [c if m>=0 and m<NoClassifiersBPO//3 else None for m,c in enumerate(classifiersBPO)]\n",
    "classifiersBPO2 = [c if m>=NoClassifiersBPO//3 and m<2*NoClassifiersBPO//3 else None for m,c in enumerate(classifiersBPO)]\n",
    "classifiersBPO3 = [c if m>=2*NoClassifiersBPO//3 and m<NoClassifiersBPO else None for m,c in enumerate(classifiersBPO)]\n",
    "\n",
    "NoClassifiersCCO = len(classifiersCCO)\n",
    "classifiersCCO1 = [c if m>=0 and m<NoClassifiersCCO//3 else None for m,c in enumerate(classifiersCCO)]\n",
    "classifiersCCO2 = [c if m>=NoClassifiersCCO//3 and m<2*NoClassifiersCCO//3 else None for m,c in enumerate(classifiersCCO)]\n",
    "classifiersCCO3 = [c if m>=2*NoClassifiersCCO//3 and m<NoClassifiersCCO else None for m,c in enumerate(classifiersCCO)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65b6faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "def batched(iterable, n):\n",
    "    \"Batch data into tuples of length n. The last batch may be shorter.\"\n",
    "    # batched('ABCDEFG', 3) --> ABC DEF G\n",
    "    if n < 1:\n",
    "        raise ValueError('n must be at least one')\n",
    "    it = iter(iterable)\n",
    "    while batch := tuple(islice(it, n)):\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfa3b6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=generator()\n",
    "batchedGen = batched(g, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc88277e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463a4c1241b74bbda04ecb43f5bb61d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp=[]\n",
    "\n",
    "for j,c in tqdm(enumerate(classifiersCCO), total=len(classifiersCCO)):\n",
    "    if(c is None):\n",
    "        continue\n",
    "    for i,batch in enumerate(batchedGen):\n",
    "        freqVectors = [el[1] for el in batch]\n",
    "        entryIds = [el[0] for el in batch]\n",
    "        resArr = c.predict_proba(freqVectors)\n",
    "        probas=[res[1] for res in resArr]\n",
    "        for m,p in enumerate(probas):\n",
    "            if(p>0.5):\n",
    "                temp.append([entryIds[m] , mlbCco.classes_[j], p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beb8a64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34122"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5308a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(temp, columns=['Entry ID', 'GO', 'Probability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b90143",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0778a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(os.path.join(DATA_PATH, \"submission.tsv\"), sep=\"\\t\", header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
