{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c1d77e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 17:38:14.685375: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-17 17:38:15.113515: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/e/ML/cafa-5-protein-function-prediction\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "DATA_PATH = os.getenv('DATA_PATH')\n",
    "print(DATA_PATH)\n",
    "\n",
    "# Choose subontology (CCO, MFO or BPO)\n",
    "SO = 'CCO'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3544f8a",
   "metadata": {},
   "source": [
    "## Reading fasta, obo and tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b515f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "sequences = [rec.seq for rec in SeqIO.parse(os.path.join(DATA_PATH, \"Test (Targets)/testsuperset.fasta\"),\"fasta\")]\n",
    "ids = [rec.id for rec in SeqIO.parse(os.path.join(DATA_PATH, \"Test (Targets)/testsuperset.fasta\"),\"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e492f673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 141865 sequences in the dataset.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} sequences in the dataset.\".format(len(sequences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2898414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "import obonet\n",
    "\n",
    "# Read the taxrank ontology\n",
    "url = os.path.join(DATA_PATH, \"Train/go-basic.obo\")\n",
    "graph = obonet.read_obo(url)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c099fc2",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f6a6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2957\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pickle \n",
    "\n",
    "# Hydrate the serialized objects.\n",
    "with open(os.path.join(DATA_PATH,'MLB_'+SO+'.pkl'), 'rb') as f:\n",
    "    mlb = pickle.load(f)\n",
    "\n",
    "print(len(mlb.classes_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92019f8c",
   "metadata": {},
   "source": [
    "## Amino acids encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b747477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aminos_list = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e42462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_dict = {'A': 1, 'B':24, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'O': 21, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'U': 22, 'V': 18, 'W': 19, 'Y': 20, 'X':30, 'Z':23}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfd823ba",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "431f9df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = 35375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44f722e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mapping = lambda x: aa_dict[x]\n",
    "vectMapping = np.vectorize(mapping)\n",
    "\n",
    "sequences=sequences[0:500]\n",
    "ids=ids[0:500]\n",
    "\n",
    "\n",
    "\n",
    "def generator(padding=True):\n",
    "    for i,seq in enumerate(sequences):\n",
    "        entryId = ids[i]\n",
    "        \n",
    "        arr = np.array(seq)\n",
    "        mappedArr = vectMapping(arr)\n",
    "        if padding:\n",
    "            padWidth = maxLen - arr.size\n",
    "            mappedArr = np.pad(mappedArr, (0, padWidth))\n",
    "        yield entryId, mappedArr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd15e8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first sample sequence: ('Q9CQV8', array([11, 17, 11, ...,  0,  0,  0]))\n"
     ]
    }
   ],
   "source": [
    "g = generator()\n",
    "test = next(g)\n",
    "print(\"The first sample sequence: {}\".format(test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10c4a51a",
   "metadata": {},
   "source": [
    "## Tensorflow Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63f0d2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 17:38:23.481285: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-17 17:38:23.499353: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-17 17:38:23.499675: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-17 17:38:23.501085: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-17 17:38:23.501383: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-17 17:38:23.501732: I tensorflow/compile"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(<tf.Tensor: shape=(), dtype=string, numpy=b'Q9CQV8'>, <tf.Tensor: shape=(35375,), dtype=int32, numpy=array([11, 17, 11, ...,  0,  0,  0], dtype=int32)>)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "r/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-17 17:38:24.002609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-17 17:38:24.002929: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-17 17:38:24.002941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-17 17:38:24.003252: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-17 17:38:24.003293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6569 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:2b:00.0, compute capability: 6.1\n",
      "2023-05-17 17:38:24.231575: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(generator, output_signature=(tf.TensorSpec(shape=(),dtype=tf.dtypes.string),\n",
    "         tf.TensorSpec(shape=(maxLen,), dtype=tf.int32)))\n",
    "print(list(dataset.take(1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9113c4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "CCOmodel = tf.keras.saving.load_model(os.path.join(DATA_PATH, \"model_CCO_epoch_1_valAcc0.997\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cefc1f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 17:38:24.647303: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-17 17:38:25.155564: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 3ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 118ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# probs= CCOmodel.predict(tf.expand_dims(list(dataset.take(64))[0][1], 0))\n",
    "# prediction= [1 if p > 0.5 else 0 for p in probs[0]]\n",
    "# probabilities= probs[probs>0.5]\n",
    "# # classes = np.argwhere(prediction)\n",
    "# print(mlb.inverse_transform(np.array([prediction])))\n",
    "# print(probabilities)\n",
    "\n",
    "\n",
    "dataset = dataset.batch(64)\n",
    "tableData=[]\n",
    "\n",
    "for entries, data in dataset:\n",
    "\n",
    "    probs= CCOmodel.predict(data)\n",
    "\n",
    "    for i,prob in enumerate(probs):\n",
    "        prediction= [1 if p > 0.5 else 0 for p in prob]\n",
    "        probabilities= prob[prob>0.5]\n",
    "        entry = entries[i]\n",
    "        GOs = mlb.inverse_transform(np.array([prediction]))\n",
    "\n",
    "        for j,g in enumerate(GOs[0]):\n",
    "            tableData.append([entry.numpy().decode(\"utf-8\") , g, probabilities[j]])\n",
    "\n",
    "        \n",
    "results = pd.DataFrame(tableData, columns=['Entry ID', 'GO', 'Probability'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0778a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add inference for all 3 models inside the dataset loop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
