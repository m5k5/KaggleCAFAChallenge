{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d77e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "DATA_PATH = os.getenv('DATA_PATH')\n",
    "print(DATA_PATH)\n",
    "\n",
    "# subontology (CCO, MFO or BPO)\n",
    "SOs = ['CCO', 'MFO', 'BPO']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3544f8a",
   "metadata": {},
   "source": [
    "## Reading fasta, obo and tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b515f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "sequences = [rec.seq for rec in SeqIO.parse(os.path.join(DATA_PATH, \"Test (Targets)/testsuperset.fasta\"),\"fasta\")]\n",
    "ids = [rec.id for rec in SeqIO.parse(os.path.join(DATA_PATH, \"Test (Targets)/testsuperset.fasta\"),\"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e492f673",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {} sequences in the dataset.\".format(len(sequences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2898414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "import obonet\n",
    "\n",
    "# Read the taxrank ontology\n",
    "url = os.path.join(DATA_PATH, \"Train/go-basic.obo\")\n",
    "graph = obonet.read_obo(url)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c099fc2",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f6a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pickle \n",
    "\n",
    "\n",
    "with open(os.path.join(DATA_PATH,'MLB_CCO.pkl'), 'rb') as f:\n",
    "    mlbCco = pickle.load(f)\n",
    "with open(os.path.join(DATA_PATH,'MLB_MFO.pkl'), 'rb') as f:\n",
    "    mlbMfo = pickle.load(f)\n",
    "with open(os.path.join(DATA_PATH,'MLB_BPO.pkl'), 'rb') as f:\n",
    "    mlbBpo = pickle.load(f)\n",
    "\n",
    "print(len(mlbCco.classes_))\n",
    "print(len(mlbMfo.classes_))\n",
    "print(len(mlbBpo.classes_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92019f8c",
   "metadata": {},
   "source": [
    "## Amino acids encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b747477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aminos_list = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e42462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_dict = {'A': 1, 'B':24, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'O': 21, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'U': 22, 'V': 18, 'W': 19, 'Y': 20, 'X':30, 'Z':23}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfd823ba",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431f9df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = 35375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f722e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from itertools import product\n",
    "\n",
    "k = 3\n",
    "\n",
    "allAA = list(aa_dict.keys())\n",
    "allAA.sort()\n",
    "allCombinations= list(product(*(allAA for i in range(k))))\n",
    "allCombinations=np.array([''.join(el) for el in allCombinations])\n",
    "\n",
    "positionDict = dict(zip(allCombinations, np.arange(0,allCombinations.size).T))\n",
    "\n",
    "mapping = lambda x: aa_dict[x]\n",
    "vectMapping = np.vectorize(mapping)\n",
    "\n",
    "\n",
    "def generator():\n",
    "    for i,seq in enumerate(sequences):\n",
    "        kmers = [seq[j:j+k] if j < len(seq)-(k-1) else 0 for j,el in enumerate(seq)]\n",
    "        kmers = kmers[0:-(k-1)]\n",
    "        kmers = [str(el) for el in kmers]\n",
    "        values, counts = np.unique(kmers, return_counts=True)\n",
    "        freqVector=np.zeros(allCombinations.shape)\n",
    "        for j,v in enumerate(values):\n",
    "            freqVector[positionDict[v]] = counts[j]\n",
    "        yield ids[i], freqVector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd15e8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = generator()\n",
    "test = next(g)\n",
    "print(\"The first sample sequence: {}\".format(test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10c4a51a",
   "metadata": {},
   "source": [
    "## Tensorflow Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f0d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(generator, output_signature=(tf.TensorSpec(shape=(),dtype=tf.dtypes.string),\n",
    "         tf.TensorSpec(shape=(allCombinations.size,), dtype=tf.int32)))\n",
    "print(list(dataset.take(1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9113c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CCOmodel = tf.keras.saving.load_model(os.path.join(DATA_PATH, \"model_CCO_epoch_20_valF1Score0.738\"))\n",
    "MFOmodel = tf.keras.saving.load_model(os.path.join(DATA_PATH, \"model_MFO_epoch_16_valF1Score0.853\"))\n",
    "# BPOmodel = tf.keras.saving.load_model(os.path.join(DATA_PATH, \"model_BPO_epoch_9_valF1Score0.568\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc1f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# probs= CCOmodel.predict(tf.expand_dims(list(dataset.take(64))[0][1], 0))\n",
    "# prediction= [1 if p > 0.5 else 0 for p in probs[0]]\n",
    "# probabilities= probs[probs>0.5]\n",
    "# # classes = np.argwhere(prediction)\n",
    "# print(mlb.inverse_transform(np.array([prediction])))\n",
    "# print(probabilities)\n",
    "\n",
    "\n",
    "batchedDataset = dataset.batch(512)\n",
    "tableData=[]\n",
    "\n",
    "for entries, data in tqdm(batchedDataset):\n",
    "\n",
    "    probsCCO= CCOmodel.predict_on_batch(data)\n",
    "    probsMFO= MFOmodel.predict_on_batch(data)\n",
    "    # probsBPO= BPOmodel.predict_on_batch(data)\n",
    "\n",
    "    for i,prob in enumerate(probsCCO):\n",
    "        prediction = np.where(probsCCO[i] > 0.5, 1, 0)\n",
    "        # prediction= [1 if p > 0.5 else 0 for p in prob]\n",
    "        probabilities= prob[prob>0.5]\n",
    "        entry = entries[i]\n",
    "        GOs = mlbCco.inverse_transform(np.array([prediction]))\n",
    "        for j,g in enumerate(GOs[0]):\n",
    "            tableData.append([entry.numpy().decode(\"utf-8\") , g, probabilities[j]])\n",
    "\n",
    "    for i,prob in enumerate(probsMFO):\n",
    "        prediction = np.where(probsMFO[i] > 0.5, 1, 0)\n",
    "        # prediction= [1 if p > 0.5 else 0 for p in prob]\n",
    "        probabilities= prob[prob>0.5]\n",
    "        entry = entries[i]\n",
    "        GOs = mlbMfo.inverse_transform(np.array([prediction]))\n",
    "        for j,g in enumerate(GOs[0]):\n",
    "            tableData.append([entry.numpy().decode(\"utf-8\") , g, probabilities[j]])\n",
    "\n",
    "    # for i,prob in enumerate(probsBPO):\n",
    "    #     prediction = np.where(probsBPO[i] > 0.5, 1, 0)\n",
    "    #     # prediction= [1 if p > 0.5 else 0 for p in prob]\n",
    "    #     probabilities= prob[prob>0.5]\n",
    "    #     entry = entries[i]\n",
    "    #     GOs = mlbBpo.inverse_transform(np.array([prediction]))\n",
    "    #     for j,g in enumerate(GOs[0]):\n",
    "    #         tableData.append([entry.numpy().decode(\"utf-8\") , g, probabilities[j]])\n",
    "\n",
    "        \n",
    "# results = pd.DataFrame(tableData, columns=['Entry ID', 'GO', 'Probability'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a007cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SO=\"BPO\"\n",
    "with open(os.path.join(DATA_PATH,\"ClassifierArray_\"+SO+\".bin\"), \"rb\") as f: \n",
    "    classifiers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669dbef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tableData=[]\n",
    "g = generator()\n",
    "entryIds=[]\n",
    "freqVectors=[]\n",
    "\n",
    "for i,(entryId, fVec) in tqdm(enumerate(g), smoothing=0.05, total=len(sequences), position=0, leave=False):\n",
    "    entryIds.append(entryId)\n",
    "    freqVectors.append(fVec)\n",
    "        \n",
    "    if(len(freqVectors)>50000):\n",
    "        # res = classifiers[0].predict(freqVectors[0:1000])\n",
    "        # results = np.concatenate((results,res))\n",
    "        for j,c in tqdm(enumerate(classifiers), total=len(classifiers), position=1, leave=False):\n",
    "            if(c is None):\n",
    "                continue\n",
    "            resArr = c.predict_proba(freqVectors)\n",
    "            for m,res in enumerate(resArr):\n",
    "                if(res[1]>0.5):\n",
    "                    tableData.append([entryIds[m] , mlbBpo.classes_[j], res[1]])\n",
    "        freqVectors=[]\n",
    "        entryIds=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5308a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0778a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(os.path.join(DATA_PATH, \"submission.tsv\"), sep=\"\\t\", header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
