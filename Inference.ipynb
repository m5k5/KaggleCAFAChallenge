{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d77e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "DATA_PATH = os.getenv('DATA_PATH')\n",
    "print(DATA_PATH)\n",
    "\n",
    "# subontology (CCO, BPO or BPO)\n",
    "SOs = ['CCO', 'MFO', 'BPO']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3544f8a",
   "metadata": {},
   "source": [
    "## Reading fasta, obo and tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b515f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "sequences = [rec.seq for rec in SeqIO.parse(os.path.join(DATA_PATH, \"Test (Targets)/testsuperset.fasta\"),\"fasta\")]\n",
    "ids = [rec.id for rec in SeqIO.parse(os.path.join(DATA_PATH, \"Test (Targets)/testsuperset.fasta\"),\"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e492f673",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {} sequences in the dataset.\".format(len(sequences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2898414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "import obonet\n",
    "\n",
    "# Read the taxrank ontology\n",
    "url = os.path.join(DATA_PATH, \"Train/go-basic.obo\")\n",
    "graph = obonet.read_obo(url)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c099fc2",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f6a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pickle \n",
    "\n",
    "\n",
    "with open(os.path.join(DATA_PATH,'MLB_CCO.pkl'), 'rb') as f:\n",
    "    mlbCco = pickle.load(f)\n",
    "with open(os.path.join(DATA_PATH,'MLB_MFO.pkl'), 'rb') as f:\n",
    "    mlbMfo = pickle.load(f)\n",
    "with open(os.path.join(DATA_PATH,'MLB_BPO.pkl'), 'rb') as f:\n",
    "    mlbBpo = pickle.load(f)\n",
    "\n",
    "print(len(mlbCco.classes_))\n",
    "print(len(mlbMfo.classes_))\n",
    "print(len(mlbBpo.classes_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92019f8c",
   "metadata": {},
   "source": [
    "## Amino acids encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b747477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aminos_list = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e42462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_dict = {'A': 1, 'B':24, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'O': 21, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'U': 22, 'V': 18, 'W': 19, 'Y': 20, 'X':30, 'Z':23}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfd823ba",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431f9df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = 35375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f722e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from itertools import product\n",
    "\n",
    "k = 3\n",
    "\n",
    "allAA = list(aa_dict.keys())\n",
    "allAA.sort()\n",
    "allCombinations= list(product(*(allAA for i in range(k))))\n",
    "allCombinations=np.array([''.join(el) for el in allCombinations])\n",
    "\n",
    "positionDict = dict(zip(allCombinations, np.arange(0,allCombinations.size).T))\n",
    "\n",
    "mapping = lambda x: aa_dict[x]\n",
    "vectMapping = np.vectorize(mapping)\n",
    "\n",
    "\n",
    "def generator():\n",
    "    for i,seq in enumerate(sequences):\n",
    "        kmers = [seq[j:j+k] if j < len(seq)-(k-1) else 0 for j,el in enumerate(seq)]\n",
    "        kmers = kmers[0:-(k-1)]\n",
    "        kmers = [str(el) for el in kmers]\n",
    "        values, counts = np.unique(kmers, return_counts=True)\n",
    "        freqVector=np.zeros(allCombinations.shape)\n",
    "        for j,v in enumerate(values):\n",
    "            freqVector[positionDict[v]] = counts[j]\n",
    "        yield ids[i], freqVector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd15e8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = generator()\n",
    "test = next(g)\n",
    "print(\"The first sample sequence: {}\".format(test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10c4a51a",
   "metadata": {},
   "source": [
    "## Tensorflow Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f0d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(generator, output_signature=(tf.TensorSpec(shape=(),dtype=tf.dtypes.string),\n",
    "         tf.TensorSpec(shape=(allCombinations.size,), dtype=tf.int32)))\n",
    "print(list(dataset.take(1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9113c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CCOmodel = tf.keras.saving.load_model(os.path.join(DATA_PATH, \"model_CCO_epoch_20_valF1Score0.738\"))\n",
    "MFOmodel = tf.keras.saving.load_model(os.path.join(DATA_PATH, \"model_MFO_epoch_16_valF1Score0.853\"))\n",
    "# BPOmodel = tf.keras.saving.load_model(os.path.join(DATA_PATH, \"model_BPO_epoch_9_valF1Score0.568\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc1f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# probs= CCOmodel.predict(tf.expand_dims(list(dataset.take(64))[0][1], 0))\n",
    "# prediction= [1 if p > 0.5 else 0 for p in probs[0]]\n",
    "# probabilities= probs[probs>0.5]\n",
    "# # classes = np.argwhere(prediction)\n",
    "# print(mlb.inverse_transform(np.array([prediction])))\n",
    "# print(probabilities)\n",
    "\n",
    "\n",
    "batchedDataset = dataset.batch(512)\n",
    "tableData=[]\n",
    "\n",
    "for entries, data in tqdm(batchedDataset):\n",
    "\n",
    "    probsCCO= CCOmodel.predict_on_batch(data)\n",
    "    probsMFO= MFOmodel.predict_on_batch(data)\n",
    "    # probsBPO= BPOmodel.predict_on_batch(data)\n",
    "\n",
    "    for i,prob in enumerate(probsCCO):\n",
    "        prediction = np.where(probsCCO[i] > 0.5, 1, 0)\n",
    "        # prediction= [1 if p > 0.5 else 0 for p in prob]\n",
    "        probabilities= prob[prob>0.5]\n",
    "        entry = entries[i]\n",
    "        GOs = mlbCco.inverse_transform(np.array([prediction]))\n",
    "        for j,g in enumerate(GOs[0]):\n",
    "            tableData.append([entry.numpy().decode(\"utf-8\") , g, probabilities[j]])\n",
    "\n",
    "    for i,prob in enumerate(probsMFO):\n",
    "        prediction = np.where(probsMFO[i] > 0.5, 1, 0)\n",
    "        # prediction= [1 if p > 0.5 else 0 for p in prob]\n",
    "        probabilities= prob[prob>0.5]\n",
    "        entry = entries[i]\n",
    "        GOs = mlbMfo.inverse_transform(np.array([prediction]))\n",
    "        for j,g in enumerate(GOs[0]):\n",
    "            tableData.append([entry.numpy().decode(\"utf-8\") , g, probabilities[j]])\n",
    "\n",
    "    # for i,prob in enumerate(probsBPO):\n",
    "    #     prediction = np.where(probsBPO[i] > 0.5, 1, 0)\n",
    "    #     # prediction= [1 if p > 0.5 else 0 for p in prob]\n",
    "    #     probabilities= prob[prob>0.5]\n",
    "    #     entry = entries[i]\n",
    "    #     GOs = mlbBpo.inverse_transform(np.array([prediction]))\n",
    "    #     for j,g in enumerate(GOs[0]):\n",
    "    #         tableData.append([entry.numpy().decode(\"utf-8\") , g, probabilities[j]])\n",
    "\n",
    "        \n",
    "# results = pd.DataFrame(tableData, columns=['Entry ID', 'GO', 'Probability'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15bedbbd",
   "metadata": {},
   "source": [
    "## 1vR Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a007cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(os.path.join(DATA_PATH,\"ClassifierArray_\"+\"MFO\"+\".bin\"), \"rb\") as f: \n",
    "    classifiersMFO = pickle.load(f)\n",
    "with open(os.path.join(DATA_PATH,\"ClassifierArray_\"+\"BPO\"+\".bin\"), \"rb\") as f: \n",
    "    classifiersBPO = pickle.load(f)\n",
    "with open(os.path.join(DATA_PATH,\"ClassifierArray_\"+\"CCO\"+\".bin\"), \"rb\") as f: \n",
    "    classifiersCCO = pickle.load(f)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5102b75",
   "metadata": {},
   "source": [
    "Split classifiers for multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282b6124",
   "metadata": {},
   "outputs": [],
   "source": [
    "NoClassifiersMFO = len(classifiersMFO)\n",
    "classifiersMFO1 = [c if m>=0 and m<NoClassifiersMFO//3 else None for m,c in enumerate(classifiersMFO)]\n",
    "classifiersMFO2 = [c if m>=NoClassifiersMFO//3 and m<2*NoClassifiersMFO//3 else None for m,c in enumerate(classifiersMFO)]\n",
    "classifiersMFO3 = [c if m>=2*NoClassifiersMFO//3 and m<NoClassifiersMFO else None for m,c in enumerate(classifiersMFO)]\n",
    "\n",
    "NoClassifiersBPO = len(classifiersBPO)\n",
    "classifiersBPO1 = [c if m>=0 and m<NoClassifiersBPO//3 else None for m,c in enumerate(classifiersBPO)]\n",
    "classifiersBPO2 = [c if m>=NoClassifiersBPO//3 and m<2*NoClassifiersBPO//3 else None for m,c in enumerate(classifiersBPO)]\n",
    "classifiersBPO3 = [c if m>=2*NoClassifiersBPO//3 and m<NoClassifiersBPO else None for m,c in enumerate(classifiersBPO)]\n",
    "\n",
    "NoClassifiersCCO = len(classifiersCCO)\n",
    "classifiersCCO1 = [c if m>=0 and m<NoClassifiersCCO//3 else None for m,c in enumerate(classifiersCCO)]\n",
    "classifiersCCO2 = [c if m>=NoClassifiersCCO//3 and m<2*NoClassifiersCCO//3 else None for m,c in enumerate(classifiersCCO)]\n",
    "classifiersCCO3 = [c if m>=2*NoClassifiersCCO//3 and m<NoClassifiersCCO else None for m,c in enumerate(classifiersCCO)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "669dbef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eea3bc9c91a414796ab37b199133432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/141865 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 38\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mwith\u001b[39;00m Pool(processes\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m) \u001b[39mas\u001b[39;00m pool:\n\u001b[1;32m     35\u001b[0m     iterable\u001b[39m=\u001b[39m[(classifiersCCO1, mlbCco, freqVectors, entryIds), (classifiersCCO2, mlbCco, freqVectors, entryIds), (classifiersCCO3, mlbCco, freqVectors, entryIds),\n\u001b[1;32m     36\u001b[0m               (classifiersBPO1, mlbBpo, freqVectors, entryIds), (classifiersBPO2, mlbBpo, freqVectors, entryIds), (classifiersBPO3, mlbBpo, freqVectors, entryIds),\n\u001b[1;32m     37\u001b[0m               (classifiersMFO1, mlbMfo, freqVectors, entryIds), (classifiersMFO2, mlbMfo, freqVectors, entryIds), (classifiersMFO3, mlbMfo, freqVectors, entryIds)]\n\u001b[0;32m---> 38\u001b[0m     result \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49mstarmap(task, iterable)\n\u001b[1;32m     39\u001b[0m     \u001b[39m# print(result)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m result:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/multiprocessing/pool.py:372\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstarmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    367\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[39m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[39m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[39m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, starmapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    766\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 581\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    582\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Pool\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "def task(classifiers, mlb, freqVectors, entryIds):\n",
    "    temp=[]\n",
    "    for j,c in tqdm(enumerate(classifiers), total=len(classifiers), position=1, leave=False):\n",
    "        if(c is None):\n",
    "            continue\n",
    "        resArr = c.predict_proba(freqVectors)\n",
    "        probas=[res[1] for res in resArr]\n",
    "        for m,p in enumerate(probas):\n",
    "            if(p>0.99):\n",
    "                temp.append([entryIds[m] , mlb.classes_[j], p])\n",
    "    return temp\n",
    "\n",
    "\n",
    "\n",
    "tableData=[]\n",
    "g = generator()\n",
    "entryIds=[]\n",
    "freqVectors=[]\n",
    "\n",
    "for i,(entryId, fVec) in tqdm(enumerate(g), smoothing=0.05, total=len(sequences), position=0, leave=False):\n",
    "    entryIds.append(entryId)\n",
    "    freqVectors.append(fVec)\n",
    "        \n",
    "    if(len(freqVectors)>1) or i==len(sequences)-1:\n",
    "        # res = classifiers[0].predict(freqVectors[0:1000])\n",
    "        # results = np.concatenate((results,res))\n",
    "        # p1=Process(target=task, args=(classifiersCCO, freqVectors, entryIds))\n",
    "        # p2=Process(target=task, args=(classifiersMFO, freqVectors, entryIds))\n",
    "        # p3=Process(target=task, args=(classifiersBPO, freqVectors, entryIds))\n",
    "        with Pool(processes=12) as pool:\n",
    "            iterable=[(classifiersCCO1, mlbCco, freqVectors, entryIds), (classifiersCCO2, mlbCco, freqVectors, entryIds), (classifiersCCO3, mlbCco, freqVectors, entryIds),\n",
    "                      (classifiersBPO1, mlbBpo, freqVectors, entryIds), (classifiersBPO2, mlbBpo, freqVectors, entryIds), (classifiersBPO3, mlbBpo, freqVectors, entryIds),\n",
    "                      (classifiersMFO1, mlbMfo, freqVectors, entryIds), (classifiersMFO2, mlbMfo, freqVectors, entryIds), (classifiersMFO3, mlbMfo, freqVectors, entryIds)]\n",
    "            result = pool.starmap(task, iterable)\n",
    "            # print(result)\n",
    "            for r in result:\n",
    "                tableData = tableData+r\n",
    "            freqVectors=[]\n",
    "            entryIds=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5308a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(tableData, columns=['Entry ID', 'GO', 'Probability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7b90143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry ID</th>\n",
       "      <th>GO</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P62259</td>\n",
       "      <td>GO:0005871</td>\n",
       "      <td>0.997291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P62259</td>\n",
       "      <td>GO:0005875</td>\n",
       "      <td>0.997826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P62259</td>\n",
       "      <td>GO:0005930</td>\n",
       "      <td>0.992776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q9CQV8</td>\n",
       "      <td>GO:0043226</td>\n",
       "      <td>0.992121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P62259</td>\n",
       "      <td>GO:0045171</td>\n",
       "      <td>0.993526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>P61982</td>\n",
       "      <td>GO:0051219</td>\n",
       "      <td>0.995546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>P68510</td>\n",
       "      <td>GO:0099106</td>\n",
       "      <td>0.995813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>P68510</td>\n",
       "      <td>GO:0140313</td>\n",
       "      <td>0.996503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>P61982</td>\n",
       "      <td>GO:0140313</td>\n",
       "      <td>0.996049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>P61982</td>\n",
       "      <td>GO:1990782</td>\n",
       "      <td>0.997424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Entry ID          GO  Probability\n",
       "0     P62259  GO:0005871     0.997291\n",
       "1     P62259  GO:0005875     0.997826\n",
       "2     P62259  GO:0005930     0.992776\n",
       "3     Q9CQV8  GO:0043226     0.992121\n",
       "4     P62259  GO:0045171     0.993526\n",
       "..       ...         ...          ...\n",
       "188   P61982  GO:0051219     0.995546\n",
       "189   P68510  GO:0099106     0.995813\n",
       "190   P68510  GO:0140313     0.996503\n",
       "191   P61982  GO:0140313     0.996049\n",
       "192   P61982  GO:1990782     0.997424\n",
       "\n",
       "[193 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0778a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(os.path.join(DATA_PATH, \"submission.tsv\"), sep=\"\\t\", header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
