{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c1d77e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 17:58:32.855877: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-16 17:58:33.332120: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/e/ML/cafa-5-protein-function-prediction\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "DATA_PATH = os.getenv('DATA_PATH')\n",
    "print(DATA_PATH)\n",
    "\n",
    "# Choose subontology (CCO, MFO or BPO)\n",
    "SO = 'BPO'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3544f8a",
   "metadata": {},
   "source": [
    "## Reading fasta, obo and tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b515f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "sequences = [rec.seq for rec in SeqIO.parse(os.path.join(DATA_PATH, \"Train/train_sequences.fasta\"),\"fasta\")]\n",
    "ids = [rec.id for rec in SeqIO.parse(os.path.join(DATA_PATH, \"Train/train_sequences.fasta\"),\"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e492f673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 142246 sequences in the dataset.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} sequences in the dataset.\".format(len(sequences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2898414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "import obonet\n",
    "\n",
    "# Read the taxrank ontology\n",
    "url = os.path.join(DATA_PATH, \"Train/go-basic.obo\")\n",
    "graph = obonet.read_obo(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f4bf949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3497732, 3)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, \"Train/train_terms.tsv\"), sep='\\t')\n",
    "dfSO = df.loc[df[\"aspect\"]==SO]\n",
    "uniqueTerms = dfSO[\"term\"].unique()\n",
    "termsArr = list(dfSO[\"term\"].to_numpy())\n",
    "\n",
    "uniqueTermsDict={}\n",
    "for i,el in enumerate(uniqueTerms):\n",
    "    uniqueTermsDict[el] = i\n",
    "    \n",
    "print(dfSO.shape)\n",
    "df=dfSO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29043526",
   "metadata": {},
   "source": [
    "Test for the first entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af3cf1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>aspect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EntryID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0008152</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0034655</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0072523</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0044270</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0006753</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:1901292</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0044237</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:1901360</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0008150</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:1901564</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  term aspect\n",
       "EntryID                      \n",
       "A0A009IHW8  GO:0008152    BPO\n",
       "A0A009IHW8  GO:0034655    BPO\n",
       "A0A009IHW8  GO:0072523    BPO\n",
       "A0A009IHW8  GO:0044270    BPO\n",
       "A0A009IHW8  GO:0006753    BPO\n",
       "A0A009IHW8  GO:1901292    BPO\n",
       "A0A009IHW8  GO:0044237    BPO\n",
       "A0A009IHW8  GO:1901360    BPO\n",
       "A0A009IHW8  GO:0008150    BPO\n",
       "A0A009IHW8  GO:1901564    BPO"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index(\"EntryID\", inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5777789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 µs ± 306 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit df.loc[\"A0A021WW32\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4dec705",
   "metadata": {},
   "outputs": [],
   "source": [
    "testID = df.index.to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cb2bccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>aspect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EntryID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0008152</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0034655</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0072523</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0044270</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0006753</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:1901292</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0044237</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:1901360</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0008150</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:1901564</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:1901565</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0009117</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0006139</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0044281</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0046496</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0019362</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0046483</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0055086</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0044248</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0019439</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0019637</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0006807</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0019677</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:1901361</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0006163</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0046700</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0009987</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0006725</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0006796</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0034641</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0072521</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0071704</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0019364</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:1901575</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0072526</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0046434</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0009166</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0072524</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0006195</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0009056</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0044238</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0006793</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A009IHW8</th>\n",
       "      <td>GO:0019674</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  term aspect\n",
       "EntryID                      \n",
       "A0A009IHW8  GO:0008152    BPO\n",
       "A0A009IHW8  GO:0034655    BPO\n",
       "A0A009IHW8  GO:0072523    BPO\n",
       "A0A009IHW8  GO:0044270    BPO\n",
       "A0A009IHW8  GO:0006753    BPO\n",
       "A0A009IHW8  GO:1901292    BPO\n",
       "A0A009IHW8  GO:0044237    BPO\n",
       "A0A009IHW8  GO:1901360    BPO\n",
       "A0A009IHW8  GO:0008150    BPO\n",
       "A0A009IHW8  GO:1901564    BPO\n",
       "A0A009IHW8  GO:1901565    BPO\n",
       "A0A009IHW8  GO:0009117    BPO\n",
       "A0A009IHW8  GO:0006139    BPO\n",
       "A0A009IHW8  GO:0044281    BPO\n",
       "A0A009IHW8  GO:0046496    BPO\n",
       "A0A009IHW8  GO:0019362    BPO\n",
       "A0A009IHW8  GO:0046483    BPO\n",
       "A0A009IHW8  GO:0055086    BPO\n",
       "A0A009IHW8  GO:0044248    BPO\n",
       "A0A009IHW8  GO:0019439    BPO\n",
       "A0A009IHW8  GO:0019637    BPO\n",
       "A0A009IHW8  GO:0006807    BPO\n",
       "A0A009IHW8  GO:0019677    BPO\n",
       "A0A009IHW8  GO:1901361    BPO\n",
       "A0A009IHW8  GO:0006163    BPO\n",
       "A0A009IHW8  GO:0046700    BPO\n",
       "A0A009IHW8  GO:0009987    BPO\n",
       "A0A009IHW8  GO:0006725    BPO\n",
       "A0A009IHW8  GO:0006796    BPO\n",
       "A0A009IHW8  GO:0034641    BPO\n",
       "A0A009IHW8  GO:0072521    BPO\n",
       "A0A009IHW8  GO:0071704    BPO\n",
       "A0A009IHW8  GO:0019364    BPO\n",
       "A0A009IHW8  GO:1901575    BPO\n",
       "A0A009IHW8  GO:0072526    BPO\n",
       "A0A009IHW8  GO:0046434    BPO\n",
       "A0A009IHW8  GO:0009166    BPO\n",
       "A0A009IHW8  GO:0072524    BPO\n",
       "A0A009IHW8  GO:0006195    BPO\n",
       "A0A009IHW8  GO:0009056    BPO\n",
       "A0A009IHW8  GO:0044238    BPO\n",
       "A0A009IHW8  GO:0006793    BPO\n",
       "A0A009IHW8  GO:0019674    BPO"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.loc[testID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "184631e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BPO'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df[\"aspect\"].to_numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5338b7f8",
   "metadata": {},
   "source": [
    "## GO analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1058ef1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO:0008150    92210\n",
      "GO:0009987    61293\n",
      "GO:0065007    41457\n",
      "GO:0050789    39256\n",
      "GO:0050794    33888\n",
      "GO:0050896    31098\n",
      "GO:0008152    30448\n",
      "GO:0032501    29274\n",
      "GO:0032502    28680\n",
      "GO:0071704    28274\n",
      "GO:0048856    27366\n",
      "GO:0044237    25273\n",
      "GO:0044238    24419\n",
      "GO:0007275    21784\n",
      "GO:0006807    21579\n",
      "GO:0071840    19458\n",
      "GO:0019222    19174\n",
      "GO:0016043    18486\n",
      "GO:0048518    18364\n",
      "GO:0043170    17450\n",
      "Name: term, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "item_counts = df[\"term\"].value_counts()\n",
    "print(item_counts[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb35584f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nuclear lumen\n"
     ]
    }
   ],
   "source": [
    "id_to_name = {id_: data.get('name') for id_, data in graph.nodes(data=True)}\n",
    "name_to_id = {data['name']: id_ for id_, data in graph.nodes(data=True) if 'name' in data}\n",
    "print(id_to_name['GO:0031981'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85b2429c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intracellular organelle lumen\n",
      "{'GO:0070449', 'GO:0005763', 'GO:0036224', 'GO:0060202', 'GO:0099086', 'GO:0000794', 'GO:0031261', 'GO:0033276', 'GO:0005668', 'GO:1990934', 'GO:0070082', 'GO:0000330', 'GO:0061201', 'GO:0030896', 'GO:0097424', 'GO:0035363', 'GO:0043596', 'GO:0033985', 'GO:0031089', 'GO:0005762', 'GO:0016606', 'GO:0036014', 'GO:0031907', 'GO:0045244', 'GO:1904724', 'GO:0070860', 'GO:0070692', 'GO:0034493', 'GO:0034774', 'GO:0034388', 'GO:0106172', 'GO:0014803', 'GO:0005759', 'GO:1990826', 'GO:0015030', 'GO:0043494', 'GO:0005662', 'GO:0034492', 'GO:0043599', 'GO:0060205', 'GO:0000817', 'GO:0032021', 'GO:0008023', 'GO:0016607', 'GO:0071601', 'GO:0071339', 'GO:0017087', 'GO:0031905', 'GO:0106098', 'GO:0008024', 'GO:0099020', 'GO:0005714', 'GO:0070823', 'GO:0062113', 'GO:0043601', 'GO:0031906', 'GO:0106176', 'GO:0016605', 'GO:0016593', 'GO:0005775', 'GO:0031972', 'GO:0031096', 'GO:0098899', 'GO:0005665', 'GO:0000120', 'GO:0005669', 'GO:0009841', 'GO:0106173', 'GO:0097486', 'GO:0101019', 'GO:0030874', 'GO:0000228', 'GO:0005726', 'GO:0032783', 'GO:0005715', 'GO:0031595', 'GO:0030062', 'GO:0070210', 'GO:0070985', 'GO:0016604', 'GO:0034468', 'GO:0016363', 'GO:0034466', 'GO:0034592', 'GO:0000801', 'GO:0031973', 'GO:0005656', 'GO:0071920', 'GO:0098898', 'GO:0005967', 'GO:0035580', 'GO:0010445', 'GO:0001405', 'GO:0097356', 'GO:0120282', 'GO:0070211', 'GO:0000811', 'GO:0000500', 'GO:0070691', 'GO:0035061', 'GO:0071682', 'GO:0001650', 'GO:0030869', 'GO:0060204', 'GO:0071162', 'GO:0061773', 'GO:0070822', 'GO:0070517', 'GO:0005652', 'GO:0005731', 'GO:0106055', 'GO:0043625', 'GO:0031970', 'GO:0016581', 'GO:0034974', 'GO:1990483', 'GO:0005672', 'GO:0005674', 'GO:0035098', 'GO:0031908', 'GO:1990251', 'GO:0034495', 'GO:0098564', 'GO:0034099', 'GO:0014804', 'GO:0034777', 'GO:1904856', 'GO:0043294', 'GO:0062238', 'GO:0048237', 'GO:0005664', 'GO:0000176', 'GO:0005736', 'GO:0019910', 'GO:0016507', 'GO:0032798', 'GO:0031298', 'GO:0000262', 'GO:0034422', 'GO:0042719', 'GO:0030998', 'GO:0000446', 'GO:0034423', 'GO:0000328', 'GO:0098566', 'GO:0048188', 'GO:0001740', 'GO:0110129', 'GO:0110145', 'GO:0099013', 'GO:0097013', 'GO:0031093', 'GO:0016580', 'GO:0005796', 'GO:0034455', 'GO:0031979', 'GO:0005654', 'GO:0030685', 'GO:0044665', 'GO:0005761', 'GO:0062246', 'GO:0031598', 'GO:0034467', 'GO:0031981', 'GO:0034457', 'GO:0035578', 'GO:0005712', 'GO:0032044', 'GO:0044842', 'GO:0070556', 'GO:0110016', 'GO:0033557', 'GO:0099021', 'GO:0005758', 'GO:0035808', 'GO:0036021', 'GO:0030875', 'GO:0005782', 'GO:0005962', 'GO:0005947', 'GO:0034399', 'GO:0000802', 'GO:0000795', 'GO:0043160', 'GO:0005788', 'GO:0031429', 'GO:0031011', 'GO:0070545', 'GO:0005673', 'GO:0048238', 'GO:0005658', 'GO:0031904', 'GO:0042645', 'GO:0034494', 'GO:0005730', 'GO:0031601', 'GO:0035097', 'GO:0070931', 'GO:0072589', 'GO:0033018', 'GO:1990836', 'GO:0030958', 'GO:0005655', 'GO:0031610', 'GO:0070824', 'GO:0001651', 'GO:0008622', 'GO:0097489', 'GO:0009529', 'GO:0000438', 'GO:0016591', 'GO:0034985', 'GO:0035062', 'GO:0005638', 'GO:0001652', 'GO:0000800', 'GO:0031613', 'GO:0097504', 'GO:0034967', 'GO:0000118', 'GO:0043202', 'GO:0009353', 'GO:0005713', 'GO:0033698', 'GO:0031604', 'GO:0005641', 'GO:0106174', 'GO:0042382', 'GO:0070311', 'GO:0005675', 'GO:0031607', 'GO:0034456', 'GO:0017133', 'GO:1904813', 'GO:0106069', 'GO:0000812', 'GO:0032221', 'GO:0035101', 'GO:0034469', 'GO:0044666', 'GO:0005760'}\n",
      "{'GO:0005575', 'GO:0043229', 'GO:0005622', 'GO:0031974', 'GO:0110165', 'GO:0043226', 'GO:0043233'}\n"
     ]
    }
   ],
   "source": [
    "print(id_to_name['GO:0070013'] )\n",
    "print(networkx.ancestors(graph, 'GO:0070013'))\n",
    "print(networkx.descendants(graph, 'GO:0070013'))\n",
    "\n",
    "paths = networkx.all_simple_paths(\n",
    "    graph,\n",
    "    source='GO:0070013',\n",
    "    target=name_to_id['molecular_function']\n",
    ")\n",
    "\n",
    "for path in paths:\n",
    "    print('•', ' ⟶ '.join(id_to_name[node] for node in path))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c099fc2",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cae9a3b0",
   "metadata": {},
   "source": [
    "The task is a multilabel classification: The output has several possible targets (Gene Ontologies) but each can only be 1 (existing) or 0 (non existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99f6a6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GO:0008152' 'GO:0034655' 'GO:0072523' 'GO:0044270' 'GO:0006753'\n",
      " 'GO:1901292' 'GO:0044237' 'GO:1901360' 'GO:0008150' 'GO:1901564'\n",
      " 'GO:1901565' 'GO:0009117' 'GO:0006139' 'GO:0044281' 'GO:0046496'\n",
      " 'GO:0019362' 'GO:0046483' 'GO:0055086' 'GO:0044248' 'GO:0019439'\n",
      " 'GO:0019637' 'GO:0006807' 'GO:0019677' 'GO:1901361' 'GO:0006163'\n",
      " 'GO:0046700' 'GO:0009987' 'GO:0006725' 'GO:0006796' 'GO:0034641'\n",
      " 'GO:0072521' 'GO:0071704' 'GO:0019364' 'GO:1901575' 'GO:0072526'\n",
      " 'GO:0046434' 'GO:0009166' 'GO:0072524' 'GO:0006195' 'GO:0009056'\n",
      " 'GO:0044238' 'GO:0006793' 'GO:0019674']\n",
      "[[0 0 0 ... 0 0 0]]\n",
      "21285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "topGOs= item_counts\n",
    "topGOs=topGOs.index.to_list()\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([topGOs])\n",
    "\n",
    "dftest=df.loc[testID]\n",
    "indices = dftest[\"term\"].to_numpy()\n",
    "print(indices)\n",
    "print(mlb.transform([indices]))\n",
    "print(len(mlb.classes_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92019f8c",
   "metadata": {},
   "source": [
    "## Amino acids encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b747477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aminos_list = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e42462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_dict = {'A': 1, 'B':24, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'O': 21, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'U': 22, 'V': 18, 'W': 19, 'Y': 20, 'X':30, 'Z':23}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfd823ba",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "431f9df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max. length of the sequences is 35375\n"
     ]
    }
   ],
   "source": [
    "seqLengths = [len(seq) for seq in sequences]\n",
    "maxLen = max(seqLengths)\n",
    "print(\"The max. length of the sequences is {}\".format(maxLen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e581e06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A0A009IHW8' 'A0A021WW32' 'A0A023FFD0' ... 'X5L1L5' 'X5L565' 'X5M5N0']\n",
      "92210\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dfAll=pd.read_csv(os.path.join(DATA_PATH, \"Train/train_terms.tsv\"), sep='\\t')\n",
    "# dfAll.set_index(\"EntryID\", inplace=True)\n",
    "soEntries = dfAll.loc[dfAll[\"aspect\"]==SO]\n",
    "soEntryIds = soEntries[\"EntryID\"].unique()\n",
    "\n",
    "# print(len(seqEntries))\n",
    "print(soEntryIds)\n",
    "\n",
    "SoSequences = []\n",
    "for entry in soEntryIds:\n",
    "    SoSequences.append(sequences[ids.index(entry)])\n",
    "\n",
    "print(len(SoSequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44f722e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64546\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "TRAIN_VAL_SPLIT = 0.7\n",
    "\n",
    "#Use numpy vectorize to speed up the mapping (hopefully)\n",
    "mapping = lambda x: aa_dict[x]\n",
    "vectMapping = np.vectorize(mapping)\n",
    "\n",
    "# Shuffle the data\n",
    "import random\n",
    "random.seed(516213)\n",
    "c = list(zip(SoSequences, soEntryIds))\n",
    "random.shuffle(c)\n",
    "sequencesShuffle, idsShuffle = zip(*c)\n",
    "\n",
    "#reduce data for now\n",
    "# sequencesShuffle = sequencesShuffle[0:10000]\n",
    "# idsShuffle = idsShuffle[0:10000]\n",
    "\n",
    "#Train Validation Split\n",
    "split = int(np.floor(len(sequencesShuffle)*TRAIN_VAL_SPLIT))\n",
    "print(split)\n",
    "trainSeq = sequencesShuffle[0:split]\n",
    "valSeq = sequencesShuffle[split+1:]\n",
    "trainIds = idsShuffle[0:split]\n",
    "valIds = idsShuffle[split+1:]\n",
    "\n",
    "\n",
    "def generator(padding=True):\n",
    "    for i,seq in enumerate(trainSeq):\n",
    "        entryId = trainIds[i]\n",
    "        labelData = df.loc[entryId]\n",
    "        \n",
    "        # indices = labelData[\"termToken\"].to_numpy()\n",
    "        indices = labelData[\"term\"].to_numpy()\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            #supress the warnings for unknown classes\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            y = mlb.transform([indices])\n",
    "        \n",
    "        arr = np.array(seq)\n",
    "        mappedArr = vectMapping(arr)\n",
    "        if padding:\n",
    "            padWidth = maxLen - arr.size\n",
    "            mappedArr = np.pad(mappedArr, (0, padWidth))\n",
    "        yield mappedArr,y[0]\n",
    "\n",
    "def generatorVal(padding=True):\n",
    "    for i,seq in enumerate(valSeq):\n",
    "        entryId = valIds[i]\n",
    "        labelData = df.loc[entryId]\n",
    "        \n",
    "        # indices = labelData[\"termToken\"].to_numpy()\n",
    "        indices = labelData[\"term\"].to_numpy()\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            #supress the warnings for unknown classes\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            y = mlb.transform([indices])\n",
    "        \n",
    "        arr = np.array(seq)\n",
    "        mappedArr = vectMapping(arr)\n",
    "        if padding:\n",
    "            padWidth = maxLen - arr.size\n",
    "            mappedArr = np.pad(mappedArr, (0, padWidth))\n",
    "        yield mappedArr,y[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd15e8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first sample sequence: [11 15  9 ...  0  0  0]\n",
      "The first sample has 127 classes\n"
     ]
    }
   ],
   "source": [
    "g = generator()\n",
    "test = next(g)\n",
    "print(\"The first sample sequence: {}\".format(test[0]))\n",
    "print(\"The first sample has {} classes\".format(np.count_nonzero(test[1])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10c4a51a",
   "metadata": {},
   "source": [
    "## Tensorflow Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63f0d2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 17:59:38.362199: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 17:59:38.385464: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 17:59:38.385793: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 17:59:38.387172: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 17:59:38.387470: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 17:59:38.387779: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 17:59:38.857956: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 17:59:38.858361: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 17:59:38.858376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-16 17:59:38.858726: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 17:59:38.858761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6569 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:2b:00.0, compute capability: 6.1\n",
      "2023-05-16 17:59:39.109481: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(<tf.Tensor: shape=(35375,), dtype=int32, numpy=array([11, 15,  9, ...,  0,  0,  0], dtype=int32)>, <tf.Tensor: shape=(21285,), dtype=int32, numpy=array([0, 0, 0, ..., 0, 0, 0], dtype=int32)>)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(generator, output_signature=(\n",
    "         tf.TensorSpec(shape=(maxLen,), dtype=tf.int32),\n",
    "         tf.TensorSpec(shape=(len(mlb.classes_),), dtype=tf.int32)))\n",
    "print(list(dataset.take(1)))\n",
    "\n",
    "datasetVal = tf.data.Dataset.from_generator(generatorVal, output_signature=(\n",
    "         tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "         tf.TensorSpec(shape=(len(mlb.classes_),), dtype=tf.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0a554f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98752d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embedConvModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 35375)]           0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 35375, 100)        2500      \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 100)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 100, 1)            0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 94, 8)             64        \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 88, 8)             456       \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 82, 8)             456       \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 76, 16)            912       \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 70, 16)            1808      \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 32, 16)            1808      \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 13, 16)            1808      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 208)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                6688      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 21285)             702405    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 719,961\n",
      "Trainable params: 719,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "VOCAB_SIZE=len(aa_dict)\n",
    "EMBED_DIM=100\n",
    "\n",
    "def createModel():\n",
    "    inputs = tf.keras.Input(shape=(maxLen,))\n",
    "    x=layers.Embedding(VOCAB_SIZE, EMBED_DIM, mask_zero=True, name=\"embedding\")(inputs)\n",
    "    x=layers.GlobalAveragePooling1D()(x)\n",
    "    x=layers.Reshape((EMBED_DIM,1))(x)\n",
    "    x=layers.Conv1D(8, 7)(x)\n",
    "    x=layers.Conv1D(8, 7)(x)\n",
    "    x=layers.Conv1D(8, 7)(x)\n",
    "    x=layers.Conv1D(16, 7)(x)\n",
    "    x=layers.Conv1D(16, 7)(x)\n",
    "    x=layers.Conv1D(16, 7, strides=2)(x)\n",
    "    x=layers.Conv1D(16, 7, strides=2)(x)\n",
    "    # x=layers.Conv1D(32, 5, activation=tf.keras.activations.relu)(x)\n",
    "    # x=layers.Conv1D(32, 5, activation=tf.keras.activations.relu)(x)\n",
    "    # x=layers.Conv1D(32, 5, activation=tf.keras.activations.relu)(x)\n",
    "    x=layers.Flatten()(x)\n",
    "    x=layers.Dense(32)(x)\n",
    "    x=layers.LeakyReLU()(x)\n",
    "    x=layers.Dense(32)(x)\n",
    "    x=layers.LeakyReLU()(x)\n",
    "    outputs=layers.Dense(len(mlb.classes_), activation=tf.keras.activations.sigmoid)(x)\n",
    "    # outputs=layers.Softmax()(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name=\"embedConvModel\")\n",
    "\n",
    "model = createModel()\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73140569",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "VOCAB_SIZE=len(aa_dict)\n",
    "EMBED_DIM=200\n",
    "\n",
    "def createRnnModel():\n",
    "    inputs = tf.keras.Input(shape=(maxLen,))\n",
    "    x = tf.keras.layers.Masking(0)(inputs)\n",
    "    x=layers.Embedding(VOCAB_SIZE, EMBED_DIM, name=\"embedding\")(x)\n",
    "\n",
    "    # x = layers.Bidirectional(layers.LSTM(32, return_sequences=True))(x)\n",
    "    # x = layers.Bidirectional(layers.GRU(16, return_sequences=True))(x)\n",
    "    x = layers.Bidirectional(layers.GRU(16))(x)\n",
    "    # x = layers.LSTM(32)(x)\n",
    "    x = layers.Dense(16)(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    outputs=layers.Dense(len(mlb.classes_), activation=tf.keras.activations.sigmoid)(x)\n",
    "    # outputs=layers.Softmax()(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name=\"embedRnnModel\")\n",
    "\n",
    "# model = createRnnModel()\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a3ddc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Learning rate schedule\n",
    "initial_learning_rate = 0.01\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10,\n",
    "    decay_rate=0.9,\n",
    "    staircase=False)\n",
    "# step = np.linspace(0,1000)\n",
    "# lr = lr_schedule(step)\n",
    "# plt.figure(figsize = (8,6))\n",
    "# plt.yscale(\"log\")\n",
    "# plt.plot(step, lr)\n",
    "# plt.ylim([0,max(plt.ylim())])\n",
    "# plt.xlabel('step')\n",
    "# _ = plt.ylabel('Learning Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9113c4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "\n",
      "Start of epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 18:07:17.970012: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/Step 0, Loss: 0.00810, Accuracy: 0.99816, lr: 0.01000\n",
      "Epoch 1/Step 10, Loss: 0.09193, Accuracy: 0.91396, lr: 0.01000\n",
      "Epoch 1/Step 20, Loss: 0.07632, Accuracy: 0.95323, lr: 0.01000\n",
      "Epoch 1/Step 30, Loss: 0.30883, Accuracy: 0.96625, lr: 0.01000\n",
      "Epoch 1/Step 40, Loss: 0.38556, Accuracy: 0.94951, lr: 0.01000\n",
      "Epoch 1/Step 50, Loss: 0.98073, Accuracy: 0.95879, lr: 0.01000\n",
      "Epoch 1/Step 60, Loss: 0.12851, Accuracy: 0.96503, lr: 0.01000\n",
      "Epoch 1/Step 70, Loss: 1.07380, Accuracy: 0.96840, lr: 0.01000\n",
      "Epoch 1/Step 80, Loss: 0.60971, Accuracy: 0.97191, lr: 0.01000\n",
      "Epoch 1/Step 90, Loss: 0.24330, Accuracy: 0.97464, lr: 0.01000\n",
      "Epoch 1/Step 100, Loss: 0.09811, Accuracy: 0.97680, lr: 0.01000\n",
      "Epoch 1/Step 110, Loss: 0.22531, Accuracy: 0.97851, lr: 0.01000\n",
      "Epoch 1/Step 120, Loss: 0.08843, Accuracy: 0.98007, lr: 0.01000\n",
      "Epoch 1/Step 130, Loss: 0.10498, Accuracy: 0.98131, lr: 0.01000\n",
      "Epoch 1/Step 140, Loss: 0.12258, Accuracy: 0.98241, lr: 0.01000\n",
      "Epoch 1/Step 150, Loss: 0.03428, Accuracy: 0.98336, lr: 0.01000\n",
      "Epoch 1/Step 160, Loss: 0.02282, Accuracy: 0.98425, lr: 0.01000\n",
      "Epoch 1/Step 170, Loss: 0.11520, Accuracy: 0.98497, lr: 0.01000\n",
      "Epoch 1/Step 180, Loss: 0.03685, Accuracy: 0.98566, lr: 0.01000\n",
      "Epoch 1/Step 190, Loss: 0.03159, Accuracy: 0.98627, lr: 0.01000\n",
      "Epoch 1/Step 200, Loss: 0.02340, Accuracy: 0.98683, lr: 0.01000\n",
      "Epoch 1/Step 210, Loss: 0.02949, Accuracy: 0.98735, lr: 0.01000\n",
      "Epoch 1/Step 220, Loss: 0.02874, Accuracy: 0.98777, lr: 0.01000\n",
      "Epoch 1/Step 230, Loss: 0.02303, Accuracy: 0.98821, lr: 0.01000\n",
      "Epoch 1/Step 240, Loss: 0.01263, Accuracy: 0.98862, lr: 0.01000\n",
      "Epoch 1/Step 250, Loss: 0.02273, Accuracy: 0.98897, lr: 0.01000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23164/1846912038.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0msaveModel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Num GPUs Available: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0mlog_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./logs/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y%m%d-%H%M%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mSO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,\n",
      "\u001b[0;32m/tmp/ipykernel_23164/1846912038.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(x_batch_train, y_batch_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# grads = [tf.clip_by_norm(g, 2.0) for g in grads]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Run one step of gradient descent by updating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# the value of the variables to minimize the loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mtrain_acc_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;34m\"experimental_aggregate_gradients\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m         )\n\u001b[1;32m   1172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_gradients_aggregation\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mexperimental_aggregate_gradients\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m             \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clip_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deduplicate_sparse_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_weight_decay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_apply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, variables)\u001b[0m\n\u001b[1;32m   1189\u001b[0m                 distribution.extended.update(\n\u001b[1;32m   1190\u001b[0m                     \u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 )\n\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m         tf.__internal__.distribute.interim.maybe_merge_call(\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mdistributed_apply_weight_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/distribute/merge_call_interim.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \"\"\"\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     return distribution_strategy_context.get_replica_context().merge_call(\n\u001b[1;32m     54\u001b[0m         fn, args=args, kwargs=kwargs)\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(distribution, variables, **kwargs)\u001b[0m\n\u001b[1;32m   1185\u001b[0m                     \u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                     \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mwd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m                 distribution.extended.update(\n\u001b[0m\u001b[1;32m   1190\u001b[0m                     \u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 )\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2633\u001b[0m         distribution_strategy_context._get_default_replica_context()):\n\u001b[1;32m   2634\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   2635\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   2636\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2638\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2639\u001b[0m       return self._replica_ctx_update(\n\u001b[1;32m   2640\u001b[0m           var, fn, args=args, kwargs=kwargs, group=group)\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3707\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3708\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3709\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3710\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   3716\u001b[0m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3717\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3718\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3719\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3720\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(variable)\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mweight_decay_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_weight_decay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                     \u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m                     \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mwd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(a, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_oper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1473\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1477\u001b[0;31m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1815\u001b[0m     new_vals = gen_sparse_ops.sparse_dense_cwise_mul(y.indices, y.values,\n\u001b[1;32m   1816\u001b[0m                                                      y.dense_shape, x, name)\n\u001b[1;32m   1817\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1818\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1819\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m    \u001b[0;34m*\u001b[0m \u001b[0mInvalidArgumentError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mWhen\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mincompatible\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m   \"\"\"\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6578\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6579\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6580\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6581\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6582\u001b[0;31m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6583\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6584\u001b[0m       return mul_eager_fallback(\n\u001b[1;32m   6585\u001b[0m           x, y, name=name, ctx=_ctx)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=32\n",
    "LOG_INTERVAL=10\n",
    "epochs = 20\n",
    "saveModel=False\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "log_dir = \"./logs/\"+model.name+\"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+\"_\"+SO\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,\n",
    "                                                      write_graph=True, update_freq=5)\n",
    "\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "# Instantiate an optimizer .\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "optimizer = tf.keras.optimizers.AdamW(learning_rate=0.01)\n",
    "\n",
    "# Instantiate a loss function.\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "train_acc_metric = tf.keras.metrics.BinaryAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.BinaryAccuracy()\n",
    "\n",
    "batchedDataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "batchedDatasetVal = datasetVal.batch(BATCH_SIZE, drop_remainder=False)\n",
    "# print(batchedDataset.take(1))\n",
    "\n",
    "batchedDataset = batchedDataset.cache(os.path.join(DATA_PATH, \"datasetCache\"+SO))\n",
    "batchedDatasetVal = batchedDatasetVal.cache(os.path.join(DATA_PATH, \"datasetCacheVal\"+SO))\n",
    "\n",
    "# @tf.function()\n",
    "def trainStep(x_batch_train, y_batch_train):\n",
    "    # Open a GradientTape to record the operations run\n",
    "    # during the forward pass, which enables auto-differentiation.\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # Run the forward pass of the layer.\n",
    "        # The operations that the layer applies\n",
    "        # to its inputs are going to be recorded\n",
    "        # on the GradientTape.\n",
    "        probs = model(x_batch_train, training=True) \n",
    "\n",
    "        # Compute the loss value for this minibatch.\n",
    "        loss_value = loss_fn(y_batch_train, probs)\n",
    "\n",
    "    # Use the gradient tape to automatically retrieve\n",
    "    # the gradients of the trainable variables with respect to the loss.\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    #Gradient clipping\n",
    "    # grads = [tf.clip_by_norm(g, 2.0) for g in grads]\n",
    "\n",
    "    # Run one step of gradient descent by updating\n",
    "    # the value of the variables to minimize the loss.\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "    train_acc_metric.update_state(y_batch_train, probs)\n",
    "    return loss_value, grads\n",
    "\n",
    "maxStep=0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch+1,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(batchedDataset):\n",
    "\n",
    "        loss_value, grads=trainStep(x_batch_train,y_batch_train)\n",
    "\n",
    "        # Log \n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            template = 'Epoch {}/Step {}, Loss: {:.5f}, Accuracy: {:.5f}, lr: {:.5f}'\n",
    "            print (template.format(epoch+1, step,loss_value, \n",
    "                                    train_acc_metric.result(), optimizer.learning_rate.numpy()))\n",
    "            # print([tf.norm(grad, ord=2).numpy() for grad in grads])\n",
    "            with summary_writer.as_default():\n",
    "                tf.summary.scalar('loss', loss_value, step=maxStep*epoch+step)\n",
    "                tf.summary.scalar('accuracy', train_acc_metric.result(), step=maxStep*epoch+step)\n",
    "                summary_writer.flush()\n",
    "\n",
    "    \n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    maxStep=step\n",
    "\n",
    "    print(\"Epoch finished. Start validation\")\n",
    "    for x_batch_val, y_batch_val in batchedDatasetVal:\n",
    "        valProbs = model(x_batch_val, training=False)\n",
    "        # Update val metrics\n",
    "        val_acc_metric.update_state(y_batch_val, valProbs)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('valAcc', float(val_acc), step=epoch)\n",
    "        summary_writer.flush()\n",
    "    if saveModel:\n",
    "      model.save(os.path.join(DATA_PATH, \"model_\"+SO+\"_epoch_{}_valAcc{:.3f}\".format(epoch, float(val_acc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f7234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in model.layers: print(layer.get_config(), layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cefc1f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 18:04:31.675169: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('GO:0008150', 'GO:0009987', 'GO:0050789', 'GO:0050794', 'GO:0065007')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "probs= model.predict(tf.expand_dims(list(datasetVal.take(32))[0][0], 0))\n",
    "prediction= [1 if p > 0.5 else 0 for p in probs[0]]\n",
    "# classes = np.argwhere(prediction)\n",
    "mlb.inverse_transform(np.array([prediction]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
