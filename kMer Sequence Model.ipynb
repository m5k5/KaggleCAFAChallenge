{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c1d77e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "/mnt/e/ML/cafa-5-protein-function-prediction\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "# try:\n",
    "#   tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "# except:\n",
    "#   # Invalid device or cannot modify virtual devices once initialized.\n",
    "#   pass\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "DATA_PATH = os.getenv('DATA_PATH')\n",
    "print(DATA_PATH)\n",
    "\n",
    "# Choose subontology (CCO, MFO or BPO)\n",
    "SO = 'BPO'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3544f8a",
   "metadata": {},
   "source": [
    "## Reading fasta, obo and tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b515f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "sequences = [rec.seq for rec in SeqIO.parse(os.path.join(DATA_PATH, \"Train/train_sequences.fasta\"),\"fasta\")]\n",
    "ids = [rec.id for rec in SeqIO.parse(os.path.join(DATA_PATH, \"Train/train_sequences.fasta\"),\"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2898414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "import obonet\n",
    "\n",
    "# Read the taxrank ontology\n",
    "url = os.path.join(DATA_PATH, \"Train/go-basic.obo\")\n",
    "graph = obonet.read_obo(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f4bf949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3497732, 3)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, \"Train/train_terms.tsv\"), sep='\\t')\n",
    "\n",
    "dfSO = df.loc[df[\"aspect\"]==SO]\n",
    "uniqueTerms = dfSO[\"term\"].unique()\n",
    "termsArr = list(dfSO[\"term\"].to_numpy())\n",
    "\n",
    "uniqueTermsDict={}\n",
    "for i,el in enumerate(uniqueTerms):\n",
    "    uniqueTermsDict[el] = i\n",
    "    \n",
    "print(dfSO.shape)\n",
    "df=dfSO\n",
    "\n",
    "df.set_index(\"EntryID\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4dec705",
   "metadata": {},
   "outputs": [],
   "source": [
    "testID = df.index.to_list()[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5338b7f8",
   "metadata": {},
   "source": [
    "## GO analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1058ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_counts = df[\"term\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb35584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_name = {id_: data.get('name') for id_, data in graph.nodes(data=True)}\n",
    "name_to_id = {data['name']: id_ for id_, data in graph.nodes(data=True) if 'name' in data}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c099fc2",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cae9a3b0",
   "metadata": {},
   "source": [
    "The task is a multilabel classification: The output has several possible targets (Gene Ontologies) but each can only be 1 (existing) or 0 (non existing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8e63ed9",
   "metadata": {},
   "source": [
    "Extract label weights from IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7e3c316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found GOs: 0 (set to 0)\n"
     ]
    }
   ],
   "source": [
    "dfIa = pd.read_csv(os.path.join(DATA_PATH, \"IA.txt\"), sep='\\t', header=None)\n",
    "\n",
    "dfIa.set_index(0, inplace=True)\n",
    "\n",
    "labelWeights=[]\n",
    "allIndices = dfIa.index.tolist()\n",
    "\n",
    "# if SO == \"BPO\":\n",
    "#     item_counts=item_counts[0:10]\n",
    "#     # item_counts=item_counts[0:len(item_counts)//2]\n",
    "\n",
    "notFound=0\n",
    "for go in item_counts.index.to_list():\n",
    "    if go in allIndices:\n",
    "        labelWeights.append(dfIa.loc[go].to_numpy()[0])\n",
    "    else:\n",
    "        notFound += 1\n",
    "        labelWeights.append(0)\n",
    "\n",
    "print(\"Not found GOs: {} (set to 0)\".format(notFound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99f6a6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GO:0008152' 'GO:0034655' 'GO:0072523' 'GO:0044270' 'GO:0006753'\n",
      " 'GO:1901292' 'GO:0044237' 'GO:1901360' 'GO:0008150' 'GO:1901564'\n",
      " 'GO:1901565' 'GO:0009117' 'GO:0006139' 'GO:0044281' 'GO:0046496'\n",
      " 'GO:0019362' 'GO:0046483' 'GO:0055086' 'GO:0044248' 'GO:0019439'\n",
      " 'GO:0019637' 'GO:0006807' 'GO:0019677' 'GO:1901361' 'GO:0006163'\n",
      " 'GO:0046700' 'GO:0009987' 'GO:0006725' 'GO:0006796' 'GO:0034641'\n",
      " 'GO:0072521' 'GO:0071704' 'GO:0019364' 'GO:1901575' 'GO:0072526'\n",
      " 'GO:0046434' 'GO:0009166' 'GO:0072524' 'GO:0006195' 'GO:0009056'\n",
      " 'GO:0044238' 'GO:0006793' 'GO:0019674']\n",
      "[[0 0 0 ... 0 0 0]]\n",
      "6355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manuel/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['GO:0006139', 'GO:0006163', 'GO:0006195', 'GO:0006725', 'GO:0006753', 'GO:0006796', 'GO:0006807', 'GO:0008150', 'GO:0008152', 'GO:0009117', 'GO:0009166', 'GO:0009987', 'GO:0019362', 'GO:0019364', 'GO:0019439', 'GO:0019637', 'GO:0019674', 'GO:0019677', 'GO:0034641', 'GO:0034655', 'GO:0044237', 'GO:0044238', 'GO:0044248', 'GO:0044270', 'GO:0046434', 'GO:0046483', 'GO:0046496', 'GO:0046700', 'GO:0055086', 'GO:0071704', 'GO:0072521', 'GO:0072523', 'GO:0072526', 'GO:1901292', 'GO:1901360', 'GO:1901361', 'GO:1901564', 'GO:1901565', 'GO:1901575'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pickle\n",
    "\n",
    "topGOs= item_counts\n",
    "topGOs=topGOs.index.to_list()\n",
    "\n",
    "threshold=2\n",
    "labelWeights=np.array(labelWeights)\n",
    "selection = labelWeights>threshold\n",
    "topGOs=np.array(topGOs)[selection]\n",
    "\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([topGOs])\n",
    "\n",
    "dftest=df.loc[testID]\n",
    "indices = dftest[\"term\"].to_numpy()\n",
    "print(indices)\n",
    "print(mlb.transform([indices]))\n",
    "print(len(mlb.classes_))\n",
    "\n",
    "with open(os.path.join(DATA_PATH,'MLB_'+SO+'.pkl'), 'wb') as f:\n",
    "    pickle.dump(mlb, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92019f8c",
   "metadata": {},
   "source": [
    "## Amino acids encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b747477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aminos_list = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e42462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_dict = {'A': 1, 'B':24, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'O': 21, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'U': 22, 'V': 18, 'W': 19, 'Y': 20, 'X':30, 'Z':23}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfd823ba",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "431f9df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max. length of the sequences is 35375\n"
     ]
    }
   ],
   "source": [
    "seqLengths = [len(seq) for seq in sequences]\n",
    "maxLen = max(seqLengths)\n",
    "print(\"The max. length of the sequences is {}\".format(maxLen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e581e06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A0A009IHW8' 'A0A021WW32' 'A0A023FFD0' ... 'X5L1L5' 'X5L565' 'X5M5N0']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dfAll=pd.read_csv(os.path.join(DATA_PATH, \"Train/train_terms.tsv\"), sep='\\t')\n",
    "\n",
    "soEntries = dfAll.loc[dfAll[\"aspect\"]==SO]\n",
    "soEntryIds = soEntries[\"EntryID\"].unique()\n",
    "\n",
    "# print(len(seqEntries))\n",
    "print(soEntryIds)\n",
    "\n",
    "# SoSequences = []\n",
    "# for entry in soEntryIds:\n",
    "#     SoSequences.append(sequences[ids.index(entry)])\n",
    "\n",
    "# print(len(SoSequences))\n",
    "dfAll.set_index(\"EntryID\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44f722e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99572\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "TRAIN_VAL_SPLIT = 0.7\n",
    "k = 3\n",
    "n=100\n",
    "maxFreqVectorLen = 5000//n\n",
    "\n",
    "allAA = list(aa_dict.keys())\n",
    "allAA.sort()\n",
    "allCombinations= list(product(*(allAA for i in range(k))))\n",
    "allCombinations=np.array([''.join(el) for el in allCombinations])\n",
    "\n",
    "positionDict = dict(zip(allCombinations, np.arange(0,allCombinations.size).T))\n",
    "\n",
    "xSize = allCombinations.shape[0]\n",
    "\n",
    "#Use numpy vectorize to speed up the mapping (hopefully)\n",
    "mapping = lambda x: aa_dict[x]\n",
    "vectMapping = np.vectorize(mapping)\n",
    "\n",
    "# Shuffle the data\n",
    "import random\n",
    "random.seed(516213)\n",
    "c = list(zip(sequences, ids))\n",
    "random.shuffle(c)\n",
    "sequencesShuffle, idsShuffle = zip(*c)\n",
    "\n",
    "\n",
    "#Train Validation Split\n",
    "split = int(np.floor(len(sequencesShuffle)*TRAIN_VAL_SPLIT))\n",
    "print(split)\n",
    "trainSeq = sequencesShuffle[0:split]\n",
    "valSeq = sequencesShuffle[split+1:]\n",
    "trainIds = idsShuffle[0:split]\n",
    "valIds = idsShuffle[split+1:]\n",
    "\n",
    "\n",
    "def generator():\n",
    "  for i,seq in enumerate(trainSeq):\n",
    "      entryId = trainIds[i]\n",
    "      \n",
    "      if entryId in soEntryIds:\n",
    "        labelData = df.loc[entryId]\n",
    "        # indices = labelData[\"termToken\"].to_numpy()\n",
    "        indices = labelData[\"term\"].to_numpy()\n",
    "      else:\n",
    "        indices=[]\n",
    "\n",
    "      with warnings.catch_warnings():\n",
    "          #supress the warnings for unknown classes\n",
    "          warnings.simplefilter(\"ignore\")\n",
    "          y = mlb.transform([indices])\n",
    "      \n",
    "      seqLen= len(seq)\n",
    "      freqVectorSeq=[]\n",
    "      for subIdx in np.arange(0, seqLen//n+1):\n",
    "        subSeq = seq[subIdx*n:(subIdx+1)*n]\n",
    "        if len(subSeq)<3:\n",
    "          continue\n",
    "        kmers = [subSeq[i:i+k] if i < len(subSeq)-(k-1) else 0 for i,el in enumerate(subSeq)]\n",
    "        kmers = kmers[0:-(k-1)]\n",
    "        kmers = [str(el) for el in kmers]\n",
    "        values, counts = np.unique(kmers, return_counts=True)\n",
    "        freqVector=np.zeros(allCombinations.shape)\n",
    "        for j,v in enumerate(values):\n",
    "          freqVector[positionDict[v]] = counts[j]\n",
    "        freqVectorSeq.append(freqVector)\n",
    "\n",
    "      #Pad or truncate the frequency vector sequence\n",
    "      if len(freqVectorSeq)>maxFreqVectorLen:\n",
    "          freqVectorSeq=np.array(freqVectorSeq[0:maxFreqVectorLen])\n",
    "      elif len(freqVectorSeq)<maxFreqVectorLen:\n",
    "          diffLen = maxFreqVectorLen - len(freqVectorSeq)\n",
    "          padding = np.zeros((diffLen,xSize))\n",
    "          freqVectorSeq = np.append(np.array(freqVectorSeq), padding, axis=0)\n",
    "      else:\n",
    "         freqVectorSeq= np.array(freqVectorSeq)\n",
    "      yield (freqVectorSeq,y[0])\n",
    "\n",
    "\n",
    "def generatorVal():\n",
    "  for i,seq in enumerate(valSeq):\n",
    "      entryId = valIds[i]\n",
    "      if entryId in soEntryIds:\n",
    "        labelData = df.loc[entryId]\n",
    "        # indices = labelData[\"termToken\"].to_numpy()\n",
    "        indices = labelData[\"term\"].to_numpy()\n",
    "      else:\n",
    "        indices=[]\n",
    "\n",
    "      with warnings.catch_warnings():\n",
    "          #supress the warnings for unknown classes\n",
    "          warnings.simplefilter(\"ignore\")\n",
    "          y = mlb.transform([indices])\n",
    "      \n",
    "      seqLen= len(seq)\n",
    "      freqVectorSeq=[]\n",
    "      for subIdx in np.arange(0, seqLen//n+1):\n",
    "        subSeq = seq[subIdx*n:(subIdx+1)*n]\n",
    "        if len(subSeq)<3:\n",
    "          continue\n",
    "        kmers = [subSeq[i:i+k] if i < len(subSeq)-(k-1) else 0 for i,el in enumerate(subSeq)]\n",
    "        kmers = kmers[0:-(k-1)]\n",
    "        kmers = [str(el) for el in kmers]\n",
    "        values, counts = np.unique(kmers, return_counts=True)\n",
    "        freqVector=np.zeros(allCombinations.shape)\n",
    "        for j,v in enumerate(values):\n",
    "          freqVector[positionDict[v]] = counts[j]\n",
    "        freqVectorSeq.append(freqVector)\n",
    "        \n",
    "      #Pad or truncate the frequency vector sequence\n",
    "      if len(freqVectorSeq)>maxFreqVectorLen:\n",
    "          freqVectorSeq=np.array(freqVectorSeq[0:maxFreqVectorLen])\n",
    "      elif len(freqVectorSeq)<maxFreqVectorLen:\n",
    "          diffLen = maxFreqVectorLen - len(freqVectorSeq)\n",
    "          padding = np.zeros((diffLen,xSize))\n",
    "          freqVectorSeq = np.append(np.array(freqVectorSeq), padding, axis=0)\n",
    "      else:\n",
    "         freqVectorSeq= np.array(freqVectorSeq)\n",
    "      yield (freqVectorSeq,y[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2727338a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first sample: \n",
      "(50, 15625)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "The first sample has 0 classes\n"
     ]
    }
   ],
   "source": [
    "g = generator()\n",
    "test = next(g)\n",
    "print(\"The first sample: \\n{}\\n{}\".format(test[0].shape, test[0]))\n",
    "print(\"The first sample has {} classes\".format(np.count_nonzero(test[1])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10c4a51a",
   "metadata": {},
   "source": [
    "## Tensorflow Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63f0d2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 12:08:23.927785: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-29 12:08:23.928125: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-29 12:08:23.928420: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-29 12:08:24.377422: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-29 12:08:24.377825: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-29 12:08:24.377837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-06-29 12:08:24.378246: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-29 12:08:24.378286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6569 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:2b:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(<tf.Tensor: shape=(50, 15625), dtype=int32, numpy=\n",
      "array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, <tf.Tensor: shape=(21285,), dtype=int32, numpy=array([0, 0, 0, ..., 0, 0, 0], dtype=int32)>)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 12:08:24.684931: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(generator, output_signature=(\n",
    "         tf.TensorSpec(shape=(None,xSize), dtype=tf.int32),\n",
    "         tf.TensorSpec(shape=(len(mlb.classes_),), dtype=tf.int32)))\n",
    "print(list(dataset.take(1)))\n",
    "\n",
    "datasetVal = tf.data.Dataset.from_generator(generatorVal, output_signature=(\n",
    "         tf.TensorSpec(shape=(None,xSize), dtype=tf.int32),\n",
    "         tf.TensorSpec(shape=(len(mlb.classes_),), dtype=tf.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0a554f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73140569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 12:08:24.897563: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:08:24.898655: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:08:24.899410: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-29 12:08:24.980119: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-29 12:08:25.005286: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:08:25.006218: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:08:25.007044: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embedRnnModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 50, 15625)]       0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 50, 15625)        62500     \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 50, 20)           1250880   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 50, 20)           80        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 20)               2480      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 20)               80        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               2688      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 21285)             2745765   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,080,985\n",
      "Trainable params: 4,049,655\n",
      "Non-trainable params: 31,330\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 12:08:25.127337: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:08:25.128385: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:08:25.129221: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-29 12:08:25.200995: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-29 12:08:25.225885: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:08:25.226606: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:08:25.227463: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "VOCAB_SIZE=len(aa_dict)\n",
    "EMBED_DIM=500\n",
    "OUT_SEQ_LENGTH=10\n",
    "\n",
    "def createRnnModel():\n",
    "    inputs = tf.keras.Input(shape=(maxFreqVectorLen, xSize,))\n",
    "    # x = tf.keras.layers.Masking(0)(inputs)\n",
    "    # x=layers.Embedding(VOCAB_SIZE, EMBED_DIM, name=\"embedding\")(inputs)\n",
    "\n",
    "    # x = layers.RepeatVector(OUT_SEQ_LENGTH)(x)\n",
    "    x=layers.BatchNormalization()(inputs)\n",
    "    x = layers.Bidirectional(layers.LSTM(10, return_sequences=True))(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(10))(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    # x = layers.LSTM(64)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    outputs=layers.Dense(len(mlb.classes_), activation=tf.keras.activations.sigmoid)(x)\n",
    "    # outputs=layers.Softmax()(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name=\"embedRnnModel\")\n",
    "\n",
    "model = createRnnModel()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a3ddc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Learning rate schedule\n",
    "initial_learning_rate = 0.001\n",
    "decaySteps=5000\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(initial_learning_rate, first_decay_steps=decaySteps,\n",
    "                                                                t_mul=2.0, m_mul=0.7)\n",
    "# lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "#     initial_learning_rate, decay_steps=decaySteps, alpha=0.01)\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate,decay_steps=decaySteps,decay_rate=0.9,staircase=False)\n",
    "step = np.linspace(0,decaySteps*3)\n",
    "lr = lr_schedule(step)\n",
    "# plt.figure(figsize = (8,6))\n",
    "# plt.yscale(\"log\")\n",
    "# plt.plot(step, lr)\n",
    "# plt.ylim([0,max(plt.ylim())])\n",
    "# plt.xlabel('step')\n",
    "# _ = plt.ylabel('Learning Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4760b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9113c4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 12:08:25.509151: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-29 12:08:25.978581: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:08:25.980344: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:08:25.981727: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-29 12:08:26.109720: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-29 12:08:26.135001: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:08:26.135793: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:08:26.136653: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-29 12:08:26.245807: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:08:26.247338: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:08:26.248232: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-29 12:08:26.320977: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-29 12:08:26.347046: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:08:26.348216: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:08:26.348964: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-29 12:08:26.640597: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-29 12:08:26.796418: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-29 12:08:28.024928: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:08:28.026351: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:08:28.027086: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-29 12:08:28.100711: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-29 12:08:28.126444: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:08:28.127527: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:08:28.128270: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-29 12:08:28.235587: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:08:28.236792: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:08:28.237599: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-29 12:08:28.313175: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-29 12:08:28.339151: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:08:28.339947: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:08:28.340834: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-29 12:08:28.555082: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-29 12:08:28.709142: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-29 12:08:29.591848: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-06-29 12:08:29.669155: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f377005d2e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-29 12:08:29.669187: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce GTX 1070, Compute Capability 6.1\n",
      "2023-06-29 12:08:29.672210: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-06-29 12:08:29.768847: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/Step 0, Loss: 0.29653, Accuracy: 0.50239, F1: 0.0020, Prec: 0.3520, Rec: 0.0010 lr: 0.00100\n",
      "Epoch 1/Step 20, Loss: 0.14601, Accuracy: 0.90894, F1: 0.0261, Prec: 0.1211, Rec: 0.0250 lr: 0.00100\n",
      "Epoch 1/Step 40, Loss: 0.00517, Accuracy: 0.95270, F1: 0.0516, Prec: 0.0899, Rec: 0.0788 lr: 0.00100\n",
      "Epoch 1/Step 60, Loss: -0.00430, Accuracy: 0.96773, F1: 0.0706, Prec: 0.0899, Rec: 0.1034 lr: 0.00100\n",
      "Epoch 1/Step 80, Loss: -0.04190, Accuracy: 0.97512, F1: 0.1024, Prec: 0.1223, Rec: 0.1237 lr: 0.00100\n",
      "Epoch 1/Step 100, Loss: -0.06933, Accuracy: 0.97944, F1: 0.1181, Prec: 0.1465, Rec: 0.1290 lr: 0.00100\n",
      "Epoch 1/Step 120, Loss: -0.09712, Accuracy: 0.98247, F1: 0.1298, Prec: 0.1580, Rec: 0.1359 lr: 0.00100\n",
      "Epoch 1/Step 140, Loss: -0.08597, Accuracy: 0.98465, F1: 0.1379, Prec: 0.1647, Rec: 0.1415 lr: 0.00100\n",
      "Epoch 1/Step 160, Loss: -0.08404, Accuracy: 0.98633, F1: 0.1451, Prec: 0.1672, Rec: 0.1504 lr: 0.00100\n",
      "Epoch 1/Step 180, Loss: -0.08279, Accuracy: 0.98764, F1: 0.1512, Prec: 0.1693, Rec: 0.1579 lr: 0.00100\n",
      "Epoch 1/Step 200, Loss: -0.10254, Accuracy: 0.98868, F1: 0.1555, Prec: 0.1697, Rec: 0.1646 lr: 0.00100\n",
      "Epoch 1/Step 220, Loss: -0.09970, Accuracy: 0.98954, F1: 0.1605, Prec: 0.1723, Rec: 0.1706 lr: 0.00100\n",
      "Epoch 1/Step 240, Loss: -0.09249, Accuracy: 0.99024, F1: 0.1640, Prec: 0.1744, Rec: 0.1744 lr: 0.00100\n",
      "Epoch 1/Step 260, Loss: -0.09898, Accuracy: 0.99085, F1: 0.1660, Prec: 0.1744, Rec: 0.1775 lr: 0.00100\n",
      "Epoch 1/Step 280, Loss: -0.09246, Accuracy: 0.99137, F1: 0.1684, Prec: 0.1746, Rec: 0.1817 lr: 0.00100\n",
      "Epoch 1/Step 300, Loss: -0.09700, Accuracy: 0.99181, F1: 0.1716, Prec: 0.1767, Rec: 0.1851 lr: 0.00100\n",
      "Epoch 1/Step 320, Loss: -0.09640, Accuracy: 0.99220, F1: 0.1732, Prec: 0.1777, Rec: 0.1865 lr: 0.00100\n",
      "Epoch 1/Step 340, Loss: -0.07763, Accuracy: 0.99255, F1: 0.1745, Prec: 0.1779, Rec: 0.1884 lr: 0.00100\n",
      "Epoch 1/Step 360, Loss: -0.09802, Accuracy: 0.99287, F1: 0.1761, Prec: 0.1783, Rec: 0.1907 lr: 0.00100\n",
      "Epoch 1/Step 380, Loss: -0.07762, Accuracy: 0.99315, F1: 0.1769, Prec: 0.1784, Rec: 0.1918 lr: 0.00100\n",
      "Epoch 1/Step 400, Loss: -0.09786, Accuracy: 0.99339, F1: 0.1787, Prec: 0.1790, Rec: 0.1942 lr: 0.00100\n",
      "Epoch 1/Step 420, Loss: -0.09252, Accuracy: 0.99361, F1: 0.1799, Prec: 0.1794, Rec: 0.1958 lr: 0.00100\n",
      "Epoch 1/Step 440, Loss: -0.09487, Accuracy: 0.99382, F1: 0.1806, Prec: 0.1797, Rec: 0.1967 lr: 0.00100\n",
      "Epoch 1/Step 460, Loss: -0.10595, Accuracy: 0.99401, F1: 0.1819, Prec: 0.1802, Rec: 0.1985 lr: 0.00100\n",
      "Epoch 1/Step 480, Loss: -0.12609, Accuracy: 0.99417, F1: 0.1830, Prec: 0.1810, Rec: 0.1995 lr: 0.00100\n",
      "Epoch 1/Step 500, Loss: -0.10409, Accuracy: 0.99433, F1: 0.1839, Prec: 0.1814, Rec: 0.2004 lr: 0.00100\n",
      "Epoch 1/Step 520, Loss: -0.11453, Accuracy: 0.99448, F1: 0.1853, Prec: 0.1821, Rec: 0.2026 lr: 0.00100\n",
      "Epoch 1/Step 540, Loss: -0.09994, Accuracy: 0.99461, F1: 0.1869, Prec: 0.1832, Rec: 0.2044 lr: 0.00100\n",
      "Epoch 1/Step 560, Loss: -0.09995, Accuracy: 0.99474, F1: 0.1876, Prec: 0.1837, Rec: 0.2051 lr: 0.00100\n",
      "Epoch 1/Step 580, Loss: -0.11457, Accuracy: 0.99485, F1: 0.1878, Prec: 0.1837, Rec: 0.2052 lr: 0.00100\n",
      "Epoch 1/Step 600, Loss: -0.11935, Accuracy: 0.99496, F1: 0.1885, Prec: 0.1840, Rec: 0.2062 lr: 0.00100\n",
      "Epoch 1/Step 620, Loss: -0.09960, Accuracy: 0.99507, F1: 0.1884, Prec: 0.1836, Rec: 0.2062 lr: 0.00100\n",
      "Epoch 1/Step 640, Loss: -0.10068, Accuracy: 0.99517, F1: 0.1888, Prec: 0.1838, Rec: 0.2067 lr: 0.00100\n",
      "Epoch 1/Step 660, Loss: -0.11614, Accuracy: 0.99526, F1: 0.1896, Prec: 0.1843, Rec: 0.2076 lr: 0.00100\n",
      "Epoch 1/Step 680, Loss: -0.10747, Accuracy: 0.99534, F1: 0.1903, Prec: 0.1846, Rec: 0.2084 lr: 0.00100\n",
      "Epoch 1/Step 700, Loss: -0.11050, Accuracy: 0.99542, F1: 0.1905, Prec: 0.1847, Rec: 0.2086 lr: 0.00100\n",
      "Epoch 1/Step 720, Loss: -0.13013, Accuracy: 0.99549, F1: 0.1913, Prec: 0.1853, Rec: 0.2094 lr: 0.00100\n",
      "Epoch 1/Step 740, Loss: -0.08427, Accuracy: 0.99556, F1: 0.1915, Prec: 0.1857, Rec: 0.2091 lr: 0.00100\n",
      "Epoch 1/Step 760, Loss: -0.11996, Accuracy: 0.99563, F1: 0.1918, Prec: 0.1862, Rec: 0.2092 lr: 0.00100\n",
      "Epoch 1/Step 780, Loss: -0.08972, Accuracy: 0.99569, F1: 0.1920, Prec: 0.1864, Rec: 0.2092 lr: 0.00100\n",
      "Epoch 1/Step 800, Loss: -0.09232, Accuracy: 0.99575, F1: 0.1921, Prec: 0.1862, Rec: 0.2096 lr: 0.00100\n",
      "Epoch 1/Step 820, Loss: -0.10577, Accuracy: 0.99581, F1: 0.1921, Prec: 0.1862, Rec: 0.2095 lr: 0.00100\n",
      "Epoch 1/Step 840, Loss: -0.11162, Accuracy: 0.99587, F1: 0.1924, Prec: 0.1864, Rec: 0.2097 lr: 0.00100\n",
      "Epoch 1/Step 860, Loss: -0.09514, Accuracy: 0.99592, F1: 0.1926, Prec: 0.1865, Rec: 0.2098 lr: 0.00100\n",
      "Epoch 1/Step 880, Loss: -0.07865, Accuracy: 0.99597, F1: 0.1932, Prec: 0.1869, Rec: 0.2104 lr: 0.00100\n",
      "Epoch 1/Step 900, Loss: -0.09593, Accuracy: 0.99601, F1: 0.1938, Prec: 0.1874, Rec: 0.2110 lr: 0.00100\n",
      "Epoch 1/Step 920, Loss: -0.09750, Accuracy: 0.99606, F1: 0.1938, Prec: 0.1873, Rec: 0.2109 lr: 0.00100\n",
      "Epoch 1/Step 940, Loss: -0.10579, Accuracy: 0.99611, F1: 0.1941, Prec: 0.1875, Rec: 0.2114 lr: 0.00100\n",
      "Epoch 1/Step 960, Loss: -0.13030, Accuracy: 0.99615, F1: 0.1947, Prec: 0.1878, Rec: 0.2121 lr: 0.00100\n",
      "Epoch 1/Step 980, Loss: -0.07299, Accuracy: 0.99619, F1: 0.1947, Prec: 0.1877, Rec: 0.2122 lr: 0.00100\n",
      "Epoch 1/Step 1000, Loss: -0.11984, Accuracy: 0.99623, F1: 0.1944, Prec: 0.1873, Rec: 0.2121 lr: 0.00100\n",
      "Epoch 1/Step 1020, Loss: -0.09251, Accuracy: 0.99627, F1: 0.1946, Prec: 0.1874, Rec: 0.2122 lr: 0.00100\n",
      "Epoch 1/Step 1040, Loss: -0.10286, Accuracy: 0.99630, F1: 0.1949, Prec: 0.1876, Rec: 0.2126 lr: 0.00100\n",
      "Epoch 1/Step 1060, Loss: -0.09585, Accuracy: 0.99634, F1: 0.1950, Prec: 0.1875, Rec: 0.2126 lr: 0.00100\n",
      "Epoch 1/Step 1080, Loss: -0.07355, Accuracy: 0.99637, F1: 0.1953, Prec: 0.1877, Rec: 0.2130 lr: 0.00100\n",
      "Epoch 1/Step 1100, Loss: -0.10692, Accuracy: 0.99640, F1: 0.1956, Prec: 0.1880, Rec: 0.2132 lr: 0.00100\n",
      "Epoch 1/Step 1120, Loss: -0.09719, Accuracy: 0.99643, F1: 0.1957, Prec: 0.1881, Rec: 0.2133 lr: 0.00100\n",
      "Epoch 1/Step 1140, Loss: -0.09331, Accuracy: 0.99646, F1: 0.1959, Prec: 0.1881, Rec: 0.2136 lr: 0.00100\n",
      "Epoch 1/Step 1160, Loss: -0.10820, Accuracy: 0.99649, F1: 0.1962, Prec: 0.1884, Rec: 0.2139 lr: 0.00100\n",
      "Epoch 1/Step 1180, Loss: -0.07514, Accuracy: 0.99652, F1: 0.1963, Prec: 0.1885, Rec: 0.2139 lr: 0.00100\n",
      "Epoch 1/Step 1200, Loss: -0.08261, Accuracy: 0.99654, F1: 0.1964, Prec: 0.1886, Rec: 0.2141 lr: 0.00100\n",
      "Epoch 1/Step 1220, Loss: -0.09903, Accuracy: 0.99656, F1: 0.1966, Prec: 0.1886, Rec: 0.2142 lr: 0.00100\n",
      "Epoch 1/Step 1240, Loss: -0.08180, Accuracy: 0.99659, F1: 0.1968, Prec: 0.1888, Rec: 0.2144 lr: 0.00100\n",
      "Epoch 1/Step 1260, Loss: -0.07868, Accuracy: 0.99661, F1: 0.1970, Prec: 0.1890, Rec: 0.2144 lr: 0.00100\n",
      "Epoch 1/Step 1280, Loss: -0.09469, Accuracy: 0.99664, F1: 0.1971, Prec: 0.1890, Rec: 0.2146 lr: 0.00100\n",
      "Epoch 1/Step 1300, Loss: -0.10972, Accuracy: 0.99666, F1: 0.1973, Prec: 0.1892, Rec: 0.2148 lr: 0.00100\n",
      "Epoch 1/Step 1320, Loss: -0.09767, Accuracy: 0.99668, F1: 0.1975, Prec: 0.1893, Rec: 0.2150 lr: 0.00100\n",
      "Epoch 1/Step 1340, Loss: -0.08365, Accuracy: 0.99670, F1: 0.1977, Prec: 0.1895, Rec: 0.2154 lr: 0.00100\n",
      "Epoch 1/Step 1360, Loss: -0.10686, Accuracy: 0.99673, F1: 0.1976, Prec: 0.1893, Rec: 0.2153 lr: 0.00100\n",
      "Epoch 1/Step 1380, Loss: -0.10281, Accuracy: 0.99675, F1: 0.1978, Prec: 0.1894, Rec: 0.2155 lr: 0.00100\n",
      "Epoch 1/Step 1400, Loss: -0.09185, Accuracy: 0.99677, F1: 0.1979, Prec: 0.1893, Rec: 0.2157 lr: 0.00100\n",
      "Epoch 1/Step 1420, Loss: -0.10272, Accuracy: 0.99679, F1: 0.1977, Prec: 0.1891, Rec: 0.2156 lr: 0.00100\n",
      "Epoch 1/Step 1440, Loss: -0.14128, Accuracy: 0.99681, F1: 0.1980, Prec: 0.1893, Rec: 0.2159 lr: 0.00100\n",
      "Epoch 1/Step 1460, Loss: -0.09997, Accuracy: 0.99683, F1: 0.1981, Prec: 0.1894, Rec: 0.2160 lr: 0.00100\n",
      "Epoch 1/Step 1480, Loss: -0.09862, Accuracy: 0.99684, F1: 0.1982, Prec: 0.1896, Rec: 0.2160 lr: 0.00100\n",
      "Epoch 1/Step 1500, Loss: -0.10020, Accuracy: 0.99686, F1: 0.1985, Prec: 0.1898, Rec: 0.2163 lr: 0.00100\n",
      "Epoch 1/Step 1520, Loss: -0.11728, Accuracy: 0.99688, F1: 0.1986, Prec: 0.1899, Rec: 0.2165 lr: 0.00100\n",
      "Epoch 1/Step 1540, Loss: -0.09975, Accuracy: 0.99690, F1: 0.1987, Prec: 0.1899, Rec: 0.2165 lr: 0.00100\n",
      "Epoch 1/Step 1560, Loss: -0.10221, Accuracy: 0.99691, F1: 0.1988, Prec: 0.1900, Rec: 0.2169 lr: 0.00100\n",
      "Epoch 1/Step 1580, Loss: -0.10853, Accuracy: 0.99693, F1: 0.1991, Prec: 0.1902, Rec: 0.2172 lr: 0.00100\n",
      "Epoch 1/Step 1600, Loss: -0.11789, Accuracy: 0.99694, F1: 0.1993, Prec: 0.1903, Rec: 0.2174 lr: 0.00100\n",
      "Epoch 1/Step 1620, Loss: -0.08643, Accuracy: 0.99696, F1: 0.1994, Prec: 0.1904, Rec: 0.2175 lr: 0.00100\n",
      "Epoch 1/Step 1640, Loss: -0.11500, Accuracy: 0.99697, F1: 0.1994, Prec: 0.1903, Rec: 0.2176 lr: 0.00100\n",
      "Epoch 1/Step 1660, Loss: -0.10396, Accuracy: 0.99699, F1: 0.1993, Prec: 0.1901, Rec: 0.2177 lr: 0.00100\n",
      "Epoch 1/Step 1680, Loss: -0.09574, Accuracy: 0.99700, F1: 0.1995, Prec: 0.1901, Rec: 0.2179 lr: 0.00100\n",
      "Epoch 1/Step 1700, Loss: -0.10114, Accuracy: 0.99701, F1: 0.1996, Prec: 0.1902, Rec: 0.2181 lr: 0.00100\n",
      "Epoch 1/Step 1720, Loss: -0.11385, Accuracy: 0.99703, F1: 0.1998, Prec: 0.1902, Rec: 0.2183 lr: 0.00100\n",
      "Epoch 1/Step 1740, Loss: -0.11283, Accuracy: 0.99704, F1: 0.1998, Prec: 0.1902, Rec: 0.2185 lr: 0.00100\n",
      "Epoch 1/Step 1760, Loss: -0.10559, Accuracy: 0.99705, F1: 0.2002, Prec: 0.1905, Rec: 0.2188 lr: 0.00100\n",
      "Epoch 1/Step 1780, Loss: -0.09776, Accuracy: 0.99706, F1: 0.2003, Prec: 0.1907, Rec: 0.2188 lr: 0.00100\n",
      "Epoch 1/Step 1800, Loss: -0.12999, Accuracy: 0.99707, F1: 0.2004, Prec: 0.1907, Rec: 0.2190 lr: 0.00100\n",
      "Epoch 1/Step 1820, Loss: -0.08901, Accuracy: 0.99709, F1: 0.2005, Prec: 0.1908, Rec: 0.2191 lr: 0.00100\n",
      "Epoch 1/Step 1840, Loss: -0.08774, Accuracy: 0.99710, F1: 0.2008, Prec: 0.1911, Rec: 0.2194 lr: 0.00100\n",
      "Epoch 1/Step 1860, Loss: -0.07543, Accuracy: 0.99711, F1: 0.2009, Prec: 0.1912, Rec: 0.2195 lr: 0.00100\n",
      "Epoch 1/Step 1880, Loss: -0.09231, Accuracy: 0.99712, F1: 0.2008, Prec: 0.1912, Rec: 0.2193 lr: 0.00100\n",
      "Epoch 1/Step 1900, Loss: -0.13451, Accuracy: 0.99713, F1: 0.2010, Prec: 0.1912, Rec: 0.2196 lr: 0.00100\n",
      "Epoch 1/Step 1920, Loss: -0.11852, Accuracy: 0.99714, F1: 0.2011, Prec: 0.1914, Rec: 0.2196 lr: 0.00100\n",
      "Epoch 1/Step 1940, Loss: -0.09569, Accuracy: 0.99715, F1: 0.2012, Prec: 0.1914, Rec: 0.2197 lr: 0.00100\n",
      "Epoch 1/Step 1960, Loss: -0.09672, Accuracy: 0.99716, F1: 0.2012, Prec: 0.1913, Rec: 0.2197 lr: 0.00100\n",
      "Epoch 1/Step 1980, Loss: -0.09258, Accuracy: 0.99717, F1: 0.2013, Prec: 0.1915, Rec: 0.2198 lr: 0.00100\n",
      "Epoch 1/Step 2000, Loss: -0.11884, Accuracy: 0.99718, F1: 0.2013, Prec: 0.1914, Rec: 0.2199 lr: 0.00100\n",
      "Epoch 1/Step 2020, Loss: -0.10063, Accuracy: 0.99719, F1: 0.2016, Prec: 0.1916, Rec: 0.2202 lr: 0.00100\n",
      "Epoch 1/Step 2040, Loss: -0.08688, Accuracy: 0.99720, F1: 0.2016, Prec: 0.1917, Rec: 0.2201 lr: 0.00100\n",
      "Epoch 1/Step 2060, Loss: -0.10290, Accuracy: 0.99721, F1: 0.2017, Prec: 0.1917, Rec: 0.2202 lr: 0.00100\n",
      "Epoch 1/Step 2080, Loss: -0.10512, Accuracy: 0.99722, F1: 0.2016, Prec: 0.1916, Rec: 0.2203 lr: 0.00100\n",
      "Epoch 1/Step 2100, Loss: -0.12419, Accuracy: 0.99723, F1: 0.2016, Prec: 0.1915, Rec: 0.2204 lr: 0.00100\n",
      "Epoch 1/Step 2120, Loss: -0.11977, Accuracy: 0.99724, F1: 0.2016, Prec: 0.1915, Rec: 0.2203 lr: 0.00100\n",
      "Epoch 1/Step 2140, Loss: -0.11181, Accuracy: 0.99724, F1: 0.2018, Prec: 0.1917, Rec: 0.2204 lr: 0.00100\n",
      "Epoch 1/Step 2160, Loss: -0.09765, Accuracy: 0.99725, F1: 0.2019, Prec: 0.1918, Rec: 0.2206 lr: 0.00100\n",
      "Epoch 1/Step 2180, Loss: -0.12396, Accuracy: 0.99726, F1: 0.2019, Prec: 0.1918, Rec: 0.2205 lr: 0.00100\n",
      "Epoch 1/Step 2200, Loss: -0.09186, Accuracy: 0.99727, F1: 0.2020, Prec: 0.1919, Rec: 0.2206 lr: 0.00100\n",
      "Epoch 1/Step 2220, Loss: -0.09644, Accuracy: 0.99727, F1: 0.2021, Prec: 0.1920, Rec: 0.2207 lr: 0.00100\n",
      "Epoch 1/Step 2240, Loss: -0.08410, Accuracy: 0.99728, F1: 0.2021, Prec: 0.1920, Rec: 0.2206 lr: 0.00100\n",
      "Epoch 1/Step 2260, Loss: -0.08715, Accuracy: 0.99729, F1: 0.2022, Prec: 0.1921, Rec: 0.2207 lr: 0.00100\n",
      "Epoch 1/Step 2280, Loss: -0.08847, Accuracy: 0.99730, F1: 0.2022, Prec: 0.1921, Rec: 0.2208 lr: 0.00100\n",
      "Epoch 1/Step 2300, Loss: -0.10430, Accuracy: 0.99731, F1: 0.2023, Prec: 0.1922, Rec: 0.2209 lr: 0.00100\n",
      "Epoch 1/Step 2320, Loss: -0.11139, Accuracy: 0.99731, F1: 0.2024, Prec: 0.1922, Rec: 0.2211 lr: 0.00100\n",
      "Epoch 1/Step 2340, Loss: -0.09353, Accuracy: 0.99732, F1: 0.2025, Prec: 0.1922, Rec: 0.2212 lr: 0.00100\n",
      "Epoch 1/Step 2360, Loss: -0.10352, Accuracy: 0.99733, F1: 0.2026, Prec: 0.1923, Rec: 0.2213 lr: 0.00100\n",
      "Epoch 1/Step 2380, Loss: -0.12821, Accuracy: 0.99733, F1: 0.2026, Prec: 0.1922, Rec: 0.2212 lr: 0.00100\n",
      "Epoch 1/Step 2400, Loss: -0.08586, Accuracy: 0.99734, F1: 0.2026, Prec: 0.1922, Rec: 0.2212 lr: 0.00100\n",
      "Epoch 1/Step 2420, Loss: -0.09407, Accuracy: 0.99735, F1: 0.2027, Prec: 0.1923, Rec: 0.2214 lr: 0.00100\n",
      "Epoch 1/Step 2440, Loss: -0.10390, Accuracy: 0.99735, F1: 0.2026, Prec: 0.1923, Rec: 0.2212 lr: 0.00100\n",
      "Epoch 1/Step 2460, Loss: -0.12111, Accuracy: 0.99736, F1: 0.2026, Prec: 0.1922, Rec: 0.2212 lr: 0.00100\n",
      "Epoch 1/Step 2480, Loss: -0.10999, Accuracy: 0.99737, F1: 0.2027, Prec: 0.1923, Rec: 0.2215 lr: 0.00100\n",
      "Epoch 1/Step 2500, Loss: -0.09932, Accuracy: 0.99737, F1: 0.2029, Prec: 0.1925, Rec: 0.2216 lr: 0.00100\n",
      "Epoch 1/Step 2520, Loss: -0.07720, Accuracy: 0.99738, F1: 0.2030, Prec: 0.1925, Rec: 0.2217 lr: 0.00100\n",
      "Epoch 1/Step 2540, Loss: -0.09966, Accuracy: 0.99738, F1: 0.2029, Prec: 0.1924, Rec: 0.2217 lr: 0.00100\n",
      "Epoch 1/Step 2560, Loss: -0.13852, Accuracy: 0.99739, F1: 0.2030, Prec: 0.1925, Rec: 0.2219 lr: 0.00100\n",
      "Epoch 1/Step 2580, Loss: -0.11670, Accuracy: 0.99740, F1: 0.2031, Prec: 0.1926, Rec: 0.2219 lr: 0.00100\n",
      "Epoch 1/Step 2600, Loss: -0.11973, Accuracy: 0.99740, F1: 0.2032, Prec: 0.1928, Rec: 0.2219 lr: 0.00100\n",
      "Epoch 1/Step 2620, Loss: -0.12887, Accuracy: 0.99741, F1: 0.2034, Prec: 0.1929, Rec: 0.2221 lr: 0.00100\n",
      "Epoch 1/Step 2640, Loss: -0.11580, Accuracy: 0.99741, F1: 0.2034, Prec: 0.1929, Rec: 0.2222 lr: 0.00100\n",
      "Epoch 1/Step 2660, Loss: -0.10928, Accuracy: 0.99742, F1: 0.2035, Prec: 0.1929, Rec: 0.2223 lr: 0.00100\n",
      "Epoch 1/Step 2680, Loss: -0.11143, Accuracy: 0.99742, F1: 0.2036, Prec: 0.1931, Rec: 0.2224 lr: 0.00100\n",
      "Epoch 1/Step 2700, Loss: -0.11285, Accuracy: 0.99743, F1: 0.2036, Prec: 0.1931, Rec: 0.2223 lr: 0.00100\n",
      "Epoch 1/Step 2720, Loss: -0.09028, Accuracy: 0.99743, F1: 0.2037, Prec: 0.1932, Rec: 0.2225 lr: 0.00100\n",
      "Epoch 1/Step 2740, Loss: -0.12747, Accuracy: 0.99744, F1: 0.2038, Prec: 0.1933, Rec: 0.2226 lr: 0.00100\n",
      "Epoch 1/Step 2760, Loss: -0.12322, Accuracy: 0.99744, F1: 0.2038, Prec: 0.1933, Rec: 0.2226 lr: 0.00100\n",
      "Epoch 1/Step 2780, Loss: -0.11554, Accuracy: 0.99745, F1: 0.2037, Prec: 0.1931, Rec: 0.2225 lr: 0.00100\n",
      "Epoch 1/Step 2800, Loss: -0.09815, Accuracy: 0.99746, F1: 0.2037, Prec: 0.1931, Rec: 0.2225 lr: 0.00100\n",
      "Epoch 1/Step 2820, Loss: -0.09829, Accuracy: 0.99746, F1: 0.2038, Prec: 0.1931, Rec: 0.2226 lr: 0.00100\n",
      "Epoch 1/Step 2840, Loss: -0.12003, Accuracy: 0.99747, F1: 0.2038, Prec: 0.1931, Rec: 0.2226 lr: 0.00100\n",
      "Epoch 1/Step 2860, Loss: -0.11078, Accuracy: 0.99747, F1: 0.2039, Prec: 0.1933, Rec: 0.2227 lr: 0.00100\n",
      "Epoch 1/Step 2880, Loss: -0.09495, Accuracy: 0.99748, F1: 0.2039, Prec: 0.1933, Rec: 0.2228 lr: 0.00100\n",
      "Epoch 1/Step 2900, Loss: -0.09709, Accuracy: 0.99748, F1: 0.2039, Prec: 0.1932, Rec: 0.2228 lr: 0.00100\n",
      "Epoch 1/Step 2920, Loss: -0.08244, Accuracy: 0.99748, F1: 0.2040, Prec: 0.1933, Rec: 0.2228 lr: 0.00100\n",
      "Epoch 1/Step 2940, Loss: -0.12623, Accuracy: 0.99749, F1: 0.2041, Prec: 0.1934, Rec: 0.2228 lr: 0.00100\n",
      "Epoch 1/Step 2960, Loss: -0.12129, Accuracy: 0.99749, F1: 0.2040, Prec: 0.1933, Rec: 0.2229 lr: 0.00100\n",
      "Epoch 1/Step 2980, Loss: -0.07887, Accuracy: 0.99750, F1: 0.2041, Prec: 0.1933, Rec: 0.2229 lr: 0.00100\n",
      "Epoch 1/Step 3000, Loss: -0.10376, Accuracy: 0.99750, F1: 0.2041, Prec: 0.1933, Rec: 0.2229 lr: 0.00100\n",
      "Epoch 1/Step 3020, Loss: -0.09867, Accuracy: 0.99751, F1: 0.2041, Prec: 0.1933, Rec: 0.2229 lr: 0.00100\n",
      "Epoch 1/Step 3040, Loss: -0.13465, Accuracy: 0.99751, F1: 0.2041, Prec: 0.1933, Rec: 0.2229 lr: 0.00100\n",
      "Epoch 1/Step 3060, Loss: -0.09832, Accuracy: 0.99751, F1: 0.2041, Prec: 0.1933, Rec: 0.2230 lr: 0.00100\n",
      "Epoch 1/Step 3080, Loss: -0.08944, Accuracy: 0.99752, F1: 0.2040, Prec: 0.1932, Rec: 0.2229 lr: 0.00100\n",
      "Epoch 1/Step 3100, Loss: -0.11760, Accuracy: 0.99752, F1: 0.2041, Prec: 0.1932, Rec: 0.2229 lr: 0.00100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 12:17:09.454918: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:17:09.455998: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:17:09.456713: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-29 12:17:09.529807: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-29 12:17:09.556936: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:17:09.557791: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:17:09.558574: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-29 12:17:09.677272: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:17:09.678547: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:17:09.679310: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-29 12:17:09.751864: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-29 12:17:09.779368: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:17:09.780121: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:17:09.780849: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-29 12:17:09.991160: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-29 12:17:10.140299: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch finished. Start validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 12:17:10.877195: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-29 12:17:11.277046: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:17:11.278807: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:17:11.281186: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-29 12:17:11.434179: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-29 12:17:11.459188: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:17:11.459936: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:17:11.460783: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-29 12:17:11.560575: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:17:11.561869: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:17:11.562738: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-29 12:17:11.635006: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-29 12:17:11.659640: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:17:11.660656: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:17:11.661526: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-29 12:20:16.474878: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:20:16.476116: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:20:16.476982: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-29 12:20:16.547794: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-29 12:20:16.572572: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:20:16.573392: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:20:16.574203: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-29 12:20:16.673611: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:20:16.674478: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:20:16.675449: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-29 12:20:16.747695: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-29 12:20:16.772438: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-29 12:20:16.773388: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-29 12:20:16.774201: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.9981\n",
      "Validation f1: 0.2047\n",
      "Validation precision: 0.1963\n",
      "Validation recall: 0.2190\n",
      "\n",
      "Start of epoch 2\n",
      "Epoch 2/Step 0, Loss: -0.11104, Accuracy: 0.99816, F1: 0.2301, Prec: 0.2250, Rec: 0.2354 lr: 0.00100\n",
      "Epoch 2/Step 20, Loss: -0.10803, Accuracy: 0.99807, F1: 0.2232, Prec: 0.2086, Rec: 0.2429 lr: 0.00100\n",
      "Epoch 2/Step 40, Loss: -0.10870, Accuracy: 0.99810, F1: 0.2208, Prec: 0.2097, Rec: 0.2370 lr: 0.00100\n",
      "Epoch 2/Step 60, Loss: -0.10323, Accuracy: 0.99814, F1: 0.2153, Prec: 0.2063, Rec: 0.2293 lr: 0.00100\n",
      "Epoch 2/Step 80, Loss: -0.08895, Accuracy: 0.99816, F1: 0.2153, Prec: 0.2035, Rec: 0.2337 lr: 0.00100\n",
      "Epoch 2/Step 100, Loss: -0.11890, Accuracy: 0.99818, F1: 0.2146, Prec: 0.2013, Rec: 0.2350 lr: 0.00100\n",
      "Epoch 2/Step 120, Loss: -0.12117, Accuracy: 0.99818, F1: 0.2132, Prec: 0.2009, Rec: 0.2322 lr: 0.00100\n",
      "Epoch 2/Step 140, Loss: -0.09694, Accuracy: 0.99820, F1: 0.2118, Prec: 0.1996, Rec: 0.2304 lr: 0.00100\n",
      "Epoch 2/Step 160, Loss: -0.10194, Accuracy: 0.99821, F1: 0.2111, Prec: 0.1984, Rec: 0.2303 lr: 0.00100\n",
      "Epoch 2/Step 180, Loss: -0.10515, Accuracy: 0.99820, F1: 0.2111, Prec: 0.1986, Rec: 0.2298 lr: 0.00100\n",
      "Epoch 2/Step 200, Loss: -0.11099, Accuracy: 0.99820, F1: 0.2101, Prec: 0.1972, Rec: 0.2295 lr: 0.00100\n",
      "Epoch 2/Step 220, Loss: -0.10220, Accuracy: 0.99819, F1: 0.2109, Prec: 0.1982, Rec: 0.2298 lr: 0.00100\n",
      "Epoch 2/Step 240, Loss: -0.10677, Accuracy: 0.99818, F1: 0.2114, Prec: 0.1999, Rec: 0.2293 lr: 0.00100\n",
      "Epoch 2/Step 260, Loss: -0.13238, Accuracy: 0.99818, F1: 0.2102, Prec: 0.1991, Rec: 0.2276 lr: 0.00100\n",
      "Epoch 2/Step 280, Loss: -0.10096, Accuracy: 0.99817, F1: 0.2104, Prec: 0.1988, Rec: 0.2283 lr: 0.00100\n",
      "Epoch 2/Step 300, Loss: -0.10291, Accuracy: 0.99816, F1: 0.2115, Prec: 0.2000, Rec: 0.2294 lr: 0.00100\n",
      "Epoch 2/Step 320, Loss: -0.10469, Accuracy: 0.99816, F1: 0.2111, Prec: 0.2001, Rec: 0.2283 lr: 0.00100\n",
      "Epoch 2/Step 340, Loss: -0.09847, Accuracy: 0.99816, F1: 0.2104, Prec: 0.1991, Rec: 0.2282 lr: 0.00100\n",
      "Epoch 2/Step 360, Loss: -0.10260, Accuracy: 0.99816, F1: 0.2102, Prec: 0.1988, Rec: 0.2281 lr: 0.00100\n",
      "Epoch 2/Step 380, Loss: -0.09863, Accuracy: 0.99816, F1: 0.2093, Prec: 0.1979, Rec: 0.2273 lr: 0.00100\n",
      "Epoch 2/Step 400, Loss: -0.11219, Accuracy: 0.99816, F1: 0.2096, Prec: 0.1980, Rec: 0.2279 lr: 0.00100\n",
      "Epoch 2/Step 420, Loss: -0.11409, Accuracy: 0.99816, F1: 0.2097, Prec: 0.1976, Rec: 0.2283 lr: 0.00100\n",
      "Epoch 2/Step 440, Loss: -0.11170, Accuracy: 0.99816, F1: 0.2094, Prec: 0.1973, Rec: 0.2282 lr: 0.00100\n",
      "Epoch 2/Step 460, Loss: -0.11705, Accuracy: 0.99816, F1: 0.2097, Prec: 0.1973, Rec: 0.2289 lr: 0.00100\n",
      "Epoch 2/Step 480, Loss: -0.15650, Accuracy: 0.99816, F1: 0.2097, Prec: 0.1975, Rec: 0.2288 lr: 0.00100\n",
      "Epoch 2/Step 500, Loss: -0.11092, Accuracy: 0.99816, F1: 0.2097, Prec: 0.1972, Rec: 0.2292 lr: 0.00100\n",
      "Epoch 2/Step 520, Loss: -0.13159, Accuracy: 0.99816, F1: 0.2105, Prec: 0.1980, Rec: 0.2299 lr: 0.00100\n",
      "Epoch 2/Step 540, Loss: -0.12421, Accuracy: 0.99816, F1: 0.2112, Prec: 0.1988, Rec: 0.2306 lr: 0.00100\n",
      "Epoch 2/Step 560, Loss: -0.10364, Accuracy: 0.99816, F1: 0.2113, Prec: 0.1989, Rec: 0.2305 lr: 0.00100\n",
      "Epoch 2/Step 580, Loss: -0.12016, Accuracy: 0.99816, F1: 0.2108, Prec: 0.1985, Rec: 0.2300 lr: 0.00100\n",
      "Epoch 2/Step 600, Loss: -0.11556, Accuracy: 0.99816, F1: 0.2109, Prec: 0.1984, Rec: 0.2302 lr: 0.00100\n",
      "Epoch 2/Step 620, Loss: -0.11463, Accuracy: 0.99817, F1: 0.2103, Prec: 0.1978, Rec: 0.2297 lr: 0.00100\n",
      "Epoch 2/Step 640, Loss: -0.09893, Accuracy: 0.99817, F1: 0.2102, Prec: 0.1978, Rec: 0.2297 lr: 0.00100\n",
      "Epoch 2/Step 660, Loss: -0.11839, Accuracy: 0.99817, F1: 0.2105, Prec: 0.1978, Rec: 0.2302 lr: 0.00100\n",
      "Epoch 2/Step 680, Loss: -0.10675, Accuracy: 0.99818, F1: 0.2107, Prec: 0.1977, Rec: 0.2308 lr: 0.00100\n",
      "Epoch 2/Step 700, Loss: -0.10383, Accuracy: 0.99818, F1: 0.2106, Prec: 0.1975, Rec: 0.2308 lr: 0.00100\n",
      "Epoch 2/Step 720, Loss: -0.14772, Accuracy: 0.99818, F1: 0.2109, Prec: 0.1977, Rec: 0.2311 lr: 0.00100\n",
      "Epoch 2/Step 740, Loss: -0.11239, Accuracy: 0.99818, F1: 0.2106, Prec: 0.1977, Rec: 0.2305 lr: 0.00100\n",
      "Epoch 2/Step 760, Loss: -0.14289, Accuracy: 0.99818, F1: 0.2105, Prec: 0.1975, Rec: 0.2304 lr: 0.00100\n",
      "Epoch 2/Step 780, Loss: -0.09920, Accuracy: 0.99818, F1: 0.2100, Prec: 0.1971, Rec: 0.2301 lr: 0.00100\n",
      "Epoch 2/Step 800, Loss: -0.10003, Accuracy: 0.99818, F1: 0.2097, Prec: 0.1965, Rec: 0.2301 lr: 0.00100\n",
      "Epoch 2/Step 820, Loss: -0.10722, Accuracy: 0.99819, F1: 0.2093, Prec: 0.1959, Rec: 0.2299 lr: 0.00100\n",
      "Epoch 2/Step 840, Loss: -0.11794, Accuracy: 0.99819, F1: 0.2092, Prec: 0.1958, Rec: 0.2299 lr: 0.00100\n",
      "Epoch 2/Step 860, Loss: -0.10675, Accuracy: 0.99819, F1: 0.2090, Prec: 0.1956, Rec: 0.2297 lr: 0.00100\n",
      "Epoch 2/Step 880, Loss: -0.07917, Accuracy: 0.99819, F1: 0.2092, Prec: 0.1958, Rec: 0.2301 lr: 0.00100\n",
      "Epoch 2/Step 900, Loss: -0.10748, Accuracy: 0.99819, F1: 0.2096, Prec: 0.1962, Rec: 0.2303 lr: 0.00100\n",
      "Epoch 2/Step 920, Loss: -0.10870, Accuracy: 0.99819, F1: 0.2092, Prec: 0.1958, Rec: 0.2298 lr: 0.00100\n",
      "Epoch 2/Step 940, Loss: -0.11099, Accuracy: 0.99819, F1: 0.2093, Prec: 0.1957, Rec: 0.2301 lr: 0.00100\n",
      "Epoch 2/Step 960, Loss: -0.13203, Accuracy: 0.99819, F1: 0.2096, Prec: 0.1959, Rec: 0.2307 lr: 0.00100\n",
      "Epoch 2/Step 980, Loss: -0.07149, Accuracy: 0.99819, F1: 0.2094, Prec: 0.1956, Rec: 0.2305 lr: 0.00100\n",
      "Epoch 2/Step 1000, Loss: -0.12926, Accuracy: 0.99819, F1: 0.2089, Prec: 0.1952, Rec: 0.2299 lr: 0.00100\n",
      "Epoch 2/Step 1020, Loss: -0.10538, Accuracy: 0.99819, F1: 0.2087, Prec: 0.1951, Rec: 0.2298 lr: 0.00100\n",
      "Epoch 2/Step 1040, Loss: -0.10242, Accuracy: 0.99819, F1: 0.2089, Prec: 0.1949, Rec: 0.2305 lr: 0.00100\n",
      "Epoch 2/Step 1060, Loss: -0.09951, Accuracy: 0.99819, F1: 0.2088, Prec: 0.1948, Rec: 0.2303 lr: 0.00100\n",
      "Epoch 2/Step 1080, Loss: -0.08919, Accuracy: 0.99819, F1: 0.2090, Prec: 0.1949, Rec: 0.2305 lr: 0.00100\n",
      "Epoch 2/Step 1100, Loss: -0.11827, Accuracy: 0.99819, F1: 0.2092, Prec: 0.1951, Rec: 0.2307 lr: 0.00100\n",
      "Epoch 2/Step 1120, Loss: -0.10178, Accuracy: 0.99819, F1: 0.2091, Prec: 0.1951, Rec: 0.2306 lr: 0.00100\n",
      "Epoch 2/Step 1140, Loss: -0.11934, Accuracy: 0.99819, F1: 0.2092, Prec: 0.1951, Rec: 0.2308 lr: 0.00100\n",
      "Epoch 2/Step 1160, Loss: -0.10943, Accuracy: 0.99819, F1: 0.2093, Prec: 0.1952, Rec: 0.2308 lr: 0.00100\n",
      "Epoch 2/Step 1180, Loss: -0.08327, Accuracy: 0.99819, F1: 0.2093, Prec: 0.1952, Rec: 0.2307 lr: 0.00100\n",
      "Epoch 2/Step 1200, Loss: -0.08406, Accuracy: 0.99819, F1: 0.2093, Prec: 0.1952, Rec: 0.2308 lr: 0.00100\n",
      "Epoch 2/Step 1220, Loss: -0.11363, Accuracy: 0.99819, F1: 0.2092, Prec: 0.1950, Rec: 0.2308 lr: 0.00100\n",
      "Epoch 2/Step 1240, Loss: -0.09809, Accuracy: 0.99819, F1: 0.2093, Prec: 0.1951, Rec: 0.2311 lr: 0.00100\n",
      "Epoch 2/Step 1260, Loss: -0.10382, Accuracy: 0.99819, F1: 0.2094, Prec: 0.1952, Rec: 0.2310 lr: 0.00100\n",
      "Epoch 2/Step 1280, Loss: -0.09972, Accuracy: 0.99819, F1: 0.2094, Prec: 0.1953, Rec: 0.2309 lr: 0.00100\n",
      "Epoch 2/Step 1300, Loss: -0.11783, Accuracy: 0.99819, F1: 0.2095, Prec: 0.1954, Rec: 0.2310 lr: 0.00100\n",
      "Epoch 2/Step 1320, Loss: -0.10750, Accuracy: 0.99819, F1: 0.2095, Prec: 0.1955, Rec: 0.2309 lr: 0.00100\n",
      "Epoch 2/Step 1340, Loss: -0.09503, Accuracy: 0.99819, F1: 0.2096, Prec: 0.1956, Rec: 0.2310 lr: 0.00100\n",
      "Epoch 2/Step 1360, Loss: -0.11807, Accuracy: 0.99819, F1: 0.2094, Prec: 0.1954, Rec: 0.2308 lr: 0.00100\n",
      "Epoch 2/Step 1380, Loss: -0.10516, Accuracy: 0.99819, F1: 0.2094, Prec: 0.1954, Rec: 0.2309 lr: 0.00100\n",
      "Epoch 2/Step 1400, Loss: -0.08753, Accuracy: 0.99819, F1: 0.2094, Prec: 0.1952, Rec: 0.2310 lr: 0.00100\n",
      "Epoch 2/Step 1420, Loss: -0.11352, Accuracy: 0.99819, F1: 0.2091, Prec: 0.1949, Rec: 0.2308 lr: 0.00100\n",
      "Epoch 2/Step 1440, Loss: -0.13194, Accuracy: 0.99820, F1: 0.2093, Prec: 0.1951, Rec: 0.2311 lr: 0.00100\n",
      "Epoch 2/Step 1460, Loss: -0.09944, Accuracy: 0.99820, F1: 0.2094, Prec: 0.1951, Rec: 0.2312 lr: 0.00100\n",
      "Epoch 2/Step 1480, Loss: -0.09807, Accuracy: 0.99820, F1: 0.2094, Prec: 0.1952, Rec: 0.2311 lr: 0.00100\n",
      "Epoch 2/Step 1500, Loss: -0.10595, Accuracy: 0.99820, F1: 0.2096, Prec: 0.1954, Rec: 0.2313 lr: 0.00100\n",
      "Epoch 2/Step 1520, Loss: -0.12040, Accuracy: 0.99820, F1: 0.2096, Prec: 0.1954, Rec: 0.2313 lr: 0.00100\n",
      "Epoch 2/Step 1540, Loss: -0.08537, Accuracy: 0.99820, F1: 0.2096, Prec: 0.1955, Rec: 0.2312 lr: 0.00100\n",
      "Epoch 2/Step 1560, Loss: -0.11995, Accuracy: 0.99820, F1: 0.2096, Prec: 0.1955, Rec: 0.2313 lr: 0.00100\n",
      "Epoch 2/Step 1580, Loss: -0.12738, Accuracy: 0.99820, F1: 0.2098, Prec: 0.1957, Rec: 0.2315 lr: 0.00100\n",
      "Epoch 2/Step 1600, Loss: -0.12534, Accuracy: 0.99820, F1: 0.2100, Prec: 0.1958, Rec: 0.2316 lr: 0.00100\n",
      "Epoch 2/Step 1620, Loss: -0.08349, Accuracy: 0.99820, F1: 0.2100, Prec: 0.1958, Rec: 0.2316 lr: 0.00100\n",
      "Epoch 2/Step 1640, Loss: -0.11242, Accuracy: 0.99820, F1: 0.2099, Prec: 0.1957, Rec: 0.2316 lr: 0.00100\n",
      "Epoch 2/Step 1660, Loss: -0.10687, Accuracy: 0.99820, F1: 0.2097, Prec: 0.1955, Rec: 0.2315 lr: 0.00100\n",
      "Epoch 2/Step 1680, Loss: -0.09675, Accuracy: 0.99820, F1: 0.2098, Prec: 0.1955, Rec: 0.2317 lr: 0.00100\n",
      "Epoch 2/Step 1700, Loss: -0.09858, Accuracy: 0.99820, F1: 0.2098, Prec: 0.1954, Rec: 0.2317 lr: 0.00100\n",
      "Epoch 2/Step 1720, Loss: -0.12535, Accuracy: 0.99820, F1: 0.2098, Prec: 0.1955, Rec: 0.2317 lr: 0.00100\n",
      "Epoch 2/Step 1740, Loss: -0.10781, Accuracy: 0.99820, F1: 0.2098, Prec: 0.1954, Rec: 0.2317 lr: 0.00100\n",
      "Epoch 2/Step 1760, Loss: -0.11854, Accuracy: 0.99819, F1: 0.2100, Prec: 0.1958, Rec: 0.2318 lr: 0.00100\n",
      "Epoch 2/Step 1780, Loss: -0.10145, Accuracy: 0.99819, F1: 0.2100, Prec: 0.1960, Rec: 0.2316 lr: 0.00100\n",
      "Epoch 2/Step 1800, Loss: -0.14282, Accuracy: 0.99819, F1: 0.2101, Prec: 0.1961, Rec: 0.2316 lr: 0.00100\n",
      "Epoch 2/Step 1820, Loss: -0.08482, Accuracy: 0.99819, F1: 0.2101, Prec: 0.1961, Rec: 0.2315 lr: 0.00100\n",
      "Epoch 2/Step 1840, Loss: -0.08647, Accuracy: 0.99819, F1: 0.2103, Prec: 0.1964, Rec: 0.2317 lr: 0.00100\n",
      "Epoch 2/Step 1860, Loss: -0.09247, Accuracy: 0.99819, F1: 0.2104, Prec: 0.1965, Rec: 0.2318 lr: 0.00100\n",
      "Epoch 2/Step 1880, Loss: -0.11011, Accuracy: 0.99819, F1: 0.2103, Prec: 0.1965, Rec: 0.2315 lr: 0.00100\n",
      "Epoch 2/Step 1900, Loss: -0.15484, Accuracy: 0.99819, F1: 0.2104, Prec: 0.1965, Rec: 0.2317 lr: 0.00100\n",
      "Epoch 2/Step 1920, Loss: -0.11751, Accuracy: 0.99819, F1: 0.2104, Prec: 0.1965, Rec: 0.2317 lr: 0.00100\n",
      "Epoch 2/Step 1940, Loss: -0.09134, Accuracy: 0.99819, F1: 0.2104, Prec: 0.1965, Rec: 0.2317 lr: 0.00100\n",
      "Epoch 2/Step 1960, Loss: -0.11394, Accuracy: 0.99819, F1: 0.2104, Prec: 0.1965, Rec: 0.2317 lr: 0.00100\n",
      "Epoch 2/Step 1980, Loss: -0.10018, Accuracy: 0.99819, F1: 0.2105, Prec: 0.1966, Rec: 0.2318 lr: 0.00100\n",
      "Epoch 2/Step 2000, Loss: -0.12137, Accuracy: 0.99819, F1: 0.2105, Prec: 0.1965, Rec: 0.2318 lr: 0.00100\n",
      "Epoch 2/Step 2020, Loss: -0.11204, Accuracy: 0.99819, F1: 0.2107, Prec: 0.1966, Rec: 0.2322 lr: 0.00100\n",
      "Epoch 2/Step 2040, Loss: -0.08912, Accuracy: 0.99819, F1: 0.2107, Prec: 0.1967, Rec: 0.2321 lr: 0.00100\n",
      "Epoch 2/Step 2060, Loss: -0.10758, Accuracy: 0.99819, F1: 0.2107, Prec: 0.1966, Rec: 0.2322 lr: 0.00100\n",
      "Epoch 2/Step 2080, Loss: -0.10854, Accuracy: 0.99819, F1: 0.2105, Prec: 0.1964, Rec: 0.2321 lr: 0.00100\n",
      "Epoch 2/Step 2100, Loss: -0.12599, Accuracy: 0.99819, F1: 0.2105, Prec: 0.1963, Rec: 0.2321 lr: 0.00100\n",
      "Epoch 2/Step 2120, Loss: -0.11995, Accuracy: 0.99819, F1: 0.2104, Prec: 0.1963, Rec: 0.2320 lr: 0.00100\n",
      "Epoch 2/Step 2140, Loss: -0.11598, Accuracy: 0.99819, F1: 0.2105, Prec: 0.1964, Rec: 0.2320 lr: 0.00100\n",
      "Epoch 2/Step 2160, Loss: -0.10495, Accuracy: 0.99819, F1: 0.2106, Prec: 0.1964, Rec: 0.2322 lr: 0.00100\n",
      "Epoch 2/Step 2180, Loss: -0.12360, Accuracy: 0.99819, F1: 0.2105, Prec: 0.1964, Rec: 0.2320 lr: 0.00100\n",
      "Epoch 2/Step 2200, Loss: -0.11126, Accuracy: 0.99819, F1: 0.2106, Prec: 0.1965, Rec: 0.2321 lr: 0.00100\n",
      "Epoch 2/Step 2220, Loss: -0.09812, Accuracy: 0.99819, F1: 0.2106, Prec: 0.1965, Rec: 0.2321 lr: 0.00100\n",
      "Epoch 2/Step 2240, Loss: -0.07845, Accuracy: 0.99819, F1: 0.2105, Prec: 0.1966, Rec: 0.2320 lr: 0.00100\n",
      "Epoch 2/Step 2260, Loss: -0.09140, Accuracy: 0.99819, F1: 0.2105, Prec: 0.1966, Rec: 0.2319 lr: 0.00100\n",
      "Epoch 2/Step 2280, Loss: -0.08944, Accuracy: 0.99819, F1: 0.2105, Prec: 0.1965, Rec: 0.2320 lr: 0.00100\n",
      "Epoch 2/Step 2300, Loss: -0.11426, Accuracy: 0.99819, F1: 0.2106, Prec: 0.1965, Rec: 0.2321 lr: 0.00100\n",
      "Epoch 2/Step 2320, Loss: -0.12221, Accuracy: 0.99819, F1: 0.2107, Prec: 0.1966, Rec: 0.2321 lr: 0.00100\n",
      "Epoch 2/Step 2340, Loss: -0.10731, Accuracy: 0.99819, F1: 0.2107, Prec: 0.1967, Rec: 0.2322 lr: 0.00100\n",
      "Epoch 2/Step 2360, Loss: -0.12175, Accuracy: 0.99819, F1: 0.2108, Prec: 0.1967, Rec: 0.2322 lr: 0.00100\n",
      "Epoch 2/Step 2380, Loss: -0.12211, Accuracy: 0.99819, F1: 0.2107, Prec: 0.1967, Rec: 0.2320 lr: 0.00100\n",
      "Epoch 2/Step 2400, Loss: -0.09079, Accuracy: 0.99819, F1: 0.2106, Prec: 0.1967, Rec: 0.2319 lr: 0.00100\n",
      "Epoch 2/Step 2420, Loss: -0.09365, Accuracy: 0.99819, F1: 0.2107, Prec: 0.1968, Rec: 0.2320 lr: 0.00100\n",
      "Epoch 2/Step 2440, Loss: -0.10332, Accuracy: 0.99819, F1: 0.2106, Prec: 0.1966, Rec: 0.2318 lr: 0.00100\n",
      "Epoch 2/Step 2460, Loss: -0.12848, Accuracy: 0.99819, F1: 0.2105, Prec: 0.1965, Rec: 0.2317 lr: 0.00100\n",
      "Epoch 2/Step 2480, Loss: -0.11521, Accuracy: 0.99819, F1: 0.2106, Prec: 0.1965, Rec: 0.2320 lr: 0.00100\n",
      "Epoch 2/Step 2500, Loss: -0.10138, Accuracy: 0.99819, F1: 0.2107, Prec: 0.1967, Rec: 0.2321 lr: 0.00100\n",
      "Epoch 2/Step 2520, Loss: -0.08011, Accuracy: 0.99819, F1: 0.2107, Prec: 0.1968, Rec: 0.2321 lr: 0.00100\n",
      "Epoch 2/Step 2540, Loss: -0.10223, Accuracy: 0.99819, F1: 0.2106, Prec: 0.1967, Rec: 0.2321 lr: 0.00100\n",
      "Epoch 2/Step 2560, Loss: -0.15093, Accuracy: 0.99819, F1: 0.2108, Prec: 0.1968, Rec: 0.2322 lr: 0.00100\n",
      "Epoch 2/Step 2580, Loss: -0.12329, Accuracy: 0.99819, F1: 0.2108, Prec: 0.1968, Rec: 0.2322 lr: 0.00100\n",
      "Epoch 2/Step 2600, Loss: -0.12514, Accuracy: 0.99819, F1: 0.2109, Prec: 0.1969, Rec: 0.2323 lr: 0.00100\n",
      "Epoch 2/Step 2620, Loss: -0.13430, Accuracy: 0.99819, F1: 0.2110, Prec: 0.1970, Rec: 0.2324 lr: 0.00100\n",
      "Epoch 2/Step 2640, Loss: -0.12579, Accuracy: 0.99819, F1: 0.2110, Prec: 0.1970, Rec: 0.2325 lr: 0.00100\n",
      "Epoch 2/Step 2660, Loss: -0.12601, Accuracy: 0.99819, F1: 0.2110, Prec: 0.1969, Rec: 0.2325 lr: 0.00100\n",
      "Epoch 2/Step 2680, Loss: -0.12526, Accuracy: 0.99819, F1: 0.2111, Prec: 0.1971, Rec: 0.2325 lr: 0.00100\n",
      "Epoch 2/Step 2700, Loss: -0.11884, Accuracy: 0.99819, F1: 0.2111, Prec: 0.1970, Rec: 0.2325 lr: 0.00100\n",
      "Epoch 2/Step 2720, Loss: -0.09057, Accuracy: 0.99819, F1: 0.2111, Prec: 0.1970, Rec: 0.2326 lr: 0.00100\n",
      "Epoch 2/Step 2740, Loss: -0.13588, Accuracy: 0.99819, F1: 0.2112, Prec: 0.1972, Rec: 0.2326 lr: 0.00100\n",
      "Epoch 2/Step 2760, Loss: -0.13351, Accuracy: 0.99819, F1: 0.2111, Prec: 0.1971, Rec: 0.2326 lr: 0.00100\n",
      "Epoch 2/Step 2780, Loss: -0.12537, Accuracy: 0.99819, F1: 0.2110, Prec: 0.1969, Rec: 0.2324 lr: 0.00100\n",
      "Epoch 2/Step 2800, Loss: -0.09940, Accuracy: 0.99819, F1: 0.2110, Prec: 0.1969, Rec: 0.2324 lr: 0.00100\n",
      "Epoch 2/Step 2820, Loss: -0.11176, Accuracy: 0.99819, F1: 0.2110, Prec: 0.1969, Rec: 0.2325 lr: 0.00100\n",
      "Epoch 2/Step 2840, Loss: -0.12305, Accuracy: 0.99819, F1: 0.2109, Prec: 0.1969, Rec: 0.2324 lr: 0.00100\n",
      "Epoch 2/Step 2860, Loss: -0.10904, Accuracy: 0.99819, F1: 0.2111, Prec: 0.1970, Rec: 0.2325 lr: 0.00100\n",
      "Epoch 2/Step 2880, Loss: -0.10317, Accuracy: 0.99819, F1: 0.2110, Prec: 0.1970, Rec: 0.2325 lr: 0.00100\n",
      "Epoch 2/Step 2900, Loss: -0.09614, Accuracy: 0.99819, F1: 0.2110, Prec: 0.1969, Rec: 0.2325 lr: 0.00100\n",
      "Epoch 2/Step 2920, Loss: -0.08688, Accuracy: 0.99819, F1: 0.2110, Prec: 0.1970, Rec: 0.2324 lr: 0.00100\n",
      "Epoch 2/Step 2940, Loss: -0.13692, Accuracy: 0.99819, F1: 0.2110, Prec: 0.1970, Rec: 0.2324 lr: 0.00100\n",
      "Epoch 2/Step 2960, Loss: -0.13778, Accuracy: 0.99819, F1: 0.2109, Prec: 0.1969, Rec: 0.2324 lr: 0.00100\n",
      "Epoch 2/Step 2980, Loss: -0.08594, Accuracy: 0.99819, F1: 0.2109, Prec: 0.1969, Rec: 0.2324 lr: 0.00100\n",
      "Epoch 2/Step 3000, Loss: -0.10545, Accuracy: 0.99819, F1: 0.2109, Prec: 0.1968, Rec: 0.2323 lr: 0.00100\n",
      "Epoch 2/Step 3020, Loss: -0.10764, Accuracy: 0.99819, F1: 0.2109, Prec: 0.1968, Rec: 0.2323 lr: 0.00100\n",
      "Epoch 2/Step 3040, Loss: -0.14322, Accuracy: 0.99819, F1: 0.2108, Prec: 0.1968, Rec: 0.2323 lr: 0.00100\n",
      "Epoch 2/Step 3060, Loss: -0.10906, Accuracy: 0.99819, F1: 0.2109, Prec: 0.1968, Rec: 0.2323 lr: 0.00100\n",
      "Epoch 2/Step 3080, Loss: -0.08873, Accuracy: 0.99819, F1: 0.2108, Prec: 0.1967, Rec: 0.2323 lr: 0.00100\n",
      "Epoch 2/Step 3100, Loss: -0.12893, Accuracy: 0.99819, F1: 0.2108, Prec: 0.1968, Rec: 0.2323 lr: 0.00100\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9982\n",
      "Validation f1: 0.2067\n",
      "Validation precision: 0.1919\n",
      "Validation recall: 0.2295\n",
      "\n",
      "Start of epoch 3\n",
      "Epoch 3/Step 0, Loss: -0.12746, Accuracy: 0.99827, F1: 0.2122, Prec: 0.2043, Rec: 0.2208 lr: 0.00100\n",
      "Epoch 3/Step 20, Loss: -0.13529, Accuracy: 0.99813, F1: 0.2283, Prec: 0.2121, Rec: 0.2503 lr: 0.00100\n",
      "Epoch 3/Step 40, Loss: -0.11430, Accuracy: 0.99815, F1: 0.2237, Prec: 0.2122, Rec: 0.2408 lr: 0.00100\n",
      "Epoch 3/Step 60, Loss: -0.10457, Accuracy: 0.99819, F1: 0.2186, Prec: 0.2085, Rec: 0.2346 lr: 0.00100\n",
      "Epoch 3/Step 80, Loss: -0.09905, Accuracy: 0.99823, F1: 0.2198, Prec: 0.2055, Rec: 0.2421 lr: 0.00100\n",
      "Epoch 3/Step 100, Loss: -0.12771, Accuracy: 0.99824, F1: 0.2196, Prec: 0.2041, Rec: 0.2436 lr: 0.00100\n",
      "Epoch 3/Step 120, Loss: -0.11547, Accuracy: 0.99825, F1: 0.2172, Prec: 0.2029, Rec: 0.2395 lr: 0.00100\n",
      "Epoch 3/Step 140, Loss: -0.09858, Accuracy: 0.99827, F1: 0.2160, Prec: 0.2010, Rec: 0.2388 lr: 0.00100\n",
      "Epoch 3/Step 160, Loss: -0.10793, Accuracy: 0.99827, F1: 0.2149, Prec: 0.1991, Rec: 0.2388 lr: 0.00100\n",
      "Epoch 3/Step 180, Loss: -0.10610, Accuracy: 0.99827, F1: 0.2151, Prec: 0.1990, Rec: 0.2392 lr: 0.00100\n",
      "Epoch 3/Step 200, Loss: -0.11029, Accuracy: 0.99827, F1: 0.2140, Prec: 0.1974, Rec: 0.2387 lr: 0.00100\n",
      "Epoch 3/Step 220, Loss: -0.10421, Accuracy: 0.99827, F1: 0.2149, Prec: 0.1979, Rec: 0.2399 lr: 0.00100\n",
      "Epoch 3/Step 240, Loss: -0.11860, Accuracy: 0.99826, F1: 0.2152, Prec: 0.1990, Rec: 0.2394 lr: 0.00100\n",
      "Epoch 3/Step 260, Loss: -0.13123, Accuracy: 0.99826, F1: 0.2137, Prec: 0.1978, Rec: 0.2375 lr: 0.00100\n",
      "Epoch 3/Step 280, Loss: -0.11118, Accuracy: 0.99826, F1: 0.2135, Prec: 0.1971, Rec: 0.2383 lr: 0.00100\n",
      "Epoch 3/Step 300, Loss: -0.11223, Accuracy: 0.99825, F1: 0.2146, Prec: 0.1979, Rec: 0.2397 lr: 0.00100\n",
      "Epoch 3/Step 320, Loss: -0.10627, Accuracy: 0.99825, F1: 0.2143, Prec: 0.1980, Rec: 0.2388 lr: 0.00100\n",
      "Epoch 3/Step 340, Loss: -0.10294, Accuracy: 0.99825, F1: 0.2136, Prec: 0.1974, Rec: 0.2378 lr: 0.00100\n",
      "Epoch 3/Step 360, Loss: -0.10303, Accuracy: 0.99825, F1: 0.2129, Prec: 0.1969, Rec: 0.2370 lr: 0.00100\n",
      "Epoch 3/Step 380, Loss: -0.06873, Accuracy: 0.99824, F1: 0.2121, Prec: 0.1962, Rec: 0.2361 lr: 0.00100\n",
      "Epoch 3/Step 400, Loss: -0.11744, Accuracy: 0.99824, F1: 0.2126, Prec: 0.1965, Rec: 0.2369 lr: 0.00100\n",
      "Epoch 3/Step 420, Loss: -0.10803, Accuracy: 0.99824, F1: 0.2127, Prec: 0.1961, Rec: 0.2377 lr: 0.00100\n",
      "Epoch 3/Step 440, Loss: -0.10346, Accuracy: 0.99824, F1: 0.2126, Prec: 0.1962, Rec: 0.2374 lr: 0.00100\n",
      "Epoch 3/Step 460, Loss: -0.11386, Accuracy: 0.99824, F1: 0.2127, Prec: 0.1960, Rec: 0.2381 lr: 0.00100\n",
      "Epoch 3/Step 480, Loss: -0.16259, Accuracy: 0.99823, F1: 0.2130, Prec: 0.1964, Rec: 0.2380 lr: 0.00100\n",
      "Epoch 3/Step 500, Loss: -0.13286, Accuracy: 0.99823, F1: 0.2131, Prec: 0.1964, Rec: 0.2384 lr: 0.00100\n",
      "Epoch 3/Step 520, Loss: -0.13480, Accuracy: 0.99823, F1: 0.2137, Prec: 0.1969, Rec: 0.2390 lr: 0.00100\n",
      "Epoch 3/Step 540, Loss: -0.12568, Accuracy: 0.99823, F1: 0.2143, Prec: 0.1976, Rec: 0.2396 lr: 0.00100\n",
      "Epoch 3/Step 560, Loss: -0.10479, Accuracy: 0.99823, F1: 0.2141, Prec: 0.1976, Rec: 0.2390 lr: 0.00100\n",
      "Epoch 3/Step 580, Loss: -0.12873, Accuracy: 0.99823, F1: 0.2136, Prec: 0.1972, Rec: 0.2384 lr: 0.00100\n",
      "Epoch 3/Step 600, Loss: -0.14503, Accuracy: 0.99823, F1: 0.2136, Prec: 0.1972, Rec: 0.2385 lr: 0.00100\n",
      "Epoch 3/Step 620, Loss: -0.10900, Accuracy: 0.99823, F1: 0.2130, Prec: 0.1966, Rec: 0.2377 lr: 0.00100\n",
      "Epoch 3/Step 640, Loss: -0.11001, Accuracy: 0.99824, F1: 0.2130, Prec: 0.1967, Rec: 0.2376 lr: 0.00100\n",
      "Epoch 3/Step 660, Loss: -0.11605, Accuracy: 0.99824, F1: 0.2133, Prec: 0.1968, Rec: 0.2382 lr: 0.00100\n",
      "Epoch 3/Step 680, Loss: -0.10698, Accuracy: 0.99824, F1: 0.2136, Prec: 0.1968, Rec: 0.2390 lr: 0.00100\n",
      "Epoch 3/Step 700, Loss: -0.10368, Accuracy: 0.99824, F1: 0.2135, Prec: 0.1966, Rec: 0.2390 lr: 0.00100\n",
      "Epoch 3/Step 720, Loss: -0.14647, Accuracy: 0.99824, F1: 0.2137, Prec: 0.1967, Rec: 0.2394 lr: 0.00100\n",
      "Epoch 3/Step 740, Loss: -0.11578, Accuracy: 0.99824, F1: 0.2135, Prec: 0.1968, Rec: 0.2387 lr: 0.00100\n",
      "Epoch 3/Step 760, Loss: -0.13774, Accuracy: 0.99824, F1: 0.2132, Prec: 0.1966, Rec: 0.2383 lr: 0.00100\n",
      "Epoch 3/Step 780, Loss: -0.10930, Accuracy: 0.99824, F1: 0.2128, Prec: 0.1962, Rec: 0.2379 lr: 0.00100\n",
      "Epoch 3/Step 800, Loss: -0.10305, Accuracy: 0.99825, F1: 0.2123, Prec: 0.1955, Rec: 0.2378 lr: 0.00100\n",
      "Epoch 3/Step 820, Loss: -0.12647, Accuracy: 0.99825, F1: 0.2119, Prec: 0.1951, Rec: 0.2375 lr: 0.00100\n",
      "Epoch 3/Step 840, Loss: -0.12394, Accuracy: 0.99825, F1: 0.2118, Prec: 0.1951, Rec: 0.2373 lr: 0.00100\n",
      "Epoch 3/Step 860, Loss: -0.11347, Accuracy: 0.99825, F1: 0.2116, Prec: 0.1945, Rec: 0.2375 lr: 0.00100\n",
      "Epoch 3/Step 880, Loss: -0.08320, Accuracy: 0.99825, F1: 0.2117, Prec: 0.1945, Rec: 0.2378 lr: 0.00100\n",
      "Epoch 3/Step 900, Loss: -0.11010, Accuracy: 0.99825, F1: 0.2120, Prec: 0.1949, Rec: 0.2380 lr: 0.00100\n",
      "Epoch 3/Step 920, Loss: -0.13433, Accuracy: 0.99825, F1: 0.2116, Prec: 0.1946, Rec: 0.2372 lr: 0.00100\n",
      "Epoch 3/Step 940, Loss: -0.12392, Accuracy: 0.99825, F1: 0.2115, Prec: 0.1945, Rec: 0.2372 lr: 0.00100\n",
      "Epoch 3/Step 960, Loss: -0.14710, Accuracy: 0.99825, F1: 0.2117, Prec: 0.1946, Rec: 0.2377 lr: 0.00100\n",
      "Epoch 3/Step 980, Loss: -0.08611, Accuracy: 0.99825, F1: 0.2114, Prec: 0.1944, Rec: 0.2373 lr: 0.00100\n",
      "Epoch 3/Step 1000, Loss: -0.14456, Accuracy: 0.99825, F1: 0.2109, Prec: 0.1940, Rec: 0.2367 lr: 0.00100\n",
      "Epoch 3/Step 1020, Loss: -0.12683, Accuracy: 0.99825, F1: 0.2109, Prec: 0.1938, Rec: 0.2368 lr: 0.00100\n",
      "Epoch 3/Step 1040, Loss: -0.09268, Accuracy: 0.99825, F1: 0.2111, Prec: 0.1938, Rec: 0.2373 lr: 0.00100\n",
      "Epoch 3/Step 1060, Loss: -0.09872, Accuracy: 0.99825, F1: 0.2110, Prec: 0.1936, Rec: 0.2373 lr: 0.00100\n",
      "Epoch 3/Step 1080, Loss: -0.09075, Accuracy: 0.99825, F1: 0.2111, Prec: 0.1937, Rec: 0.2375 lr: 0.00100\n",
      "Epoch 3/Step 1100, Loss: -0.10731, Accuracy: 0.99825, F1: 0.2113, Prec: 0.1940, Rec: 0.2375 lr: 0.00100\n",
      "Epoch 3/Step 1120, Loss: -0.09450, Accuracy: 0.99825, F1: 0.2112, Prec: 0.1942, Rec: 0.2371 lr: 0.00100\n",
      "Epoch 3/Step 1140, Loss: -0.12584, Accuracy: 0.99825, F1: 0.2113, Prec: 0.1942, Rec: 0.2372 lr: 0.00100\n",
      "Epoch 3/Step 1160, Loss: -0.11634, Accuracy: 0.99825, F1: 0.2114, Prec: 0.1944, Rec: 0.2371 lr: 0.00100\n",
      "Epoch 3/Step 1180, Loss: -0.09794, Accuracy: 0.99825, F1: 0.2114, Prec: 0.1944, Rec: 0.2370 lr: 0.00100\n",
      "Epoch 3/Step 1200, Loss: -0.09638, Accuracy: 0.99825, F1: 0.2114, Prec: 0.1944, Rec: 0.2370 lr: 0.00100\n",
      "Epoch 3/Step 1220, Loss: -0.11156, Accuracy: 0.99825, F1: 0.2112, Prec: 0.1941, Rec: 0.2371 lr: 0.00100\n",
      "Epoch 3/Step 1240, Loss: -0.10632, Accuracy: 0.99825, F1: 0.2113, Prec: 0.1941, Rec: 0.2373 lr: 0.00100\n",
      "Epoch 3/Step 1260, Loss: -0.11022, Accuracy: 0.99825, F1: 0.2114, Prec: 0.1943, Rec: 0.2373 lr: 0.00100\n",
      "Epoch 3/Step 1280, Loss: -0.09826, Accuracy: 0.99825, F1: 0.2113, Prec: 0.1943, Rec: 0.2372 lr: 0.00100\n",
      "Epoch 3/Step 1300, Loss: -0.12624, Accuracy: 0.99824, F1: 0.2114, Prec: 0.1944, Rec: 0.2372 lr: 0.00100\n",
      "Epoch 3/Step 1320, Loss: -0.11057, Accuracy: 0.99824, F1: 0.2114, Prec: 0.1945, Rec: 0.2370 lr: 0.00100\n",
      "Epoch 3/Step 1340, Loss: -0.09625, Accuracy: 0.99824, F1: 0.2115, Prec: 0.1946, Rec: 0.2372 lr: 0.00100\n",
      "Epoch 3/Step 1360, Loss: -0.11765, Accuracy: 0.99824, F1: 0.2113, Prec: 0.1945, Rec: 0.2368 lr: 0.00100\n",
      "Epoch 3/Step 1380, Loss: -0.11736, Accuracy: 0.99824, F1: 0.2114, Prec: 0.1945, Rec: 0.2369 lr: 0.00100\n",
      "Epoch 3/Step 1400, Loss: -0.09301, Accuracy: 0.99825, F1: 0.2114, Prec: 0.1944, Rec: 0.2371 lr: 0.00100\n",
      "Epoch 3/Step 1420, Loss: -0.10741, Accuracy: 0.99825, F1: 0.2111, Prec: 0.1940, Rec: 0.2370 lr: 0.00100\n",
      "Epoch 3/Step 1440, Loss: -0.15341, Accuracy: 0.99825, F1: 0.2113, Prec: 0.1942, Rec: 0.2372 lr: 0.00100\n",
      "Epoch 3/Step 1460, Loss: -0.09588, Accuracy: 0.99825, F1: 0.2113, Prec: 0.1942, Rec: 0.2373 lr: 0.00100\n",
      "Epoch 3/Step 1480, Loss: -0.10231, Accuracy: 0.99825, F1: 0.2113, Prec: 0.1943, Rec: 0.2372 lr: 0.00100\n",
      "Epoch 3/Step 1500, Loss: -0.10531, Accuracy: 0.99825, F1: 0.2115, Prec: 0.1945, Rec: 0.2373 lr: 0.00100\n",
      "Epoch 3/Step 1520, Loss: -0.12451, Accuracy: 0.99825, F1: 0.2115, Prec: 0.1946, Rec: 0.2373 lr: 0.00100\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow_addons as tfa\n",
    "\n",
    "BATCH_SIZE=32\n",
    "LOG_INTERVAL=20\n",
    "epochs = 15\n",
    "saveModel=False\n",
    "\n",
    "\n",
    "log_dir = \"./logs/\"+model.name+\"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+\"_\"+SO\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,\n",
    "                                                      write_graph=True, update_freq=5)\n",
    "\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "# Instantiate an optimizer .\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "# Instantiate a loss function.\n",
    "# loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "# loss_fn = WeightedBinaryCE(np.ones(len(mlb.classes_)))\n",
    "# loss_fn = WeightedBinaryCE(labelWeights)\n",
    "loss_fn = WeightedComboLoss(labelWeights, alpha=0.5, beta=0.5)\n",
    "\n",
    "train_acc_metric = WeightedAccuracy(classWeights=labelWeights)\n",
    "train_f1_metric = WeightedF1(classWeights=labelWeights, threshold=0.5)\n",
    "train_prec = WeightedPrecision(classWeights=labelWeights)\n",
    "train_rec = WeightedRecall(classWeights=labelWeights)\n",
    "\n",
    "val_acc_metric = WeightedAccuracy(classWeights=labelWeights)\n",
    "val_f1_metric = WeightedF1(classWeights=labelWeights, threshold=0.5)\n",
    "val_prec = WeightedPrecision(classWeights=labelWeights)\n",
    "val_rec = WeightedRecall(classWeights=labelWeights)\n",
    "\n",
    "batchedDataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "batchedDatasetVal = datasetVal.batch(BATCH_SIZE, drop_remainder=False)\n",
    "\n",
    "# batchedDataset = batchedDataset.cache(os.path.join(DATA_PATH, \"datasetCache\"+SO))\n",
    "# batchedDatasetVal = batchedDatasetVal.cache(os.path.join(DATA_PATH, \"datasetCacheVal\"+SO))\n",
    "\n",
    "@tf.function()\n",
    "def trainStep(x_batch_train, y_batch_train):\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        probs = model(x_batch_train, training=True) \n",
    "        loss_value = loss_fn(y_batch_train, probs)\n",
    "\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    #Gradient clipping\n",
    "    # grads = [tf.clip_by_norm(g, 2.0) for g in grads]\n",
    "\n",
    "    train_acc_metric.update_state(y_batch_train, probs)\n",
    "    train_f1_metric.update_state(y_batch_train, probs)\n",
    "    train_prec.update_state(y_batch_train, probs)\n",
    "    train_rec.update_state(y_batch_train, probs)\n",
    "\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights)) \n",
    "    return loss_value\n",
    "\n",
    "@tf.function()\n",
    "def valStep(x_batch_val, y_batch_val):\n",
    "    valProbs = model(x_batch_val, training=False)\n",
    "    # Update val metrics\n",
    "    val_acc_metric.update_state(y_batch_val, valProbs)\n",
    "    val_f1_metric.update_state(y_batch_val, valProbs)\n",
    "    val_prec.update_state(y_batch_val, valProbs)\n",
    "    val_rec.update_state(y_batch_val, valProbs)\n",
    "\n",
    "maxStep=0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch+1,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(batchedDataset):\n",
    "\n",
    "        loss_value =trainStep(x_batch_train,y_batch_train)\n",
    "\n",
    "        # Log \n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            template = 'Epoch {}/Step {}, Loss: {:.5f}, Accuracy: {:.5f}, F1: {:.4f}, Prec: {:.4f}, Rec: {:.4f} lr: {:.5f}'\n",
    "            print(template.format(epoch+1, step,loss_value.numpy(), \n",
    "                                    train_acc_metric.result(),train_f1_metric.result(),\n",
    "                                    train_prec.result(), train_rec.result(), optimizer.learning_rate.numpy()))\n",
    "            \n",
    "            with summary_writer.as_default():\n",
    "                tf.summary.scalar('loss', loss_value, step=maxStep*epoch+step)\n",
    "                tf.summary.scalar('accuracy', train_acc_metric.result(), step=maxStep*epoch+step)\n",
    "                tf.summary.scalar('f1', train_f1_metric.result(), step=maxStep*epoch+step)\n",
    "                tf.summary.scalar('prec', train_prec.result(), step=maxStep*epoch+step)\n",
    "                tf.summary.scalar('rec', train_rec.result(), step=maxStep*epoch+step)\n",
    "                tf.summary.scalar('learning rate', optimizer.learning_rate.numpy(), step=maxStep*epoch+step)\n",
    "                summary_writer.flush()\n",
    "\n",
    "    \n",
    "    train_acc_metric.reset_states()\n",
    "    train_f1_metric.reset_states()\n",
    "    train_prec.reset_states()\n",
    "    train_rec.reset_states()\n",
    "\n",
    "    maxStep=step\n",
    "\n",
    "    print(\"Epoch finished. Start validation\")\n",
    "    for x_batch_val, y_batch_val in batchedDatasetVal:\n",
    "        valStep(x_batch_val, y_batch_val)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    val_f1 = val_f1_metric.result()\n",
    "    val_f1_metric.reset_states()\n",
    "    val_precision = val_prec.result()\n",
    "    val_prec.reset_states()\n",
    "    val_recall = val_rec.result()\n",
    "    val_rec.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    print(\"Validation f1: %.4f\" % (float(val_f1),))\n",
    "    print(\"Validation precision: %.4f\" % (float(val_precision),))\n",
    "    print(\"Validation recall: %.4f\" % (float(val_recall),))\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('valAcc', float(val_acc), step=epoch)\n",
    "        tf.summary.scalar('valF1', float(val_f1), step=epoch)\n",
    "        tf.summary.scalar('valPrecision', float(val_precision), step=epoch)\n",
    "        tf.summary.scalar('valRecall', float(val_recall), step=epoch)\n",
    "        summary_writer.flush()\n",
    "    if saveModel:\n",
    "      model.save(os.path.join(DATA_PATH, \"model_\"+SO+\"_epoch_{}_valF1Score{:.3f}\".format(epoch, float(val_f1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f7234",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model.save(os.path.join(DATA_PATH, \"model_\"+SO+\"_epoch_{}_valf1Score{:.3f}\".format(epoch, float(val_f1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc1f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "probs= model.predict(tf.expand_dims(list(datasetVal.take(32))[10][0], 0))\n",
    "prediction= [1 if p > 0.5 else 0 for p in probs[0]]\n",
    "probabilities= probs[probs>0.5]\n",
    "# classes = np.argwhere(prediction)\n",
    "print(mlb.inverse_transform(np.array([prediction])))\n",
    "print(probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
