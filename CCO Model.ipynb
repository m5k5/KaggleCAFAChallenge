{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c1d77e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 15:36:23.738649: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-16 15:36:24.197650: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/e/ML/cafa-5-protein-function-prediction\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "DATA_PATH = os.getenv('DATA_PATH')\n",
    "print(DATA_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3544f8a",
   "metadata": {},
   "source": [
    "## Reading fasta, obo and tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b515f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "sequences = [rec.seq for rec in SeqIO.parse(os.path.join(DATA_PATH, \"Train/train_sequences.fasta\"),\"fasta\")]\n",
    "ids = [rec.id for rec in SeqIO.parse(os.path.join(DATA_PATH, \"Train/train_sequences.fasta\"),\"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e492f673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 142246 sequences in the dataset.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} sequences in the dataset.\".format(len(sequences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2898414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "import obonet\n",
    "\n",
    "# Read the taxrank ontology\n",
    "url = os.path.join(DATA_PATH, \"Train/go-basic.obo\")\n",
    "graph = obonet.read_obo(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f4bf949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1196017, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25289/428058261.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfCco[\"termToken\"] = termToken\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, \"Train/train_terms.tsv\"), sep='\\t')\n",
    "dfCco = df.loc[df[\"aspect\"]==\"CCO\"]\n",
    "uniqueTerms = dfCco[\"term\"].unique()\n",
    "termsArr = list(dfCco[\"term\"].to_numpy())\n",
    "\n",
    "uniqueTermsDict={}\n",
    "for i,el in enumerate(uniqueTerms):\n",
    "    uniqueTermsDict[el] = i\n",
    "    \n",
    "termToken = [uniqueTermsDict[el] for el in termsArr]\n",
    "dfCco[\"termToken\"] = termToken\n",
    "print(dfCco.shape)\n",
    "df=dfCco"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29043526",
   "metadata": {},
   "source": [
    "Test for the first entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "af3cf1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>aspect</th>\n",
       "      <th>termToken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EntryID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0099086</td>\n",
       "      <td>CCO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0000228</td>\n",
       "      <td>CCO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0005622</td>\n",
       "      <td>CCO</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0043226</td>\n",
       "      <td>CCO</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0000792</td>\n",
       "      <td>CCO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0000795</td>\n",
       "      <td>CCO</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0000785</td>\n",
       "      <td>CCO</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0043231</td>\n",
       "      <td>CCO</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0032991</td>\n",
       "      <td>CCO</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0043229</td>\n",
       "      <td>CCO</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0043232</td>\n",
       "      <td>CCO</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0005634</td>\n",
       "      <td>CCO</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0005705</td>\n",
       "      <td>CCO</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0043228</td>\n",
       "      <td>CCO</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0031981</td>\n",
       "      <td>CCO</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0000793</td>\n",
       "      <td>CCO</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0098687</td>\n",
       "      <td>CCO</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0043233</td>\n",
       "      <td>CCO</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0005700</td>\n",
       "      <td>CCO</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0005575</td>\n",
       "      <td>CCO</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  term aspect  termToken\n",
       "EntryID                                 \n",
       "A0A021WW32  GO:0099086    CCO          0\n",
       "A0A021WW32  GO:0000228    CCO          1\n",
       "A0A021WW32  GO:0005622    CCO          2\n",
       "A0A021WW32  GO:0043226    CCO          3\n",
       "A0A021WW32  GO:0000792    CCO          4\n",
       "A0A021WW32  GO:0000795    CCO          5\n",
       "A0A021WW32  GO:0000785    CCO          6\n",
       "A0A021WW32  GO:0043231    CCO          7\n",
       "A0A021WW32  GO:0032991    CCO          8\n",
       "A0A021WW32  GO:0043229    CCO          9\n",
       "A0A021WW32  GO:0043232    CCO         10\n",
       "A0A021WW32  GO:0005634    CCO         11\n",
       "A0A021WW32  GO:0005705    CCO         12\n",
       "A0A021WW32  GO:0043228    CCO         13\n",
       "A0A021WW32  GO:0031981    CCO         14\n",
       "A0A021WW32  GO:0000793    CCO         15\n",
       "A0A021WW32  GO:0098687    CCO         16\n",
       "A0A021WW32  GO:0043233    CCO         17\n",
       "A0A021WW32  GO:0005700    CCO         18\n",
       "A0A021WW32  GO:0005575    CCO         19"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index(\"EntryID\", inplace=True)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5777789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.4 µs ± 75.5 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit df.loc[\"A0A021WW32\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cb2bccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>aspect</th>\n",
       "      <th>termToken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EntryID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0099086</td>\n",
       "      <td>CCO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0000228</td>\n",
       "      <td>CCO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0005622</td>\n",
       "      <td>CCO</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0043226</td>\n",
       "      <td>CCO</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0000792</td>\n",
       "      <td>CCO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0000795</td>\n",
       "      <td>CCO</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0000785</td>\n",
       "      <td>CCO</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0043231</td>\n",
       "      <td>CCO</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0032991</td>\n",
       "      <td>CCO</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0043229</td>\n",
       "      <td>CCO</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0043232</td>\n",
       "      <td>CCO</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0005634</td>\n",
       "      <td>CCO</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0005705</td>\n",
       "      <td>CCO</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0043228</td>\n",
       "      <td>CCO</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0031981</td>\n",
       "      <td>CCO</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0000793</td>\n",
       "      <td>CCO</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0098687</td>\n",
       "      <td>CCO</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0043233</td>\n",
       "      <td>CCO</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0005700</td>\n",
       "      <td>CCO</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0005575</td>\n",
       "      <td>CCO</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0044815</td>\n",
       "      <td>CCO</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0005694</td>\n",
       "      <td>CCO</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0000794</td>\n",
       "      <td>CCO</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0008278</td>\n",
       "      <td>CCO</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0110165</td>\n",
       "      <td>CCO</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0005721</td>\n",
       "      <td>CCO</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0070013</td>\n",
       "      <td>CCO</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0043227</td>\n",
       "      <td>CCO</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0000775</td>\n",
       "      <td>CCO</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A021WW32</th>\n",
       "      <td>GO:0031974</td>\n",
       "      <td>CCO</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  term aspect  termToken\n",
       "EntryID                                 \n",
       "A0A021WW32  GO:0099086    CCO          0\n",
       "A0A021WW32  GO:0000228    CCO          1\n",
       "A0A021WW32  GO:0005622    CCO          2\n",
       "A0A021WW32  GO:0043226    CCO          3\n",
       "A0A021WW32  GO:0000792    CCO          4\n",
       "A0A021WW32  GO:0000795    CCO          5\n",
       "A0A021WW32  GO:0000785    CCO          6\n",
       "A0A021WW32  GO:0043231    CCO          7\n",
       "A0A021WW32  GO:0032991    CCO          8\n",
       "A0A021WW32  GO:0043229    CCO          9\n",
       "A0A021WW32  GO:0043232    CCO         10\n",
       "A0A021WW32  GO:0005634    CCO         11\n",
       "A0A021WW32  GO:0005705    CCO         12\n",
       "A0A021WW32  GO:0043228    CCO         13\n",
       "A0A021WW32  GO:0031981    CCO         14\n",
       "A0A021WW32  GO:0000793    CCO         15\n",
       "A0A021WW32  GO:0098687    CCO         16\n",
       "A0A021WW32  GO:0043233    CCO         17\n",
       "A0A021WW32  GO:0005700    CCO         18\n",
       "A0A021WW32  GO:0005575    CCO         19\n",
       "A0A021WW32  GO:0044815    CCO         20\n",
       "A0A021WW32  GO:0005694    CCO         21\n",
       "A0A021WW32  GO:0000794    CCO         22\n",
       "A0A021WW32  GO:0008278    CCO         23\n",
       "A0A021WW32  GO:0110165    CCO         24\n",
       "A0A021WW32  GO:0005721    CCO         25\n",
       "A0A021WW32  GO:0070013    CCO         26\n",
       "A0A021WW32  GO:0043227    CCO         27\n",
       "A0A021WW32  GO:0000775    CCO         28\n",
       "A0A021WW32  GO:0031974    CCO         29"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[\"A0A021WW32\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "184631e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CCO'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df[\"aspect\"].to_numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5338b7f8",
   "metadata": {},
   "source": [
    "## GO analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1058ef1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO:0005575    92912\n",
      "GO:0110165    91286\n",
      "GO:0005622    70785\n",
      "GO:0043226    60883\n",
      "GO:0043229    58315\n",
      "GO:0043227    55452\n",
      "GO:0005737    53193\n",
      "GO:0043231    52218\n",
      "GO:0005634    28932\n",
      "GO:0016020    25768\n",
      "GO:0071944    20467\n",
      "GO:0005829    18216\n",
      "GO:0005886    16738\n",
      "GO:0032991    16657\n",
      "GO:0043228    16145\n",
      "GO:0043232    16124\n",
      "GO:0031974    15696\n",
      "GO:0043233    15694\n",
      "GO:0070013    15688\n",
      "GO:0031981    13510\n",
      "Name: term, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "item_counts = df[\"term\"].value_counts()\n",
    "print(item_counts[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb35584f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nuclear lumen\n"
     ]
    }
   ],
   "source": [
    "id_to_name = {id_: data.get('name') for id_, data in graph.nodes(data=True)}\n",
    "name_to_id = {data['name']: id_ for id_, data in graph.nodes(data=True) if 'name' in data}\n",
    "print(id_to_name['GO:0031981'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85b2429c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intracellular organelle lumen\n",
      "{'GO:0005730', 'GO:0070860', 'GO:0000438', 'GO:0043202', 'GO:1990251', 'GO:0015030', 'GO:0101019', 'GO:0033557', 'GO:0070517', 'GO:0042645', 'GO:0061773', 'GO:0106098', 'GO:0106173', 'GO:0042382', 'GO:0120282', 'GO:0035808', 'GO:0000330', 'GO:0033276', 'GO:0030685', 'GO:0044842', 'GO:0034399', 'GO:0008023', 'GO:0016606', 'GO:0070449', 'GO:0005664', 'GO:0106055', 'GO:0001651', 'GO:0044665', 'GO:0005775', 'GO:1990483', 'GO:0032021', 'GO:0061201', 'GO:0034492', 'GO:0034423', 'GO:0016607', 'GO:0070556', 'GO:1990826', 'GO:0000118', 'GO:0097356', 'GO:0001405', 'GO:0031595', 'GO:0098566', 'GO:0031429', 'GO:0034457', 'GO:0016580', 'GO:0034469', 'GO:0062246', 'GO:0032221', 'GO:0001652', 'GO:0014803', 'GO:0043596', 'GO:0005641', 'GO:0000817', 'GO:0016604', 'GO:0008024', 'GO:0016605', 'GO:0035061', 'GO:0031601', 'GO:1904813', 'GO:0070824', 'GO:0005762', 'GO:0071339', 'GO:0031607', 'GO:0110016', 'GO:0005672', 'GO:0110145', 'GO:1990934', 'GO:0071162', 'GO:0000801', 'GO:0060202', 'GO:0070210', 'GO:0031298', 'GO:0036014', 'GO:0030875', 'GO:0005759', 'GO:0035363', 'GO:0000800', 'GO:0005761', 'GO:0043160', 'GO:0070692', 'GO:0030958', 'GO:0062238', 'GO:0000802', 'GO:0034495', 'GO:0031904', 'GO:0031908', 'GO:0097424', 'GO:0005796', 'GO:0099020', 'GO:0016581', 'GO:0005674', 'GO:0031610', 'GO:0005673', 'GO:0031979', 'GO:0005726', 'GO:0005652', 'GO:0000794', 'GO:0032798', 'GO:0034493', 'GO:0031907', 'GO:0009841', 'GO:0031093', 'GO:0031604', 'GO:0034592', 'GO:0034456', 'GO:0005665', 'GO:0008622', 'GO:0099021', 'GO:1904724', 'GO:0005675', 'GO:0035101', 'GO:0030874', 'GO:0000795', 'GO:0030062', 'GO:0005763', 'GO:0070311', 'GO:0005758', 'GO:0000262', 'GO:0048238', 'GO:0072589', 'GO:0005736', 'GO:0034985', 'GO:0071682', 'GO:0036224', 'GO:0005662', 'GO:0099013', 'GO:0000812', 'GO:0044666', 'GO:0043599', 'GO:0005788', 'GO:0016363', 'GO:0031905', 'GO:0032044', 'GO:0070082', 'GO:0005714', 'GO:0031981', 'GO:0031598', 'GO:0000328', 'GO:0000811', 'GO:0097486', 'GO:0001740', 'GO:0019910', 'GO:0031906', 'GO:0031973', 'GO:0005731', 'GO:0042719', 'GO:0034974', 'GO:0005712', 'GO:0031972', 'GO:0005658', 'GO:0110129', 'GO:0034494', 'GO:0017087', 'GO:0017133', 'GO:0031613', 'GO:0043625', 'GO:0005638', 'GO:0005656', 'GO:0043294', 'GO:0005669', 'GO:0005962', 'GO:0000120', 'GO:0070823', 'GO:0036021', 'GO:0106172', 'GO:0070822', 'GO:0005947', 'GO:0005760', 'GO:0106174', 'GO:0005654', 'GO:0035062', 'GO:0034777', 'GO:0000446', 'GO:0005668', 'GO:0001650', 'GO:0005782', 'GO:0033698', 'GO:0070211', 'GO:0030869', 'GO:0032783', 'GO:0098899', 'GO:0035097', 'GO:0098898', 'GO:0043601', 'GO:0071601', 'GO:0016593', 'GO:0071920', 'GO:0030896', 'GO:0035098', 'GO:0034455', 'GO:0000500', 'GO:0034099', 'GO:0043494', 'GO:0031970', 'GO:0034467', 'GO:0016507', 'GO:0070691', 'GO:1904856', 'GO:0031261', 'GO:0034774', 'GO:0034388', 'GO:0031096', 'GO:0034468', 'GO:0000176', 'GO:1990836', 'GO:0099086', 'GO:0106069', 'GO:0106176', 'GO:0034967', 'GO:0030998', 'GO:0070985', 'GO:0060204', 'GO:0005713', 'GO:0048188', 'GO:0070931', 'GO:0014804', 'GO:0097489', 'GO:0048237', 'GO:0016591', 'GO:0070545', 'GO:0031089', 'GO:0062113', 'GO:0005655', 'GO:0005967', 'GO:0009353', 'GO:0034466', 'GO:0097504', 'GO:0060205', 'GO:0033018', 'GO:0097013', 'GO:0033985', 'GO:0005715', 'GO:0098564', 'GO:0034422', 'GO:0035580', 'GO:0000228', 'GO:0009529', 'GO:0045244', 'GO:0010445', 'GO:0035578', 'GO:0031011'}\n",
      "{'GO:0031974', 'GO:0043226', 'GO:0005575', 'GO:0043233', 'GO:0110165', 'GO:0043229', 'GO:0005622'}\n"
     ]
    }
   ],
   "source": [
    "print(id_to_name['GO:0070013'] )\n",
    "print(networkx.ancestors(graph, 'GO:0070013'))\n",
    "print(networkx.descendants(graph, 'GO:0070013'))\n",
    "\n",
    "paths = networkx.all_simple_paths(\n",
    "    graph,\n",
    "    source='GO:0070013',\n",
    "    target=name_to_id['molecular_function']\n",
    ")\n",
    "\n",
    "for path in paths:\n",
    "    print('•', ' ⟶ '.join(id_to_name[node] for node in path))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c099fc2",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cae9a3b0",
   "metadata": {},
   "source": [
    "The task is a multilabel classification: The output has several possible targets (Gene Ontologies) but each can only be 1 (existing) or 0 (non existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48073ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "[[1 1 1 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "dftest=df.loc[\"A0A021WW32\"]\n",
    "indices = dftest[\"termToken\"].to_numpy()\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([termToken])\n",
    "print(indices)\n",
    "print(mlb.transform([indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99f6a6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "[[0 0 0 ... 0 0 0]]\n",
      "2957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manuel/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) [0, 1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 3, 4, 5, 6, 7, 8, 9] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "topGOs= item_counts\n",
    "topGOs=topGOs.index.to_list()\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([topGOs])\n",
    "print(indices)\n",
    "print(mlb.transform([indices]))\n",
    "print(len(mlb.classes_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92019f8c",
   "metadata": {},
   "source": [
    "## Amino acids encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b747477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aminos_list = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e42462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_dict = {'A': 1, 'B':24, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'O': 21, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'U': 22, 'V': 18, 'W': 19, 'Y': 20, 'X':30, 'Z':23}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfd823ba",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "431f9df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max. length of the sequences is 35375\n"
     ]
    }
   ],
   "source": [
    "seqLengths = [len(seq) for seq in sequences]\n",
    "maxLen = max(seqLengths)\n",
    "print(\"The max. length of the sequences is {}\".format(maxLen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e581e06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A0A021WW32' 'A0A021WZA4' 'A0A023GPJ3' ... 'X6RLP6' 'X6RLR1' 'X6RM59']\n",
      "92912\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dfAll=pd.read_csv(os.path.join(DATA_PATH, \"Train/train_terms.tsv\"), sep='\\t')\n",
    "# dfAll.set_index(\"EntryID\", inplace=True)\n",
    "ccoEntries = dfAll.loc[dfAll[\"aspect\"]==\"CCO\"]\n",
    "ccoEntryIds = ccoEntries[\"EntryID\"].unique()\n",
    "\n",
    "# print(len(seqEntries))\n",
    "print(ccoEntryIds)\n",
    "\n",
    "ccoSequences = []\n",
    "for entry in ccoEntryIds:\n",
    "    ccoSequences.append(sequences[ids.index(entry)])\n",
    "\n",
    "print(len(ccoSequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a692b0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryID</th>\n",
       "      <th>term</th>\n",
       "      <th>aspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4061166</th>\n",
       "      <td>P9WMJ9</td>\n",
       "      <td>GO:0009274</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4061167</th>\n",
       "      <td>P9WMJ9</td>\n",
       "      <td>GO:0005829</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4061168</th>\n",
       "      <td>P9WMJ9</td>\n",
       "      <td>GO:0110165</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4061169</th>\n",
       "      <td>P9WMJ9</td>\n",
       "      <td>GO:1903561</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4061170</th>\n",
       "      <td>P9WMJ9</td>\n",
       "      <td>GO:0031982</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4061171</th>\n",
       "      <td>P9WMJ9</td>\n",
       "      <td>GO:0030112</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4061172</th>\n",
       "      <td>P9WMJ9</td>\n",
       "      <td>GO:0071944</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4061173</th>\n",
       "      <td>P9WMJ9</td>\n",
       "      <td>GO:0005737</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4061174</th>\n",
       "      <td>P9WMJ9</td>\n",
       "      <td>GO:0043227</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4061175</th>\n",
       "      <td>P9WMJ9</td>\n",
       "      <td>GO:0005618</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4061176</th>\n",
       "      <td>P9WMJ9</td>\n",
       "      <td>GO:0042603</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4061177</th>\n",
       "      <td>P9WMJ9</td>\n",
       "      <td>GO:0005886</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4061178</th>\n",
       "      <td>P9WMJ9</td>\n",
       "      <td>GO:0030312</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4061179</th>\n",
       "      <td>P9WMJ9</td>\n",
       "      <td>GO:0005576</td>\n",
       "      <td>CCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019167</th>\n",
       "      <td>P9WMJ9</td>\n",
       "      <td>GO:0035375</td>\n",
       "      <td>MFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019168</th>\n",
       "      <td>P9WMJ9</td>\n",
       "      <td>GO:0005488</td>\n",
       "      <td>MFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019169</th>\n",
       "      <td>P9WMJ9</td>\n",
       "      <td>GO:0019899</td>\n",
       "      <td>MFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019170</th>\n",
       "      <td>P9WMJ9</td>\n",
       "      <td>GO:0001968</td>\n",
       "      <td>MFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019171</th>\n",
       "      <td>P9WMJ9</td>\n",
       "      <td>GO:0003674</td>\n",
       "      <td>MFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019172</th>\n",
       "      <td>P9WMJ9</td>\n",
       "      <td>GO:0005515</td>\n",
       "      <td>MFO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EntryID        term aspect\n",
       "4061166  P9WMJ9  GO:0009274    CCO\n",
       "4061167  P9WMJ9  GO:0005829    CCO\n",
       "4061168  P9WMJ9  GO:0110165    CCO\n",
       "4061169  P9WMJ9  GO:1903561    CCO\n",
       "4061170  P9WMJ9  GO:0031982    CCO\n",
       "4061171  P9WMJ9  GO:0030112    CCO\n",
       "4061172  P9WMJ9  GO:0071944    CCO\n",
       "4061173  P9WMJ9  GO:0005737    CCO\n",
       "4061174  P9WMJ9  GO:0043227    CCO\n",
       "4061175  P9WMJ9  GO:0005618    CCO\n",
       "4061176  P9WMJ9  GO:0042603    CCO\n",
       "4061177  P9WMJ9  GO:0005886    CCO\n",
       "4061178  P9WMJ9  GO:0030312    CCO\n",
       "4061179  P9WMJ9  GO:0005576    CCO\n",
       "5019167  P9WMJ9  GO:0035375    MFO\n",
       "5019168  P9WMJ9  GO:0005488    MFO\n",
       "5019169  P9WMJ9  GO:0019899    MFO\n",
       "5019170  P9WMJ9  GO:0001968    MFO\n",
       "5019171  P9WMJ9  GO:0003674    MFO\n",
       "5019172  P9WMJ9  GO:0005515    MFO"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAll.loc[dfAll[\"EntryID\"]==\"P9WMJ9\"].tail(20)\n",
    "# \"P9WMJ9\" in ccoEntryIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "44f722e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "TRAIN_VAL_SPLIT = 0.7\n",
    "\n",
    "#Use numpy vectorize to speed up the mapping (hopefully)\n",
    "mapping = lambda x: aa_dict[x]\n",
    "vectMapping = np.vectorize(mapping)\n",
    "\n",
    "# Shuffle the data\n",
    "import random\n",
    "random.seed(516213)\n",
    "c = list(zip(ccoSequences, ccoEntryIds))\n",
    "random.shuffle(c)\n",
    "sequencesShuffle, idsShuffle = zip(*c)\n",
    "\n",
    "#reduce data for now\n",
    "sequencesShuffle = sequencesShuffle[0:10000]\n",
    "idsShuffle = idsShuffle[0:10000]\n",
    "\n",
    "#Train Validation Split\n",
    "split = int(np.floor(len(sequencesShuffle)*TRAIN_VAL_SPLIT))\n",
    "print(split)\n",
    "trainSeq = sequencesShuffle[0:split]\n",
    "valSeq = sequencesShuffle[split+1:]\n",
    "trainIds = idsShuffle[0:split]\n",
    "valIds = idsShuffle[split+1:]\n",
    "\n",
    "\n",
    "def generator(padding=True):\n",
    "    for i,seq in enumerate(trainSeq):\n",
    "        entryId = trainIds[i]\n",
    "        labelData = df.loc[entryId]\n",
    "        \n",
    "        # indices = labelData[\"termToken\"].to_numpy()\n",
    "        indices = labelData[\"term\"].to_numpy()\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            #supress the warnings for unknown classes\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            y = mlb.transform([indices])\n",
    "        \n",
    "        arr = np.array(seq)\n",
    "        mappedArr = vectMapping(arr)\n",
    "        if padding:\n",
    "            padWidth = maxLen - arr.size\n",
    "            mappedArr = np.pad(mappedArr, (0, padWidth))\n",
    "        yield mappedArr,y[0]\n",
    "\n",
    "def generatorVal(padding=True):\n",
    "    for i,seq in enumerate(valSeq):\n",
    "        entryId = valIds[i]\n",
    "        labelData = df.loc[entryId]\n",
    "        \n",
    "        # indices = labelData[\"termToken\"].to_numpy()\n",
    "        indices = labelData[\"term\"].to_numpy()\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            #supress the warnings for unknown classes\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            y = mlb.transform([indices])\n",
    "        \n",
    "        arr = np.array(seq)\n",
    "        mappedArr = vectMapping(arr)\n",
    "        if padding:\n",
    "            padWidth = maxLen - arr.size\n",
    "            mappedArr = np.pad(mappedArr, (0, padWidth))\n",
    "        yield mappedArr,y[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bd15e8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first sample sequence: [11  1 15 ...  0  0  0]\n",
      "The first sample has 21 classes\n"
     ]
    }
   ],
   "source": [
    "g = generator()\n",
    "test = next(g)\n",
    "print(\"The first sample sequence: {}\".format(test[0]))\n",
    "print(\"The first sample has {} classes\".format(np.count_nonzero(test[1])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c2d5f18",
   "metadata": {},
   "source": [
    "## Test data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "26769fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "for i,el in enumerate(g):\n",
    "    X.append(el[0])\n",
    "    y.append(el[1])\n",
    "    if i ==10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5eabba57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 35375)\n",
      "(11, 2957)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X= np.array(X)\n",
    "y= np.array(y)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10c4a51a",
   "metadata": {},
   "source": [
    "## Tensorflow Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "63f0d2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(<tf.Tensor: shape=(35375,), dtype=int32, numpy=array([11,  1, 15, ...,  0,  0,  0], dtype=int32)>, <tf.Tensor: shape=(2957,), dtype=int32, numpy=array([0, 0, 0, ..., 0, 0, 0], dtype=int32)>)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 16:47:22.012762: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(generator, output_signature=(\n",
    "         tf.TensorSpec(shape=(maxLen,), dtype=tf.int32),\n",
    "         tf.TensorSpec(shape=(len(mlb.classes_),), dtype=tf.int32)))\n",
    "print(list(dataset.take(1)))\n",
    "\n",
    "datasetVal = tf.data.Dataset.from_generator(generatorVal, output_signature=(\n",
    "         tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "         tf.TensorSpec(shape=(len(mlb.classes_),), dtype=tf.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f0a554f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "98752d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embedConvModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 35375)]           0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 35375, 100)        2500      \n",
      "                                                                 \n",
      " global_average_pooling1d_2   (None, 100)              0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 100, 1)            0         \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 94, 8)             64        \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 88, 8)             456       \n",
      "                                                                 \n",
      " conv1d_16 (Conv1D)          (None, 82, 8)             456       \n",
      "                                                                 \n",
      " conv1d_17 (Conv1D)          (None, 76, 16)            912       \n",
      "                                                                 \n",
      " conv1d_18 (Conv1D)          (None, 70, 16)            1808      \n",
      "                                                                 \n",
      " conv1d_19 (Conv1D)          (None, 32, 16)            1808      \n",
      "                                                                 \n",
      " conv1d_20 (Conv1D)          (None, 13, 16)            1808      \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 208)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                6688      \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 32)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 32)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2957)              97581     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 115,137\n",
      "Trainable params: 115,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "VOCAB_SIZE=len(aa_dict)\n",
    "EMBED_DIM=100\n",
    "\n",
    "def createModel():\n",
    "    inputs = tf.keras.Input(shape=(maxLen,))\n",
    "    x=layers.Embedding(VOCAB_SIZE, EMBED_DIM, mask_zero=True, name=\"embedding\")(inputs)\n",
    "    x=layers.GlobalAveragePooling1D()(x)\n",
    "    x=layers.Reshape((EMBED_DIM,1))(x)\n",
    "    x=layers.Conv1D(8, 7)(x)\n",
    "    x=layers.Conv1D(8, 7)(x)\n",
    "    x=layers.Conv1D(8, 7)(x)\n",
    "    x=layers.Conv1D(16, 7)(x)\n",
    "    x=layers.Conv1D(16, 7)(x)\n",
    "    x=layers.Conv1D(16, 7, strides=2)(x)\n",
    "    x=layers.Conv1D(16, 7, strides=2)(x)\n",
    "    # x=layers.Conv1D(32, 5, activation=tf.keras.activations.relu)(x)\n",
    "    # x=layers.Conv1D(32, 5, activation=tf.keras.activations.relu)(x)\n",
    "    # x=layers.Conv1D(32, 5, activation=tf.keras.activations.relu)(x)\n",
    "    x=layers.Flatten()(x)\n",
    "    x=layers.Dense(32)(x)\n",
    "    x=layers.LeakyReLU()(x)\n",
    "    x=layers.Dense(32)(x)\n",
    "    x=layers.LeakyReLU()(x)\n",
    "    outputs=layers.Dense(len(mlb.classes_), activation=tf.keras.activations.sigmoid)(x)\n",
    "    # outputs=layers.Softmax()(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name=\"embedConvModel\")\n",
    "\n",
    "model = createModel()\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "73140569",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "VOCAB_SIZE=len(aa_dict)\n",
    "EMBED_DIM=200\n",
    "\n",
    "def createRnnModel():\n",
    "    inputs = tf.keras.Input(shape=(maxLen,))\n",
    "    x = tf.keras.layers.Masking(0)(inputs)\n",
    "    x=layers.Embedding(VOCAB_SIZE, EMBED_DIM, name=\"embedding\")(x)\n",
    "\n",
    "    # x = layers.Bidirectional(layers.LSTM(32, return_sequences=True))(x)\n",
    "    # x = layers.Bidirectional(layers.GRU(16, return_sequences=True))(x)\n",
    "    x = layers.Bidirectional(layers.GRU(16))(x)\n",
    "    # x = layers.LSTM(32)(x)\n",
    "    x = layers.Dense(16)(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    outputs=layers.Dense(len(mlb.classes_), activation=tf.keras.activations.sigmoid)(x)\n",
    "    # outputs=layers.Softmax()(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name=\"embedRnnModel\")\n",
    "\n",
    "# model = createRnnModel()\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5a3ddc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25289/2623022177.py:14: UserWarning: Attempt to set non-positive ylim on a log-scaled axis will be ignored.\n",
      "  plt.ylim([0,max(plt.ylim())])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Learning rate schedule\n",
    "initial_learning_rate = 0.01\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10,\n",
    "    decay_rate=0.9,\n",
    "    staircase=False)\n",
    "step = np.linspace(0,1000)\n",
    "lr = lr_schedule(step)\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(step, lr)\n",
    "plt.ylim([0,max(plt.ylim())])\n",
    "plt.xlabel('step')\n",
    "_ = plt.ylabel('Learning Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9113c4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "\n",
      "Start of epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 16:48:23.401363: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/Step 0, Loss: 0.6931, Accuracy: 0.5045, lr schedule: 0.01000\n",
      "Epoch 1/Step 5, Loss: 0.0526, Accuracy: 0.8777, lr schedule: 0.01000\n",
      "Epoch 1/Step 10, Loss: 0.0344, Accuracy: 0.9307, lr schedule: 0.01000\n",
      "Epoch 1/Step 15, Loss: 0.0162, Accuracy: 0.9508, lr schedule: 0.01000\n",
      "Epoch 1/Step 20, Loss: 0.0258, Accuracy: 0.9616, lr schedule: 0.01000\n",
      "Epoch 1/Step 25, Loss: 0.0155, Accuracy: 0.9684, lr schedule: 0.01000\n",
      "Epoch 1/Step 30, Loss: 0.0133, Accuracy: 0.9729, lr schedule: 0.01000\n",
      "Epoch 1/Step 35, Loss: 0.0138, Accuracy: 0.9762, lr schedule: 0.01000\n",
      "Epoch 1/Step 40, Loss: 0.0186, Accuracy: 0.9786, lr schedule: 0.01000\n",
      "Epoch 1/Step 45, Loss: 0.0165, Accuracy: 0.9806, lr schedule: 0.01000\n",
      "Epoch 1/Step 50, Loss: 0.0088, Accuracy: 0.9822, lr schedule: 0.01000\n",
      "Epoch 1/Step 55, Loss: 0.0124, Accuracy: 0.9835, lr schedule: 0.01000\n",
      "Epoch 1/Step 60, Loss: 0.0114, Accuracy: 0.9845, lr schedule: 0.01000\n",
      "Epoch 1/Step 65, Loss: 0.0113, Accuracy: 0.9855, lr schedule: 0.01000\n",
      "Epoch 1/Step 70, Loss: 0.0114, Accuracy: 0.9863, lr schedule: 0.01000\n",
      "Epoch 1/Step 75, Loss: 0.0139, Accuracy: 0.9870, lr schedule: 0.01000\n",
      "Epoch 1/Step 80, Loss: 0.0130, Accuracy: 0.9876, lr schedule: 0.01000\n",
      "Epoch 1/Step 85, Loss: 0.0131, Accuracy: 0.9881, lr schedule: 0.01000\n",
      "Epoch 1/Step 90, Loss: 0.0133, Accuracy: 0.9886, lr schedule: 0.01000\n",
      "Epoch 1/Step 95, Loss: 0.0113, Accuracy: 0.9890, lr schedule: 0.01000\n",
      "Epoch 1/Step 100, Loss: 0.0113, Accuracy: 0.9894, lr schedule: 0.01000\n",
      "Epoch 1/Step 105, Loss: 0.0123, Accuracy: 0.9898, lr schedule: 0.01000\n",
      "Epoch 1/Step 110, Loss: 0.0116, Accuracy: 0.9901, lr schedule: 0.01000\n",
      "Epoch 1/Step 115, Loss: 0.0141, Accuracy: 0.9904, lr schedule: 0.01000\n",
      "Epoch 1/Step 120, Loss: 0.0117, Accuracy: 0.9906, lr schedule: 0.01000\n",
      "Epoch 1/Step 125, Loss: 0.0118, Accuracy: 0.9909, lr schedule: 0.01000\n",
      "Epoch 1/Step 130, Loss: 0.0113, Accuracy: 0.9911, lr schedule: 0.01000\n",
      "Epoch 1/Step 135, Loss: 0.0104, Accuracy: 0.9913, lr schedule: 0.01000\n",
      "Epoch 1/Step 140, Loss: 0.0152, Accuracy: 0.9915, lr schedule: 0.01000\n",
      "Epoch 1/Step 145, Loss: 0.0117, Accuracy: 0.9917, lr schedule: 0.01000\n",
      "Epoch 1/Step 150, Loss: 0.0113, Accuracy: 0.9919, lr schedule: 0.01000\n",
      "Epoch 1/Step 155, Loss: 0.0147, Accuracy: 0.9920, lr schedule: 0.01000\n",
      "Epoch 1/Step 160, Loss: 0.0103, Accuracy: 0.9922, lr schedule: 0.01000\n",
      "Epoch 1/Step 165, Loss: 0.0130, Accuracy: 0.9923, lr schedule: 0.01000\n",
      "Epoch 1/Step 170, Loss: 0.0122, Accuracy: 0.9925, lr schedule: 0.01000\n",
      "Epoch 1/Step 175, Loss: 0.0159, Accuracy: 0.9926, lr schedule: 0.01000\n",
      "Epoch 1/Step 180, Loss: 0.0099, Accuracy: 0.9927, lr schedule: 0.01000\n",
      "Epoch 1/Step 185, Loss: 0.0141, Accuracy: 0.9928, lr schedule: 0.01000\n",
      "Epoch 1/Step 190, Loss: 0.0121, Accuracy: 0.9929, lr schedule: 0.01000\n",
      "Epoch 1/Step 195, Loss: 0.0150, Accuracy: 0.9930, lr schedule: 0.01000\n",
      "Epoch 1/Step 200, Loss: 0.0118, Accuracy: 0.9931, lr schedule: 0.01000\n",
      "Epoch 1/Step 205, Loss: 0.0122, Accuracy: 0.9932, lr schedule: 0.01000\n",
      "Epoch 1/Step 210, Loss: 0.0083, Accuracy: 0.9933, lr schedule: 0.01000\n",
      "Epoch 1/Step 215, Loss: 0.0117, Accuracy: 0.9933, lr schedule: 0.01000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 16:48:44.722216: W tensorflow/core/kernels/data/cache_dataset_ops.cc:296] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-16 16:48:44.727691: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch finished. Start validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 16:48:48.452212: W tensorflow/core/kernels/data/cache_dataset_ops.cc:296] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.9968\n",
      "\n",
      "Start of epoch 2\n",
      "Epoch 2/Step 0, Loss: 0.0151, Accuracy: 0.9962, lr schedule: 0.01000\n",
      "Epoch 2/Step 5, Loss: 0.0099, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 2/Step 10, Loss: 0.0157, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 2/Step 15, Loss: 0.0084, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 20, Loss: 0.0119, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 25, Loss: 0.0119, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 30, Loss: 0.0120, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 35, Loss: 0.0124, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 40, Loss: 0.0177, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 2/Step 45, Loss: 0.0155, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 2/Step 50, Loss: 0.0087, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 2/Step 55, Loss: 0.0122, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 2/Step 60, Loss: 0.0113, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 2/Step 65, Loss: 0.0112, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 2/Step 70, Loss: 0.0114, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 2/Step 75, Loss: 0.0138, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 2/Step 80, Loss: 0.0129, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 2/Step 85, Loss: 0.0131, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 2/Step 90, Loss: 0.0134, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 95, Loss: 0.0113, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 100, Loss: 0.0113, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 105, Loss: 0.0122, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 110, Loss: 0.0116, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 115, Loss: 0.0141, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 120, Loss: 0.0117, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 125, Loss: 0.0118, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 130, Loss: 0.0113, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 135, Loss: 0.0104, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 140, Loss: 0.0150, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 145, Loss: 0.0118, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 150, Loss: 0.0114, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 155, Loss: 0.0146, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 160, Loss: 0.0099, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 165, Loss: 0.0127, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 170, Loss: 0.0124, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 175, Loss: 0.0158, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 180, Loss: 0.0096, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 185, Loss: 0.0140, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 190, Loss: 0.0120, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 195, Loss: 0.0151, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 200, Loss: 0.0118, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 205, Loss: 0.0124, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 210, Loss: 0.0085, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 2/Step 215, Loss: 0.0116, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9968\n",
      "\n",
      "Start of epoch 3\n",
      "Epoch 3/Step 0, Loss: 0.0152, Accuracy: 0.9962, lr schedule: 0.01000\n",
      "Epoch 3/Step 5, Loss: 0.0100, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 3/Step 10, Loss: 0.0157, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 3/Step 15, Loss: 0.0084, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 20, Loss: 0.0119, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 25, Loss: 0.0119, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 30, Loss: 0.0120, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 35, Loss: 0.0123, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 40, Loss: 0.0176, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 3/Step 45, Loss: 0.0155, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 3/Step 50, Loss: 0.0087, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 3/Step 55, Loss: 0.0122, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 3/Step 60, Loss: 0.0113, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 3/Step 65, Loss: 0.0112, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 3/Step 70, Loss: 0.0114, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 3/Step 75, Loss: 0.0138, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 3/Step 80, Loss: 0.0129, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 3/Step 85, Loss: 0.0130, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 3/Step 90, Loss: 0.0134, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 95, Loss: 0.0113, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 100, Loss: 0.0113, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 105, Loss: 0.0122, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 110, Loss: 0.0115, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 115, Loss: 0.0141, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 120, Loss: 0.0117, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 125, Loss: 0.0118, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 130, Loss: 0.0113, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 135, Loss: 0.0104, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 140, Loss: 0.0150, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 145, Loss: 0.0117, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 150, Loss: 0.0113, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 155, Loss: 0.0146, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 160, Loss: 0.0102, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 165, Loss: 0.0130, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 170, Loss: 0.0121, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 175, Loss: 0.0158, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 180, Loss: 0.0099, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 185, Loss: 0.0140, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 190, Loss: 0.0121, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 195, Loss: 0.0150, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 200, Loss: 0.0117, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 205, Loss: 0.0122, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 210, Loss: 0.0083, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 3/Step 215, Loss: 0.0115, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9968\n",
      "\n",
      "Start of epoch 4\n",
      "Epoch 4/Step 0, Loss: 0.0150, Accuracy: 0.9962, lr schedule: 0.01000\n",
      "Epoch 4/Step 5, Loss: 0.0099, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 4/Step 10, Loss: 0.0156, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 4/Step 15, Loss: 0.0083, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 20, Loss: 0.0118, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 25, Loss: 0.0119, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 30, Loss: 0.0119, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 35, Loss: 0.0123, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 40, Loss: 0.0175, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 4/Step 45, Loss: 0.0155, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 4/Step 50, Loss: 0.0087, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 4/Step 55, Loss: 0.0122, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 4/Step 60, Loss: 0.0112, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 4/Step 65, Loss: 0.0111, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 4/Step 70, Loss: 0.0113, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 75, Loss: 0.0137, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 4/Step 80, Loss: 0.0129, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 85, Loss: 0.0130, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 4/Step 90, Loss: 0.0134, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 95, Loss: 0.0113, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 100, Loss: 0.0113, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 105, Loss: 0.0121, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 110, Loss: 0.0115, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 115, Loss: 0.0140, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 120, Loss: 0.0116, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 125, Loss: 0.0117, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 130, Loss: 0.0113, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 135, Loss: 0.0103, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 140, Loss: 0.0149, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 145, Loss: 0.0117, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 150, Loss: 0.0113, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 155, Loss: 0.0145, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 160, Loss: 0.0101, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 165, Loss: 0.0130, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 170, Loss: 0.0120, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 175, Loss: 0.0157, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 180, Loss: 0.0099, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 185, Loss: 0.0140, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 190, Loss: 0.0121, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 195, Loss: 0.0149, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 200, Loss: 0.0116, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 205, Loss: 0.0121, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 210, Loss: 0.0083, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 4/Step 215, Loss: 0.0114, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9968\n",
      "\n",
      "Start of epoch 5\n",
      "Epoch 5/Step 0, Loss: 0.0149, Accuracy: 0.9962, lr schedule: 0.01000\n",
      "Epoch 5/Step 5, Loss: 0.0099, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 5/Step 10, Loss: 0.0157, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 5/Step 15, Loss: 0.0085, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 20, Loss: 0.0119, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 25, Loss: 0.0119, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 30, Loss: 0.0119, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 35, Loss: 0.0123, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 40, Loss: 0.0174, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 5/Step 45, Loss: 0.0154, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 5/Step 50, Loss: 0.0087, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 5/Step 55, Loss: 0.0122, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 5/Step 60, Loss: 0.0112, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 5/Step 65, Loss: 0.0111, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 5/Step 70, Loss: 0.0114, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 75, Loss: 0.0137, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 5/Step 80, Loss: 0.0129, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 85, Loss: 0.0130, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 90, Loss: 0.0134, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 95, Loss: 0.0113, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 100, Loss: 0.0112, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 105, Loss: 0.0121, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 110, Loss: 0.0115, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 115, Loss: 0.0139, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 120, Loss: 0.0117, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 125, Loss: 0.0116, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 130, Loss: 0.0112, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 135, Loss: 0.0103, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 140, Loss: 0.0150, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 145, Loss: 0.0118, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 150, Loss: 0.0113, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 155, Loss: 0.0145, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 160, Loss: 0.0098, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 165, Loss: 0.0128, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 170, Loss: 0.0120, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 175, Loss: 0.0162, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 180, Loss: 0.0105, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 185, Loss: 0.0143, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 190, Loss: 0.0121, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 195, Loss: 0.0149, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 200, Loss: 0.0116, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 205, Loss: 0.0121, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 210, Loss: 0.0082, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 5/Step 215, Loss: 0.0114, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9968\n",
      "\n",
      "Start of epoch 6\n",
      "Epoch 6/Step 0, Loss: 0.0149, Accuracy: 0.9962, lr schedule: 0.01000\n",
      "Epoch 6/Step 5, Loss: 0.0099, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 6/Step 10, Loss: 0.0156, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 6/Step 15, Loss: 0.0083, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 20, Loss: 0.0118, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 25, Loss: 0.0118, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 30, Loss: 0.0119, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 35, Loss: 0.0123, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 40, Loss: 0.0175, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 6/Step 45, Loss: 0.0154, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 6/Step 50, Loss: 0.0086, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 6/Step 55, Loss: 0.0121, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 6/Step 60, Loss: 0.0112, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 6/Step 65, Loss: 0.0112, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 6/Step 70, Loss: 0.0114, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 75, Loss: 0.0137, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 6/Step 80, Loss: 0.0129, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 85, Loss: 0.0130, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 90, Loss: 0.0133, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 95, Loss: 0.0112, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 100, Loss: 0.0111, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 105, Loss: 0.0122, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 110, Loss: 0.0115, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 115, Loss: 0.0139, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 120, Loss: 0.0117, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 125, Loss: 0.0116, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 130, Loss: 0.0112, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 135, Loss: 0.0104, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 140, Loss: 0.0150, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 145, Loss: 0.0118, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 150, Loss: 0.0112, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 155, Loss: 0.0146, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 160, Loss: 0.0102, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 165, Loss: 0.0129, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 170, Loss: 0.0119, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 175, Loss: 0.0156, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 180, Loss: 0.0098, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 185, Loss: 0.0141, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 190, Loss: 0.0121, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 195, Loss: 0.0149, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 200, Loss: 0.0115, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 205, Loss: 0.0121, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 210, Loss: 0.0082, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 6/Step 215, Loss: 0.0113, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9968\n",
      "\n",
      "Start of epoch 7\n",
      "Epoch 7/Step 0, Loss: 0.0148, Accuracy: 0.9962, lr schedule: 0.01000\n",
      "Epoch 7/Step 5, Loss: 0.0099, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 7/Step 10, Loss: 0.0155, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 7/Step 15, Loss: 0.0082, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 20, Loss: 0.0117, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 25, Loss: 0.0117, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 30, Loss: 0.0119, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 35, Loss: 0.0123, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 40, Loss: 0.0175, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 7/Step 45, Loss: 0.0154, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 7/Step 50, Loss: 0.0086, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 7/Step 55, Loss: 0.0121, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 7/Step 60, Loss: 0.0111, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 7/Step 65, Loss: 0.0111, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 7/Step 70, Loss: 0.0114, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 75, Loss: 0.0137, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 7/Step 80, Loss: 0.0128, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 85, Loss: 0.0129, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 7/Step 90, Loss: 0.0134, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 95, Loss: 0.0112, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 100, Loss: 0.0111, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 105, Loss: 0.0121, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 110, Loss: 0.0114, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 115, Loss: 0.0139, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 120, Loss: 0.0116, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 125, Loss: 0.0116, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 130, Loss: 0.0112, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 135, Loss: 0.0103, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 140, Loss: 0.0149, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 145, Loss: 0.0118, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 150, Loss: 0.0111, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 155, Loss: 0.0145, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 160, Loss: 0.0100, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 165, Loss: 0.0127, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 170, Loss: 0.0119, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 175, Loss: 0.0159, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 180, Loss: 0.0102, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 185, Loss: 0.0143, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 190, Loss: 0.0122, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 195, Loss: 0.0150, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 200, Loss: 0.0115, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 205, Loss: 0.0120, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 210, Loss: 0.0081, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 7/Step 215, Loss: 0.0113, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch finished. Start validation\n",
      "Validation acc: 0.9968\n",
      "\n",
      "Start of epoch 8\n",
      "Epoch 8/Step 0, Loss: 0.0148, Accuracy: 0.9962, lr schedule: 0.01000\n",
      "Epoch 8/Step 5, Loss: 0.0099, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 8/Step 10, Loss: 0.0155, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 8/Step 15, Loss: 0.0082, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 8/Step 20, Loss: 0.0117, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 8/Step 25, Loss: 0.0118, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 8/Step 30, Loss: 0.0119, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 8/Step 35, Loss: 0.0123, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 8/Step 40, Loss: 0.0174, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 8/Step 45, Loss: 0.0153, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 8/Step 50, Loss: 0.0086, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 8/Step 55, Loss: 0.0121, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 8/Step 60, Loss: 0.0111, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 8/Step 65, Loss: 0.0111, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 8/Step 70, Loss: 0.0113, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 8/Step 75, Loss: 0.0136, Accuracy: 0.9967, lr schedule: 0.01000\n",
      "Epoch 8/Step 80, Loss: 0.0128, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 8/Step 85, Loss: 0.0129, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 8/Step 90, Loss: 0.0132, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 8/Step 95, Loss: 0.0112, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 8/Step 100, Loss: 0.0111, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 8/Step 105, Loss: 0.0122, Accuracy: 0.9968, lr schedule: 0.01000\n",
      "Epoch 8/Step 110, Loss: 0.0114, Accuracy: 0.9968, lr schedule: 0.01000\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=32\n",
    "LOG_INTERVAL=5\n",
    "epochs = 20\n",
    "saveModel=False\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "log_dir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,\n",
    "                                                      write_graph=True, update_freq=5)\n",
    "\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "# Instantiate an optimizer .\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "optimizer = tf.keras.optimizers.AdamW(learning_rate=0.01)\n",
    "\n",
    "# Instantiate a loss function.\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "train_acc_metric = tf.keras.metrics.BinaryAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.BinaryAccuracy()\n",
    "\n",
    "batchedDataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "batchedDatasetVal = datasetVal.batch(BATCH_SIZE, drop_remainder=False)\n",
    "# print(batchedDataset.take(1))\n",
    "\n",
    "batchedDataset = batchedDataset.cache(os.path.join(DATA_PATH, \"datasetCache\"))\n",
    "batchedDatasetVal = batchedDatasetVal.cache(os.path.join(DATA_PATH, \"datasetCacheVal\"))\n",
    "\n",
    "# @tf.function()\n",
    "def trainStep(x_batch_train, y_batch_train):\n",
    "    # Open a GradientTape to record the operations run\n",
    "    # during the forward pass, which enables auto-differentiation.\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # Run the forward pass of the layer.\n",
    "        # The operations that the layer applies\n",
    "        # to its inputs are going to be recorded\n",
    "        # on the GradientTape.\n",
    "        probs = model(x_batch_train, training=True) \n",
    "\n",
    "        # Compute the loss value for this minibatch.\n",
    "        loss_value = loss_fn(y_batch_train, probs)\n",
    "\n",
    "    # Use the gradient tape to automatically retrieve\n",
    "    # the gradients of the trainable variables with respect to the loss.\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    #Gradient clipping\n",
    "    # grads = [tf.clip_by_norm(g, 2.0) for g in grads]\n",
    "\n",
    "    # Run one step of gradient descent by updating\n",
    "    # the value of the variables to minimize the loss.\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "    train_acc_metric.update_state(y_batch_train, probs)\n",
    "    return loss_value, grads\n",
    "\n",
    "maxStep=0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch+1,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(batchedDataset):\n",
    "\n",
    "        loss_value, grads=trainStep(x_batch_train,y_batch_train)\n",
    "\n",
    "        # Log \n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            template = 'Epoch {}/Step {}, Loss: {:.4f}, Accuracy: {:.4f}, lr schedule: {:.5f}'\n",
    "            print (template.format(epoch+1, step,loss_value, \n",
    "                                    train_acc_metric.result(), optimizer.learning_rate.numpy()))\n",
    "            # print([tf.norm(grad, ord=2).numpy() for grad in grads])\n",
    "            with summary_writer.as_default():\n",
    "                tf.summary.scalar('loss', loss_value, step=maxStep*epoch+step)\n",
    "                tf.summary.scalar('accuracy', train_acc_metric.result(), step=maxStep*epoch+step)\n",
    "                summary_writer.flush()\n",
    "\n",
    "    \n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    maxStep=step\n",
    "\n",
    "    print(\"Epoch finished. Start validation\")\n",
    "    for x_batch_val, y_batch_val in batchedDatasetVal:\n",
    "        valProbs = model(x_batch_val, training=False)\n",
    "        # Update val metrics\n",
    "        val_acc_metric.update_state(y_batch_val, valProbs)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('valAcc', float(val_acc), step=epoch)\n",
    "        summary_writer.flush()\n",
    "    if saveModel:\n",
    "      model.save(os.path.join(DATA_PATH, \"model_epoch_{}_valAcc{:.3f}\".format(epoch, float(val_acc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f7234",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers: print(layer.get_config(), layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc1f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
